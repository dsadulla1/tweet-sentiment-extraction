{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do you need psuedo labels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You might need a token for space itself? start and stop tokens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification model with test as well in train? Will increase the vocab size as well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * https://www.tensorflow.org/tutorials/text/transformer\n",
    "# * https://pytorch.org/tutorials/beginner/transformer_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTROLS\n",
    "MODEL_PREFIX = \"V11\"\n",
    "MODEL_NUMBER = MODEL_PREFIX[-2:]\n",
    "TRAIN_SPLIT_RATIO = 0.8\n",
    "\n",
    "DROPOUT = 0.3\n",
    "MIN_LR = 1e-6\n",
    "MAX_LR = 1e-3\n",
    "BATCH_SIZE = 1024\n",
    "PREDICT_BATCH_SIZE = 2048\n",
    "STEP_SIZE = 10\n",
    "CLR_METHOD = \"triangular2\" # exp_range, triangular, triangular2\n",
    "NUM_EPOCHS = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler, LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import pickle, os, sys, re\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, LSTM, Embedding, Dense, concatenate, MaxPooling2D, Softmax, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout, Reshape, Activation, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.layers import RepeatVector, Multiply\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def signaltonoise(a, axis=0, ddof=0):\n",
    "    a = np.asanyarray(a)\n",
    "    m = a.mean(axis)\n",
    "    sd = a.std(axis=axis, ddof=ddof)\n",
    "    return np.where(sd == 0, 0, m/sd)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import *\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "class CyclicLR(Callback):\n",
    "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
    "    The method cycles the learning rate between two boundaries with\n",
    "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
    "    The amplitude of the cycle can be scaled on a per-iteration or \n",
    "    per-cycle basis.\n",
    "    This class has three built-in policies, as put forth in the paper.\n",
    "    \"triangular\":\n",
    "        A basic triangular cycle w/ no amplitude scaling.\n",
    "    \"triangular2\":\n",
    "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
    "    \"exp_range\":\n",
    "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n",
    "        cycle iteration.\n",
    "    For more detail, please see paper.\n",
    "    \n",
    "    # Example\n",
    "        ```python\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```\n",
    "    \n",
    "    Class also supports custom scaling functions:\n",
    "        ```python\n",
    "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., scale_fn=clr_fn,\n",
    "                                scale_mode='cycle')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```    \n",
    "    # Arguments\n",
    "        base_lr: initial learning rate which is the\n",
    "            lower boundary in the cycle.\n",
    "        max_lr: upper boundary in the cycle. Functionally,\n",
    "            it defines the cycle amplitude (max_lr - base_lr).\n",
    "            The lr at any cycle is the sum of base_lr\n",
    "            and some scaling of the amplitude; therefore \n",
    "            max_lr may not actually be reached depending on\n",
    "            scaling function.\n",
    "        step_size: number of training iterations per\n",
    "            half cycle. Authors suggest setting step_size\n",
    "            2-8 x training iterations in epoch.\n",
    "        mode: one of {triangular, triangular2, exp_range}.\n",
    "            Default 'triangular'.\n",
    "            Values correspond to policies detailed above.\n",
    "            If scale_fn is not None, this argument is ignored.\n",
    "        gamma: constant in 'exp_range' scaling function:\n",
    "            gamma**(cycle iterations)\n",
    "        scale_fn: Custom scaling policy defined by a single\n",
    "            argument lambda function, where \n",
    "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
    "            mode paramater is ignored \n",
    "        scale_mode: {'cycle', 'iterations'}.\n",
    "            Defines whether scale_fn is evaluated on \n",
    "            cycle number or cycle iterations (training\n",
    "            iterations since start of cycle). Default is 'cycle'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma**(x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        \"\"\"Resets cycle iterations.\n",
    "        Optional boundary/step size adjustment.\n",
    "        \"\"\"\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "        \n",
    "    def clr(self):\n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
    "            \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\deepak\\miniconda3\\envs\\dev\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "np.random.seed(54321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0  1\n",
      "textID         object  0\n",
      "text           object  1\n",
      "selected_text  object  1\n",
      "sentiment      object  0\n",
      "(27481, 4)\n",
      "{'textID': 27481, 'text': 27480, 'selected_text': 22463, 'sentiment': 3}\n",
      "            textID  \\\n",
      "count   27481        \n",
      "unique  27481        \n",
      "top     0257d899c7   \n",
      "freq    1            \n",
      "\n",
      "                                                                                                                             text  \\\n",
      "count   27480                                                                                                                       \n",
      "unique  27480                                                                                                                       \n",
      "top      - Yeah I know they are **** annoying with that... But it,s such good promo... I lost some contacts for business in there   \n",
      "freq    1                                                                                                                           \n",
      "\n",
      "       selected_text sentiment  \n",
      "count   27480         27481     \n",
      "unique  22463         3         \n",
      "top     good          neutral   \n",
      "freq    199           11118     \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                            text  \\\n",
       "0  cb774db0d1   I`d have responded, if I were going             \n",
       "1  549e992a42   Sooo SAD I will miss you here in San Diego!!!   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going  neutral   \n",
       "1  Sooo SAD                             negative  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\",\n",
    "                 dtype={\"time\":np.float64,\"signal\":np.float64,\"open_channels\":np.int16},\n",
    "                 encoding=\"utf8\")\n",
    "\n",
    "df2 = pd.read_csv(\"../data/train.csv\",\n",
    "                 dtype={\"time\":np.float64,\"signal\":np.float64,\"open_channels\":np.int16})\n",
    "\n",
    "print(pd.concat((df.dtypes, df.isna().sum()), axis=1))\n",
    "print(df.shape)\n",
    "\n",
    "# Counts of various columns\n",
    "print({i:df[i].nunique() for i in df.columns})\n",
    "print(df.describe()) #.astype(int)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0  1\n",
      "textID     object  0\n",
      "text       object  0\n",
      "sentiment  object  0\n",
      "(3534, 3)\n",
      "{'textID': 3534, 'text': 3534, 'sentiment': 3}\n",
      "            textID  \\\n",
      "count   3534         \n",
      "unique  3534         \n",
      "top     5921dbcbf3   \n",
      "freq    1            \n",
      "\n",
      "                                                                                                                                             text  \\\n",
      "count   3534                                                                                                                                        \n",
      "unique  3534                                                                                                                                        \n",
      "top     Hmm...Whilst, walking through the city I received an inviataion into an SUV Limo via some prom fellows... Don`t they have dates? Oh boys!   \n",
      "freq    1                                                                                                                                           \n",
      "\n",
      "       sentiment  \n",
      "count   3534      \n",
      "unique  3         \n",
      "top     neutral   \n",
      "freq    1430      \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID  \\\n",
       "0  f87dea47db   \n",
       "1  96d74cb729   \n",
       "\n",
       "                                                                                                      text  \\\n",
       "0  Last session of the day  http://twitpic.com/67ezh                                                         \n",
       "1   Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).   \n",
       "\n",
       "  sentiment  \n",
       "0  neutral   \n",
       "1  positive  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"../data/test.csv\", dtype={\"time\":np.float64,\"signal\":np.float64})\n",
    "print(pd.concat((test_df.dtypes, test_df.isna().sum()), axis=1))\n",
    "print(test_df.shape)\n",
    "\n",
    "# Counts of various columns\n",
    "print({i:test_df[i].nunique() for i in test_df.columns})\n",
    "print(test_df.describe())\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>c77717b103</td>\n",
       "      <td>I love to! But I`m only available from 5pm.  and where dear? Would love to help  convert her vids.ï¿½</td>\n",
       "      <td>I love to!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>28dbada620</td>\n",
       "      <td>*phew*  Will make a note in case anyone else runs into the same issueï¿½</td>\n",
       "      <td>*phew*  Will make a note in case anyone else runs into the same issueï¿½</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         textID  \\\n",
       "44   c77717b103   \n",
       "192  28dbada620   \n",
       "\n",
       "                                                                                                       text  \\\n",
       "44    I love to! But I`m only available from 5pm.  and where dear? Would love to help  convert her vids.ï¿½   \n",
       "192   *phew*  Will make a note in case anyone else runs into the same issueï¿½                                \n",
       "\n",
       "                                                                selected_text  \\\n",
       "44   I love to!                                                                 \n",
       "192  *phew*  Will make a note in case anyone else runs into the same issueï¿½   \n",
       "\n",
       "    sentiment  \n",
       "44   positive  \n",
       "192  neutral   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df2['text'].astype('str').apply(lambda x : len(re.findall(pattern=\"ï¿½\", string=x))>0)].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>7223fdccc2</td>\n",
       "      <td>tikcets are only ï¿½91...each...BUT I SO WANT TO GO</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>43ad351369</td>\n",
       "      <td>AHHH - Whatchu talkinï¿½ baby?  HAHAHA I canï¿½t believe youu:O heh, actually I can. Life is worth taking risks... http://tumblr.com/xs81qy54s</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         textID  \\\n",
       "145  7223fdccc2   \n",
       "618  43ad351369   \n",
       "\n",
       "                                                                                                                                               text  \\\n",
       "145  tikcets are only ï¿½91...each...BUT I SO WANT TO GO                                                                                              \n",
       "618  AHHH - Whatchu talkinï¿½ baby?  HAHAHA I canï¿½t believe youu:O heh, actually I can. Life is worth taking risks... http://tumblr.com/xs81qy54s   \n",
       "\n",
       "    sentiment  \n",
       "145  positive  \n",
       "618  positive  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df['text'].astype('str').apply(lambda x : len(re.findall(pattern=\"ï¿½\", string=x))>0)].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment count in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>7781</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>11117</td>\n",
       "      <td>1430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>8582</td>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text  text\n",
       "sentiment             \n",
       "negative   7781   1001\n",
       "neutral    11117  1430\n",
       "positive   8582   1103"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df.groupby(\"sentiment\")[[\"text\"]].count(), test_df.groupby(\"sentiment\")[[\"text\"]].count()], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For traceability\n",
    "df[\"original_index\"] = df.index\n",
    "test_df[\"original_index\"] = test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27481, 5)\n",
      "(27480, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df[(~df.text.isna())]\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.copy()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment_code\"] = df[\"sentiment\"].astype(\"category\")\n",
    "X_sentiments = df[\"sentiment_code\"].cat.codes.values\n",
    "\n",
    "test_df[\"sentiment_code\"] = test_df[\"sentiment\"].astype(\"category\")\n",
    "X_sentiments_test = test_df[\"sentiment_code\"].cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "df[\"selected_text\"] = df[\"selected_text\"].astype(str)\n",
    "test_df[\"text\"] = test_df[\"text\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(x, extra_string=None):\n",
    "    x = x.lower()\n",
    "    x = re.sub('([!\"#$%&()*+,-./:;\\'<=>?@[\\\\]^_{|}~\\t\\n])', ' \\\\1 ', x) # Not including ` here since used in couldn`t, isn`t\n",
    "    x = x.strip()\n",
    "    x = re.sub(' +', ' ', x)\n",
    "    x = x.split(\" \")\n",
    "    if extra_string is not None:\n",
    "        x = [\"xxxSTART\"] + x + [\"xxxSENTIMENT\"] + [extra_string] + [\"xxxEND\"]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extremities(l_string, s_string, extra_string, print_it=False):\n",
    "    l_string = preprocess_text(l_string, extra_string)\n",
    "    s_string = preprocess_text(s_string, extra_string=None)\n",
    "    \n",
    "    len_l = len(l_string)\n",
    "    len_s = len(s_string)\n",
    "    \n",
    "    for i in range(len_l - len_s + 1):\n",
    "        if (i + len_s) <= len_l:\n",
    "            substring = l_string[i:i+len_s]\n",
    "            if substring == s_string:\n",
    "                if print_it:\n",
    "                    print(l_string)\n",
    "                    print(substring)\n",
    "                    print(i, i+len_s, substring)\n",
    "                \n",
    "                start_vector, end_vector = np.zeros(len_l, dtype=np.int16), np.zeros(len_l, dtype=np.int16)\n",
    "                att_vector = np.ones(len_l, dtype=np.int16)\n",
    "                start_vector[i], end_vector[i+len_s-1] = 1, 1\n",
    "                \n",
    "                return (l_string, s_string, start_vector, end_vector, att_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['xxxSTART',\n",
       "  '4am',\n",
       "  '.',\n",
       "  'and',\n",
       "  'im',\n",
       "  'on',\n",
       "  'the',\n",
       "  'beach',\n",
       "  '.',\n",
       "  'pretty',\n",
       "  'xxxSENTIMENT',\n",
       "  'positive',\n",
       "  'xxxEND'],\n",
       " ['pretty'],\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], dtype=int16),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], dtype=int16),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int16))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 100\n",
    "get_extremities(df.text[idx], df.selected_text[idx], df.sentiment[idx], print_it=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"text_mod\", \"selected_text_mod\", \"target_start\", \"target_stop\", \"target_atten\"]] = df.apply(lambda x: get_extremities(x.text, x.selected_text, x.sentiment), axis=1).apply(pd.Series)\n",
    "test_df[[\"text_mod\"]] = test_df.apply(lambda x: [preprocess_text(x.text, extra_string = x.sentiment)], axis=1).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID               0   \n",
       "text                 0   \n",
       "selected_text        0   \n",
       "sentiment            0   \n",
       "original_index       0   \n",
       "sentiment_code       0   \n",
       "text_mod             1476\n",
       "selected_text_mod    1476\n",
       "target_start         1476\n",
       "target_stop          1476\n",
       "target_atten         1476\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID            0\n",
       "text              0\n",
       "sentiment         0\n",
       "original_index    0\n",
       "sentiment_code    0\n",
       "text_mod          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>original_index</th>\n",
       "      <th>sentiment_code</th>\n",
       "      <th>text_mod</th>\n",
       "      <th>selected_text_mod</th>\n",
       "      <th>target_start</th>\n",
       "      <th>target_stop</th>\n",
       "      <th>target_atten</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[xxxSTART, i`d, have, responded, ,, if, i, were, going, xxxSENTIMENT, neutral, xxxEND]</td>\n",
       "      <td>[i`d, have, responded, ,, if, i, were, going]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>[xxxSTART, sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !, xxxSENTIMENT, negative, xxxEND]</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                            text  \\\n",
       "0  cb774db0d1   I`d have responded, if I were going             \n",
       "1  549e992a42   Sooo SAD I will miss you here in San Diego!!!   \n",
       "\n",
       "                         selected_text sentiment  original_index  \\\n",
       "0  I`d have responded, if I were going  neutral   0                \n",
       "1  Sooo SAD                             negative  1                \n",
       "\n",
       "  sentiment_code  \\\n",
       "0  neutral         \n",
       "1  negative        \n",
       "\n",
       "                                                                                                   text_mod  \\\n",
       "0  [xxxSTART, i`d, have, responded, ,, if, i, were, going, xxxSENTIMENT, neutral, xxxEND]                     \n",
       "1  [xxxSTART, sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !, xxxSENTIMENT, negative, xxxEND]   \n",
       "\n",
       "                               selected_text_mod  \\\n",
       "0  [i`d, have, responded, ,, if, i, were, going]   \n",
       "1  [sooo, sad]                                     \n",
       "\n",
       "                                          target_start  \\\n",
       "0  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]                  \n",
       "1  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                           target_stop  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]                  \n",
       "1  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                          target_atten  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]                 \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>original_index</th>\n",
       "      <th>sentiment_code</th>\n",
       "      <th>text_mod</th>\n",
       "      <th>selected_text_mod</th>\n",
       "      <th>target_start</th>\n",
       "      <th>target_stop</th>\n",
       "      <th>target_atten</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>af3fed7fc3</td>\n",
       "      <td>is back home now      gonna miss every one</td>\n",
       "      <td>onna</td>\n",
       "      <td>negative</td>\n",
       "      <td>18</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1c31703aef</td>\n",
       "      <td>If it is any consolation I got my BMI tested hahaha it says I am obesed  well so much for being unhappy for about 10 minutes.</td>\n",
       "      <td>well so much for being unhappy for about 10 minute</td>\n",
       "      <td>negative</td>\n",
       "      <td>32</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        textID  \\\n",
       "18  af3fed7fc3   \n",
       "32  1c31703aef   \n",
       "\n",
       "                                                                                                                              text  \\\n",
       "18  is back home now      gonna miss every one                                                                                       \n",
       "32   If it is any consolation I got my BMI tested hahaha it says I am obesed  well so much for being unhappy for about 10 minutes.   \n",
       "\n",
       "                                         selected_text sentiment  \\\n",
       "18  onna                                                negative   \n",
       "32  well so much for being unhappy for about 10 minute  negative   \n",
       "\n",
       "    original_index sentiment_code text_mod selected_text_mod target_start  \\\n",
       "18  18              negative       NaN      NaN               NaN           \n",
       "32  32              negative       NaN      NaN               NaN           \n",
       "\n",
       "   target_stop target_atten  \n",
       "18  NaN         NaN          \n",
       "32  NaN         NaN          "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[df.loc[df['target_start'].isna()].index].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>original_index</th>\n",
       "      <th>sentiment_code</th>\n",
       "      <th>text_mod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[xxxSTART, last, session, of, the, day, http, :, /, /, twitpic, ., com, /, 67ezh, xxxSENTIMENT, neutral, xxxEND]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>[xxxSTART, shanghai, is, also, really, exciting, (, precisely, -, -, skyscrapers, galore, ), ., good, tweeps, in, china, :, (, sh, ), (, bj, ), ., xxxSENTIMENT, positive, xxxEND]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID  \\\n",
       "0  f87dea47db   \n",
       "1  96d74cb729   \n",
       "\n",
       "                                                                                                      text  \\\n",
       "0  Last session of the day  http://twitpic.com/67ezh                                                         \n",
       "1   Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).   \n",
       "\n",
       "  sentiment  original_index sentiment_code  \\\n",
       "0  neutral   0               neutral         \n",
       "1  positive  1               positive        \n",
       "\n",
       "                                                                                                                                                                             text_mod  \n",
       "0  [xxxSTART, last, session, of, the, day, http, :, /, /, twitpic, ., com, /, 67ezh, xxxSENTIMENT, neutral, xxxEND]                                                                    \n",
       "1  [xxxSTART, shanghai, is, also, really, exciting, (, precisely, -, -, skyscrapers, galore, ), ., good, tweeps, in, china, :, (, sh, ), (, bj, ), ., xxxSENTIMENT, positive, xxxEND]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalous_idxs = df.loc[df['target_start'].isna()].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27480, 11)\n",
      "(26004, 11)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df[~df.index.isin(anomalous_idxs)]\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.copy()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " X_words: \t 26004 \n",
      " X_att: \t 26004 \n",
      " Y_words: \t 26004 \n",
      " Y_starts: \t 26004 \n",
      " Y_stops: \t 26004 \n",
      " X_words_test: \t 3534 \n",
      " X_att_test: \t 3534 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_words = df['text_mod'].apply(lambda x:list(x)).tolist()\n",
    "X_att = df['target_atten'].apply(lambda x:list(x)).tolist()\n",
    "\n",
    "X_words_test = test_df['text_mod'].apply(lambda x:list(x)).tolist()\n",
    "X_att_test = [[1 for j in i] for i in X_words_test]\n",
    "\n",
    "Y_words = df['selected_text_mod'].apply(lambda x:list(x)).tolist()\n",
    "Y_starts = df['target_start'].apply(lambda x:list(x)).tolist()\n",
    "Y_stops = df['target_stop'].apply(lambda x:list(x)).tolist()\n",
    "\n",
    "print(\"\\n\",\n",
    "    \"X_words:\",\"\\t\", len(X_words),\"\\n\",\n",
    "    \"X_att:\",\"\\t\", len(X_att),\"\\n\",\n",
    "    \"Y_words:\",\"\\t\", len(Y_words),\"\\n\",\n",
    "    \"Y_starts:\",\"\\t\", len(Y_starts),\"\\n\",\n",
    "    \"Y_stops:\",\"\\t\", len(Y_stops),\"\\n\",\n",
    "    \"X_words_test:\",\"\\t\", len(X_words_test),\"\\n\",\n",
    "    \"X_att_test:\",\"\\t\", len(X_att_test),\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3534\n",
      "26004\n"
     ]
    }
   ],
   "source": [
    "print(sum([len(i)==len(j) for i,j in zip(X_att_test, X_words_test)]))\n",
    "print(sum([len(i)==len(j) for i,j in zip(X_att, X_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 33619),\n",
       " ('xxxSTART', 26004),\n",
       " ('xxxSENTIMENT', 26004),\n",
       " ('xxxEND', 26004),\n",
       " ('!', 14379),\n",
       " ('i', 12615),\n",
       " ('neutral', 10941),\n",
       " ('to', 9447),\n",
       " ('the', 8445),\n",
       " (',', 7984)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "word_counts = Counter([j for i in X_words for j in i])\n",
    "\n",
    "X_unique_tokens = len(word_counts)\n",
    "word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_WORD_FREQ = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB reduced from 25847 to 10178\n"
     ]
    }
   ],
   "source": [
    "word_subset = [i for i,j in word_counts.items() if j >= MIN_WORD_FREQ]\n",
    "print(\"VOCAB reduced from\", len(word_counts), \"to\", len(word_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_of_words = set(sorted([j for i in X_words for j in i]))\n",
    "#Y_list_of_words = set(sorted([j for i in Y_words for j in i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_itos = {i+2:j for i,j in enumerate(word_subset)}\n",
    "vocab_stoi = {j:i+2 for i,j in enumerate(word_subset)}\n",
    "\n",
    "vocab_stoi[\"xxxUNK\"] = 1\n",
    "vocab_itos[1] = \"xxxUNK\"\n",
    "\n",
    "vocab_stoi[\"xxxNone\"] = 0\n",
    "vocab_itos[0] = \"xxxNone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_vocab(vocab, word):\n",
    "    try:\n",
    "        value = vocab[word]\n",
    "    except KeyError as k:\n",
    "        value = vocab_stoi[\"xxxUNK\"]\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[get_from_vocab(vocab_stoi,j) for j in i] for i in X_words]\n",
    "Y = [[get_from_vocab(vocab_stoi,j) for j in i] for i in Y_words]\n",
    "X_test = [[get_from_vocab(vocab_stoi,j) for j in i] for i in X_words_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10180 110\n"
     ]
    }
   ],
   "source": [
    "max_len = max([len(i) for i in X])\n",
    "VOCAB_SIZE = len(vocab_stoi)\n",
    "print(VOCAB_SIZE, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Validation  split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26004 20803 5201 26004\n"
     ]
    }
   ],
   "source": [
    "idx = [i for i in np.arange(len(Y))]\n",
    "np.random.shuffle(idx)\n",
    "train_idx, val_idx = idx[:round(TRAIN_SPLIT_RATIO*len(Y))], idx[round(TRAIN_SPLIT_RATIO * len(Y)):]\n",
    "\n",
    "print(len(idx), len(train_idx), len(val_idx), len(train_idx) + len(val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 20803 \t : X_train \n",
      " 20803 \t : X_att_train \n",
      " 20803 \t : Y_train \n",
      " 20803 \t : Y_starts_train \n",
      " 20803 \t : Y_stops_train \n",
      " 5201 \t : X_val \n",
      " 5201 \t : X_att_val \n",
      " 5201 \t : Y_val \n",
      " 5201 \t : Y_starts_val \n",
      " 5201 \t : Y_stops_val \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val = [X[i] for i in train_idx], [X[i] for i in val_idx]\n",
    "X_att_train, X_att_val = [X_att[i] for i in train_idx], [X_att[i] for i in val_idx]\n",
    "\n",
    "Y_train, Y_val = [Y[i] for i in train_idx], [Y[i] for i in val_idx]\n",
    "Y_starts_train, Y_starts_val = [Y_starts[i] for i in train_idx], [Y_starts[i] for i in val_idx]\n",
    "Y_stops_train, Y_stops_val = [Y_stops[i] for i in train_idx], [Y_stops[i] for i in val_idx]\n",
    "\n",
    "print(\"\\n\",\n",
    "    len(X_train),\"\\t\",\": X_train\",\"\\n\",\n",
    "    len(X_att_train),\"\\t\",\": X_att_train\",\"\\n\",\n",
    "    len(Y_train),\"\\t\",\": Y_train\",\"\\n\",\n",
    "    len(Y_starts_train),\"\\t\",\": Y_starts_train\",\"\\n\",\n",
    "    len(Y_stops_train),\"\\t\",\": Y_stops_train\",\"\\n\",\n",
    "    len(X_val),\"\\t\",\": X_val\",\"\\n\",\n",
    "    len(X_att_val),\"\\t\",\": X_att_val\",\"\\n\",\n",
    "    len(Y_val),\"\\t\",\": Y_val\",\"\\n\",\n",
    "    len(Y_starts_val),\"\\t\",\": Y_starts_val\",\"\\n\",\n",
    "    len(Y_stops_val),\"\\t\",\": Y_stops_val\",\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=max_len, padding=\"post\")\n",
    "X_att_train = pad_sequences(X_att_train, maxlen=max_len, padding=\"post\")\n",
    "Y_train = pad_sequences(Y_train, maxlen=max_len, padding=\"post\")\n",
    "Y_starts_train = pad_sequences(Y_starts_train, maxlen=max_len, padding=\"post\")\n",
    "Y_stops_train = pad_sequences(Y_stops_train, maxlen=max_len, padding=\"post\")\n",
    "\n",
    "X_val = pad_sequences(X_val, maxlen=max_len, padding=\"post\")\n",
    "X_att_val = pad_sequences(X_att_val, maxlen=max_len, padding=\"post\")\n",
    "Y_val = pad_sequences(Y_val, maxlen=max_len, padding=\"post\")\n",
    "Y_starts_val = pad_sequences(Y_starts_val, maxlen=max_len, padding=\"post\")\n",
    "Y_stops_val = pad_sequences(Y_stops_val, maxlen=max_len, padding=\"post\")\n",
    "\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding=\"post\")\n",
    "X_att_test = pad_sequences(X_att_test, maxlen=max_len, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " (20803, 110) \t: X_train  \n",
      " (20803, 110) \t: X_att_train  \n",
      " (20803, 110) \t: Y_train  \n",
      " (20803, 110) \t: Y_starts_train  \n",
      " (20803, 110) \t: Y_stops_train  \n",
      " (5201, 110) \t: X_val  \n",
      " (5201, 110) \t: X_att_val  \n",
      " (5201, 110) \t: Y_val  \n",
      " (5201, 110) \t: Y_starts_val  \n",
      " (5201, 110) \t: Y_stops_val  \n",
      " (3534, 110) \t: X_test  \n",
      " (3534, 110) \t: X_att_test  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\",\n",
    "     X_train.shape, \"\\t: X_train \", \"\\n\",\n",
    "     X_att_train.shape, \"\\t: X_att_train \", \"\\n\",\n",
    "     Y_train.shape, \"\\t: Y_train \", \"\\n\",\n",
    "     Y_starts_train.shape, \"\\t: Y_starts_train \", \"\\n\",\n",
    "     Y_stops_train.shape, \"\\t: Y_stops_train \", \"\\n\",\n",
    "\n",
    "     X_val.shape, \"\\t: X_val \", \"\\n\",\n",
    "     X_att_val.shape, \"\\t: X_att_val \", \"\\n\",\n",
    "     Y_val.shape, \"\\t: Y_val \", \"\\n\",\n",
    "     Y_starts_val.shape, \"\\t: Y_starts_val \", \"\\n\",\n",
    "     Y_stops_val.shape, \"\\t: Y_stops_val \", \"\\n\",\n",
    "\n",
    "     X_test.shape, \"\\t: X_test \", \"\\n\",\n",
    "     X_att_test.shape, \"\\t: X_att_test \", \"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for zero input vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 36\n",
      "0 36\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax([X_train.sum(axis=1)==0]), np.min([X_train.sum(axis=1)]))\n",
    "print(np.argmax([X_val.sum(axis=1)==0]), np.min([X_val.sum(axis=1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1, 1662, 0, 0],\n",
       " [87, 1, 648, 0, 0],\n",
       " [17, 1, 2533, 0, 0],\n",
       " [2174, 1, 7, 0, 0],\n",
       " [669, 1, 1685, 0, 0],\n",
       " [84, 1, 278, 0, 0],\n",
       " [1662, 1, 17, 1, 0],\n",
       " [648, 1, 229, 0, 0],\n",
       " [2533, 1, 4625, 0, 0],\n",
       " [7, 1, 116, 0, 0],\n",
       " [1685, 1, 44, 0, 0],\n",
       " [278, 1, 406, 0, 0],\n",
       " [17, 1, 8227, 0, 0],\n",
       " [229, 1, 0, 0, 0],\n",
       " [4625, 1, 0, 0, 0],\n",
       " [116, 1, 0, 0, 0],\n",
       " [44, 1, 0, 0, 0],\n",
       " [406, 1, 0, 0, 0],\n",
       " [8227, 1, 0, 0, 1],\n",
       " [7492, 1, 0, 0, 0],\n",
       " [10, 1, 0, 0, 0],\n",
       " [11, 1, 0, 0, 0],\n",
       " [12, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train\n",
    "num = 100\n",
    "[[i,j,k,l,m] for i,j,k,l,m in zip(X_train[num],\n",
    "                                  X_att_train[num],\n",
    "                                  Y_train[num],\n",
    "                                  Y_starts_train[num],\n",
    "                                  Y_stops_train[num])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1, 9890, 0, 0],\n",
       " [9890, 1, 8753, 1, 0],\n",
       " [8753, 1, 55, 0, 0],\n",
       " [55, 1, 4465, 0, 0],\n",
       " [4465, 1, 305, 0, 0],\n",
       " [305, 1, 1, 0, 0],\n",
       " [1, 1, 28, 0, 0],\n",
       " [28, 1, 0, 0, 1],\n",
       " [47, 1, 0, 0, 0],\n",
       " [48, 1, 0, 0, 0],\n",
       " [49, 1, 0, 0, 0],\n",
       " [49, 1, 0, 0, 0],\n",
       " [50, 1, 0, 0, 0],\n",
       " [28, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [28, 1, 0, 0, 0],\n",
       " [51, 1, 0, 0, 0],\n",
       " [49, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [49, 1, 0, 0, 0],\n",
       " [9890, 1, 0, 0, 0],\n",
       " [28, 1, 0, 0, 0],\n",
       " [7327, 1, 0, 0, 0],\n",
       " [10, 1, 0, 0, 0],\n",
       " [11, 1, 0, 0, 0],\n",
       " [12, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Val\n",
    "num = 100\n",
    "[[i,j,k,l,m] for i,j,k,l,m in zip(X_val[num],\n",
    "                                  X_att_val[num],\n",
    "                                  Y_val[num],\n",
    "                                  Y_starts_val[num],\n",
    "                                  Y_stops_val[num])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['xxxSTART', 2, 1],\n",
       " ['oooh', 3482, 1],\n",
       " [',', 5, 1],\n",
       " ['sunshine', 1726, 1],\n",
       " ['!', 22, 1],\n",
       " ['a', 142, 1],\n",
       " ['patch', 905, 1],\n",
       " ['of', 34, 1],\n",
       " ['sunshine', 1726, 1],\n",
       " ['!', 22, 1],\n",
       " ['and', 68, 1],\n",
       " ['it', 144, 1],\n",
       " ['will', 15, 1],\n",
       " ['be', 89, 1],\n",
       " ['gone', 544, 1],\n",
       " ['by', 106, 1],\n",
       " ['the', 42, 1],\n",
       " ['time', 504, 1],\n",
       " ['i', 7, 1],\n",
       " ['leave', 31, 1],\n",
       " ['work', 342, 1],\n",
       " ['and', 68, 1],\n",
       " ['replaced', 1, 1],\n",
       " ['with', 278, 1],\n",
       " ['rain', 1901, 1],\n",
       " ['.', 28, 1],\n",
       " ['/', 49, 1],\n",
       " ['vent', 9146, 1],\n",
       " ['xxxSENTIMENT', 10, 1],\n",
       " ['neutral', 11, 1],\n",
       " ['xxxEND', 12, 1]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "num = 100\n",
    "[[i,j,k] for i,j,k in zip(X_words_test[num],\n",
    "                          X_test[num],\n",
    "                          X_att_test[num])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_att_flags = Input((max_len), name=\"att_flags\")\n",
    "input_sequences = Input((max_len), name=\"words\")\n",
    "\n",
    "emb_sequences = Embedding(input_dim=VOCAB_SIZE, input_length=max_len, output_dim=64, mask_zero=True)(input_sequences)\n",
    "\n",
    "seq = Bidirectional(LSTM(16, activation=None, return_sequences=True))(emb_sequences)\n",
    "seq = BatchNormalization()(seq)\n",
    "seq = Activation(\"relu\")(seq)\n",
    "seq = Dropout(DROPOUT)(seq)\n",
    "\n",
    "seq = Bidirectional(LSTM(16, activation=None, return_sequences=False))(seq)\n",
    "seq = BatchNormalization()(seq)\n",
    "seq = Activation(\"relu\")(seq)\n",
    "seq = Dropout(DROPOUT)(seq)\n",
    "\n",
    "seq = Dense(max_len, activation=\"relu\")(seq)\n",
    "seq = BatchNormalization()(seq)\n",
    "seq = Dropout(DROPOUT)(seq)\n",
    "\n",
    "att = Dense(max_len, activation=\"relu\")(input_att_flags)\n",
    "att = BatchNormalization()(att)\n",
    "att = Dropout(DROPOUT)(att)\n",
    "\n",
    "convs = Conv1D(filters=32, kernel_size=8, padding=\"same\", activation=None)(emb_sequences)\n",
    "convs = BatchNormalization()(convs)\n",
    "convs = Activation(\"relu\")(convs)\n",
    "convs = Dropout(DROPOUT)(convs)\n",
    "\n",
    "convs = Conv1D(filters=32, kernel_size=8, padding=\"same\", activation=None)(convs)\n",
    "convs = BatchNormalization()(convs)\n",
    "convs = Activation(\"relu\")(convs)\n",
    "convs = Dropout(DROPOUT)(convs)\n",
    "\n",
    "convs = Flatten()(convs)\n",
    "convs = Dense(max_len, activation=None)(convs)\n",
    "convs = BatchNormalization()(convs)\n",
    "convs = Activation(\"relu\")(convs)\n",
    "convs = Dropout(DROPOUT)(convs)\n",
    "\n",
    "conv = Multiply()([att, convs])\n",
    "seq = Multiply()([att, seq])\n",
    "concat_layer = concatenate([conv, seq])\n",
    "\n",
    "output_starts = Dense(max_len, activation=None)(concat_layer)\n",
    "output_starts = BatchNormalization()(output_starts)\n",
    "output_starts = Activation(\"relu\")(output_starts)\n",
    "\n",
    "output_stops = Dense(max_len, activation=None)(concat_layer)\n",
    "output_stops = BatchNormalization()(output_stops)\n",
    "output_stops = Activation(\"relu\")(output_stops)\n",
    "\n",
    "output_starts = Dense(max_len, activation='softmax', name=\"starts\")(output_starts)\n",
    "output_stops = Dense(max_len, activation='softmax', name=\"stops\")(output_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words (InputLayer)              [(None, 110)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 110, 64)      651520      words[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 110, 32)      16416       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 110, 32)      128         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 110, 32)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 110, 32)      10368       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 110, 32)      0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 110, 32)      128         bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 110, 32)      8224        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 110, 32)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 110, 32)      128         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 110, 32)      0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 110, 32)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 32)           6272        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 110, 32)      0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32)           128         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3520)         0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32)           0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "att_flags (InputLayer)          [(None, 110)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 110)          387310      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 110)          12210       att_flags[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 110)          440         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 110)          3630        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 110)          440         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 110)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 110)          440         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 110)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 110)          0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 110)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 110)          0           dropout_3[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 110)          0           dropout_3[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 220)          0           multiply[0][0]                   \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 110)          24310       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 110)          24310       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 110)          440         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 110)          440         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 110)          0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 110)          0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "starts (Dense)                  (None, 110)          12210       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stops (Dense)                   (None, 110)          12210       activation_6[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,171,702\n",
      "Trainable params: 1,170,346\n",
      "Non-trainable params: 1,356\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([input_att_flags, input_sequences], [output_starts, output_stops])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=MIN_LR)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=adam , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks\n",
    "mcp = ModelCheckpoint(filepath=\"../results/\"+MODEL_PREFIX+\"BestCheckpoint.h5\",\n",
    "                      monitor='val_loss',\n",
    "                      mode=\"auto\",\n",
    "                      save_weights_only=False,\n",
    "                      save_best_only=True)\n",
    "\n",
    "clr = CyclicLR(mode=CLR_METHOD,\n",
    "               base_lr=MIN_LR,\n",
    "               max_lr=MAX_LR,\n",
    "               step_size= STEP_SIZE * (X_train.shape[0] // BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20803 samples, validate on 5201 samples\n",
      "Epoch 1/200\n",
      "20803/20803 [==============================] - 25s 1ms/sample - loss: 9.8364 - starts_loss: 4.9002 - stops_loss: 4.9330 - starts_accuracy: 0.0117 - stops_accuracy: 0.0170 - val_loss: 9.3949 - val_starts_loss: 4.6973 - val_stops_loss: 4.6976 - val_starts_accuracy: 1.9227e-04 - val_stops_accuracy: 0.0179\n",
      "Epoch 2/200\n",
      "20803/20803 [==============================] - 13s 626us/sample - loss: 9.5058 - starts_loss: 4.7483 - stops_loss: 4.7469 - starts_accuracy: 0.0215 - stops_accuracy: 0.0312 - val_loss: 9.3647 - val_starts_loss: 4.6818 - val_stops_loss: 4.6833 - val_starts_accuracy: 0.0171 - val_stops_accuracy: 0.0300\n",
      "Epoch 3/200\n",
      "20803/20803 [==============================] - 14s 671us/sample - loss: 8.8410 - starts_loss: 4.4273 - stops_loss: 4.3940 - starts_accuracy: 0.0855 - stops_accuracy: 0.0763 - val_loss: 9.3035 - val_starts_loss: 4.6593 - val_stops_loss: 4.6455 - val_starts_accuracy: 0.1604 - val_stops_accuracy: 0.0846\n",
      "Epoch 4/200\n",
      "20803/20803 [==============================] - 13s 636us/sample - loss: 7.8548 - starts_loss: 3.9955 - stops_loss: 3.8421 - starts_accuracy: 0.1809 - stops_accuracy: 0.1858 - val_loss: 9.1878 - val_starts_loss: 4.6303 - val_stops_loss: 4.5604 - val_starts_accuracy: 0.1742 - val_stops_accuracy: 0.1136\n",
      "Epoch 5/200\n",
      "20803/20803 [==============================] - 13s 620us/sample - loss: 6.6788 - starts_loss: 3.4775 - stops_loss: 3.1888 - starts_accuracy: 0.2835 - stops_accuracy: 0.3621 - val_loss: 8.9280 - val_starts_loss: 4.5087 - val_stops_loss: 4.4241 - val_starts_accuracy: 0.2025 - val_stops_accuracy: 0.2380\n",
      "Epoch 6/200\n",
      "20803/20803 [==============================] - 13s 625us/sample - loss: 5.5258 - starts_loss: 2.8877 - stops_loss: 2.6240 - starts_accuracy: 0.4267 - stops_accuracy: 0.4922 - val_loss: 8.5508 - val_starts_loss: 4.3047 - val_stops_loss: 4.2530 - val_starts_accuracy: 0.2746 - val_stops_accuracy: 0.3167\n",
      "Epoch 7/200\n",
      "20803/20803 [==============================] - 13s 620us/sample - loss: 4.6331 - starts_loss: 2.3553 - stops_loss: 2.2701 - starts_accuracy: 0.5531 - stops_accuracy: 0.5540 - val_loss: 8.0244 - val_starts_loss: 3.9927 - val_stops_loss: 4.0425 - val_starts_accuracy: 0.5776 - val_stops_accuracy: 0.3703\n",
      "Epoch 8/200\n",
      "20803/20803 [==============================] - 13s 626us/sample - loss: 4.0466 - starts_loss: 1.9867 - stops_loss: 2.0512 - starts_accuracy: 0.5827 - stops_accuracy: 0.5736 - val_loss: 7.4027 - val_starts_loss: 3.5996 - val_stops_loss: 3.8191 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.3740\n",
      "Epoch 9/200\n",
      "20803/20803 [==============================] - 13s 627us/sample - loss: 3.7011 - starts_loss: 1.7867 - stops_loss: 1.9051 - starts_accuracy: 0.5884 - stops_accuracy: 0.5820 - val_loss: 6.7644 - val_starts_loss: 3.1929 - val_stops_loss: 3.5931 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.3826\n",
      "Epoch 10/200\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 3.4692 - starts_loss: 1.6687 - stops_loss: 1.7974 - starts_accuracy: 0.5924 - stops_accuracy: 0.5840 - val_loss: 6.1719 - val_starts_loss: 2.8346 - val_stops_loss: 3.3650 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.3859\n",
      "Epoch 11/200\n",
      "20803/20803 [==============================] - 13s 622us/sample - loss: 3.3320 - starts_loss: 1.5996 - stops_loss: 1.7299 - starts_accuracy: 0.5948 - stops_accuracy: 0.5886 - val_loss: 5.6767 - val_starts_loss: 2.5451 - val_stops_loss: 3.1658 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.3870\n",
      "Epoch 12/200\n",
      "20803/20803 [==============================] - 13s 624us/sample - loss: 3.2274 - starts_loss: 1.5619 - stops_loss: 1.6709 - starts_accuracy: 0.5947 - stops_accuracy: 0.5903 - val_loss: 5.2959 - val_starts_loss: 2.3337 - val_stops_loss: 3.0015 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.3895\n",
      "Epoch 13/200\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 3.1440 - starts_loss: 1.5244 - stops_loss: 1.6257 - starts_accuracy: 0.5964 - stops_accuracy: 0.5978 - val_loss: 5.0286 - val_starts_loss: 2.2033 - val_stops_loss: 2.8688 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4036\n",
      "Epoch 14/200\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 3.0769 - starts_loss: 1.4873 - stops_loss: 1.5807 - starts_accuracy: 0.5978 - stops_accuracy: 0.6015 - val_loss: 4.8298 - val_starts_loss: 2.1066 - val_stops_loss: 2.7689 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4074\n",
      "Epoch 15/200\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 3.0096 - starts_loss: 1.4650 - stops_loss: 1.5417 - starts_accuracy: 0.5991 - stops_accuracy: 0.6077 - val_loss: 4.6562 - val_starts_loss: 2.0269 - val_stops_loss: 2.6759 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4065\n",
      "Epoch 16/200\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 2.9573 - starts_loss: 1.4376 - stops_loss: 1.5182 - starts_accuracy: 0.6008 - stops_accuracy: 0.6105 - val_loss: 4.5359 - val_starts_loss: 1.9833 - val_stops_loss: 2.6015 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4155\n",
      "Epoch 17/200\n",
      "20803/20803 [==============================] - 13s 618us/sample - loss: 2.9092 - starts_loss: 1.4246 - stops_loss: 1.4883 - starts_accuracy: 0.6029 - stops_accuracy: 0.6114 - val_loss: 4.4099 - val_starts_loss: 1.9439 - val_stops_loss: 2.5148 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4384\n",
      "Epoch 18/200\n",
      "20803/20803 [==============================] - 13s 626us/sample - loss: 2.8747 - starts_loss: 1.4038 - stops_loss: 1.4692 - starts_accuracy: 0.6036 - stops_accuracy: 0.6180 - val_loss: 4.2949 - val_starts_loss: 1.9185 - val_stops_loss: 2.4251 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4799\n",
      "Epoch 19/200\n",
      "20803/20803 [==============================] - 13s 623us/sample - loss: 2.8576 - starts_loss: 1.3938 - stops_loss: 1.4605 - starts_accuracy: 0.6037 - stops_accuracy: 0.6198 - val_loss: 4.1788 - val_starts_loss: 1.8972 - val_stops_loss: 2.3294 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.5036\n",
      "Epoch 20/200\n",
      "20803/20803 [==============================] - 13s 622us/sample - loss: 2.8446 - starts_loss: 1.3977 - stops_loss: 1.4564 - starts_accuracy: 0.6045 - stops_accuracy: 0.6171 - val_loss: 4.0630 - val_starts_loss: 1.8775 - val_stops_loss: 2.2322 - val_starts_accuracy: 0.5991 - val_stops_accuracy: 0.5236\n",
      "Epoch 21/200\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 2.8273 - starts_loss: 1.3842 - stops_loss: 1.4387 - starts_accuracy: 0.6076 - stops_accuracy: 0.6203 - val_loss: 3.9533 - val_starts_loss: 1.8583 - val_stops_loss: 2.1406 - val_starts_accuracy: 0.5980 - val_stops_accuracy: 0.5349\n",
      "Epoch 22/200\n",
      "20803/20803 [==============================] - 13s 624us/sample - loss: 2.8249 - starts_loss: 1.3843 - stops_loss: 1.4454 - starts_accuracy: 0.6067 - stops_accuracy: 0.6189 - val_loss: 3.8536 - val_starts_loss: 1.8396 - val_stops_loss: 2.0584 - val_starts_accuracy: 0.5953 - val_stops_accuracy: 0.5457\n",
      "Epoch 23/200\n",
      "20803/20803 [==============================] - 13s 621us/sample - loss: 2.7949 - starts_loss: 1.3764 - stops_loss: 1.4234 - starts_accuracy: 0.6083 - stops_accuracy: 0.6245 - val_loss: 3.7809 - val_starts_loss: 1.8336 - val_stops_loss: 1.9906 - val_starts_accuracy: 0.5878 - val_stops_accuracy: 0.5560\n",
      "Epoch 24/200\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.7613 - starts_loss: 1.3580 - stops_loss: 1.3990 - starts_accuracy: 0.6112 - stops_accuracy: 0.6247 - val_loss: 3.6802 - val_starts_loss: 1.8077 - val_stops_loss: 1.9144 - val_starts_accuracy: 0.5822 - val_stops_accuracy: 0.5676\n",
      "Epoch 25/200\n",
      "20803/20803 [==============================] - 13s 623us/sample - loss: 2.7247 - starts_loss: 1.3383 - stops_loss: 1.3931 - starts_accuracy: 0.6153 - stops_accuracy: 0.6277 - val_loss: 3.5744 - val_starts_loss: 1.7742 - val_stops_loss: 1.8382 - val_starts_accuracy: 0.5762 - val_stops_accuracy: 0.5762\n",
      "Epoch 26/200\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 2.6682 - starts_loss: 1.3144 - stops_loss: 1.3490 - starts_accuracy: 0.6164 - stops_accuracy: 0.6337 - val_loss: 3.5606 - val_starts_loss: 1.7894 - val_stops_loss: 1.8062 - val_starts_accuracy: 0.5559 - val_stops_accuracy: 0.5768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200\n",
      "20803/20803 [==============================] - 14s 685us/sample - loss: 2.6181 - starts_loss: 1.2958 - stops_loss: 1.3210 - starts_accuracy: 0.6165 - stops_accuracy: 0.6403 - val_loss: 3.4431 - val_starts_loss: 1.7441 - val_stops_loss: 1.7314 - val_starts_accuracy: 0.5605 - val_stops_accuracy: 0.5820\n",
      "Epoch 28/200\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 2.5552 - starts_loss: 1.2699 - stops_loss: 1.2946 - starts_accuracy: 0.6234 - stops_accuracy: 0.6466 - val_loss: 3.4215 - val_starts_loss: 1.7547 - val_stops_loss: 1.6959 - val_starts_accuracy: 0.5528 - val_stops_accuracy: 0.5810\n",
      "Epoch 29/200\n",
      "20803/20803 [==============================] - 13s 626us/sample - loss: 2.4726 - starts_loss: 1.2250 - stops_loss: 1.2412 - starts_accuracy: 0.6289 - stops_accuracy: 0.6556 - val_loss: 3.3274 - val_starts_loss: 1.7410 - val_stops_loss: 1.6153 - val_starts_accuracy: 0.5462 - val_stops_accuracy: 0.5901\n",
      "Epoch 30/200\n",
      "20803/20803 [==============================] - 13s 640us/sample - loss: 2.3988 - starts_loss: 1.1961 - stops_loss: 1.2030 - starts_accuracy: 0.6373 - stops_accuracy: 0.6650 - val_loss: 3.2575 - val_starts_loss: 1.6850 - val_stops_loss: 1.5904 - val_starts_accuracy: 0.5520 - val_stops_accuracy: 0.5930\n",
      "Epoch 31/200\n",
      "20803/20803 [==============================] - 13s 647us/sample - loss: 2.3275 - starts_loss: 1.1653 - stops_loss: 1.1606 - starts_accuracy: 0.6433 - stops_accuracy: 0.6701 - val_loss: 3.1835 - val_starts_loss: 1.6487 - val_stops_loss: 1.5429 - val_starts_accuracy: 0.5591 - val_stops_accuracy: 0.6001\n",
      "Epoch 32/200\n",
      "20803/20803 [==============================] - 13s 632us/sample - loss: 2.2539 - starts_loss: 1.1377 - stops_loss: 1.1166 - starts_accuracy: 0.6526 - stops_accuracy: 0.6859 - val_loss: 3.1668 - val_starts_loss: 1.6600 - val_stops_loss: 1.5142 - val_starts_accuracy: 0.5535 - val_stops_accuracy: 0.6039\n",
      "Epoch 33/200\n",
      "20803/20803 [==============================] - 13s 619us/sample - loss: 2.1910 - starts_loss: 1.1057 - stops_loss: 1.0816 - starts_accuracy: 0.6571 - stops_accuracy: 0.6915 - val_loss: 3.1118 - val_starts_loss: 1.6212 - val_stops_loss: 1.4961 - val_starts_accuracy: 0.5582 - val_stops_accuracy: 0.6074\n",
      "Epoch 34/200\n",
      "20803/20803 [==============================] - 13s 630us/sample - loss: 2.1483 - starts_loss: 1.0861 - stops_loss: 1.0582 - starts_accuracy: 0.6614 - stops_accuracy: 0.6975 - val_loss: 3.0884 - val_starts_loss: 1.5948 - val_stops_loss: 1.4948 - val_starts_accuracy: 0.5635 - val_stops_accuracy: 0.6116\n",
      "Epoch 35/200\n",
      "20803/20803 [==============================] - 13s 648us/sample - loss: 2.1077 - starts_loss: 1.0751 - stops_loss: 1.0347 - starts_accuracy: 0.6696 - stops_accuracy: 0.7040 - val_loss: 3.0704 - val_starts_loss: 1.5866 - val_stops_loss: 1.4810 - val_starts_accuracy: 0.5649 - val_stops_accuracy: 0.6135\n",
      "Epoch 36/200\n",
      "20803/20803 [==============================] - 13s 639us/sample - loss: 2.0783 - starts_loss: 1.0588 - stops_loss: 1.0221 - starts_accuracy: 0.6713 - stops_accuracy: 0.7092 - val_loss: 3.0498 - val_starts_loss: 1.5683 - val_stops_loss: 1.4781 - val_starts_accuracy: 0.5709 - val_stops_accuracy: 0.6149\n",
      "Epoch 37/200\n",
      "20803/20803 [==============================] - 13s 626us/sample - loss: 2.0503 - starts_loss: 1.0439 - stops_loss: 1.0073 - starts_accuracy: 0.6706 - stops_accuracy: 0.7137 - val_loss: 3.0283 - val_starts_loss: 1.5538 - val_stops_loss: 1.4652 - val_starts_accuracy: 0.5712 - val_stops_accuracy: 0.6176\n",
      "Epoch 38/200\n",
      "20803/20803 [==============================] - 13s 638us/sample - loss: 2.0307 - starts_loss: 1.0380 - stops_loss: 0.9993 - starts_accuracy: 0.6775 - stops_accuracy: 0.7174 - val_loss: 3.0165 - val_starts_loss: 1.5423 - val_stops_loss: 1.4617 - val_starts_accuracy: 0.5730 - val_stops_accuracy: 0.6172\n",
      "Epoch 39/200\n",
      "20803/20803 [==============================] - 13s 641us/sample - loss: 2.0241 - starts_loss: 1.0320 - stops_loss: 0.9921 - starts_accuracy: 0.6771 - stops_accuracy: 0.7155 - val_loss: 3.0120 - val_starts_loss: 1.5346 - val_stops_loss: 1.4620 - val_starts_accuracy: 0.5747 - val_stops_accuracy: 0.6189\n",
      "Epoch 40/200\n",
      "20803/20803 [==============================] - 13s 631us/sample - loss: 2.0322 - starts_loss: 1.0376 - stops_loss: 0.9943 - starts_accuracy: 0.6738 - stops_accuracy: 0.7172 - val_loss: 2.9999 - val_starts_loss: 1.5257 - val_stops_loss: 1.4562 - val_starts_accuracy: 0.5762 - val_stops_accuracy: 0.6187\n",
      "Epoch 41/200\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.0069 - starts_loss: 1.0240 - stops_loss: 0.9807 - starts_accuracy: 0.6785 - stops_accuracy: 0.7202 - val_loss: 3.0066 - val_starts_loss: 1.5292 - val_stops_loss: 1.4602 - val_starts_accuracy: 0.5751 - val_stops_accuracy: 0.6182\n",
      "Epoch 42/200\n",
      "20803/20803 [==============================] - 13s 625us/sample - loss: 2.0056 - starts_loss: 1.0290 - stops_loss: 0.9730 - starts_accuracy: 0.6764 - stops_accuracy: 0.7230 - val_loss: 2.9840 - val_starts_loss: 1.5168 - val_stops_loss: 1.4454 - val_starts_accuracy: 0.5785 - val_stops_accuracy: 0.6210\n",
      "Epoch 43/200\n",
      "20803/20803 [==============================] - 13s 625us/sample - loss: 1.9892 - starts_loss: 1.0187 - stops_loss: 0.9689 - starts_accuracy: 0.6788 - stops_accuracy: 0.7224 - val_loss: 2.9827 - val_starts_loss: 1.5209 - val_stops_loss: 1.4426 - val_starts_accuracy: 0.5787 - val_stops_accuracy: 0.6180\n",
      "Epoch 44/200\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 1.9774 - starts_loss: 1.0135 - stops_loss: 0.9654 - starts_accuracy: 0.6834 - stops_accuracy: 0.7280 - val_loss: 2.9917 - val_starts_loss: 1.5149 - val_stops_loss: 1.4469 - val_starts_accuracy: 0.5766 - val_stops_accuracy: 0.6193\n",
      "Epoch 45/200\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 1.9538 - starts_loss: 1.0017 - stops_loss: 0.9532 - starts_accuracy: 0.6837 - stops_accuracy: 0.7261 - val_loss: 2.9920 - val_starts_loss: 1.5186 - val_stops_loss: 1.4482 - val_starts_accuracy: 0.5801 - val_stops_accuracy: 0.6187\n",
      "Epoch 46/200\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 1.9223 - starts_loss: 0.9903 - stops_loss: 0.9350 - starts_accuracy: 0.6870 - stops_accuracy: 0.7310 - val_loss: 2.9905 - val_starts_loss: 1.5183 - val_stops_loss: 1.4512 - val_starts_accuracy: 0.5845 - val_stops_accuracy: 0.6201\n",
      "Epoch 47/200\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 1.9076 - starts_loss: 0.9825 - stops_loss: 0.9237 - starts_accuracy: 0.6902 - stops_accuracy: 0.7335 - val_loss: 2.9870 - val_starts_loss: 1.5119 - val_stops_loss: 1.4465 - val_starts_accuracy: 0.5791 - val_stops_accuracy: 0.6193\n",
      "Epoch 48/200\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 1.8784 - starts_loss: 0.9733 - stops_loss: 0.9081 - starts_accuracy: 0.6931 - stops_accuracy: 0.7379 - val_loss: 3.0176 - val_starts_loss: 1.5149 - val_stops_loss: 1.4761 - val_starts_accuracy: 0.5824 - val_stops_accuracy: 0.6255\n",
      "Epoch 49/200\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 1.8511 - starts_loss: 0.9602 - stops_loss: 0.8909 - starts_accuracy: 0.6990 - stops_accuracy: 0.7435 - val_loss: 3.0170 - val_starts_loss: 1.5291 - val_stops_loss: 1.4585 - val_starts_accuracy: 0.5747 - val_stops_accuracy: 0.6187\n",
      "Epoch 50/200\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.8095 - starts_loss: 0.9391 - stops_loss: 0.8693 - starts_accuracy: 0.7033 - stops_accuracy: 0.7501 - val_loss: 3.0203 - val_starts_loss: 1.5319 - val_stops_loss: 1.4658 - val_starts_accuracy: 0.5799 - val_stops_accuracy: 0.6222\n",
      "Epoch 51/200\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 1.7896 - starts_loss: 0.9362 - stops_loss: 0.8551 - starts_accuracy: 0.7027 - stops_accuracy: 0.7530 - val_loss: 3.0079 - val_starts_loss: 1.5160 - val_stops_loss: 1.4587 - val_starts_accuracy: 0.5782 - val_stops_accuracy: 0.6218\n",
      "Epoch 52/200\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 1.7696 - starts_loss: 0.9230 - stops_loss: 0.8423 - starts_accuracy: 0.7069 - stops_accuracy: 0.7547 - val_loss: 3.0271 - val_starts_loss: 1.5366 - val_stops_loss: 1.4576 - val_starts_accuracy: 0.5778 - val_stops_accuracy: 0.6216\n",
      "Epoch 53/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20803/20803 [==============================] - 13s 611us/sample - loss: 1.7489 - starts_loss: 0.9167 - stops_loss: 0.8299 - starts_accuracy: 0.7114 - stops_accuracy: 0.7578 - val_loss: 3.0284 - val_starts_loss: 1.5256 - val_stops_loss: 1.4668 - val_starts_accuracy: 0.5822 - val_stops_accuracy: 0.6203\n",
      "Epoch 54/200\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 1.7372 - starts_loss: 0.9115 - stops_loss: 0.8288 - starts_accuracy: 0.7086 - stops_accuracy: 0.7584 - val_loss: 3.0155 - val_starts_loss: 1.5255 - val_stops_loss: 1.4598 - val_starts_accuracy: 0.5841 - val_stops_accuracy: 0.6208\n",
      "Epoch 55/200\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 1.7260 - starts_loss: 0.8999 - stops_loss: 0.8252 - starts_accuracy: 0.7160 - stops_accuracy: 0.7621 - val_loss: 3.0355 - val_starts_loss: 1.5228 - val_stops_loss: 1.4758 - val_starts_accuracy: 0.5849 - val_stops_accuracy: 0.6241\n",
      "Epoch 56/200\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 1.7030 - starts_loss: 0.8937 - stops_loss: 0.8063 - starts_accuracy: 0.7173 - stops_accuracy: 0.7660 - val_loss: 3.0374 - val_starts_loss: 1.5251 - val_stops_loss: 1.4740 - val_starts_accuracy: 0.5822 - val_stops_accuracy: 0.6235\n",
      "Epoch 57/200\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 1.6972 - starts_loss: 0.8957 - stops_loss: 0.8072 - starts_accuracy: 0.7159 - stops_accuracy: 0.7681 - val_loss: 3.0456 - val_starts_loss: 1.5255 - val_stops_loss: 1.4812 - val_starts_accuracy: 0.5820 - val_stops_accuracy: 0.6237\n",
      "Epoch 58/200\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 1.6976 - starts_loss: 0.8965 - stops_loss: 0.8044 - starts_accuracy: 0.7169 - stops_accuracy: 0.7655 - val_loss: 3.0513 - val_starts_loss: 1.5248 - val_stops_loss: 1.4877 - val_starts_accuracy: 0.5824 - val_stops_accuracy: 0.6235\n",
      "Epoch 59/200\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 1.6972 - starts_loss: 0.8896 - stops_loss: 0.8109 - starts_accuracy: 0.7173 - stops_accuracy: 0.7663 - val_loss: 3.0407 - val_starts_loss: 1.5243 - val_stops_loss: 1.4769 - val_starts_accuracy: 0.5826 - val_stops_accuracy: 0.6235\n",
      "Epoch 60/200\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 1.7001 - starts_loss: 0.8930 - stops_loss: 0.8047 - starts_accuracy: 0.7140 - stops_accuracy: 0.7648 - val_loss: 3.0491 - val_starts_loss: 1.5221 - val_stops_loss: 1.4881 - val_starts_accuracy: 0.5841 - val_stops_accuracy: 0.6235\n",
      "Epoch 61/200\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 1.6847 - starts_loss: 0.8865 - stops_loss: 0.8021 - starts_accuracy: 0.7150 - stops_accuracy: 0.7682 - val_loss: 3.0472 - val_starts_loss: 1.5207 - val_stops_loss: 1.4871 - val_starts_accuracy: 0.5853 - val_stops_accuracy: 0.6231\n",
      "Epoch 62/200\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 1.6920 - starts_loss: 0.8918 - stops_loss: 0.8011 - starts_accuracy: 0.7157 - stops_accuracy: 0.7677 - val_loss: 3.0512 - val_starts_loss: 1.5235 - val_stops_loss: 1.4888 - val_starts_accuracy: 0.5860 - val_stops_accuracy: 0.6222\n",
      "Epoch 63/200\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 1.6679 - starts_loss: 0.8785 - stops_loss: 0.7877 - starts_accuracy: 0.7168 - stops_accuracy: 0.7725 - val_loss: 3.0438 - val_starts_loss: 1.5269 - val_stops_loss: 1.4799 - val_starts_accuracy: 0.5870 - val_stops_accuracy: 0.6241\n",
      "Epoch 64/200\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 1.6631 - starts_loss: 0.8771 - stops_loss: 0.7849 - starts_accuracy: 0.7212 - stops_accuracy: 0.7704 - val_loss: 3.0536 - val_starts_loss: 1.5254 - val_stops_loss: 1.4855 - val_starts_accuracy: 0.5837 - val_stops_accuracy: 0.6241\n",
      "Epoch 65/200\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.6676 - starts_loss: 0.8849 - stops_loss: 0.7861 - starts_accuracy: 0.7175 - stops_accuracy: 0.7711 - val_loss: 3.0480 - val_starts_loss: 1.5286 - val_stops_loss: 1.4791 - val_starts_accuracy: 0.5814 - val_stops_accuracy: 0.6226\n",
      "Epoch 66/200\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 1.6501 - starts_loss: 0.8718 - stops_loss: 0.7803 - starts_accuracy: 0.7228 - stops_accuracy: 0.7762 - val_loss: 3.0598 - val_starts_loss: 1.5342 - val_stops_loss: 1.4851 - val_starts_accuracy: 0.5801 - val_stops_accuracy: 0.6233\n",
      "Epoch 67/200\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 1.6304 - starts_loss: 0.8653 - stops_loss: 0.7700 - starts_accuracy: 0.7247 - stops_accuracy: 0.7771 - val_loss: 3.0734 - val_starts_loss: 1.5384 - val_stops_loss: 1.4954 - val_starts_accuracy: 0.5860 - val_stops_accuracy: 0.6235\n",
      "Epoch 68/200\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 1.6238 - starts_loss: 0.8639 - stops_loss: 0.7599 - starts_accuracy: 0.7250 - stops_accuracy: 0.7780 - val_loss: 3.0808 - val_starts_loss: 1.5356 - val_stops_loss: 1.5078 - val_starts_accuracy: 0.5833 - val_stops_accuracy: 0.6241\n",
      "Epoch 69/200\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 1.6071 - starts_loss: 0.8529 - stops_loss: 0.7535 - starts_accuracy: 0.7286 - stops_accuracy: 0.7820 - val_loss: 3.1020 - val_starts_loss: 1.5399 - val_stops_loss: 1.5220 - val_starts_accuracy: 0.5828 - val_stops_accuracy: 0.6241\n",
      "Epoch 70/200\n",
      "20803/20803 [==============================] - 13s 632us/sample - loss: 1.6019 - starts_loss: 0.8520 - stops_loss: 0.7526 - starts_accuracy: 0.7266 - stops_accuracy: 0.7809 - val_loss: 3.0869 - val_starts_loss: 1.5453 - val_stops_loss: 1.4998 - val_starts_accuracy: 0.5824 - val_stops_accuracy: 0.6239\n",
      "Epoch 71/200\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 1.5790 - starts_loss: 0.8458 - stops_loss: 0.7309 - starts_accuracy: 0.7272 - stops_accuracy: 0.7881 - val_loss: 3.1046 - val_starts_loss: 1.5485 - val_stops_loss: 1.5146 - val_starts_accuracy: 0.5860 - val_stops_accuracy: 0.6247\n",
      "Epoch 72/200\n",
      "20803/20803 [==============================] - 13s 618us/sample - loss: 1.5842 - starts_loss: 0.8467 - stops_loss: 0.7406 - starts_accuracy: 0.7294 - stops_accuracy: 0.7861 - val_loss: 3.1027 - val_starts_loss: 1.5477 - val_stops_loss: 1.5128 - val_starts_accuracy: 0.5843 - val_stops_accuracy: 0.6237\n",
      "Epoch 73/200\n",
      "20803/20803 [==============================] - 13s 623us/sample - loss: 1.5658 - starts_loss: 0.8331 - stops_loss: 0.7291 - starts_accuracy: 0.7339 - stops_accuracy: 0.7866 - val_loss: 3.1221 - val_starts_loss: 1.5497 - val_stops_loss: 1.5301 - val_starts_accuracy: 0.5870 - val_stops_accuracy: 0.6228\n",
      "Epoch 74/200\n",
      "20803/20803 [==============================] - 13s 645us/sample - loss: 1.5600 - starts_loss: 0.8294 - stops_loss: 0.7290 - starts_accuracy: 0.7345 - stops_accuracy: 0.7887 - val_loss: 3.1166 - val_starts_loss: 1.5497 - val_stops_loss: 1.5232 - val_starts_accuracy: 0.5830 - val_stops_accuracy: 0.6216\n",
      "Epoch 75/200\n",
      "20803/20803 [==============================] - 13s 645us/sample - loss: 1.5596 - starts_loss: 0.8330 - stops_loss: 0.7278 - starts_accuracy: 0.7355 - stops_accuracy: 0.7876 - val_loss: 3.1218 - val_starts_loss: 1.5469 - val_stops_loss: 1.5308 - val_starts_accuracy: 0.5833 - val_stops_accuracy: 0.6231\n",
      "Epoch 76/200\n",
      "20803/20803 [==============================] - 13s 620us/sample - loss: 1.5573 - starts_loss: 0.8318 - stops_loss: 0.7303 - starts_accuracy: 0.7319 - stops_accuracy: 0.7890 - val_loss: 3.1192 - val_starts_loss: 1.5460 - val_stops_loss: 1.5292 - val_starts_accuracy: 0.5837 - val_stops_accuracy: 0.6226\n",
      "Epoch 77/200\n",
      "20803/20803 [==============================] - 13s 635us/sample - loss: 1.5525 - starts_loss: 0.8260 - stops_loss: 0.7228 - starts_accuracy: 0.7335 - stops_accuracy: 0.7883 - val_loss: 3.1204 - val_starts_loss: 1.5467 - val_stops_loss: 1.5295 - val_starts_accuracy: 0.5841 - val_stops_accuracy: 0.6230\n",
      "Epoch 78/200\n",
      "20803/20803 [==============================] - 13s 644us/sample - loss: 1.5523 - starts_loss: 0.8353 - stops_loss: 0.7174 - starts_accuracy: 0.7321 - stops_accuracy: 0.7891 - val_loss: 3.1231 - val_starts_loss: 1.5482 - val_stops_loss: 1.5313 - val_starts_accuracy: 0.5853 - val_stops_accuracy: 0.6230\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20803/20803 [==============================] - 14s 667us/sample - loss: 1.5518 - starts_loss: 0.8299 - stops_loss: 0.7190 - starts_accuracy: 0.7344 - stops_accuracy: 0.7886 - val_loss: 3.1221 - val_starts_loss: 1.5483 - val_stops_loss: 1.5293 - val_starts_accuracy: 0.5843 - val_stops_accuracy: 0.6231\n",
      "Epoch 80/200\n",
      "20803/20803 [==============================] - 13s 648us/sample - loss: 1.5517 - starts_loss: 0.8259 - stops_loss: 0.7284 - starts_accuracy: 0.7380 - stops_accuracy: 0.7894 - val_loss: 3.1221 - val_starts_loss: 1.5472 - val_stops_loss: 1.5315 - val_starts_accuracy: 0.5870 - val_stops_accuracy: 0.6226\n",
      "Epoch 81/200\n",
      "20803/20803 [==============================] - 13s 622us/sample - loss: 1.5512 - starts_loss: 0.8289 - stops_loss: 0.7205 - starts_accuracy: 0.7347 - stops_accuracy: 0.7857 - val_loss: 3.1280 - val_starts_loss: 1.5510 - val_stops_loss: 1.5338 - val_starts_accuracy: 0.5870 - val_stops_accuracy: 0.6224\n",
      "Epoch 82/200\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 1.5446 - starts_loss: 0.8290 - stops_loss: 0.7201 - starts_accuracy: 0.7360 - stops_accuracy: 0.7899 - val_loss: 3.1231 - val_starts_loss: 1.5516 - val_stops_loss: 1.5286 - val_starts_accuracy: 0.5860 - val_stops_accuracy: 0.6230\n",
      "Epoch 83/200\n",
      "20803/20803 [==============================] - 13s 627us/sample - loss: 1.5353 - starts_loss: 0.8243 - stops_loss: 0.7106 - starts_accuracy: 0.7369 - stops_accuracy: 0.7932 - val_loss: 3.1311 - val_starts_loss: 1.5560 - val_stops_loss: 1.5305 - val_starts_accuracy: 0.5828 - val_stops_accuracy: 0.6222\n",
      "Epoch 84/200\n",
      "20803/20803 [==============================] - 13s 627us/sample - loss: 1.5372 - starts_loss: 0.8235 - stops_loss: 0.7164 - starts_accuracy: 0.7347 - stops_accuracy: 0.7941 - val_loss: 3.1366 - val_starts_loss: 1.5566 - val_stops_loss: 1.5341 - val_starts_accuracy: 0.5843 - val_stops_accuracy: 0.6212\n",
      "Epoch 85/200\n",
      "20803/20803 [==============================] - 13s 622us/sample - loss: 1.5261 - starts_loss: 0.8143 - stops_loss: 0.7108 - starts_accuracy: 0.7384 - stops_accuracy: 0.7939 - val_loss: 3.1324 - val_starts_loss: 1.5581 - val_stops_loss: 1.5283 - val_starts_accuracy: 0.5830 - val_stops_accuracy: 0.6222\n",
      "Epoch 86/200\n",
      "20803/20803 [==============================] - 13s 635us/sample - loss: 1.5157 - starts_loss: 0.8124 - stops_loss: 0.7037 - starts_accuracy: 0.7392 - stops_accuracy: 0.7946 - val_loss: 3.1465 - val_starts_loss: 1.5559 - val_stops_loss: 1.5432 - val_starts_accuracy: 0.5857 - val_stops_accuracy: 0.6243\n",
      "Epoch 87/200\n",
      "20803/20803 [==============================] - 13s 632us/sample - loss: 1.5142 - starts_loss: 0.8108 - stops_loss: 0.7018 - starts_accuracy: 0.7417 - stops_accuracy: 0.7959 - val_loss: 3.1460 - val_starts_loss: 1.5620 - val_stops_loss: 1.5386 - val_starts_accuracy: 0.5857 - val_stops_accuracy: 0.6228\n",
      "Epoch 88/200\n",
      "20803/20803 [==============================] - 14s 661us/sample - loss: 1.5129 - starts_loss: 0.8114 - stops_loss: 0.7049 - starts_accuracy: 0.7408 - stops_accuracy: 0.7936 - val_loss: 3.1308 - val_starts_loss: 1.5566 - val_stops_loss: 1.5278 - val_starts_accuracy: 0.5868 - val_stops_accuracy: 0.6239\n",
      "Epoch 89/200\n",
      "20803/20803 [==============================] - 14s 668us/sample - loss: 1.5046 - starts_loss: 0.8073 - stops_loss: 0.6993 - starts_accuracy: 0.7430 - stops_accuracy: 0.7984 - val_loss: 3.1477 - val_starts_loss: 1.5625 - val_stops_loss: 1.5380 - val_starts_accuracy: 0.5864 - val_stops_accuracy: 0.6243\n",
      "Epoch 90/200\n",
      "20803/20803 [==============================] - 14s 655us/sample - loss: 1.5004 - starts_loss: 0.8106 - stops_loss: 0.6935 - starts_accuracy: 0.7422 - stops_accuracy: 0.7969 - val_loss: 3.1459 - val_starts_loss: 1.5604 - val_stops_loss: 1.5370 - val_starts_accuracy: 0.5857 - val_stops_accuracy: 0.6235\n",
      "Epoch 91/200\n",
      "20803/20803 [==============================] - 14s 676us/sample - loss: 1.4942 - starts_loss: 0.8050 - stops_loss: 0.6910 - starts_accuracy: 0.7407 - stops_accuracy: 0.7978 - val_loss: 3.1549 - val_starts_loss: 1.5621 - val_stops_loss: 1.5453 - val_starts_accuracy: 0.5862 - val_stops_accuracy: 0.6231\n",
      "Epoch 92/200\n",
      "20803/20803 [==============================] - 13s 641us/sample - loss: 1.4954 - starts_loss: 0.8051 - stops_loss: 0.6899 - starts_accuracy: 0.7447 - stops_accuracy: 0.8001 - val_loss: 3.1520 - val_starts_loss: 1.5590 - val_stops_loss: 1.5448 - val_starts_accuracy: 0.5860 - val_stops_accuracy: 0.6241\n",
      "Epoch 93/200\n",
      "20803/20803 [==============================] - 13s 623us/sample - loss: 1.4927 - starts_loss: 0.7988 - stops_loss: 0.6897 - starts_accuracy: 0.7422 - stops_accuracy: 0.7957 - val_loss: 3.1527 - val_starts_loss: 1.5590 - val_stops_loss: 1.5447 - val_starts_accuracy: 0.5849 - val_stops_accuracy: 0.6235\n",
      "Epoch 94/200\n",
      "20803/20803 [==============================] - 13s 642us/sample - loss: 1.4906 - starts_loss: 0.7981 - stops_loss: 0.6929 - starts_accuracy: 0.7440 - stops_accuracy: 0.7980 - val_loss: 3.1573 - val_starts_loss: 1.5602 - val_stops_loss: 1.5491 - val_starts_accuracy: 0.5858 - val_stops_accuracy: 0.6231\n",
      "Epoch 95/200\n",
      "20803/20803 [==============================] - 14s 654us/sample - loss: 1.4931 - starts_loss: 0.8026 - stops_loss: 0.6889 - starts_accuracy: 0.7420 - stops_accuracy: 0.7997 - val_loss: 3.1598 - val_starts_loss: 1.5611 - val_stops_loss: 1.5507 - val_starts_accuracy: 0.5860 - val_stops_accuracy: 0.6233\n",
      "Epoch 96/200\n",
      "20803/20803 [==============================] - 14s 672us/sample - loss: 1.4791 - starts_loss: 0.7964 - stops_loss: 0.6815 - starts_accuracy: 0.7435 - stops_accuracy: 0.7995 - val_loss: 3.1635 - val_starts_loss: 1.5613 - val_stops_loss: 1.5538 - val_starts_accuracy: 0.5858 - val_stops_accuracy: 0.6226\n",
      "Epoch 97/200\n",
      "20803/20803 [==============================] - 13s 641us/sample - loss: 1.4900 - starts_loss: 0.8014 - stops_loss: 0.6894 - starts_accuracy: 0.7406 - stops_accuracy: 0.7971 - val_loss: 3.1619 - val_starts_loss: 1.5618 - val_stops_loss: 1.5515 - val_starts_accuracy: 0.5849 - val_stops_accuracy: 0.6230\n",
      "Epoch 98/200\n",
      "20803/20803 [==============================] - 13s 628us/sample - loss: 1.4877 - starts_loss: 0.8022 - stops_loss: 0.6809 - starts_accuracy: 0.7435 - stops_accuracy: 0.8002 - val_loss: 3.1612 - val_starts_loss: 1.5626 - val_stops_loss: 1.5494 - val_starts_accuracy: 0.5853 - val_stops_accuracy: 0.6228\n",
      "Epoch 99/200\n",
      "20803/20803 [==============================] - 13s 629us/sample - loss: 1.4939 - starts_loss: 0.8021 - stops_loss: 0.6882 - starts_accuracy: 0.7455 - stops_accuracy: 0.7961 - val_loss: 3.1623 - val_starts_loss: 1.5642 - val_stops_loss: 1.5492 - val_starts_accuracy: 0.5857 - val_stops_accuracy: 0.6233\n",
      "Epoch 100/200\n",
      "20803/20803 [==============================] - 13s 630us/sample - loss: 1.4783 - starts_loss: 0.7929 - stops_loss: 0.6844 - starts_accuracy: 0.7447 - stops_accuracy: 0.7992 - val_loss: 3.1718 - val_starts_loss: 1.5661 - val_stops_loss: 1.5570 - val_starts_accuracy: 0.5864 - val_stops_accuracy: 0.6241\n",
      "Epoch 101/200\n",
      "20803/20803 [==============================] - 13s 641us/sample - loss: 1.4860 - starts_loss: 0.7981 - stops_loss: 0.6854 - starts_accuracy: 0.7445 - stops_accuracy: 0.8009 - val_loss: 3.1689 - val_starts_loss: 1.5666 - val_stops_loss: 1.5527 - val_starts_accuracy: 0.5858 - val_stops_accuracy: 0.6220\n",
      "Epoch 102/200\n",
      "20803/20803 [==============================] - 13s 621us/sample - loss: 1.4883 - starts_loss: 0.7958 - stops_loss: 0.6916 - starts_accuracy: 0.7441 - stops_accuracy: 0.7970 - val_loss: 3.1674 - val_starts_loss: 1.5656 - val_stops_loss: 1.5504 - val_starts_accuracy: 0.5841 - val_stops_accuracy: 0.6218\n",
      "Epoch 103/200\n",
      "20803/20803 [==============================] - 13s 641us/sample - loss: 1.4815 - starts_loss: 0.7962 - stops_loss: 0.6871 - starts_accuracy: 0.7432 - stops_accuracy: 0.7990 - val_loss: 3.1668 - val_starts_loss: 1.5658 - val_stops_loss: 1.5497 - val_starts_accuracy: 0.5833 - val_stops_accuracy: 0.6231\n",
      "Epoch 104/200\n",
      "20803/20803 [==============================] - 14s 651us/sample - loss: 1.4693 - starts_loss: 0.7933 - stops_loss: 0.6779 - starts_accuracy: 0.7462 - stops_accuracy: 0.7998 - val_loss: 3.1695 - val_starts_loss: 1.5669 - val_stops_loss: 1.5545 - val_starts_accuracy: 0.5864 - val_stops_accuracy: 0.6245\n",
      "Epoch 105/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20803/20803 [==============================] - 13s 631us/sample - loss: 1.4722 - starts_loss: 0.7971 - stops_loss: 0.6725 - starts_accuracy: 0.7472 - stops_accuracy: 0.8014 - val_loss: 3.1758 - val_starts_loss: 1.5715 - val_stops_loss: 1.5547 - val_starts_accuracy: 0.5841 - val_stops_accuracy: 0.6237\n",
      "Epoch 106/200\n",
      "20803/20803 [==============================] - 13s 641us/sample - loss: 1.4707 - starts_loss: 0.7870 - stops_loss: 0.6829 - starts_accuracy: 0.7463 - stops_accuracy: 0.8007 - val_loss: 3.1677 - val_starts_loss: 1.5727 - val_stops_loss: 1.5457 - val_starts_accuracy: 0.5857 - val_stops_accuracy: 0.6222\n",
      "Epoch 107/200\n",
      "20803/20803 [==============================] - 13s 639us/sample - loss: 1.4645 - starts_loss: 0.7882 - stops_loss: 0.6761 - starts_accuracy: 0.7477 - stops_accuracy: 0.8002 - val_loss: 3.1717 - val_starts_loss: 1.5709 - val_stops_loss: 1.5508 - val_starts_accuracy: 0.5845 - val_stops_accuracy: 0.6235\n",
      "Epoch 108/200\n",
      "20803/20803 [==============================] - 14s 665us/sample - loss: 1.4589 - starts_loss: 0.7903 - stops_loss: 0.6709 - starts_accuracy: 0.7500 - stops_accuracy: 0.8003 - val_loss: 3.1726 - val_starts_loss: 1.5720 - val_stops_loss: 1.5519 - val_starts_accuracy: 0.5855 - val_stops_accuracy: 0.6230\n",
      "Epoch 109/200\n",
      "20803/20803 [==============================] - 14s 670us/sample - loss: 1.4634 - starts_loss: 0.7875 - stops_loss: 0.6761 - starts_accuracy: 0.7452 - stops_accuracy: 0.8048 - val_loss: 3.1839 - val_starts_loss: 1.5733 - val_stops_loss: 1.5603 - val_starts_accuracy: 0.5845 - val_stops_accuracy: 0.6235\n",
      "Epoch 110/200\n",
      "20803/20803 [==============================] - 14s 666us/sample - loss: 1.4613 - starts_loss: 0.7849 - stops_loss: 0.6776 - starts_accuracy: 0.7494 - stops_accuracy: 0.8031 - val_loss: 3.1855 - val_starts_loss: 1.5734 - val_stops_loss: 1.5620 - val_starts_accuracy: 0.5853 - val_stops_accuracy: 0.6239\n",
      "Epoch 111/200\n",
      "20803/20803 [==============================] - 13s 639us/sample - loss: 1.4621 - starts_loss: 0.7907 - stops_loss: 0.6737 - starts_accuracy: 0.7481 - stops_accuracy: 0.8029 - val_loss: 3.1899 - val_starts_loss: 1.5752 - val_stops_loss: 1.5659 - val_starts_accuracy: 0.5882 - val_stops_accuracy: 0.6239\n",
      "Epoch 112/200\n",
      "20803/20803 [==============================] - 14s 653us/sample - loss: 1.4602 - starts_loss: 0.7913 - stops_loss: 0.6694 - starts_accuracy: 0.7435 - stops_accuracy: 0.8057 - val_loss: 3.1857 - val_starts_loss: 1.5742 - val_stops_loss: 1.5613 - val_starts_accuracy: 0.5851 - val_stops_accuracy: 0.6235\n",
      "Epoch 113/200\n",
      "20803/20803 [==============================] - 13s 649us/sample - loss: 1.4489 - starts_loss: 0.7813 - stops_loss: 0.6582 - starts_accuracy: 0.7480 - stops_accuracy: 0.8056 - val_loss: 3.1881 - val_starts_loss: 1.5742 - val_stops_loss: 1.5640 - val_starts_accuracy: 0.5864 - val_stops_accuracy: 0.6233\n",
      "Epoch 114/200\n",
      "20803/20803 [==============================] - 14s 657us/sample - loss: 1.4391 - starts_loss: 0.7825 - stops_loss: 0.6584 - starts_accuracy: 0.7512 - stops_accuracy: 0.8085 - val_loss: 3.1889 - val_starts_loss: 1.5746 - val_stops_loss: 1.5641 - val_starts_accuracy: 0.5862 - val_stops_accuracy: 0.6231\n",
      "Epoch 115/200\n",
      "20803/20803 [==============================] - 13s 629us/sample - loss: 1.4519 - starts_loss: 0.7853 - stops_loss: 0.6704 - starts_accuracy: 0.7476 - stops_accuracy: 0.8035 - val_loss: 3.1903 - val_starts_loss: 1.5748 - val_stops_loss: 1.5650 - val_starts_accuracy: 0.5858 - val_stops_accuracy: 0.6235\n",
      "Epoch 116/200\n",
      "20803/20803 [==============================] - 13s 635us/sample - loss: 1.4467 - starts_loss: 0.7800 - stops_loss: 0.6657 - starts_accuracy: 0.7497 - stops_accuracy: 0.8047 - val_loss: 3.1906 - val_starts_loss: 1.5749 - val_stops_loss: 1.5654 - val_starts_accuracy: 0.5860 - val_stops_accuracy: 0.6233\n",
      "Epoch 117/200\n",
      "20803/20803 [==============================] - 13s 632us/sample - loss: 1.4577 - starts_loss: 0.7912 - stops_loss: 0.6737 - starts_accuracy: 0.7472 - stops_accuracy: 0.8033 - val_loss: 3.1889 - val_starts_loss: 1.5750 - val_stops_loss: 1.5640 - val_starts_accuracy: 0.5868 - val_stops_accuracy: 0.6235\n",
      "Epoch 118/200\n",
      "20803/20803 [==============================] - 13s 645us/sample - loss: 1.4592 - starts_loss: 0.7887 - stops_loss: 0.6748 - starts_accuracy: 0.7494 - stops_accuracy: 0.8010 - val_loss: 3.1922 - val_starts_loss: 1.5754 - val_stops_loss: 1.5669 - val_starts_accuracy: 0.5872 - val_stops_accuracy: 0.6241\n",
      "Epoch 119/200\n",
      "20803/20803 [==============================] - 14s 684us/sample - loss: 1.4518 - starts_loss: 0.7844 - stops_loss: 0.6688 - starts_accuracy: 0.7477 - stops_accuracy: 0.8036 - val_loss: 3.1889 - val_starts_loss: 1.5744 - val_stops_loss: 1.5638 - val_starts_accuracy: 0.5858 - val_stops_accuracy: 0.6237\n",
      "Epoch 120/200\n",
      "20803/20803 [==============================] - 13s 643us/sample - loss: 1.4581 - starts_loss: 0.7827 - stops_loss: 0.6727 - starts_accuracy: 0.7474 - stops_accuracy: 0.8020 - val_loss: 3.1873 - val_starts_loss: 1.5742 - val_stops_loss: 1.5621 - val_starts_accuracy: 0.5866 - val_stops_accuracy: 0.6228\n",
      "Epoch 121/200\n",
      "20803/20803 [==============================] - 13s 638us/sample - loss: 1.4477 - starts_loss: 0.7794 - stops_loss: 0.6723 - starts_accuracy: 0.7514 - stops_accuracy: 0.8049 - val_loss: 3.1908 - val_starts_loss: 1.5754 - val_stops_loss: 1.5644 - val_starts_accuracy: 0.5858 - val_stops_accuracy: 0.6231\n",
      "Epoch 122/200\n",
      "20803/20803 [==============================] - 13s 624us/sample - loss: 1.4465 - starts_loss: 0.7809 - stops_loss: 0.6664 - starts_accuracy: 0.7496 - stops_accuracy: 0.8042 - val_loss: 3.1953 - val_starts_loss: 1.5786 - val_stops_loss: 1.5664 - val_starts_accuracy: 0.5874 - val_stops_accuracy: 0.6233\n",
      "Epoch 123/200\n",
      "20803/20803 [==============================] - 13s 629us/sample - loss: 1.4461 - starts_loss: 0.7829 - stops_loss: 0.6690 - starts_accuracy: 0.7489 - stops_accuracy: 0.8033 - val_loss: 3.1923 - val_starts_loss: 1.5783 - val_stops_loss: 1.5631 - val_starts_accuracy: 0.5862 - val_stops_accuracy: 0.6228\n",
      "Epoch 124/200\n",
      "20803/20803 [==============================] - 13s 640us/sample - loss: 1.4529 - starts_loss: 0.7876 - stops_loss: 0.6687 - starts_accuracy: 0.7476 - stops_accuracy: 0.8042 - val_loss: 3.1890 - val_starts_loss: 1.5785 - val_stops_loss: 1.5619 - val_starts_accuracy: 0.5876 - val_stops_accuracy: 0.6230\n",
      "Epoch 125/200\n",
      "20803/20803 [==============================] - 13s 625us/sample - loss: 1.4436 - starts_loss: 0.7814 - stops_loss: 0.6642 - starts_accuracy: 0.7506 - stops_accuracy: 0.8047 - val_loss: 3.1998 - val_starts_loss: 1.5775 - val_stops_loss: 1.5731 - val_starts_accuracy: 0.5878 - val_stops_accuracy: 0.6235\n",
      "Epoch 126/200\n",
      "20803/20803 [==============================] - 13s 620us/sample - loss: 1.4392 - starts_loss: 0.7765 - stops_loss: 0.6624 - starts_accuracy: 0.7494 - stops_accuracy: 0.8083 - val_loss: 3.2024 - val_starts_loss: 1.5780 - val_stops_loss: 1.5740 - val_starts_accuracy: 0.5866 - val_stops_accuracy: 0.6231\n",
      "Epoch 127/200\n",
      "20803/20803 [==============================] - 13s 633us/sample - loss: 1.4365 - starts_loss: 0.7818 - stops_loss: 0.6568 - starts_accuracy: 0.7498 - stops_accuracy: 0.8092 - val_loss: 3.2060 - val_starts_loss: 1.5794 - val_stops_loss: 1.5759 - val_starts_accuracy: 0.5872 - val_stops_accuracy: 0.6228\n",
      "Epoch 128/200\n",
      "20803/20803 [==============================] - 13s 623us/sample - loss: 1.4445 - starts_loss: 0.7830 - stops_loss: 0.6634 - starts_accuracy: 0.7491 - stops_accuracy: 0.8084 - val_loss: 3.2069 - val_starts_loss: 1.5800 - val_stops_loss: 1.5761 - val_starts_accuracy: 0.5858 - val_stops_accuracy: 0.6233\n",
      "Epoch 129/200\n",
      "20803/20803 [==============================] - 13s 645us/sample - loss: 1.4409 - starts_loss: 0.7793 - stops_loss: 0.6614 - starts_accuracy: 0.7484 - stops_accuracy: 0.8057 - val_loss: 3.2037 - val_starts_loss: 1.5803 - val_stops_loss: 1.5724 - val_starts_accuracy: 0.5868 - val_stops_accuracy: 0.6233\n",
      "Epoch 130/200\n",
      "20803/20803 [==============================] - 14s 662us/sample - loss: 1.4364 - starts_loss: 0.7731 - stops_loss: 0.6578 - starts_accuracy: 0.7486 - stops_accuracy: 0.8036 - val_loss: 3.1985 - val_starts_loss: 1.5792 - val_stops_loss: 1.5677 - val_starts_accuracy: 0.5857 - val_stops_accuracy: 0.6231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/200\n",
      "20803/20803 [==============================] - 14s 655us/sample - loss: 1.4408 - starts_loss: 0.7792 - stops_loss: 0.6632 - starts_accuracy: 0.7525 - stops_accuracy: 0.8057 - val_loss: 3.2029 - val_starts_loss: 1.5794 - val_stops_loss: 1.5718 - val_starts_accuracy: 0.5860 - val_stops_accuracy: 0.6241\n",
      "Epoch 132/200\n",
      "20803/20803 [==============================] - 14s 652us/sample - loss: 1.4356 - starts_loss: 0.7763 - stops_loss: 0.6619 - starts_accuracy: 0.7508 - stops_accuracy: 0.8050 - val_loss: 3.2033 - val_starts_loss: 1.5787 - val_stops_loss: 1.5729 - val_starts_accuracy: 0.5860 - val_stops_accuracy: 0.6231\n",
      "Epoch 133/200\n",
      "20803/20803 [==============================] - 13s 630us/sample - loss: 1.4292 - starts_loss: 0.7747 - stops_loss: 0.6574 - starts_accuracy: 0.7520 - stops_accuracy: 0.8073 - val_loss: 3.2048 - val_starts_loss: 1.5791 - val_stops_loss: 1.5742 - val_starts_accuracy: 0.5862 - val_stops_accuracy: 0.6231\n",
      "Epoch 134/200\n",
      "20803/20803 [==============================] - 13s 643us/sample - loss: 1.4417 - starts_loss: 0.7765 - stops_loss: 0.6668 - starts_accuracy: 0.7488 - stops_accuracy: 0.8031 - val_loss: 3.2061 - val_starts_loss: 1.5796 - val_stops_loss: 1.5753 - val_starts_accuracy: 0.5864 - val_stops_accuracy: 0.6230\n",
      "Epoch 135/200\n",
      "20803/20803 [==============================] - 13s 623us/sample - loss: 1.4284 - starts_loss: 0.7756 - stops_loss: 0.6506 - starts_accuracy: 0.7516 - stops_accuracy: 0.8119 - val_loss: 3.2062 - val_starts_loss: 1.5798 - val_stops_loss: 1.5753 - val_starts_accuracy: 0.5866 - val_stops_accuracy: 0.6235\n",
      "Epoch 136/200\n",
      "20803/20803 [==============================] - 13s 626us/sample - loss: 1.4423 - starts_loss: 0.7797 - stops_loss: 0.6671 - starts_accuracy: 0.7485 - stops_accuracy: 0.8065 - val_loss: 3.2046 - val_starts_loss: 1.5800 - val_stops_loss: 1.5734 - val_starts_accuracy: 0.5866 - val_stops_accuracy: 0.6237\n",
      "Epoch 137/200\n",
      "20803/20803 [==============================] - 13s 620us/sample - loss: 1.4426 - starts_loss: 0.7828 - stops_loss: 0.6628 - starts_accuracy: 0.7509 - stops_accuracy: 0.8064 - val_loss: 3.2039 - val_starts_loss: 1.5802 - val_stops_loss: 1.5725 - val_starts_accuracy: 0.5864 - val_stops_accuracy: 0.6235\n",
      "Epoch 138/200\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 1.4305 - starts_loss: 0.7733 - stops_loss: 0.6584 - starts_accuracy: 0.7542 - stops_accuracy: 0.8063 - val_loss: 3.2066 - val_starts_loss: 1.5806 - val_stops_loss: 1.5744 - val_starts_accuracy: 0.5860 - val_stops_accuracy: 0.6231\n",
      "Epoch 139/200\n",
      "20803/20803 [==============================] - 13s 633us/sample - loss: 1.4417 - starts_loss: 0.7793 - stops_loss: 0.6634 - starts_accuracy: 0.7481 - stops_accuracy: 0.8090 - val_loss: 3.2090 - val_starts_loss: 1.5815 - val_stops_loss: 1.5760 - val_starts_accuracy: 0.5866 - val_stops_accuracy: 0.6235\n",
      "Epoch 140/200\n",
      "20803/20803 [==============================] - 13s 619us/sample - loss: 1.4402 - starts_loss: 0.7863 - stops_loss: 0.6555 - starts_accuracy: 0.7475 - stops_accuracy: 0.8083 - val_loss: 3.2106 - val_starts_loss: 1.5827 - val_stops_loss: 1.5765 - val_starts_accuracy: 0.5858 - val_stops_accuracy: 0.6237\n",
      "Epoch 141/200\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 1.4328 - starts_loss: 0.7783 - stops_loss: 0.6593 - starts_accuracy: 0.7509 - stops_accuracy: 0.8084 - val_loss: 3.2104 - val_starts_loss: 1.5837 - val_stops_loss: 1.5757 - val_starts_accuracy: 0.5868 - val_stops_accuracy: 0.6235\n",
      "Epoch 142/200\n",
      "20803/20803 [==============================] - 13s 630us/sample - loss: 1.4279 - starts_loss: 0.7759 - stops_loss: 0.6545 - starts_accuracy: 0.7501 - stops_accuracy: 0.8085 - val_loss: 3.2072 - val_starts_loss: 1.5830 - val_stops_loss: 1.5734 - val_starts_accuracy: 0.5868 - val_stops_accuracy: 0.6243\n",
      "Epoch 143/200\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 1.4288 - starts_loss: 0.7794 - stops_loss: 0.6536 - starts_accuracy: 0.7499 - stops_accuracy: 0.8074 - val_loss: 3.2103 - val_starts_loss: 1.5823 - val_stops_loss: 1.5771 - val_starts_accuracy: 0.5868 - val_stops_accuracy: 0.6231\n",
      "Epoch 144/200\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 1.4367 - starts_loss: 0.7759 - stops_loss: 0.6586 - starts_accuracy: 0.7517 - stops_accuracy: 0.8061 - val_loss: 3.2118 - val_starts_loss: 1.5839 - val_stops_loss: 1.5775 - val_starts_accuracy: 0.5870 - val_stops_accuracy: 0.6230\n",
      "Epoch 145/200\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.4327 - starts_loss: 0.7722 - stops_loss: 0.6578 - starts_accuracy: 0.7504 - stops_accuracy: 0.8082 - val_loss: 3.2121 - val_starts_loss: 1.5842 - val_stops_loss: 1.5772 - val_starts_accuracy: 0.5855 - val_stops_accuracy: 0.6226\n",
      "Epoch 146/200\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 1.4388 - starts_loss: 0.7772 - stops_loss: 0.6664 - starts_accuracy: 0.7509 - stops_accuracy: 0.8081 - val_loss: 3.2124 - val_starts_loss: 1.5845 - val_stops_loss: 1.5772 - val_starts_accuracy: 0.5860 - val_stops_accuracy: 0.6226\n",
      "Epoch 147/200\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 1.4269 - starts_loss: 0.7795 - stops_loss: 0.6495 - starts_accuracy: 0.7482 - stops_accuracy: 0.8088 - val_loss: 3.2121 - val_starts_loss: 1.5861 - val_stops_loss: 1.5753 - val_starts_accuracy: 0.5857 - val_stops_accuracy: 0.6228\n",
      "Epoch 148/200\n",
      "20803/20803 [==============================] - 13s 634us/sample - loss: 1.4349 - starts_loss: 0.7797 - stops_loss: 0.6559 - starts_accuracy: 0.7523 - stops_accuracy: 0.8081 - val_loss: 3.2114 - val_starts_loss: 1.5859 - val_stops_loss: 1.5748 - val_starts_accuracy: 0.5855 - val_stops_accuracy: 0.6228\n",
      "Epoch 149/200\n",
      "20803/20803 [==============================] - 14s 650us/sample - loss: 1.4301 - starts_loss: 0.7724 - stops_loss: 0.6592 - starts_accuracy: 0.7528 - stops_accuracy: 0.8064 - val_loss: 3.2137 - val_starts_loss: 1.5864 - val_stops_loss: 1.5762 - val_starts_accuracy: 0.5851 - val_stops_accuracy: 0.6226\n",
      "Epoch 150/200\n",
      "20803/20803 [==============================] - 13s 639us/sample - loss: 1.4316 - starts_loss: 0.7708 - stops_loss: 0.6584 - starts_accuracy: 0.7502 - stops_accuracy: 0.8096 - val_loss: 3.2140 - val_starts_loss: 1.5864 - val_stops_loss: 1.5764 - val_starts_accuracy: 0.5849 - val_stops_accuracy: 0.6230\n",
      "Epoch 151/200\n",
      "20803/20803 [==============================] - 13s 619us/sample - loss: 1.4302 - starts_loss: 0.7724 - stops_loss: 0.6605 - starts_accuracy: 0.7539 - stops_accuracy: 0.8092 - val_loss: 3.2134 - val_starts_loss: 1.5861 - val_stops_loss: 1.5762 - val_starts_accuracy: 0.5853 - val_stops_accuracy: 0.6231\n",
      "Epoch 152/200\n",
      "20803/20803 [==============================] - 13s 631us/sample - loss: 1.4272 - starts_loss: 0.7759 - stops_loss: 0.6527 - starts_accuracy: 0.7489 - stops_accuracy: 0.8099 - val_loss: 3.2142 - val_starts_loss: 1.5860 - val_stops_loss: 1.5771 - val_starts_accuracy: 0.5857 - val_stops_accuracy: 0.6226\n",
      "Epoch 153/200\n",
      "20803/20803 [==============================] - 13s 634us/sample - loss: 1.4223 - starts_loss: 0.7637 - stops_loss: 0.6545 - starts_accuracy: 0.7535 - stops_accuracy: 0.8090 - val_loss: 3.2139 - val_starts_loss: 1.5859 - val_stops_loss: 1.5771 - val_starts_accuracy: 0.5858 - val_stops_accuracy: 0.6228\n",
      "Epoch 154/200\n",
      "20803/20803 [==============================] - 13s 623us/sample - loss: 1.4225 - starts_loss: 0.7661 - stops_loss: 0.6557 - starts_accuracy: 0.7556 - stops_accuracy: 0.8096 - val_loss: 3.2133 - val_starts_loss: 1.5853 - val_stops_loss: 1.5770 - val_starts_accuracy: 0.5858 - val_stops_accuracy: 0.6226\n",
      "Epoch 155/200\n",
      "20803/20803 [==============================] - 13s 623us/sample - loss: 1.4318 - starts_loss: 0.7751 - stops_loss: 0.6613 - starts_accuracy: 0.7518 - stops_accuracy: 0.8064 - val_loss: 3.2139 - val_starts_loss: 1.5855 - val_stops_loss: 1.5776 - val_starts_accuracy: 0.5860 - val_stops_accuracy: 0.6220\n",
      "Epoch 156/200\n",
      "20803/20803 [==============================] - 25s 1ms/sample - loss: 1.4209 - starts_loss: 0.7666 - stops_loss: 0.6554 - starts_accuracy: 0.7512 - stops_accuracy: 0.8082 - val_loss: 3.2155 - val_starts_loss: 1.5858 - val_stops_loss: 1.5789 - val_starts_accuracy: 0.5855 - val_stops_accuracy: 0.6226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/200\n",
      "20803/20803 [==============================] - 38s 2ms/sample - loss: 1.4255 - starts_loss: 0.7710 - stops_loss: 0.6527 - starts_accuracy: 0.7542 - stops_accuracy: 0.8084 - val_loss: 3.2158 - val_starts_loss: 1.5863 - val_stops_loss: 1.5789 - val_starts_accuracy: 0.5855 - val_stops_accuracy: 0.6222\n",
      "Epoch 158/200\n",
      "20803/20803 [==============================] - 28s 1ms/sample - loss: 1.4266 - starts_loss: 0.7684 - stops_loss: 0.6547 - starts_accuracy: 0.7523 - stops_accuracy: 0.8061 - val_loss: 3.2154 - val_starts_loss: 1.5867 - val_stops_loss: 1.5780 - val_starts_accuracy: 0.5855 - val_stops_accuracy: 0.6224\n",
      "Epoch 159/200\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 1.4294 - starts_loss: 0.7818 - stops_loss: 0.6533 - starts_accuracy: 0.7472 - stops_accuracy: 0.8082 - val_loss: 3.2166 - val_starts_loss: 1.5867 - val_stops_loss: 1.5790 - val_starts_accuracy: 0.5849 - val_stops_accuracy: 0.6220\n",
      "Epoch 160/200\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 1.4224 - starts_loss: 0.7717 - stops_loss: 0.6563 - starts_accuracy: 0.7551 - stops_accuracy: 0.8057 - val_loss: 3.2177 - val_starts_loss: 1.5873 - val_stops_loss: 1.5795 - val_starts_accuracy: 0.5845 - val_stops_accuracy: 0.6224\n",
      "Epoch 161/200\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 1.4210 - starts_loss: 0.7676 - stops_loss: 0.6512 - starts_accuracy: 0.7487 - stops_accuracy: 0.8066 - val_loss: 3.2154 - val_starts_loss: 1.5865 - val_stops_loss: 1.5777 - val_starts_accuracy: 0.5845 - val_stops_accuracy: 0.6230\n",
      "Epoch 162/200\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 1.4192 - starts_loss: 0.7742 - stops_loss: 0.6460 - starts_accuracy: 0.7531 - stops_accuracy: 0.8092 - val_loss: 3.2169 - val_starts_loss: 1.5864 - val_stops_loss: 1.5791 - val_starts_accuracy: 0.5847 - val_stops_accuracy: 0.6228\n",
      "Epoch 163/200\n",
      "20803/20803 [==============================] - 13s 642us/sample - loss: 1.4193 - starts_loss: 0.7688 - stops_loss: 0.6510 - starts_accuracy: 0.7530 - stops_accuracy: 0.8074 - val_loss: 3.2179 - val_starts_loss: 1.5866 - val_stops_loss: 1.5802 - val_starts_accuracy: 0.5851 - val_stops_accuracy: 0.6226\n",
      "Epoch 164/200\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.4274 - starts_loss: 0.7717 - stops_loss: 0.6545 - starts_accuracy: 0.7516 - stops_accuracy: 0.8077 - val_loss: 3.2179 - val_starts_loss: 1.5870 - val_stops_loss: 1.5796 - val_starts_accuracy: 0.5855 - val_stops_accuracy: 0.6226\n",
      "Epoch 165/200\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 1.4279 - starts_loss: 0.7711 - stops_loss: 0.6602 - starts_accuracy: 0.7514 - stops_accuracy: 0.8055 - val_loss: 3.2169 - val_starts_loss: 1.5873 - val_stops_loss: 1.5783 - val_starts_accuracy: 0.5857 - val_stops_accuracy: 0.6233\n",
      "Epoch 166/200\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 1.4207 - starts_loss: 0.7662 - stops_loss: 0.6522 - starts_accuracy: 0.7529 - stops_accuracy: 0.8085 - val_loss: 3.2203 - val_starts_loss: 1.5886 - val_stops_loss: 1.5806 - val_starts_accuracy: 0.5857 - val_stops_accuracy: 0.6230\n",
      "Epoch 167/200\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 1.4169 - starts_loss: 0.7643 - stops_loss: 0.6552 - starts_accuracy: 0.7588 - stops_accuracy: 0.8079 - val_loss: 3.2189 - val_starts_loss: 1.5886 - val_stops_loss: 1.5793 - val_starts_accuracy: 0.5858 - val_stops_accuracy: 0.6231\n",
      "Epoch 168/200\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 1.4221 - starts_loss: 0.7717 - stops_loss: 0.6549 - starts_accuracy: 0.7519 - stops_accuracy: 0.8082 - val_loss: 3.2188 - val_starts_loss: 1.5888 - val_stops_loss: 1.5790 - val_starts_accuracy: 0.5860 - val_stops_accuracy: 0.6228\n",
      "Epoch 169/200\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 1.4231 - starts_loss: 0.7747 - stops_loss: 0.6458 - starts_accuracy: 0.7474 - stops_accuracy: 0.8093 - val_loss: 3.2190 - val_starts_loss: 1.5887 - val_stops_loss: 1.5794 - val_starts_accuracy: 0.5858 - val_stops_accuracy: 0.6226\n",
      "Epoch 170/200\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 1.4229 - starts_loss: 0.7727 - stops_loss: 0.6489 - starts_accuracy: 0.7540 - stops_accuracy: 0.8078 - val_loss: 3.2192 - val_starts_loss: 1.5885 - val_stops_loss: 1.5797 - val_starts_accuracy: 0.5860 - val_stops_accuracy: 0.6230\n",
      "Epoch 171/200\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 1.4237 - starts_loss: 0.7729 - stops_loss: 0.6569 - starts_accuracy: 0.7543 - stops_accuracy: 0.8066 - val_loss: 3.2192 - val_starts_loss: 1.5886 - val_stops_loss: 1.5794 - val_starts_accuracy: 0.5855 - val_stops_accuracy: 0.6228\n",
      "Epoch 172/200\n",
      "20803/20803 [==============================] - 13s 620us/sample - loss: 1.4273 - starts_loss: 0.7720 - stops_loss: 0.6544 - starts_accuracy: 0.7489 - stops_accuracy: 0.8074 - val_loss: 3.2189 - val_starts_loss: 1.5880 - val_stops_loss: 1.5797 - val_starts_accuracy: 0.5855 - val_stops_accuracy: 0.6230\n",
      "Epoch 173/200\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 1.4195 - starts_loss: 0.7690 - stops_loss: 0.6496 - starts_accuracy: 0.7528 - stops_accuracy: 0.8121 - val_loss: 3.2198 - val_starts_loss: 1.5881 - val_stops_loss: 1.5806 - val_starts_accuracy: 0.5860 - val_stops_accuracy: 0.6231\n",
      "Epoch 174/200\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 1.4202 - starts_loss: 0.7700 - stops_loss: 0.6528 - starts_accuracy: 0.7494 - stops_accuracy: 0.8097 - val_loss: 3.2200 - val_starts_loss: 1.5882 - val_stops_loss: 1.5808 - val_starts_accuracy: 0.5860 - val_stops_accuracy: 0.6230\n",
      "Epoch 175/200\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 1.4138 - starts_loss: 0.7675 - stops_loss: 0.6422 - starts_accuracy: 0.7556 - stops_accuracy: 0.8103 - val_loss: 3.2194 - val_starts_loss: 1.5882 - val_stops_loss: 1.5801 - val_starts_accuracy: 0.5862 - val_stops_accuracy: 0.6231\n",
      "Epoch 176/200\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 1.4241 - starts_loss: 0.7736 - stops_loss: 0.6521 - starts_accuracy: 0.7508 - stops_accuracy: 0.8082 - val_loss: 3.2199 - val_starts_loss: 1.5882 - val_stops_loss: 1.5805 - val_starts_accuracy: 0.5855 - val_stops_accuracy: 0.6233\n",
      "Epoch 177/200\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.4187 - starts_loss: 0.7696 - stops_loss: 0.6444 - starts_accuracy: 0.7542 - stops_accuracy: 0.8101 - val_loss: 3.2205 - val_starts_loss: 1.5885 - val_stops_loss: 1.5810 - val_starts_accuracy: 0.5864 - val_stops_accuracy: 0.6230\n",
      "Epoch 178/200\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 1.4200 - starts_loss: 0.7718 - stops_loss: 0.6434 - starts_accuracy: 0.7505 - stops_accuracy: 0.8107 - val_loss: 3.2206 - val_starts_loss: 1.5889 - val_stops_loss: 1.5806 - val_starts_accuracy: 0.5860 - val_stops_accuracy: 0.6226\n",
      "Epoch 179/200\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 1.4073 - starts_loss: 0.7678 - stops_loss: 0.6437 - starts_accuracy: 0.7558 - stops_accuracy: 0.8090 - val_loss: 3.2199 - val_starts_loss: 1.5886 - val_stops_loss: 1.5803 - val_starts_accuracy: 0.5858 - val_stops_accuracy: 0.6226\n",
      "Epoch 180/200\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 1.4288 - starts_loss: 0.7684 - stops_loss: 0.6618 - starts_accuracy: 0.7518 - stops_accuracy: 0.8054 - val_loss: 3.2195 - val_starts_loss: 1.5882 - val_stops_loss: 1.5802 - val_starts_accuracy: 0.5860 - val_stops_accuracy: 0.6231\n",
      "Epoch 181/200\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 1.4064 - starts_loss: 0.7670 - stops_loss: 0.6401 - starts_accuracy: 0.7541 - stops_accuracy: 0.8130 - val_loss: 3.2201 - val_starts_loss: 1.5882 - val_stops_loss: 1.5808 - val_starts_accuracy: 0.5862 - val_stops_accuracy: 0.6231\n",
      "Epoch 182/200\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.4196 - starts_loss: 0.7691 - stops_loss: 0.6524 - starts_accuracy: 0.7535 - stops_accuracy: 0.8090 - val_loss: 3.2209 - val_starts_loss: 1.5890 - val_stops_loss: 1.5803 - val_starts_accuracy: 0.5868 - val_stops_accuracy: 0.6231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/200\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.4252 - starts_loss: 0.7706 - stops_loss: 0.6551 - starts_accuracy: 0.7522 - stops_accuracy: 0.8058 - val_loss: 3.2215 - val_starts_loss: 1.5893 - val_stops_loss: 1.5805 - val_starts_accuracy: 0.5866 - val_stops_accuracy: 0.6228\n",
      "Epoch 184/200\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 1.4152 - starts_loss: 0.7696 - stops_loss: 0.6482 - starts_accuracy: 0.7553 - stops_accuracy: 0.8102 - val_loss: 3.2200 - val_starts_loss: 1.5886 - val_stops_loss: 1.5793 - val_starts_accuracy: 0.5858 - val_stops_accuracy: 0.6231\n",
      "Epoch 185/200\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.4207 - starts_loss: 0.7743 - stops_loss: 0.6498 - starts_accuracy: 0.7537 - stops_accuracy: 0.8092 - val_loss: 3.2194 - val_starts_loss: 1.5888 - val_stops_loss: 1.5787 - val_starts_accuracy: 0.5860 - val_stops_accuracy: 0.6231\n",
      "Epoch 186/200\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 1.4168 - starts_loss: 0.7737 - stops_loss: 0.6501 - starts_accuracy: 0.7514 - stops_accuracy: 0.8098 - val_loss: 3.2203 - val_starts_loss: 1.5894 - val_stops_loss: 1.5792 - val_starts_accuracy: 0.5860 - val_stops_accuracy: 0.6228\n",
      "Epoch 187/200\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 1.4273 - starts_loss: 0.7765 - stops_loss: 0.6514 - starts_accuracy: 0.7482 - stops_accuracy: 0.8085 - val_loss: 3.2211 - val_starts_loss: 1.5900 - val_stops_loss: 1.5795 - val_starts_accuracy: 0.5864 - val_stops_accuracy: 0.6230\n",
      "Epoch 188/200\n",
      "20803/20803 [==============================] - 13s 618us/sample - loss: 1.4106 - starts_loss: 0.7649 - stops_loss: 0.6458 - starts_accuracy: 0.7561 - stops_accuracy: 0.8121 - val_loss: 3.2193 - val_starts_loss: 1.5900 - val_stops_loss: 1.5779 - val_starts_accuracy: 0.5868 - val_stops_accuracy: 0.6228\n",
      "Epoch 189/200\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 1.4135 - starts_loss: 0.7651 - stops_loss: 0.6475 - starts_accuracy: 0.7525 - stops_accuracy: 0.8125 - val_loss: 3.2211 - val_starts_loss: 1.5908 - val_stops_loss: 1.5788 - val_starts_accuracy: 0.5872 - val_stops_accuracy: 0.6231\n",
      "Epoch 190/200\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.4238 - starts_loss: 0.7660 - stops_loss: 0.6597 - starts_accuracy: 0.7521 - stops_accuracy: 0.8071 - val_loss: 3.2221 - val_starts_loss: 1.5908 - val_stops_loss: 1.5798 - val_starts_accuracy: 0.5866 - val_stops_accuracy: 0.6230\n",
      "Epoch 191/200\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 1.4217 - starts_loss: 0.7647 - stops_loss: 0.6547 - starts_accuracy: 0.7514 - stops_accuracy: 0.8076 - val_loss: 3.2223 - val_starts_loss: 1.5907 - val_stops_loss: 1.5800 - val_starts_accuracy: 0.5864 - val_stops_accuracy: 0.6233\n",
      "Epoch 192/200\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 1.4160 - starts_loss: 0.7663 - stops_loss: 0.6463 - starts_accuracy: 0.7538 - stops_accuracy: 0.8076 - val_loss: 3.2218 - val_starts_loss: 1.5905 - val_stops_loss: 1.5800 - val_starts_accuracy: 0.5864 - val_stops_accuracy: 0.6231\n",
      "Epoch 193/200\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 1.4157 - starts_loss: 0.7687 - stops_loss: 0.6509 - starts_accuracy: 0.7544 - stops_accuracy: 0.8119 - val_loss: 3.2218 - val_starts_loss: 1.5903 - val_stops_loss: 1.5803 - val_starts_accuracy: 0.5866 - val_stops_accuracy: 0.6233\n",
      "Epoch 194/200\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 1.4214 - starts_loss: 0.7635 - stops_loss: 0.6537 - starts_accuracy: 0.7532 - stops_accuracy: 0.8080 - val_loss: 3.2218 - val_starts_loss: 1.5903 - val_stops_loss: 1.5802 - val_starts_accuracy: 0.5868 - val_stops_accuracy: 0.6231\n",
      "Epoch 195/200\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 1.4209 - starts_loss: 0.7723 - stops_loss: 0.6467 - starts_accuracy: 0.7511 - stops_accuracy: 0.8115 - val_loss: 3.2214 - val_starts_loss: 1.5905 - val_stops_loss: 1.5797 - val_starts_accuracy: 0.5868 - val_stops_accuracy: 0.6231\n",
      "Epoch 196/200\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 1.4182 - starts_loss: 0.7691 - stops_loss: 0.6466 - starts_accuracy: 0.7497 - stops_accuracy: 0.8127 - val_loss: 3.2211 - val_starts_loss: 1.5902 - val_stops_loss: 1.5798 - val_starts_accuracy: 0.5868 - val_stops_accuracy: 0.6231\n",
      "Epoch 197/200\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 1.4280 - starts_loss: 0.7730 - stops_loss: 0.6565 - starts_accuracy: 0.7531 - stops_accuracy: 0.8057 - val_loss: 3.2212 - val_starts_loss: 1.5904 - val_stops_loss: 1.5797 - val_starts_accuracy: 0.5862 - val_stops_accuracy: 0.6231\n",
      "Epoch 198/200\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 1.4112 - starts_loss: 0.7669 - stops_loss: 0.6447 - starts_accuracy: 0.7556 - stops_accuracy: 0.8112 - val_loss: 3.2224 - val_starts_loss: 1.5912 - val_stops_loss: 1.5801 - val_starts_accuracy: 0.5862 - val_stops_accuracy: 0.6233\n",
      "Epoch 199/200\n",
      "20803/20803 [==============================] - 13s 622us/sample - loss: 1.4196 - starts_loss: 0.7673 - stops_loss: 0.6493 - starts_accuracy: 0.7530 - stops_accuracy: 0.8104 - val_loss: 3.2230 - val_starts_loss: 1.5915 - val_stops_loss: 1.5801 - val_starts_accuracy: 0.5864 - val_stops_accuracy: 0.6235\n",
      "Epoch 200/200\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 1.4142 - starts_loss: 0.7627 - stops_loss: 0.6495 - starts_accuracy: 0.7527 - stops_accuracy: 0.8097 - val_loss: 3.2238 - val_starts_loss: 1.5916 - val_stops_loss: 1.5809 - val_starts_accuracy: 0.5866 - val_stops_accuracy: 0.6233\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x={\"att_flags\":X_att_train,\n",
    "                       \"words\":X_train},\n",
    "                    y={\"starts\":Y_starts_train.argmax(axis=1),\n",
    "                       \"stops\":Y_stops_train.argmax(axis=1)},\n",
    "                    shuffle=True,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    validation_data=({\"att_flags\":X_att_val, \"words\":X_val},\n",
    "                                     {\"starts\":Y_starts_val.argmax(axis=1), \"stops\":Y_stops_val.argmax(axis=1)}),\n",
    "                    verbose=1,\n",
    "                    callbacks=[clr, mcp]) #es, rlrop, tb, mcp,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#metric_names = ['loss' ,'accuracy']\n",
    "metric_names = [\"loss\", \"starts_loss\", \"stops_loss\", \"starts_accuracy\", \"stops_accuracy\"]\n",
    "\n",
    "for i, j in zip(metric_names, ['val_'+i for i in metric_names]):\n",
    "    plt.plot(history.history[i])\n",
    "    plt.plot(history.history[j])\n",
    "    plt.title('Model '+i)\n",
    "    plt.ylabel(i.upper())\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_model.save(\"../results/\"+MODEL_PREFIX+\"EndCheckpoint.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = tf.keras.models.load_model(\n",
    "    filepath=\"../results/\"+MODEL_PREFIX+\"BestCheckpoint.h5\",\n",
    "    compile=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5201/5201 [==============================] - 1s 254us/sample - loss: 2.9827 - starts_loss: 1.5264 - stops_loss: 1.4567 - starts_accuracy: 0.5787 - stops_accuracy: 0.6180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.9827149592324234, 1.5263637, 1.4566754, 0.5787349, 0.61795807]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x = {\"att_flags\":X_att_val, \"words\":X_val},\n",
    "               y={\"starts\":Y_starts_val.argmax(axis=1), \"stops\":Y_stops_val.argmax(axis=1)},\n",
    "               batch_size=PREDICT_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(x = {\"att_flags\":X_att_train, \"words\":X_train},\n",
    "                           batch_size=PREDICT_BATCH_SIZE)\n",
    "pred_val = model.predict(x = {\"att_flags\":X_att_val, \"words\":X_val},\n",
    "                         batch_size=PREDICT_BATCH_SIZE)\n",
    "pred_test = model.predict(x = {\"att_flags\":X_att_test, \"words\":X_test},\n",
    "                          batch_size=PREDICT_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_starts_train, pred_stops_train = pred_train[0], pred_train[1]\n",
    "pred_starts_val, pred_stops_val = pred_val[0], pred_val[1]\n",
    "pred_starts_test, pred_stops_test = pred_test[0], pred_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20803, 110) (20803, 110)\n",
      "(5201, 110) (5201, 110)\n",
      "(3534, 110) (3534, 110)\n"
     ]
    }
   ],
   "source": [
    "print(pred_starts_train.shape, pred_stops_train.shape)\n",
    "print(pred_starts_val.shape, pred_stops_val.shape)\n",
    "print(pred_starts_test.shape, pred_stops_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = {\n",
    "    \"train\":{\n",
    "        \"starts\":{\n",
    "            \"y_true\":Y_starts_train.argmax(axis=1),\n",
    "            \"y_pred\":pred_starts_train.argmax(axis=1)\n",
    "        },\n",
    "        \"stops\":{\n",
    "            \"y_true\":Y_stops_train.argmax(axis=1),\n",
    "            \"y_pred\":pred_stops_train.argmax(axis=1)\n",
    "        }\n",
    "    },\n",
    "    \"valid\":{\n",
    "        \"starts\":{\n",
    "            \"y_true\":Y_starts_val.argmax(axis=1),\n",
    "            \"y_pred\":pred_starts_val.argmax(axis=1)\n",
    "        },\n",
    "        \"stops\":{\n",
    "            \"y_true\":Y_stops_train.argmax(axis=1),\n",
    "            \"y_pred\":pred_stops_train.argmax(axis=1)\n",
    "        }        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.07 \t|| train \t|| starts \t|| accuracy_score\n",
      "79.66 \t|| train \t|| stops \t|| accuracy_score\n",
      "57.87 \t|| valid \t|| starts \t|| accuracy_score\n",
      "79.66 \t|| valid \t|| stops \t|| accuracy_score\n",
      "================================================================\n",
      "25.92 \t|| train \t|| starts \t|| f1_score\n",
      "63.67 \t|| train \t|| stops \t|| f1_score\n",
      "11.56 \t|| valid \t|| starts \t|| f1_score\n",
      "63.67 \t|| valid \t|| stops \t|| f1_score\n",
      "================================================================\n",
      "30.95 \t|| train \t|| starts \t|| precision_score\n",
      "63.23 \t|| train \t|| stops \t|| precision_score\n",
      "12.01 \t|| valid \t|| starts \t|| precision_score\n",
      "63.23 \t|| valid \t|| stops \t|| precision_score\n",
      "================================================================\n",
      "27.34 \t|| train \t|| starts \t|| recall_score\n",
      "64.98 \t|| train \t|| stops \t|| recall_score\n",
      "12.52 \t|| valid \t|| starts \t|| recall_score\n",
      "64.98"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\deepak\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \t|| valid \t|| stops \t|| recall_score\n",
      "================================================================\n",
      "\t|| train \t|| starts \t|| confusion_matrix \t|| ../results/ConfusionMatrix_V11_train_starts.csv\n",
      "\t|| train \t|| stops \t|| confusion_matrix \t|| ../results/ConfusionMatrix_V11_train_stops.csv\n",
      "\t|| valid \t|| starts \t|| confusion_matrix \t|| ../results/ConfusionMatrix_V11_valid_starts.csv\n",
      "\t|| valid \t|| stops \t|| confusion_matrix \t|| ../results/ConfusionMatrix_V11_valid_stops.csv\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "def print_metrics():\n",
    "    funcs = [accuracy_score, f1_score, precision_score, recall_score, confusion_matrix]\n",
    "    for f in funcs:\n",
    "        for data_set in [\"train\",\"valid\"]:\n",
    "            for var in [\"starts\", \"stops\"]:\n",
    "                if f in [accuracy_score]:\n",
    "                    res = f(**preds[data_set][var])\n",
    "                    print(\"{:.2f}\".format(100 * res), \"\\t||\", data_set, \"\\t||\", var, \"\\t||\", f.__name__)\n",
    "                elif f in [confusion_matrix]:\n",
    "                    res = f(**preds[data_set][var], labels = np.arange(max_len))\n",
    "                    np.savetxt(X=res, fmt='%i', delimiter=\",\",\n",
    "                               fname=\"../results/ConfusionMatrix_\"+MODEL_PREFIX+\"_\"+data_set+\"_\"+var+\".csv\")\n",
    "                    print(\"\\t||\", data_set, \"\\t||\", var, \"\\t||\", f.__name__, \"\\t||\", \n",
    "                          \"../results/ConfusionMatrix_\"+MODEL_PREFIX+\"_\"+data_set+\"_\"+var+\".csv\")\n",
    "                else:\n",
    "                    res = f(**preds[data_set][var], average=\"macro\")\n",
    "                    print(\"{:.2f}\".format(100 * res), \"\\t||\", data_set, \"\\t||\", var, \"\\t||\", f.__name__)\n",
    "        print(\"================================================================\")\n",
    "\n",
    "print_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_words_train = [[vocab_itos[j] for j in i if j!=0] for num,i in enumerate(Y_train)]\n",
    "Y_words_val = [[vocab_itos[j] for j in i if j!=0] for num,i in enumerate(Y_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17832\n",
      "4778\n",
      "3232\n"
     ]
    }
   ],
   "source": [
    "print(sum([s<e for s,e in zip(pred_starts_train.argmax(axis=1), pred_stops_train.argmax(axis=1))]))\n",
    "print(sum([s<e for s,e in zip(pred_starts_val.argmax(axis=1), pred_stops_val.argmax(axis=1))]))\n",
    "print(sum([s<e for s,e in zip(pred_starts_test.argmax(axis=1), pred_stops_test.argmax(axis=1))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_words_train = [t[s:e+1] if s<e else t[e:-3] for t,s,e in zip([[vocab_itos[j] for j in i  if j!=0] for i in X_train], pred_starts_train.argmax(axis=1), pred_stops_train.argmax(axis=1))]\n",
    "pred_words_val = [t[s:e+1] if s<e else t[e:-3] for t,s,e in zip([[vocab_itos[j] for j in i  if j!=0] for i in X_val], pred_starts_val.argmax(axis=1), pred_stops_val.argmax(axis=1))]\n",
    "pred_words_test = [t[s:e+1] if s<e else t[e:-3] for t,s,e in zip([[vocab_itos[j] for j in i  if j!=0] for i in X_test], pred_starts_test.argmax(axis=1), pred_stops_test.argmax(axis=1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(str1, str2):\n",
    "    a = set(str1)\n",
    "    b = set(str2)\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Jaccard Score 0.7252863016730643\n",
      "Validation Jaccard Score 0.6195739765226269\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Jaccard Score\", np.mean([jaccard(str1=i, str2=j) for i,j in zip(Y_words_train, pred_words_train)]))\n",
    "print(\"Validation Jaccard Score\", np.mean([jaccard(str1=i, str2=j) for i,j in zip(Y_words_val, pred_words_val)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_labels = {i:j for i,j in enumerate(df.sentiment_code.cat.categories)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spot Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spot_check(index_to_check, mode):\n",
    "    print(\"================== Sample #\", index_to_check, \"==================\")\n",
    "    if mode == \"train\":\n",
    "        print(\"Selected_text:\")\n",
    "        print('\\t', Y_words[train_idx[index_to_check]])\n",
    "        print(\"Predicted_text:\")\n",
    "        print('\\t', pred_words_train[index_to_check])\n",
    "        print(\"Predictions:\")\n",
    "        print('\\t',*[[\"%.2f\"%j, \n",
    "                      \"%.2f\"%k,\n",
    "                      i,\n",
    "                      X_words[train_idx[index_to_check]][num]] for num, (i,j,k) in enumerate(zip(X_train[index_to_check].tolist(),\n",
    "                                                                                               pred_starts_train[index_to_check].tolist(),\n",
    "                                                                                               pred_stops_train[index_to_check].tolist())) if i!=0], sep=\"\\n\\t\")\n",
    "        \n",
    "    elif mode == \"validation\":\n",
    "        print(\"Selected_text:\")\n",
    "        print('\\t', Y_words[val_idx[index_to_check]])\n",
    "        print(\"Predicted_text:\")\n",
    "        print('\\t', pred_words_val[index_to_check])\n",
    "        print(\"Predictions:\")\n",
    "        print('\\t',*[[\"%.2f\"%j, \n",
    "                      \"%.2f\"%k,\n",
    "                      i,\n",
    "                      X_words[val_idx[index_to_check]][num]] for num, (i,j,k) in enumerate(zip(X_val[index_to_check].tolist(),\n",
    "                                                                                               pred_starts_val[index_to_check].tolist(),\n",
    "                                                                                               pred_stops_val[index_to_check].tolist())) if i!=0], sep=\"\\n\\t\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Selected_text:\")\n",
    "        print('\\t', \"Not Available\")\n",
    "        print(\"Predicted_text:\")\n",
    "        print('\\t', pred_words_test[index_to_check])\n",
    "        print(\"Predictions:\")\n",
    "        print('\\t',*[[\"%.2f\"%j, \n",
    "                      \"%.2f\"%k,\n",
    "                      i,\n",
    "                      X_words_test[index_to_check][num]] for num, (i,j,k) in enumerate(zip(X_test[index_to_check].tolist(),\n",
    "                                                                                               pred_starts_test[index_to_check].tolist(),\n",
    "                                                                                               pred_stops_test[index_to_check].tolist())) if i!=0], sep=\"\\n\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Sample # 10 ==================\n",
      "Selected_text:\n",
      "\t ['says', 'good', '(', 'or', 'should', 'i', 'say', 'bad', '?', ')', 'afternoon', '!']\n",
      "Predicted_text:\n",
      "\t ['says', 'good', '(', 'or', 'should', 'i', 'say', 'bad', '?', ')', 'afternoon', '!', 'http', ':', '/', '/', 'plurk', '.', 'com', '/', 'p', '/', 'xxxUNK']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.88', '0.03', 1103, 'says']\n",
      "\t['0.01', '0.03', 448, 'good']\n",
      "\t['0.01', '0.02', 81, '(']\n",
      "\t['0.00', '0.02', 758, 'or']\n",
      "\t['0.00', '0.01', 350, 'should']\n",
      "\t['0.00', '0.02', 7, 'i']\n",
      "\t['0.01', '0.03', 460, 'say']\n",
      "\t['0.01', '0.03', 318, 'bad']\n",
      "\t['0.01', '0.06', 74, '?']\n",
      "\t['0.01', '0.14', 84, ')']\n",
      "\t['0.01', '0.04', 1434, 'afternoon']\n",
      "\t['0.01', '0.18', 22, '!']\n",
      "\t['0.00', '0.02', 47, 'http']\n",
      "\t['0.00', '0.01', 48, ':']\n",
      "\t['0.00', '0.01', 49, '/']\n",
      "\t['0.00', '0.01', 49, '/']\n",
      "\t['0.00', '0.01', 376, 'plurk']\n",
      "\t['0.00', '0.01', 28, '.']\n",
      "\t['0.00', '0.01', 51, 'com']\n",
      "\t['0.00', '0.00', 49, '/']\n",
      "\t['0.00', '0.01', 95, 'p']\n",
      "\t['0.00', '0.02', 49, '/']\n",
      "\t['0.00', '0.21', 1, 'wxpdj']\n",
      "\t['0.00', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.01', 12, 'xxxEND']\n",
      "================== Sample # 11 ==================\n",
      "Selected_text:\n",
      "\t ['goodnight']\n",
      "Predicted_text:\n",
      "\t ['goodnight', 'all', 'in', 'the', 'twitterverse']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.79', '0.86', 2223, 'goodnight']\n",
      "\t['0.11', '0.09', 66, 'all']\n",
      "\t['0.04', '0.02', 19, 'in']\n",
      "\t['0.03', '0.01', 42, 'the']\n",
      "\t['0.01', '0.01', 2113, 'twitterverse']\n",
      "\t['0.01', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 12 ==================\n",
      "Selected_text:\n",
      "\t ['is', 'resting', '.', 'ahhhhh', '.', 'i', 'feel', 'good']\n",
      "Predicted_text:\n",
      "\t ['is', 'resting', '.', 'ahhhhh', '.', 'i', 'feel', 'good']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.79', '0.00', 26, 'is']\n",
      "\t['0.01', '0.00', 6136, 'resting']\n",
      "\t['0.01', '0.00', 28, '.']\n",
      "\t['0.01', '0.00', 3328, 'ahhhhh']\n",
      "\t['0.02', '0.00', 28, '.']\n",
      "\t['0.03', '0.00', 7, 'i']\n",
      "\t['0.06', '0.00', 338, 'feel']\n",
      "\t['0.04', '0.99', 448, 'good']\n",
      "\t['0.01', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 13 ==================\n",
      "Selected_text:\n",
      "\t ['awww', ',', 'that`s', 'nice', '.']\n",
      "Predicted_text:\n",
      "\t ['awww', ',', 'that`s', 'nice', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.22', '0.07', 2124, 'awww']\n",
      "\t['0.18', '0.16', 5, ',']\n",
      "\t['0.15', '0.11', 240, 'that`s']\n",
      "\t['0.12', '0.11', 397, 'nice']\n",
      "\t['0.11', '0.22', 28, '.']\n",
      "\t['0.06', '0.12', 17, 'you']\n",
      "\t['0.04', '0.06', 72, 'both']\n",
      "\t['0.02', '0.03', 237, 'make']\n",
      "\t['0.02', '0.02', 142, 'a']\n",
      "\t['0.01', '0.01', 102, 'really']\n",
      "\t['0.01', '0.02', 2048, 'beautiful']\n",
      "\t['0.01', '0.01', 912, 'couple']\n",
      "\t['0.01', '0.01', 5, ',']\n",
      "\t['0.00', '0.02', 17, 'you']\n",
      "\t['0.00', '0.00', 8708, 'balance']\n",
      "\t['0.00', '0.00', 1127, 'each']\n",
      "\t['0.00', '0.00', 353, 'other']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 14 ==================\n",
      "Selected_text:\n",
      "\t ['disappointed']\n",
      "Predicted_text:\n",
      "\t ['disappointed', 'she', 'didn`t', 'win', 'teh', 'xxxUNK', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.76', '0.47', 924, 'disappointed']\n",
      "\t['0.08', '0.17', 447, 'she']\n",
      "\t['0.05', '0.07', 475, 'didn`t']\n",
      "\t['0.05', '0.08', 738, 'win']\n",
      "\t['0.03', '0.08', 6019, 'teh']\n",
      "\t['0.01', '0.02', 1, 'glassez']\n",
      "\t['0.01', '0.07', 28, '.']\n",
      "\t['0.00', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 23, 'negative']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 15 ==================\n",
      "Selected_text:\n",
      "\t ['back', 'here', ',', 'i', 'was', 'busy', 'xd', 'wirting', 'stars', 'loves', ',', 'almos', '400', 'pages', 'xd', 'and', 'listenint', 'afh', 'and', 'tv']\n",
      "Predicted_text:\n",
      "\t ['back', 'here', ',', 'i', 'was', 'busy', 'xd', 'xxxUNK', 'stars', 'loves', ',', 'xxxUNK', '400', 'pages', 'xd', 'and', 'xxxUNK', 'xxxUNK', 'and', 'tv']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.98', '0.00', 224, 'back']\n",
      "\t['0.00', '0.00', 18, 'here']\n",
      "\t['0.00', '0.00', 5, ',']\n",
      "\t['0.00', '0.00', 7, 'i']\n",
      "\t['0.00', '0.00', 183, 'was']\n",
      "\t['0.00', '0.00', 275, 'busy']\n",
      "\t['0.00', '0.00', 2529, 'xd']\n",
      "\t['0.00', '0.00', 1, 'wirting']\n",
      "\t['0.00', '0.00', 2240, 'stars']\n",
      "\t['0.00', '0.00', 1482, 'loves']\n",
      "\t['0.00', '0.00', 5, ',']\n",
      "\t['0.00', '0.00', 1, 'almos']\n",
      "\t['0.00', '0.00', 5941, '400']\n",
      "\t['0.00', '0.00', 3439, 'pages']\n",
      "\t['0.00', '0.00', 2529, 'xd']\n",
      "\t['0.00', '0.00', 68, 'and']\n",
      "\t['0.00', '0.00', 1, 'listenint']\n",
      "\t['0.00', '0.00', 1, 'afh']\n",
      "\t['0.00', '0.00', 68, 'and']\n",
      "\t['0.00', '0.99', 1216, 'tv']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 16 ==================\n",
      "Selected_text:\n",
      "\t ['my', 'kind', 'of', 'night']\n",
      "Predicted_text:\n",
      "\t ['my', 'kind', 'of', 'night']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.01', '0.00', 44, 'we']\n",
      "\t['0.01', '0.00', 406, 'got']\n",
      "\t['0.01', '0.00', 1, 'jojo']\n",
      "\t['0.01', '0.00', 19, 'in']\n",
      "\t['0.01', '0.01', 55, 'for']\n",
      "\t['0.02', '0.01', 197, 'free']\n",
      "\t['0.03', '0.01', 68, 'and']\n",
      "\t['0.04', '0.01', 197, 'free']\n",
      "\t['0.05', '0.01', 2813, 'drinks']\n",
      "\t['0.11', '0.01', 55, 'for']\n",
      "\t['0.14', '0.05', 932, 'mom']\n",
      "\t['0.11', '0.05', 22, '!']\n",
      "\t['0.15', '0.03', 24, 'my']\n",
      "\t['0.14', '0.04', 1543, 'kind']\n",
      "\t['0.09', '0.13', 34, 'of']\n",
      "\t['0.06', '0.57', 559, 'night']\n",
      "\t['0.01', '0.02', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.01', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 17 ==================\n",
      "Selected_text:\n",
      "\t ['just', 'got', 'home', 'from', 'the', 'last', 'day', 'of', 'school', '.', 'graduation', 'tomorrow', '.']\n",
      "Predicted_text:\n",
      "\t ['just', 'got', 'home', 'from', 'the', 'last', 'day', 'of', 'school', '.', 'graduation', 'tomorrow', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.92', '0.00', 77, 'just']\n",
      "\t['0.00', '0.00', 406, 'got']\n",
      "\t['0.01', '0.00', 228, 'home']\n",
      "\t['0.00', '0.00', 120, 'from']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.00', '0.00', 285, 'last']\n",
      "\t['0.01', '0.00', 286, 'day']\n",
      "\t['0.00', '0.00', 34, 'of']\n",
      "\t['0.00', '0.00', 288, 'school']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.00', '0.00', 541, 'graduation']\n",
      "\t['0.00', '0.00', 251, 'tomorrow']\n",
      "\t['0.00', '0.98', 28, '.']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 18 ==================\n",
      "Selected_text:\n",
      "\t ['*', '*', '*', '*']\n",
      "Predicted_text:\n",
      "\t ['the', '*', '*', '*', '*', 'up']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.00', '0.00', 19, 'in']\n",
      "\t['0.02', '0.01', 142, 'a']\n",
      "\t['0.02', '0.01', 9548, 'drill']\n",
      "\t['0.02', '0.01', 1, 'sergeant`s']\n",
      "\t['0.02', '0.04', 118, 'voice']\n",
      "\t['0.03', '0.01', 48, ':']\n",
      "\t['0.05', '0.02', 1856, 'everybody']\n",
      "\t['0.05', '0.03', 1271, 'wake']\n",
      "\t['0.09', '0.02', 42, 'the']\n",
      "\t['0.08', '0.06', 35, '*']\n",
      "\t['0.04', '0.03', 35, '*']\n",
      "\t['0.06', '0.09', 35, '*']\n",
      "\t['0.08', '0.09', 35, '*']\n",
      "\t['0.08', '0.11', 225, 'up']\n",
      "\t['0.08', '0.08', 22, '!']\n",
      "\t['0.05', '0.04', 22, '!']\n",
      "\t['0.03', '0.05', 22, '!']\n",
      "\t['0.03', '0.06', 35, '*']\n",
      "\t['0.02', '0.04', 9838, 'flicks']\n",
      "\t['0.03', '0.02', 41, 'on']\n",
      "\t['0.04', '0.01', 3301, 'everyone`s']\n",
      "\t['0.02', '0.03', 8221, 'lights']\n",
      "\t['0.01', '0.02', 35, '*']\n",
      "\t['0.01', '0.01', 192, 'it`s']\n",
      "\t['0.01', '0.01', 5001, '500']\n",
      "\t['0.00', '0.01', 9839, 'est']\n",
      "\t['0.00', '0.00', 4080, 'rise']\n",
      "\t['0.01', '0.01', 68, 'and']\n",
      "\t['0.01', '0.01', 2998, 'shine']\n",
      "\t['0.00', '0.00', 1, 'beetches']\n",
      "\t['0.00', '0.01', 22, '!']\n",
      "\t['0.00', '0.00', 22, '!']\n",
      "\t['0.00', '0.00', 426, 'lol']\n",
      "\t['0.00', '0.00', 3953, 'jk']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 23, 'negative']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 19 ==================\n",
      "Selected_text:\n",
      "\t ['really', 'good', 'job', '!']\n",
      "Predicted_text:\n",
      "\t ['really', 'good', 'job', '!']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.01', '0.00', 1997, 'gave']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.00', '0.00', 3155, 'bikes']\n",
      "\t['0.00', '0.00', 142, 'a']\n",
      "\t['0.00', '0.00', 1, 'thorough']\n",
      "\t['0.00', '0.00', 2140, 'wash']\n",
      "\t['0.00', '0.00', 5, ',']\n",
      "\t['0.01', '0.00', 1, 'degrease']\n",
      "\t['0.01', '0.00', 144, 'it']\n",
      "\t['0.01', '0.00', 68, 'and']\n",
      "\t['0.02', '0.00', 3315, 'grease']\n",
      "\t['0.03', '0.00', 144, 'it']\n",
      "\t['0.03', '0.00', 28, '.']\n",
      "\t['0.04', '0.00', 425, 'think']\n",
      "\t['0.05', '0.00', 7, 'i']\n",
      "\t['0.09', '0.00', 765, 'did']\n",
      "\t['0.16', '0.00', 142, 'a']\n",
      "\t['0.23', '0.02', 102, 'really']\n",
      "\t['0.14', '0.12', 448, 'good']\n",
      "\t['0.05', '0.02', 167, 'job']\n",
      "\t['0.07', '0.81', 22, '!']\n",
      "\t['0.02', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 69, 'positive']\n",
      "\t['0.01', '0.00', 12, 'xxxEND']\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,20):\n",
    "    spot_check(i, mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Sample # 200 ==================\n",
      "Selected_text:\n",
      "\t ['bad', 'day', 'the', 'day', 'you', 'realize', 'what', 'mess', 'you`ve', 'put', 'me', 'through', 'will', 'be', 'one', 'of', 'the', 'happiest', 'days', 'of', 'my', 'life', '.', '.', '.']\n",
      "Predicted_text:\n",
      "\t ['bad', 'day', 'the', 'day', 'you', 'realize', 'what', 'mess', 'you`ve', 'put', 'me', 'through', 'will', 'be', 'one', 'of', 'the', 'happiest', 'days', 'of', 'my', 'life', '.', '.', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['1.00', '0.00', 318, 'bad']\n",
      "\t['0.00', '0.00', 286, 'day']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.00', '0.00', 286, 'day']\n",
      "\t['0.00', '0.00', 17, 'you']\n",
      "\t['0.00', '0.00', 972, 'realize']\n",
      "\t['0.00', '0.00', 29, 'what']\n",
      "\t['0.00', '0.00', 345, 'mess']\n",
      "\t['0.00', '0.00', 973, 'you`ve']\n",
      "\t['0.00', '0.00', 39, 'put']\n",
      "\t['0.00', '0.00', 27, 'me']\n",
      "\t['0.00', '0.00', 247, 'through']\n",
      "\t['0.00', '0.00', 15, 'will']\n",
      "\t['0.00', '0.00', 89, 'be']\n",
      "\t['0.00', '0.00', 310, 'one']\n",
      "\t['0.00', '0.00', 34, 'of']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.00', '0.00', 974, 'happiest']\n",
      "\t['0.00', '0.00', 136, 'days']\n",
      "\t['0.00', '0.00', 34, 'of']\n",
      "\t['0.00', '0.00', 24, 'my']\n",
      "\t['0.00', '0.00', 868, 'life']\n",
      "\t['0.00', '0.01', 28, '.']\n",
      "\t['0.00', '0.01', 28, '.']\n",
      "\t['0.00', '0.93', 28, '.']\n",
      "\t['0.00', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 201 ==================\n",
      "Selected_text:\n",
      "\t ['visiting', 'family', 'in', 'hospital', '=', 'not', 'fun']\n",
      "Predicted_text:\n",
      "\t ['visiting', 'family', 'in', 'hospital', '=', 'not', 'fun']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.20', '0.00', 346, 'visiting']\n",
      "\t['0.06', '0.01', 173, 'family']\n",
      "\t['0.08', '0.01', 19, 'in']\n",
      "\t['0.13', '0.01', 455, 'hospital']\n",
      "\t['0.13', '0.01', 94, '=']\n",
      "\t['0.17', '0.01', 149, 'not']\n",
      "\t['0.15', '0.95', 63, 'fun']\n",
      "\t['0.02', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.01', '0.00', 23, 'negative']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 202 ==================\n",
      "Selected_text:\n",
      "\t ['wish', 'me', 'luck']\n",
      "Predicted_text:\n",
      "\t ['me', 'luck', '.', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.10', '0.00', 9, 'going']\n",
      "\t['0.01', '0.00', 88, 'to']\n",
      "\t['0.02', '0.00', 433, 'take']\n",
      "\t['0.01', '0.00', 24, 'my']\n",
      "\t['0.02', '0.01', 285, 'last']\n",
      "\t['0.03', '0.00', 1897, 'final']\n",
      "\t['0.06', '0.00', 28, '.']\n",
      "\t['0.05', '0.01', 28, '.']\n",
      "\t['0.07', '0.01', 28, '.']\n",
      "\t['0.17', '0.04', 520, 'wish']\n",
      "\t['0.21', '0.05', 27, 'me']\n",
      "\t['0.09', '0.07', 2010, 'luck']\n",
      "\t['0.07', '0.04', 28, '.']\n",
      "\t['0.04', '0.73', 28, '.']\n",
      "\t['0.01', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.01', '0.00', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 203 ==================\n",
      "Selected_text:\n",
      "\t ['lol']\n",
      "Predicted_text:\n",
      "\t ['fun', '!']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.02', '0.00', 426, 'lol']\n",
      "\t['0.00', '0.00', 1967, 'simpsons']\n",
      "\t['0.01', '0.00', 1, 's20e19']\n",
      "\t['0.00', '0.01', 48, ':']\n",
      "\t['0.01', '0.01', 332, \"'\"]\n",
      "\t['0.01', '0.00', 813, 'first']\n",
      "\t['0.01', '0.00', 286, 'day']\n",
      "\t['0.01', '0.00', 358, 'at']\n",
      "\t['0.01', '0.00', 305, 'your']\n",
      "\t['0.02', '0.01', 163, 'new']\n",
      "\t['0.04', '0.01', 288, 'school']\n",
      "\t['0.06', '0.03', 5, ',']\n",
      "\t['0.05', '0.02', 151, 'so']\n",
      "\t['0.07', '0.01', 3838, 'lisa']\n",
      "\t['0.09', '0.04', 48, ':']\n",
      "\t['0.14', '0.03', 4, 'have']\n",
      "\t['0.14', '0.18', 63, 'fun']\n",
      "\t['0.11', '0.19', 22, '!']\n",
      "\t['0.05', '0.07', 68, 'and']\n",
      "\t['0.02', '0.04', 8516, 'bart']\n",
      "\t['0.03', '0.08', 48, ':']\n",
      "\t['0.03', '0.09', 424, 'don`t']\n",
      "\t['0.00', '0.04', 22, '!']\n",
      "\t['0.01', '0.06', 332, \"'\"]\n",
      "\t['0.01', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 69, 'positive']\n",
      "\t['0.00', '0.01', 12, 'xxxEND']\n",
      "================== Sample # 204 ==================\n",
      "Selected_text:\n",
      "\t ['hahaha', 'sa', 'una', 'lang', 'yan', '!', 'i', 'started', 'with', '40', 'minutes', 'ng', '5k', '.', 'that', 'was', 'a', 'year', 'ago', '.']\n",
      "Predicted_text:\n",
      "\t ['hahaha', 'sa', 'una', 'lang', 'yan', '!', 'i', 'started', 'with', '40', 'minutes', 'ng', '5k', '.', 'that', 'was', 'a', 'year', 'ago', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.92', '0.00', 939, 'hahaha']\n",
      "\t['0.00', '0.00', 4426, 'sa']\n",
      "\t['0.01', '0.00', 8599, 'una']\n",
      "\t['0.00', '0.00', 2847, 'lang']\n",
      "\t['0.00', '0.00', 8600, 'yan']\n",
      "\t['0.00', '0.00', 22, '!']\n",
      "\t['0.00', '0.00', 7, 'i']\n",
      "\t['0.00', '0.00', 1877, 'started']\n",
      "\t['0.00', '0.00', 278, 'with']\n",
      "\t['0.00', '0.00', 2965, '40']\n",
      "\t['0.01', '0.01', 713, 'minutes']\n",
      "\t['0.00', '0.00', 2844, 'ng']\n",
      "\t['0.00', '0.00', 6604, '5k']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.00', '0.00', 82, 'that']\n",
      "\t['0.00', '0.01', 183, 'was']\n",
      "\t['0.00', '0.00', 142, 'a']\n",
      "\t['0.00', '0.00', 882, 'year']\n",
      "\t['0.00', '0.01', 913, 'ago']\n",
      "\t['0.00', '0.92', 28, '.']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 205 ==================\n",
      "Selected_text:\n",
      "\t ['_', 'devil1', 'big', 'brother', 'quiz', '?', 'what', '?', '!', 'i`m', 'too', 'busy', 'rocking', 'out', 'on', 'guitar', 'hero', ',', 'i', 'didn`t', 'notice', 'any', 'such', 'thing']\n",
      "Predicted_text:\n",
      "\t ['_', 'xxxUNK', 'big', 'brother', 'quiz', '?', 'what', '?', '!', 'i`m', 'too', 'busy', 'rocking', 'out', 'on', 'guitar', 'hero', ',', 'i', 'didn`t', 'notice', 'any', 'such', 'thing']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.85', '0.00', 405, '_']\n",
      "\t['0.01', '0.00', 1, 'devil1']\n",
      "\t['0.01', '0.00', 292, 'big']\n",
      "\t['0.00', '0.00', 1087, 'brother']\n",
      "\t['0.00', '0.00', 3851, 'quiz']\n",
      "\t['0.00', '0.00', 74, '?']\n",
      "\t['0.00', '0.00', 29, 'what']\n",
      "\t['0.00', '0.00', 74, '?']\n",
      "\t['0.00', '0.00', 22, '!']\n",
      "\t['0.01', '0.00', 96, 'i`m']\n",
      "\t['0.01', '0.00', 227, 'too']\n",
      "\t['0.01', '0.00', 275, 'busy']\n",
      "\t['0.00', '0.00', 994, 'rocking']\n",
      "\t['0.00', '0.00', 215, 'out']\n",
      "\t['0.00', '0.00', 41, 'on']\n",
      "\t['0.00', '0.00', 2389, 'guitar']\n",
      "\t['0.01', '0.00', 261, 'hero']\n",
      "\t['0.01', '0.00', 5, ',']\n",
      "\t['0.01', '0.00', 7, 'i']\n",
      "\t['0.01', '0.00', 475, 'didn`t']\n",
      "\t['0.01', '0.00', 2396, 'notice']\n",
      "\t['0.01', '0.00', 853, 'any']\n",
      "\t['0.00', '0.01', 416, 'such']\n",
      "\t['0.00', '0.97', 311, 'thing']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 206 ==================\n",
      "Selected_text:\n",
      "\t ['actually', ',', 'by', 'the', 'time', 'i', 'get', 'there', ',', 'the', 'train', 'would', 'have', 'arrived', '.', '.', '.']\n",
      "Predicted_text:\n",
      "\t ['actually', ',', 'by', 'the', 'time', 'i', 'get', 'there', ',', 'the', 'train', 'would', 'have', 'arrived', '.', '.', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.95', '0.00', 732, 'actually']\n",
      "\t['0.00', '0.00', 5, ',']\n",
      "\t['0.00', '0.00', 106, 'by']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.00', '0.00', 504, 'time']\n",
      "\t['0.00', '0.00', 7, 'i']\n",
      "\t['0.00', '0.00', 99, 'get']\n",
      "\t['0.00', '0.00', 216, 'there']\n",
      "\t['0.00', '0.00', 5, ',']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.00', '0.00', 1752, 'train']\n",
      "\t['0.00', '0.00', 145, 'would']\n",
      "\t['0.00', '0.00', 4, 'have']\n",
      "\t['0.00', '0.00', 3306, 'arrived']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.00', '0.96', 28, '.']\n",
      "\t['0.00', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 207 ==================\n",
      "Selected_text:\n",
      "\t ['sounds', 'good', ',', 'the', 'one', 'i', 'was', 'too', 'was', 'also', 'fun']\n",
      "Predicted_text:\n",
      "\t ['was', 'also', 'fun']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.10', '0.00', 423, 'sounds']\n",
      "\t['0.03', '0.00', 448, 'good']\n",
      "\t['0.11', '0.01', 5, ',']\n",
      "\t['0.08', '0.01', 42, 'the']\n",
      "\t['0.07', '0.01', 310, 'one']\n",
      "\t['0.05', '0.01', 7, 'i']\n",
      "\t['0.10', '0.01', 183, 'was']\n",
      "\t['0.08', '0.00', 227, 'too']\n",
      "\t['0.13', '0.01', 183, 'was']\n",
      "\t['0.11', '0.00', 356, 'also']\n",
      "\t['0.10', '0.92', 63, 'fun']\n",
      "\t['0.01', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 208 ==================\n",
      "Selected_text:\n",
      "\t ['decreasing']\n",
      "Predicted_text:\n",
      "\t ['showed', 'my', 'fluids', 'decreasing', 'slightly', '.', 'so', 'doesn`t', 'look', 'like', 'she`s', 'letting', 'me', 'out', 'of', 'this', 'bed', 'anytime']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.27', '0.02', 1112, 'showed']\n",
      "\t['0.03', '0.04', 24, 'my']\n",
      "\t['0.03', '0.04', 3935, 'fluids']\n",
      "\t['0.01', '0.03', 9167, 'decreasing']\n",
      "\t['0.02', '0.01', 1567, 'slightly']\n",
      "\t['0.01', '0.02', 28, '.']\n",
      "\t['0.02', '0.02', 151, 'so']\n",
      "\t['0.01', '0.03', 1279, 'doesn`t']\n",
      "\t['0.01', '0.03', 146, 'look']\n",
      "\t['0.01', '0.03', 103, 'like']\n",
      "\t['0.03', '0.02', 547, 'she`s']\n",
      "\t['0.02', '0.03', 4986, 'letting']\n",
      "\t['0.03', '0.03', 27, 'me']\n",
      "\t['0.03', '0.03', 215, 'out']\n",
      "\t['0.02', '0.01', 34, 'of']\n",
      "\t['0.04', '0.04', 276, 'this']\n",
      "\t['0.03', '0.05', 557, 'bed']\n",
      "\t['0.03', '0.08', 2022, 'anytime']\n",
      "\t['0.03', '0.08', 156, 'soon']\n",
      "\t['0.02', '0.05', 7, 'i']\n",
      "\t['0.02', '0.01', 4, 'have']\n",
      "\t['0.01', '0.01', 142, 'a']\n",
      "\t['0.01', '0.00', 1240, 'follow']\n",
      "\t['0.02', '0.01', 225, 'up']\n",
      "\t['0.01', '0.03', 76, 'u']\n",
      "\t['0.02', '0.01', 49, '/']\n",
      "\t['0.01', '0.01', 2148, 's']\n",
      "\t['0.01', '0.01', 574, 'next']\n",
      "\t['0.01', '0.07', 570, 'week']\n",
      "\t['0.01', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.01', '0.00', 23, 'negative']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 209 ==================\n",
      "Selected_text:\n",
      "\t ['jealous', '*']\n",
      "Predicted_text:\n",
      "\t ['.', 'there', 'is', 'one', 'down', 'the', 'rd', ',', 'but', 'it`s', 'no', 'longer', 'operational', ':', '|']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.01', '0.00', 405, '_']\n",
      "\t['0.01', '0.01', 706, 'r']\n",
      "\t['0.01', '0.01', 731, 'drive']\n",
      "\t['0.01', '0.00', 52, '-']\n",
      "\t['0.01', '0.01', 19, 'in']\n",
      "\t['0.01', '0.00', 22, '!']\n",
      "\t['0.02', '0.01', 74, '?']\n",
      "\t['0.02', '0.00', 2036, 'srsly']\n",
      "\t['0.01', '0.00', 22, '!']\n",
      "\t['0.03', '0.00', 74, '?']\n",
      "\t['0.03', '0.01', 35, '*']\n",
      "\t['0.03', '0.01', 408, 'jealous']\n",
      "\t['0.03', '0.01', 35, '*']\n",
      "\t['0.04', '0.02', 7, 'i']\n",
      "\t['0.05', '0.02', 4, 'have']\n",
      "\t['0.05', '0.08', 97, 'never']\n",
      "\t['0.04', '0.01', 817, 'ever']\n",
      "\t['0.06', '0.01', 132, 'been']\n",
      "\t['0.06', '0.02', 88, 'to']\n",
      "\t['0.04', '0.03', 310, 'one']\n",
      "\t['0.07', '0.02', 28, '.']\n",
      "\t['0.07', '0.03', 216, 'there']\n",
      "\t['0.03', '0.02', 26, 'is']\n",
      "\t['0.05', '0.03', 310, 'one']\n",
      "\t['0.04', '0.01', 585, 'down']\n",
      "\t['0.03', '0.04', 42, 'the']\n",
      "\t['0.02', '0.02', 1675, 'rd']\n",
      "\t['0.02', '0.02', 5, ',']\n",
      "\t['0.02', '0.01', 116, 'but']\n",
      "\t['0.02', '0.03', 192, 'it`s']\n",
      "\t['0.02', '0.04', 204, 'no']\n",
      "\t['0.00', '0.08', 727, 'longer']\n",
      "\t['0.00', '0.05', 4367, 'operational']\n",
      "\t['0.00', '0.02', 48, ':']\n",
      "\t['0.00', '0.26', 2428, '|']\n",
      "\t['0.00', '0.02', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.01', 23, 'negative']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n"
     ]
    }
   ],
   "source": [
    "for i in range(200,210):\n",
    "    spot_check(i, mode=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Sample # 10 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['total', 'bummer']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.02', '0.00', 24, 'my']\n",
      "\t['0.01', '0.00', 977, 'bike']\n",
      "\t['0.00', '0.00', 183, 'was']\n",
      "\t['0.00', '0.00', 39, 'put']\n",
      "\t['0.00', '0.00', 41, 'on']\n",
      "\t['0.00', '0.00', 3270, 'hold']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.01', '0.00', 28, '.']\n",
      "\t['0.01', '0.00', 350, 'should']\n",
      "\t['0.01', '0.00', 4, 'have']\n",
      "\t['0.01', '0.00', 2467, 'known']\n",
      "\t['0.02', '0.00', 82, 'that']\n",
      "\t['0.03', '0.00', 28, '.']\n",
      "\t['0.05', '0.00', 28, '.']\n",
      "\t['0.09', '0.00', 28, '.']\n",
      "\t['0.13', '0.00', 28, '.']\n",
      "\t['0.21', '0.00', 1286, 'argh']\n",
      "\t['0.28', '0.03', 1291, 'total']\n",
      "\t['0.04', '0.95', 5242, 'bummer']\n",
      "\t['0.04', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.01', '0.00', 23, 'negative']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 11 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['i', 'checked', '.', 'we', 'didn`t', 'win']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.96', '0.00', 7, 'i']\n",
      "\t['0.00', '0.00', 2486, 'checked']\n",
      "\t['0.01', '0.00', 28, '.']\n",
      "\t['0.00', '0.00', 44, 'we']\n",
      "\t['0.00', '0.00', 475, 'didn`t']\n",
      "\t['0.00', '0.99', 738, 'win']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 12 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['.', '.', 'and', 'you`re', 'on', 'twitter', '!', 'did', 'the', 'xxxUNK', 'xxxUNK', 'you', 'that', 'much', '?']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.88', '0.00', 28, '.']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.01', '0.00', 68, 'and']\n",
      "\t['0.00', '0.00', 956, 'you`re']\n",
      "\t['0.00', '0.00', 41, 'on']\n",
      "\t['0.00', '0.00', 231, 'twitter']\n",
      "\t['0.00', '0.00', 22, '!']\n",
      "\t['0.00', '0.00', 765, 'did']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.01', '0.00', 1, 'tavern']\n",
      "\t['0.02', '0.00', 1, 'bore']\n",
      "\t['0.01', '0.00', 17, 'you']\n",
      "\t['0.01', '0.00', 82, 'that']\n",
      "\t['0.02', '0.01', 86, 'much']\n",
      "\t['0.02', '0.99', 74, '?']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 13 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['kinda', 'sad']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.01', '0.00', 96, 'i`m']\n",
      "\t['0.00', '0.00', 19, 'in']\n",
      "\t['0.00', '0.00', 6180, 'va']\n",
      "\t['0.00', '0.00', 55, 'for']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.00', '0.00', 1231, 'weekend']\n",
      "\t['0.00', '0.00', 5, ',']\n",
      "\t['0.00', '0.00', 24, 'my']\n",
      "\t['0.00', '0.00', 1, 'youngest']\n",
      "\t['0.01', '0.00', 945, 'son']\n",
      "\t['0.01', '0.00', 1040, 'turns']\n",
      "\t['0.01', '0.00', 694, '2']\n",
      "\t['0.01', '0.00', 251, 'tomorrow']\n",
      "\t['0.01', '0.01', 28, '.']\n",
      "\t['0.01', '0.00', 28, '.']\n",
      "\t['0.02', '0.01', 28, '.']\n",
      "\t['0.02', '0.00', 28, '.']\n",
      "\t['0.04', '0.01', 28, '.']\n",
      "\t['0.06', '0.02', 28, '.']\n",
      "\t['0.06', '0.04', 144, 'it']\n",
      "\t['0.11', '0.01', 1151, 'makes']\n",
      "\t['0.11', '0.04', 27, 'me']\n",
      "\t['0.17', '0.06', 1814, 'kinda']\n",
      "\t['0.10', '0.21', 14, 'sad']\n",
      "\t['0.10', '0.18', 5, ',']\n",
      "\t['0.05', '0.08', 65, 'he']\n",
      "\t['0.02', '0.01', 26, 'is']\n",
      "\t['0.02', '0.04', 540, 'getting']\n",
      "\t['0.01', '0.02', 151, 'so']\n",
      "\t['0.02', '0.01', 292, 'big']\n",
      "\t['0.00', '0.04', 5, ',']\n",
      "\t['0.00', '0.02', 351, 'check']\n",
      "\t['0.00', '0.04', 215, 'out']\n",
      "\t['0.00', '0.01', 24, 'my']\n",
      "\t['0.00', '0.07', 1, 'twipics']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.01', 23, 'negative']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 14 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['its', 'coming', 'out', 'the', 'xxxUNK', 'i', 'feel', 'like', 'my', 'phones', 'hole', 'is', 'not', 'a', 'virgin', '.', 'that`s', 'how', 'loose']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.28', '0.00', 213, 'its']\n",
      "\t['0.01', '0.00', 277, 'coming']\n",
      "\t['0.01', '0.01', 215, 'out']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.01', '0.01', 1, 'socket']\n",
      "\t['0.00', '0.00', 7, 'i']\n",
      "\t['0.00', '0.00', 338, 'feel']\n",
      "\t['0.00', '0.00', 103, 'like']\n",
      "\t['0.00', '0.00', 24, 'my']\n",
      "\t['0.01', '0.00', 1682, 'phones']\n",
      "\t['0.03', '0.00', 5511, 'hole']\n",
      "\t['0.01', '0.01', 26, 'is']\n",
      "\t['0.02', '0.01', 149, 'not']\n",
      "\t['0.02', '0.01', 142, 'a']\n",
      "\t['0.02', '0.01', 10085, 'virgin']\n",
      "\t['0.08', '0.02', 28, '.']\n",
      "\t['0.05', '0.02', 240, 'that`s']\n",
      "\t['0.08', '0.06', 335, 'how']\n",
      "\t['0.10', '0.18', 4396, 'loose']\n",
      "\t['0.04', '0.09', 144, 'it']\n",
      "\t['0.05', '0.09', 26, 'is']\n",
      "\t['0.02', '0.05', 28, '.']\n",
      "\t['0.01', '0.07', 28, '.']\n",
      "\t['0.03', '0.09', 28, '.']\n",
      "\t['0.02', '0.10', 48, ':']\n",
      "\t['0.03', '0.01', 3541, '`']\n",
      "\t['0.01', '0.04', 81, '(']\n",
      "\t['0.00', '0.02', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.02', 23, 'negative']\n",
      "\t['0.01', '0.01', 12, 'xxxEND']\n",
      "================== Sample # 15 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['i', 'hate', 'my', 'new', 'xxxUNK', ',', 'having', 'such', 'a', 'bad', 'week']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.02', '0.00', 151, 'so']\n",
      "\t['0.01', '0.01', 1662, 'hot']\n",
      "\t['0.01', '0.01', 177, 'today']\n",
      "\t['0.01', '0.01', 94, '=']\n",
      "\t['0.01', '0.01', 405, '_']\n",
      "\t['0.01', '0.01', 94, '=']\n",
      "\t['0.01', '0.01', 424, 'don`t']\n",
      "\t['0.02', '0.01', 103, 'like']\n",
      "\t['0.02', '0.00', 144, 'it']\n",
      "\t['0.07', '0.01', 68, 'and']\n",
      "\t['0.13', '0.04', 7, 'i']\n",
      "\t['0.10', '0.05', 355, 'hate']\n",
      "\t['0.09', '0.03', 24, 'my']\n",
      "\t['0.08', '0.02', 163, 'new']\n",
      "\t['0.07', '0.03', 1, 'timetable']\n",
      "\t['0.07', '0.05', 5, ',']\n",
      "\t['0.06', '0.03', 830, 'having']\n",
      "\t['0.06', '0.05', 416, 'such']\n",
      "\t['0.04', '0.07', 142, 'a']\n",
      "\t['0.03', '0.03', 318, 'bad']\n",
      "\t['0.02', '0.41', 570, 'week']\n",
      "\t['0.01', '0.02', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.02', 23, 'negative']\n",
      "\t['0.01', '0.03', 12, 'xxxEND']\n",
      "================== Sample # 16 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['miss', 'you']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.82', '0.20', 16, 'miss']\n",
      "\t['0.12', '0.76', 17, 'you']\n",
      "\t['0.03', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.01', '0.01', 23, 'negative']\n",
      "\t['0.01', '0.01', 12, 'xxxEND']\n",
      "================== Sample # 17 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['cramps', '.', '.', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.92', '0.34', 1896, 'cramps']\n",
      "\t['0.02', '0.12', 28, '.']\n",
      "\t['0.03', '0.08', 28, '.']\n",
      "\t['0.02', '0.37', 28, '.']\n",
      "\t['0.00', '0.02', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.02', 23, 'negative']\n",
      "\t['0.00', '0.02', 12, 'xxxEND']\n",
      "================== Sample # 18 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['yesterday', 'but', 'nice', 'songs', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.01', '0.01', 17, 'you']\n",
      "\t['0.01', '0.01', 493, 'guys']\n",
      "\t['0.01', '0.01', 475, 'didn`t']\n",
      "\t['0.02', '0.01', 460, 'say']\n",
      "\t['0.02', '0.01', 461, 'hi']\n",
      "\t['0.04', '0.01', 758, 'or']\n",
      "\t['0.09', '0.02', 1677, 'answer']\n",
      "\t['0.10', '0.07', 24, 'my']\n",
      "\t['0.18', '0.05', 2614, 'questions']\n",
      "\t['0.21', '0.21', 453, 'yesterday']\n",
      "\t['0.14', '0.06', 116, 'but']\n",
      "\t['0.07', '0.13', 397, 'nice']\n",
      "\t['0.05', '0.02', 645, 'songs']\n",
      "\t['0.03', '0.33', 28, '.']\n",
      "\t['0.01', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.01', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 19 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['i`m', 'going', 'into', 'a', 'xxxUNK', 'xxxUNK', ',', 'its', 'xxxUNK', 'my', 'ego', '!', '.', 'i', 'now', 'realise', ',', 'i`m', 'not', 'all', 'that', 'great', '.', 'and', 'i`m', 'ok', 'with', 'that', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.81', '0.00', 96, 'i`m']\n",
      "\t['0.01', '0.00', 9, 'going']\n",
      "\t['0.01', '0.00', 150, 'into']\n",
      "\t['0.00', '0.00', 142, 'a']\n",
      "\t['0.00', '0.00', 1, 'spiritual']\n",
      "\t['0.00', '0.00', 1, 'stagnentation']\n",
      "\t['0.00', '0.00', 5, ',']\n",
      "\t['0.00', '0.00', 213, 'its']\n",
      "\t['0.00', '0.00', 1, 'exploding']\n",
      "\t['0.00', '0.00', 24, 'my']\n",
      "\t['0.00', '0.00', 5906, 'ego']\n",
      "\t['0.00', '0.00', 22, '!']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.00', '0.00', 7, 'i']\n",
      "\t['0.00', '0.00', 229, 'now']\n",
      "\t['0.00', '0.00', 2825, 'realise']\n",
      "\t['0.00', '0.00', 5, ',']\n",
      "\t['0.00', '0.00', 96, 'i`m']\n",
      "\t['0.00', '0.00', 149, 'not']\n",
      "\t['0.00', '0.00', 66, 'all']\n",
      "\t['0.01', '0.00', 82, 'that']\n",
      "\t['0.00', '0.00', 812, 'great']\n",
      "\t['0.01', '0.00', 28, '.']\n",
      "\t['0.01', '0.00', 68, 'and']\n",
      "\t['0.01', '0.01', 96, 'i`m']\n",
      "\t['0.02', '0.00', 458, 'ok']\n",
      "\t['0.02', '0.00', 278, 'with']\n",
      "\t['0.01', '0.01', 82, 'that']\n",
      "\t['0.00', '0.95', 28, '.']\n",
      "\t['0.01', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,20):\n",
    "    spot_check(i, mode=\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
