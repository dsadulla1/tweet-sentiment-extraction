{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You might need a token for space itself?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do you need psuedo labels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification model with test as well in train? Will increase the vocab size as well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTROLS\n",
    "MODEL_PREFIX = \"V04\"\n",
    "MODEL_NUMBER = MODEL_PREFIX[-2:]\n",
    "TRAIN_SPLIT_RATIO = 0.8\n",
    "\n",
    "DROPOUT = 0.1\n",
    "MIN_LR = 1e-5\n",
    "MAX_LR = 1e-3\n",
    "BATCH_SIZE = 512\n",
    "PREDICT_BATCH_SIZE = 2048\n",
    "STEP_SIZE = 20\n",
    "CLR_METHOD = \"triangular2\" # exp_range, triangular, triangular2\n",
    "NUM_EPOCHS = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import pickle, os, sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, LSTM, Embedding, Dense, concatenate, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout, Flatten, Reshape, Activation, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def signaltonoise(a, axis=0, ddof=0):\n",
    "    a = np.asanyarray(a)\n",
    "    m = a.mean(axis)\n",
    "    sd = a.std(axis=axis, ddof=ddof)\n",
    "    return np.where(sd == 0, 0, m/sd)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import *\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "class CyclicLR(Callback):\n",
    "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
    "    The method cycles the learning rate between two boundaries with\n",
    "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
    "    The amplitude of the cycle can be scaled on a per-iteration or \n",
    "    per-cycle basis.\n",
    "    This class has three built-in policies, as put forth in the paper.\n",
    "    \"triangular\":\n",
    "        A basic triangular cycle w/ no amplitude scaling.\n",
    "    \"triangular2\":\n",
    "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
    "    \"exp_range\":\n",
    "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n",
    "        cycle iteration.\n",
    "    For more detail, please see paper.\n",
    "    \n",
    "    # Example\n",
    "        ```python\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```\n",
    "    \n",
    "    Class also supports custom scaling functions:\n",
    "        ```python\n",
    "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., scale_fn=clr_fn,\n",
    "                                scale_mode='cycle')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```    \n",
    "    # Arguments\n",
    "        base_lr: initial learning rate which is the\n",
    "            lower boundary in the cycle.\n",
    "        max_lr: upper boundary in the cycle. Functionally,\n",
    "            it defines the cycle amplitude (max_lr - base_lr).\n",
    "            The lr at any cycle is the sum of base_lr\n",
    "            and some scaling of the amplitude; therefore \n",
    "            max_lr may not actually be reached depending on\n",
    "            scaling function.\n",
    "        step_size: number of training iterations per\n",
    "            half cycle. Authors suggest setting step_size\n",
    "            2-8 x training iterations in epoch.\n",
    "        mode: one of {triangular, triangular2, exp_range}.\n",
    "            Default 'triangular'.\n",
    "            Values correspond to policies detailed above.\n",
    "            If scale_fn is not None, this argument is ignored.\n",
    "        gamma: constant in 'exp_range' scaling function:\n",
    "            gamma**(cycle iterations)\n",
    "        scale_fn: Custom scaling policy defined by a single\n",
    "            argument lambda function, where \n",
    "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
    "            mode paramater is ignored \n",
    "        scale_mode: {'cycle', 'iterations'}.\n",
    "            Defines whether scale_fn is evaluated on \n",
    "            cycle number or cycle iterations (training\n",
    "            iterations since start of cycle). Default is 'cycle'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma**(x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        \"\"\"Resets cycle iterations.\n",
    "        Optional boundary/step size adjustment.\n",
    "        \"\"\"\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "        \n",
    "    def clr(self):\n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
    "            \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0  1\n",
      "textID         object  0\n",
      "text           object  1\n",
      "selected_text  object  1\n",
      "sentiment      object  0\n",
      "(27481, 4)\n",
      "{'textID': 27481, 'text': 27480, 'selected_text': 22463, 'sentiment': 3}\n",
      "            textID                                               text  \\\n",
      "count        27481                                              27480   \n",
      "unique       27481                                              27480   \n",
      "top     6bf46b99ce  is wondering y Mother Nature is making my life...   \n",
      "freq             1                                                  1   \n",
      "\n",
      "       selected_text sentiment  \n",
      "count          27480     27481  \n",
      "unique         22463         3  \n",
      "top             good   neutral  \n",
      "freq             199     11118  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\", dtype={\"time\":np.float64,\"signal\":np.float64,\"open_channels\":np.int16})\n",
    "print(pd.concat((df.dtypes, df.isna().sum()), axis=1))\n",
    "print(df.shape)\n",
    "\n",
    "# Counts of various columns\n",
    "print({i:df[i].nunique() for i in df.columns})\n",
    "print(df.describe()) #.astype(int)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0  1\n",
      "textID     object  0\n",
      "text       object  0\n",
      "sentiment  object  0\n",
      "(3534, 3)\n",
      "{'textID': 3534, 'text': 3534, 'sentiment': 3}\n",
      "            textID         text sentiment\n",
      "count         3534         3534      3534\n",
      "unique        3534         3534         3\n",
      "top     fec3cae0c2   Great idea   neutral\n",
      "freq             1            1      1430\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral\n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive\n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative\n",
       "3  01082688c6                                        happy bday!  positive\n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"../data/test.csv\", dtype={\"time\":np.float64,\"signal\":np.float64})\n",
    "print(pd.concat((test_df.dtypes, test_df.isna().sum()), axis=1))\n",
    "print(test_df.shape)\n",
    "\n",
    "# Counts of various columns\n",
    "print({i:test_df[i].nunique() for i in test_df.columns})\n",
    "print(test_df.describe())\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment count in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>7781</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>11117</td>\n",
       "      <td>1430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>8582</td>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text  text\n",
       "sentiment             \n",
       "negative    7781  1001\n",
       "neutral    11117  1430\n",
       "positive    8582  1103"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df.groupby(\"sentiment\")[[\"text\"]].count(), test_df.groupby(\"sentiment\")[[\"text\"]].count()], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalous_idxs = [27302, 18, 27, 149, 160, 251, 295, 309, 398, 458, 492, 581, 637, 639, 678, 757, 787, 863, 1077, 1096, 1157, 1376, 1393, 1420, 1515, 1518, 1693, 1696, 1728, 1754, 1798, 1929, 2008, 2056, 2124, 2136, 2187, 2213, 2324, 2364, 2392, 2401, 2439, 2440, 2785, 2787, 2986, 3319, 3363, 3369, 3399, 3400, 3411, 3473, 4148, 4369, 4404, 4576, 4639, 4654, 4747, 5167, 5189, 5196, 5213, 5241, 5358, 5361, 5510, 5530, 5560, 5687, 5697, 5712, 5751, 6113, 6131, 6230, 6261, 6360, 6528, 6540, 6627, 6686, 6724, 6759, 6804, 6859, 6948, 6987, 7024, 7040, 7331, 7409, 7438, 7442, 7506, 7513, 7530, 7642, 7663, 7818, 7837, 8005, 8049, 8052, 8153, 8161, 8235, 8249, 8497, 8569, 8594, 8624, 8691, 8706, 8720, 8749, 8803, 8999, 9113, 9190, 9374, 9442, 9449, 9496, 9535, 9539, 9594, 9631, 9696, 9882, 10007, 10050, 10070, 10164, 10293, 10411, 10492, 10508, 10521, 10530, 10672, 10747, 10813, 10935, 10968, 10981, 10986, 11176, 11228, 11300, 11323, 11349, 11353, 11480, 11588, 11643, 11698, 11706, 11745, 11861, 11963, 11985, 12138, 12205, 12283, 12356, 12397, 12416, 12474, 12522, 12563, 12576, 12662, 12736, 12803, 12843, 12972, 12977, 13004, 13124, 13237, 13365, 13379, 13605, 13637, 13704, 13796, 13803, 13907, 13965, 13975, 14058, 14213, 14230, 14257, 14275, 14571, 14611, 14779, 14855, 14880, 15010, 15056, 15165, 15207, 15372, 15462, 15528, 15562, 15660, 15998, 16117, 16175, 16352, 16372, 16391, 16423, 16493, 16500, 16570, 16643, 16665, 16720, 16726, 16876, 16915, 17013, 17029, 17062, 17160, 17404, 17412, 17417, 17513, 17530, 17531, 17600, 17627, 17729, 17762, 17893, 17945, 17986, 18003, 18086, 18099, 18314, 18342, 18355, 18375, 18536, 18616, 18778, 18862, 18908, 18912, 18930, 18997, 19028, 19057, 19162, 19213, 19239, 19274, 19279, 19405, 19431, 19481, 19486, 19536, 19562, 19634, 19651, 19754, 19963, 19985, 19988, 20014, 20216, 20299, 20394, 20440, 20451, 20506, 20644, 20865, 20895, 21013, 21018, 21114, 21205, 21316, 21331, 21349, 21376, 21556, 21737, 21755, 21876, 21923, 22117, 22205, 22234, 22280, 22363, 22365, 22378, 22383, 22387, 22536, 22588, 22717, 22744, 22768, 22769, 22836, 22864, 22938, 23081, 23108, 23145, 23199, 23205, 23290, 23352, 23372, 23528, 23617, 23630, 23680, 23690, 23733, 23746, 23784, 23842, 23959, 24026, 24046, 24274, 24378, 24476, 24490, 24502, 24504, 24597, 24682, 24753, 24766, 24886, 24909, 24996, 25104, 25267, 25338, 25380, 25422, 25446, 25486, 25499, 25601, 25691, 25712, 25732, 25760, 25908, 25947, 25996, 26017, 26025, 26256, 26268, 26625, 26643, 26677, 26687, 26762, 26781, 26830, 26870, 26882, 26927, 27067, 27121, 27209, 27229, 27280, 27349, 27362, 27386, 27401]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(~df.index.isin(anomalous_idxs)) & (~df.selected_text.isna())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"original_index\"] = df.index\n",
    "test_df[\"original_index\"] = test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment_code\"] = df[\"sentiment\"].astype(\"category\")\n",
    "X_sentiments = df[\"sentiment_code\"].cat.codes.values\n",
    "\n",
    "test_df[\"sentiment_code\"] = test_df[\"sentiment\"].astype(\"category\")\n",
    "X_sentiments_test = test_df[\"sentiment_code\"].cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "tokenizer = nlp.Defaults.create_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "df[\"selected_text\"] = df[\"selected_text\"].astype(str)\n",
    "test_df[\"text\"] = test_df[\"text\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: re.sub(pattern=\"`\", repl=\" ` \", string=x))\n",
    "df['selected_text'] = df['selected_text'].apply(lambda x: re.sub(pattern=\"`\", repl=\" ` \", string=x))\n",
    "test_df['text'] = test_df['text'].apply(lambda x: re.sub(pattern=\"`\", repl=\" ` \", string=x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_t'] = df['text'].apply(lambda x: tokenizer(x))\n",
    "df['selected_text_t'] = df['selected_text'].apply(lambda x: tokenizer(x))\n",
    "test_df['text_t'] = test_df['text'].apply(lambda x: tokenizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27088 27088 3534\n"
     ]
    }
   ],
   "source": [
    "X_words = [[word.orth_ if not word.like_url else 'xxxURL' for word in row] for row in df['text_t']]\n",
    "Y_words = [[word.orth_ if not word.like_url else 'xxxURL' for word in row] for row in df['selected_text_t']]\n",
    "X_test_words = [[word.orth_ if not word.like_url else 'xxxURL' for word in row] for row in test_df['text_t']]\n",
    "\n",
    "print(len(X_words), len(Y_words), len(X_test_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_words = set(sorted([j for i in X_words for j in i]))\n",
    "Y_list_of_words = set(sorted([j for i in Y_words for j in i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_itos = {i+1:j for i,j in enumerate(list_of_words)}\n",
    "vocab_stoi = {j:i+1 for i,j in enumerate(list_of_words)}\n",
    "\n",
    "vocab_stoi[\"xxxUNK\"] = 0\n",
    "vocab_itos[0] = \"xxxUNK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_vocab(vocab, word):\n",
    "    try:\n",
    "        value = vocab[word]\n",
    "    except KeyError as k:\n",
    "        value = 0\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[get_from_vocab(vocab_stoi,j) for j in i] for i in X_words]\n",
    "Y = [[get_from_vocab(vocab_stoi,j) for j in i] for i in Y_words]\n",
    "Y2 = [[1 if j in y else 0 for j in X[i]] for i,y in enumerate(Y)]\n",
    "X_test = [[get_from_vocab(vocab_stoi,j) for j in i] for i in X_test_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 106\n"
     ]
    }
   ],
   "source": [
    "max_len = max([len(i) for i in X])\n",
    "max_len_y = max([len(i) for i in Y2])\n",
    "print(max_len, max_len_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27088 21670 5418 27088\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "idx = [i for i in np.arange(len(Y))]\n",
    "np.random.shuffle(idx)\n",
    "train_idx, val_idx = idx[:round(TRAIN_SPLIT_RATIO*len(Y))], idx[round(TRAIN_SPLIT_RATIO*len(Y)):]\n",
    "\n",
    "print(len(idx), len(train_idx), len(val_idx), len(train_idx) + len(val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21670, 5418, 21670, 5418, 21670, 5418, 21670, 5418]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val = [X[i] for i in train_idx], [X[i] for i in val_idx]\n",
    "X_sentiments_train, X_sentiments_val = [X_sentiments[i] for i in train_idx], [X_sentiments[i] for i in val_idx]\n",
    "X_sentiments_train, X_sentiments_val = np.array(X_sentiments_train, dtype=np.int32), np.array(X_sentiments_val, dtype=np.int32)\n",
    "Y_train, Y_val = [Y[i] for i in train_idx], [Y[i] for i in val_idx]\n",
    "Y2_train, Y2_val = [Y2[i] for i in train_idx], [Y2[i] for i in val_idx]\n",
    "\n",
    "[len(i) for i in [X_train, X_val, X_sentiments_train, X_sentiments_val, Y_train, Y_val, Y2_train, Y2_val]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=max_len + 1, padding=\"post\")\n",
    "Y_train = pad_sequences(Y_train, maxlen=max_len + 1, padding=\"post\")\n",
    "Y2_train = pad_sequences(Y2_train, maxlen=max_len + 1, padding=\"post\")\n",
    "\n",
    "X_val = pad_sequences(X_val, maxlen=max_len + 1, padding=\"post\")\n",
    "Y_val = pad_sequences(Y_val, maxlen=max_len + 1, padding=\"post\")\n",
    "Y2_val = pad_sequences(Y2_val, maxlen=max_len + 1, padding=\"post\")\n",
    "\n",
    "X_test = pad_sequences(X_test, maxlen=max_len + 1, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21670, 107) (21670,) (5418, 107) (5418,) (3534, 107)\n",
      "(21670, 107) (21670, 107) (5418, 107) (5418, 107)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_sentiments_train.shape, X_val.shape, X_sentiments_val.shape, X_test.shape)\n",
    "print(Y_train.shape, Y2_train.shape, Y_val.shape, Y2_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab_stoi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for zero input vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_x_train = X_train.sum(axis=1) > 0\n",
    "X_train, Y_train = X_train[keep_x_train], Y_train[keep_x_train]\n",
    "X_sentiments_train, Y2_train = X_sentiments_train[keep_x_train], Y2_train[keep_x_train]\n",
    "\n",
    "keep_x_val = X_val.sum(axis=1) > 0\n",
    "X_val, Y_val = X_val[keep_x_val], Y_val[keep_x_val]\n",
    "X_sentiments_val, Y2_val = X_sentiments_val[keep_x_val], Y2_val[keep_x_val]\n",
    "\n",
    "keep_x_test = X_test.sum(axis=1) > 0\n",
    "test_df[\"kept\"] = keep_x_test\n",
    "X_test, X_sentiments_test = X_test[keep_x_test], X_sentiments_test[keep_x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1824\n",
      "0 3262\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax([X_train.sum(axis=1)==0]), np.min([X_train.sum(axis=1)]))\n",
    "print(np.argmax([X_val.sum(axis=1)==0]), np.min([X_val.sum(axis=1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentiment = Input((1))\n",
    "input_sequences = Input((max_len+1))\n",
    "\n",
    "emb_sequences = Embedding(input_dim=VOCAB_SIZE+1, input_length=max_len+1, output_dim=32, mask_zero=True)(input_sequences)\n",
    "\n",
    "seq = Bidirectional(LSTM(16, activation='relu', return_sequences=True))(emb_sequences)\n",
    "seq = BatchNormalization()(seq)\n",
    "seq = Dropout(DROPOUT)(seq)\n",
    "\n",
    "seq = Bidirectional(LSTM(16, activation='relu', return_sequences=True))(seq)\n",
    "seq = BatchNormalization()(seq)\n",
    "seq = Dropout(DROPOUT)(seq)\n",
    "\n",
    "seq = TimeDistributed(Dense(16, activation=\"relu\"))(seq)\n",
    "seq = BatchNormalization()(seq)\n",
    "seq = Dropout(DROPOUT)(seq)\n",
    "\n",
    "seq = Flatten()(seq)\n",
    "\n",
    "emb_sentiment = Embedding(input_dim=3, input_length=1, output_dim=5)(input_sentiment)\n",
    "senti = Dense(8, activation=\"relu\")(emb_sentiment)\n",
    "senti = BatchNormalization()(senti)\n",
    "senti = Dropout(DROPOUT)(senti)\n",
    "senti = Flatten()(senti)\n",
    "\n",
    "concat_layer = concatenate([senti, seq])\n",
    "output = Dense(max_len+1, activation=\"sigmoid\")(concat_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 107)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 107, 32)      1017152     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 107, 32)      6272        embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 107, 32)      128         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 107, 32)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 107, 32)      6272        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 107, 32)      128         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 5)         15          input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 107, 32)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1, 8)         48          embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 107, 16)      528         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1, 8)         32          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 107, 16)      64          time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 1, 8)         0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 107, 16)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 8)            0           dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 1712)         0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1720)         0           flatten_5[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 107)          184147      concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,214,786\n",
      "Trainable params: 1,214,610\n",
      "Non-trainable params: 176\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([input_sentiment, input_sequences], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=MIN_LR)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "#model.compile(loss='sparse_categorical_crossentropy',\n",
    "#              optimizer=adam) #, metrics=['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks\n",
    "mcp = ModelCheckpoint(filepath=\"../results/\"+MODEL_PREFIX+\"Checkpoint.h5\",\n",
    "                      monitor='val_loss',\n",
    "                      mode=\"auto\",\n",
    "                      save_weights_only=False,\n",
    "                      save_best_only=True)\n",
    "\n",
    "clr = CyclicLR(mode=CLR_METHOD,\n",
    "               base_lr=MIN_LR,\n",
    "               max_lr=MAX_LR,\n",
    "               step_size= STEP_SIZE * (X_train.shape[0] // BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21670 samples, validate on 5418 samples\n",
      "Epoch 1/40\n",
      "21670/21670 [==============================] - 33s 2ms/sample - loss: 0.7786 - accuracy: 0.5750 - val_loss: 0.6721 - val_accuracy: 0.6873\n",
      "Epoch 2/40\n",
      "21670/21670 [==============================] - 26s 1ms/sample - loss: 0.4154 - accuracy: 0.8229 - val_loss: 0.5797 - val_accuracy: 0.8785\n",
      "Epoch 3/40\n",
      "21670/21670 [==============================] - 25s 1ms/sample - loss: 0.2049 - accuracy: 0.9192 - val_loss: 0.4612 - val_accuracy: 0.9183\n",
      "Epoch 4/40\n",
      "21670/21670 [==============================] - 25s 1ms/sample - loss: 0.1525 - accuracy: 0.9259 - val_loss: 0.3693 - val_accuracy: 0.9183\n",
      "Epoch 5/40\n",
      "21670/21670 [==============================] - 25s 1ms/sample - loss: 0.1305 - accuracy: 0.9323 - val_loss: 0.3068 - val_accuracy: 0.9183\n",
      "Epoch 6/40\n",
      "21670/21670 [==============================] - 25s 1ms/sample - loss: 0.1150 - accuracy: 0.9406 - val_loss: 0.2626 - val_accuracy: 0.9187\n",
      "Epoch 7/40\n",
      "21670/21670 [==============================] - 25s 1ms/sample - loss: 0.1024 - accuracy: 0.9491 - val_loss: 0.2328 - val_accuracy: 0.9202\n",
      "Epoch 8/40\n",
      "21670/21670 [==============================] - 25s 1ms/sample - loss: 0.0910 - accuracy: 0.9571 - val_loss: 0.2101 - val_accuracy: 0.9264\n",
      "Epoch 9/40\n",
      "21670/21670 [==============================] - 25s 1ms/sample - loss: 0.0804 - accuracy: 0.9639 - val_loss: 0.2060 - val_accuracy: 0.9283\n",
      "Epoch 10/40\n",
      "21670/21670 [==============================] - 27s 1ms/sample - loss: 0.0710 - accuracy: 0.9691 - val_loss: 0.1985 - val_accuracy: 0.9283\n",
      "Epoch 11/40\n",
      "21670/21670 [==============================] - 27s 1ms/sample - loss: 0.0629 - accuracy: 0.9731 - val_loss: 0.1674 - val_accuracy: 0.9293\n",
      "Epoch 12/40\n",
      "21670/21670 [==============================] - 26s 1ms/sample - loss: 0.0568 - accuracy: 0.9762 - val_loss: 0.1612 - val_accuracy: 0.9310\n",
      "Epoch 13/40\n",
      "21670/21670 [==============================] - 25s 1ms/sample - loss: 0.0525 - accuracy: 0.9781 - val_loss: 0.1581 - val_accuracy: 0.9339\n",
      "Epoch 14/40\n",
      "21670/21670 [==============================] - 28s 1ms/sample - loss: 0.0483 - accuracy: 0.9802 - val_loss: 0.1344 - val_accuracy: 0.9428\n",
      "Epoch 15/40\n",
      "21670/21670 [==============================] - 27s 1ms/sample - loss: 0.0445 - accuracy: 0.9818 - val_loss: 0.1279 - val_accuracy: 0.9470\n",
      "Epoch 16/40\n",
      "21670/21670 [==============================] - 26s 1ms/sample - loss: 0.0420 - accuracy: 0.9831 - val_loss: 0.1205 - val_accuracy: 0.9510\n",
      "Epoch 17/40\n",
      "21670/21670 [==============================] - 26s 1ms/sample - loss: 0.0399 - accuracy: 0.9838 - val_loss: 0.1238 - val_accuracy: 0.9502\n",
      "Epoch 18/40\n",
      "21670/21670 [==============================] - 25s 1ms/sample - loss: 0.0378 - accuracy: 0.9849 - val_loss: 0.1107 - val_accuracy: 0.9554\n",
      "Epoch 19/40\n",
      "21670/21670 [==============================] - 26s 1ms/sample - loss: 0.0360 - accuracy: 0.9857 - val_loss: 0.1069 - val_accuracy: 0.9564\n",
      "Epoch 20/40\n",
      "21670/21670 [==============================] - 26s 1ms/sample - loss: 0.0349 - accuracy: 0.9862 - val_loss: 0.1031 - val_accuracy: 0.9584\n",
      "Epoch 21/40\n",
      "21670/21670 [==============================] - 25s 1ms/sample - loss: 0.0328 - accuracy: 0.9870 - val_loss: 0.1063 - val_accuracy: 0.9578\n",
      "Epoch 22/40\n",
      "21670/21670 [==============================] - 25s 1ms/sample - loss: 0.0310 - accuracy: 0.9877 - val_loss: 0.1089 - val_accuracy: 0.9579\n",
      "Epoch 23/40\n",
      "21670/21670 [==============================] - 26s 1ms/sample - loss: 0.0295 - accuracy: 0.9884 - val_loss: 0.1123 - val_accuracy: 0.9576\n",
      "Epoch 24/40\n",
      "21670/21670 [==============================] - 26s 1ms/sample - loss: 0.0283 - accuracy: 0.9889 - val_loss: 0.1178 - val_accuracy: 0.9563\n",
      "Epoch 25/40\n",
      "21670/21670 [==============================] - 26s 1ms/sample - loss: 0.0272 - accuracy: 0.9892 - val_loss: 0.1198 - val_accuracy: 0.9564\n",
      "Epoch 26/40\n",
      "21670/21670 [==============================] - 25s 1ms/sample - loss: 0.0268 - accuracy: 0.9895 - val_loss: 0.1191 - val_accuracy: 0.9569\n",
      "Epoch 27/40\n",
      "21670/21670 [==============================] - 25s 1ms/sample - loss: 0.0255 - accuracy: 0.9901 - val_loss: 0.1229 - val_accuracy: 0.9562\n",
      "Epoch 28/40\n",
      "21670/21670 [==============================] - 25s 1ms/sample - loss: 0.0247 - accuracy: 0.9904 - val_loss: 0.1237 - val_accuracy: 0.9563\n",
      "Epoch 29/40\n",
      "21670/21670 [==============================] - 26s 1ms/sample - loss: 0.0240 - accuracy: 0.9906 - val_loss: 0.1252 - val_accuracy: 0.9561\n",
      "Epoch 30/40\n",
      "21670/21670 [==============================] - 25s 1ms/sample - loss: 0.0233 - accuracy: 0.9908 - val_loss: 0.1277 - val_accuracy: 0.9557\n",
      "Epoch 31/40\n",
      "21670/21670 [==============================] - 26s 1ms/sample - loss: 0.0227 - accuracy: 0.9911 - val_loss: 0.1321 - val_accuracy: 0.9555\n",
      "Epoch 32/40\n",
      "21670/21670 [==============================] - 25s 1ms/sample - loss: 0.0221 - accuracy: 0.9914 - val_loss: 0.1319 - val_accuracy: 0.9553\n",
      "Epoch 33/40\n",
      "21670/21670 [==============================] - 26s 1ms/sample - loss: 0.0217 - accuracy: 0.9916 - val_loss: 0.1331 - val_accuracy: 0.9553\n",
      "Epoch 34/40\n",
      "21670/21670 [==============================] - 25s 1ms/sample - loss: 0.0213 - accuracy: 0.9917 - val_loss: 0.1322 - val_accuracy: 0.9554\n",
      "Epoch 35/40\n",
      "21670/21670 [==============================] - 25s 1ms/sample - loss: 0.0208 - accuracy: 0.9919 - val_loss: 0.1349 - val_accuracy: 0.9551\n",
      "Epoch 36/40\n",
      "21670/21670 [==============================] - 26s 1ms/sample - loss: 0.0204 - accuracy: 0.9921 - val_loss: 0.1367 - val_accuracy: 0.9547\n",
      "Epoch 37/40\n",
      "21670/21670 [==============================] - 26s 1ms/sample - loss: 0.0202 - accuracy: 0.9922 - val_loss: 0.1372 - val_accuracy: 0.9545\n",
      "Epoch 38/40\n",
      "21670/21670 [==============================] - 27s 1ms/sample - loss: 0.0200 - accuracy: 0.9922 - val_loss: 0.1369 - val_accuracy: 0.9547\n",
      "Epoch 39/40\n",
      "21670/21670 [==============================] - 26s 1ms/sample - loss: 0.0198 - accuracy: 0.9924 - val_loss: 0.1381 - val_accuracy: 0.9547\n",
      "Epoch 40/40\n",
      "21670/21670 [==============================] - 27s 1ms/sample - loss: 0.0196 - accuracy: 0.9924 - val_loss: 0.1379 - val_accuracy: 0.9546\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[X_sentiments_train, X_train],\n",
    "                    y=Y2_train,\n",
    "                    shuffle=True,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    validation_data=([X_sentiments_val, X_val], Y2_val),\n",
    "                    verbose=1,\n",
    "                    callbacks=[clr, mcp]) #es, rlrop, tb, mcp, \n",
    "\n",
    "## Might need a callback as described here https://stackoverflow.com/questions/51728648/how-do-masked-values-affect-the-metrics-in-keras\n",
    "#history = model.fit(x=[X_sentiments_train, X_train],\n",
    "#                    y=Y_train,\n",
    "#                    shuffle=True,\n",
    "#                    batch_size=BATCH_SIZE,\n",
    "#                    epochs=NUM_EPOCHS,\n",
    "#                    validation_data=([X_sentiments_val, X_val], Y_val),\n",
    "#                    verbose=1,\n",
    "#                    callbacks=[clr, mcp]) #es, rlrop, tb, mcp, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric_names = ['loss' ,'accuracy']\n",
    "\n",
    "for i, j in zip(metric_names, ['val_'+i for i in metric_names]):\n",
    "    plt.plot(history.history[i])\n",
    "    plt.plot(history.history[j])\n",
    "    plt.title('Model '+i)\n",
    "    plt.ylabel(i.upper())\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = tf.keras.models.load_model(\n",
    "    filepath=\"../results/\"+MODEL_PREFIX+\"Checkpoint.h5\",\n",
    "    compile=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5418/5418 [==============================] - 1s 191us/sample - loss: 0.1031 - accuracy: 0.9584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10305292358716153, 0.95842004]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x = [X_sentiments_val, X_val], y=Y2_val, batch_size=PREDICT_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(x = [X_sentiments_train, X_train], batch_size=PREDICT_BATCH_SIZE)\n",
    "pred_val = model.predict(x = [X_sentiments_val, X_val], batch_size=PREDICT_BATCH_SIZE)\n",
    "pred_test = model.predict(x = [X_sentiments_test, X_test], batch_size=PREDICT_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21670, 107), (21670, 107), (21670, 107))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, pred_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_words = [i[j>0.5].tolist() for i,j in zip(X_train, pred_train)]\n",
    "pred_val_words = [i[j>0.5].tolist() for i,j in zip(X_val, pred_val)]\n",
    "pred_test_words = [i[j>0.5].tolist() for i,j in zip(X_test, pred_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6021665168183049"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is it generally predicting words that are in itself??\n",
    "np.mean([sum([1  if (k in j) else 0 for k in i])/len(i) if len(i)!=0 else 0 for i,j in zip(pred_val_words, Y_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eyeball and check if preds make sense\n",
    "#sent_labels = {i:j for i,j in enumerate(df.sentiment_code.cat.categories)}\n",
    "#\n",
    "#[(sent_labels[X_sentiments_val[num]], [get_from_vocab(vocab_itos,j) for j in i]) for num, i in enumerate(pred_val_words)]\n",
    "#[(sent_labels[X_sentiments_test[num]], [get_from_vocab(vocab_itos,j) for j in i]) for num, i in enumerate(pred_test_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_words = [[get_from_vocab(vocab_itos,j) for j in i] for i in pred_train_words]\n",
    "pred_val_words = [[get_from_vocab(vocab_itos,j) for j in i] for i in pred_val_words]\n",
    "pred_test_words = [[get_from_vocab(vocab_itos,j) for j in i] for i in pred_test_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(str1, str2):\n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21670, (21670,), (21670, 107))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_idx), keep_x_train.shape, pred_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\n",
    "    \"pred_selected_text\" : pred_train_words + pred_val_words,\n",
    "    \"original_index\" : np.concatenate((np.array(train_idx, dtype=np.int64)[keep_x_train],\n",
    "                                       np.array(val_idx, dtype=np.int64)[keep_x_val])),\n",
    "    \"set\" : [\"train\" for i in range(sum(keep_x_train))] + [\"val\" for i in range(sum(keep_x_val))]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-8f2bdfe0c189>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moriginal_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moriginal_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moriginal_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moriginal_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert (predictions.original_index.min(), predictions.original_index.max()) == (df.original_index.min(), df.original_index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27088, 8) (27088, 3)\n",
      "(27088, 8) (27088, 3) (26704, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape, predictions.shape)\n",
    "results = pd.merge(df, predictions, on = \"original_index\", how=\"inner\")\n",
    "print(df.shape, predictions.shape, results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>original_index</th>\n",
       "      <th>sentiment_code</th>\n",
       "      <th>text_t</th>\n",
       "      <th>selected_text_t</th>\n",
       "      <th>pred_selected_text</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc2cbefa9d</td>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n",
       "      <td>Wow... u just became cooler.</td>\n",
       "      <td>positive</td>\n",
       "      <td>9</td>\n",
       "      <td>positive</td>\n",
       "      <td>( , Journey, !, ?, Wow, ..., u, just, became, ...</td>\n",
       "      <td>(Wow, ..., u, just, became, cooler, .)</td>\n",
       "      <td>[]</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>919fa93391</td>\n",
       "      <td>i ` ve been sick for the past few days  and th...</td>\n",
       "      <td>sick</td>\n",
       "      <td>negative</td>\n",
       "      <td>17</td>\n",
       "      <td>negative</td>\n",
       "      <td>(i, `, ve, been, sick, for, the, past, few, da...</td>\n",
       "      <td>(sick)</td>\n",
       "      <td>[]</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6ce4a4954b</td>\n",
       "      <td>juss came backk from Berkeleyy ; omg its madd ...</td>\n",
       "      <td>fun</td>\n",
       "      <td>positive</td>\n",
       "      <td>28</td>\n",
       "      <td>positive</td>\n",
       "      <td>(juss, came, backk, from, Berkeleyy, ;, omg, i...</td>\n",
       "      <td>(fun)</td>\n",
       "      <td>[I, Quite, ...., heavenly, isn, `, *, *, *, *, ?]</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2863f435bd</td>\n",
       "      <td>A little happy for the wine jeje ok it ` sm my...</td>\n",
       "      <td>A little happy fo</td>\n",
       "      <td>positive</td>\n",
       "      <td>39</td>\n",
       "      <td>positive</td>\n",
       "      <td>(A, little, happy, for, the, wine, jeje, ok, i...</td>\n",
       "      <td>(A, little, happy, fo)</td>\n",
       "      <td>[m, an, avid, fan, of, *, *, *, *, magazine, a...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>d93afa85cf</td>\n",
       "      <td>Car not happy, big big dent in boot! Hoping t...</td>\n",
       "      <td>Car not happy, big big dent in boot! Hoping th...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>40</td>\n",
       "      <td>neutral</td>\n",
       "      <td>( , Car, not, happy, ,, big, big, dent, in, bo...</td>\n",
       "      <td>(Car, not, happy, ,, big, big, dent, in, boot,...</td>\n",
       "      <td>[MAYDAY, ?, !]</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>c77717b103</td>\n",
       "      <td>I love to! But I ` m only available from 5pm....</td>\n",
       "      <td>I love to!</td>\n",
       "      <td>positive</td>\n",
       "      <td>44</td>\n",
       "      <td>positive</td>\n",
       "      <td>( , I, love, to, !, But, I, `, m, only, availa...</td>\n",
       "      <td>(I, love, to, !)</td>\n",
       "      <td>[]</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>a9d499e123</td>\n",
       "      <td>The girl in the hair salon asked me 'Shall I t...</td>\n",
       "      <td>The girl in the hair salon asked me 'Shall I t...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>45</td>\n",
       "      <td>neutral</td>\n",
       "      <td>(The, girl, in, the, hair, salon, asked, me, '...</td>\n",
       "      <td>(The, girl, in, the, hair, salon, asked, me, '...</td>\n",
       "      <td>[:, visiting, my, friendster, and, facebook]</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>52483f7da8</td>\n",
       "      <td>i lost all my friends, i ` m alone and sleepy....</td>\n",
       "      <td>i lost all my friends, i ` m alone and sleepy..</td>\n",
       "      <td>negative</td>\n",
       "      <td>60</td>\n",
       "      <td>negative</td>\n",
       "      <td>(i, lost, all, my, friends, ,, i, `, m, alone,...</td>\n",
       "      <td>(i, lost, all, my, friends, ,, i, `, m, alone,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>90a2cdb657</td>\n",
       "      <td>What better way to spoil mum than to let her k...</td>\n",
       "      <td>favorite</td>\n",
       "      <td>positive</td>\n",
       "      <td>63</td>\n",
       "      <td>positive</td>\n",
       "      <td>(What, better, way, to, spoil, mum, than, to, ...</td>\n",
       "      <td>(favorite)</td>\n",
       "      <td>[Is, at, a, photoshoot, .]</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>04e2e334de</td>\n",
       "      <td>Anyone have an extra Keane ticket? I promise t...</td>\n",
       "      <td>Anyone have an extra Keane ticket? I promise t...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>72</td>\n",
       "      <td>neutral</td>\n",
       "      <td>(Anyone, have, an, extra, Keane, ticket, ?, I,...</td>\n",
       "      <td>(Anyone, have, an, extra, Keane, ticket, ?, I,...</td>\n",
       "      <td>[she, is, good, !, so, gor, -, juz, yea, i, kn...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        textID                                               text  \\\n",
       "9   fc2cbefa9d   Journey!? Wow... u just became cooler.  hehe....   \n",
       "17  919fa93391  i ` ve been sick for the past few days  and th...   \n",
       "26  6ce4a4954b  juss came backk from Berkeleyy ; omg its madd ...   \n",
       "37  2863f435bd  A little happy for the wine jeje ok it ` sm my...   \n",
       "38  d93afa85cf   Car not happy, big big dent in boot! Hoping t...   \n",
       "42  c77717b103   I love to! But I ` m only available from 5pm....   \n",
       "43  a9d499e123  The girl in the hair salon asked me 'Shall I t...   \n",
       "58  52483f7da8  i lost all my friends, i ` m alone and sleepy....   \n",
       "61  90a2cdb657  What better way to spoil mum than to let her k...   \n",
       "70  04e2e334de  Anyone have an extra Keane ticket? I promise t...   \n",
       "\n",
       "                                        selected_text sentiment  \\\n",
       "9                        Wow... u just became cooler.  positive   \n",
       "17                                               sick  negative   \n",
       "26                                                fun  positive   \n",
       "37                                  A little happy fo  positive   \n",
       "38  Car not happy, big big dent in boot! Hoping th...   neutral   \n",
       "42                                         I love to!  positive   \n",
       "43  The girl in the hair salon asked me 'Shall I t...   neutral   \n",
       "58    i lost all my friends, i ` m alone and sleepy..  negative   \n",
       "61                                           favorite  positive   \n",
       "70  Anyone have an extra Keane ticket? I promise t...   neutral   \n",
       "\n",
       "    original_index sentiment_code  \\\n",
       "9                9       positive   \n",
       "17              17       negative   \n",
       "26              28       positive   \n",
       "37              39       positive   \n",
       "38              40        neutral   \n",
       "42              44       positive   \n",
       "43              45        neutral   \n",
       "58              60       negative   \n",
       "61              63       positive   \n",
       "70              72        neutral   \n",
       "\n",
       "                                               text_t  \\\n",
       "9   ( , Journey, !, ?, Wow, ..., u, just, became, ...   \n",
       "17  (i, `, ve, been, sick, for, the, past, few, da...   \n",
       "26  (juss, came, backk, from, Berkeleyy, ;, omg, i...   \n",
       "37  (A, little, happy, for, the, wine, jeje, ok, i...   \n",
       "38  ( , Car, not, happy, ,, big, big, dent, in, bo...   \n",
       "42  ( , I, love, to, !, But, I, `, m, only, availa...   \n",
       "43  (The, girl, in, the, hair, salon, asked, me, '...   \n",
       "58  (i, lost, all, my, friends, ,, i, `, m, alone,...   \n",
       "61  (What, better, way, to, spoil, mum, than, to, ...   \n",
       "70  (Anyone, have, an, extra, Keane, ticket, ?, I,...   \n",
       "\n",
       "                                      selected_text_t  \\\n",
       "9              (Wow, ..., u, just, became, cooler, .)   \n",
       "17                                             (sick)   \n",
       "26                                              (fun)   \n",
       "37                             (A, little, happy, fo)   \n",
       "38  (Car, not, happy, ,, big, big, dent, in, boot,...   \n",
       "42                                   (I, love, to, !)   \n",
       "43  (The, girl, in, the, hair, salon, asked, me, '...   \n",
       "58  (i, lost, all, my, friends, ,, i, `, m, alone,...   \n",
       "61                                         (favorite)   \n",
       "70  (Anyone, have, an, extra, Keane, ticket, ?, I,...   \n",
       "\n",
       "                                   pred_selected_text  set  \n",
       "9                                                  []  val  \n",
       "17                                                 []  val  \n",
       "26  [I, Quite, ...., heavenly, isn, `, *, *, *, *, ?]  val  \n",
       "37  [m, an, avid, fan, of, *, *, *, *, magazine, a...  val  \n",
       "38                                     [MAYDAY, ?, !]  val  \n",
       "42                                                 []  val  \n",
       "43       [:, visiting, my, friendster, and, facebook]  val  \n",
       "58                                                 []  val  \n",
       "61                         [Is, at, a, photoshoot, .]  val  \n",
       "70  [she, is, good, !, so, gor, -, juz, yea, i, kn...  val  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[results.set==\"val\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[results.set==\"train\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_train = confusion_matrix(Y_train.argmax(axis=1).reshape(-1), pred_train.reshape(-1))\n",
    "conf_mat_val = confusion_matrix(Y_val.argmax(axis=1).reshape(-1), pred_val.reshape(-1))\n",
    "print(\"The train accuracy is\\t\",np.round(100 * np.sum(np.diag(conf_mat_train)) / np.sum(conf_mat_train),2))\n",
    "print(\"The valid accuracy is\\t\",np.round(100 * np.sum(np.diag(conf_mat_val)) / np.sum(conf_mat_val),2))\n",
    "\n",
    "np.savetxt(X=conf_mat_train, fname=\"../results/ConfMatrix_train_\" + MODEL_PREFIX + \".txt\")\n",
    "np.savetxt(X=conf_mat_val, fname=\"../results/ConfMatrix_val_\" + MODEL_PREFIX + \".txt\")\n",
    "\n",
    "f1_train = f1_score(Y_train.argmax(axis=1).reshape(-1), pred_train.reshape(-1), average='macro')\n",
    "f1_val = f1_score(Y_val.argmax(axis=1).reshape(-1), pred_val.reshape(-1), average='macro')\n",
    "print(\"The train macro f1score is\\t\",np.round(f1_train,2))\n",
    "print(\"The valid macro f1score is\\t\",np.round(f1_val,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'time':test_df['time'],'open_channels':pred_test.reshape(-1)})\n",
    "submission.to_csv(\"../results/submission_20200412V\"+MODEL_NUMBER+\".csv\", index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "best_model = tf.keras.models.load_model(\n",
    "    filepath=\"../results/\"+MODEL_PREFIX+\"Checkpoint.h5\",\n",
    "    compile=True,\n",
    "    custom_objects = {'macro_soft_f1':macro_soft_f1, 'macro_f1':macro_f1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = best_model.predict(x = X_train, batch_size=PREDICT_BATCH_SIZE)\n",
    "pred_val = best_model.predict(x = X_val, batch_size=PREDICT_BATCH_SIZE)\n",
    "pred_test = best_model.predict(x = X_test, batch_size=PREDICT_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = pred_train.argmax(axis=1)\n",
    "pred_val = pred_val.argmax(axis=1)\n",
    "pred_test = pred_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_train = confusion_matrix(Y_train.argmax(axis=1).reshape(-1), pred_train.reshape(-1))\n",
    "conf_mat_val = confusion_matrix(Y_val.argmax(axis=1).reshape(-1), pred_val.reshape(-1))\n",
    "\n",
    "print(\"The train accuracy is\\t\",np.round(100 * np.sum(np.diag(conf_mat_train)) / np.sum(conf_mat_train),2))\n",
    "print(\"The valid accuracy is\\t\",np.round(100 * np.sum(np.diag(conf_mat_val)) / np.sum(conf_mat_val),2))\n",
    "\n",
    "np.savetxt(X=conf_mat_train, fname=\"../results/BestConfMatrix_train_\" + MODEL_PREFIX + \".txt\")\n",
    "np.savetxt(X=conf_mat_val, fname=\"../results/BestConfMatrix_val_\" + MODEL_PREFIX + \".txt\")\n",
    "\n",
    "f1_train = f1_score(Y_train.argmax(axis=1).reshape(-1), pred_train.reshape(-1), average='macro')\n",
    "f1_val = f1_score(Y_train.argmax(axis=1).reshape(-1), pred_train.reshape(-1), average='macro')\n",
    "print(\"The train macro f1score is\\t\",np.round(f1_train,2))\n",
    "print(\"The valid macro f1score is\\t\",np.round(f1_val,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'time':test_df['time'],'open_channels':pred_test.reshape(-1)})\n",
    "submission.to_csv(\"../results/best_submission_20200412V\"+MODEL_NUMBER+\".csv\", index=False, float_format='%.4f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
