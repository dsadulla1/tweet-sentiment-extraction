{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do you need psuedo labels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You might need a token for space itself? start and stop tokens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification model with test as well in train? Will increase the vocab size as well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * https://www.tensorflow.org/tutorials/text/transformer\n",
    "# * https://pytorch.org/tutorials/beginner/transformer_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTROLS\n",
    "MODEL_PREFIX = \"V13\"\n",
    "MODEL_NUMBER = MODEL_PREFIX[-2:]\n",
    "TRAIN_SPLIT_RATIO = 0.8\n",
    "\n",
    "DROPOUT = 0.3\n",
    "MIN_LR = 1e-6\n",
    "MAX_LR = 1e-3\n",
    "BATCH_SIZE = 1024\n",
    "PREDICT_BATCH_SIZE = 2048\n",
    "STEP_SIZE = 10\n",
    "CLR_METHOD = \"triangular\" # exp_range, triangular, triangular2\n",
    "NUM_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler, LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import pickle, os, sys, re\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, LSTM, Embedding, Dense, concatenate, MaxPooling2D, Softmax, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout, Reshape, Activation, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.layers import RepeatVector, Multiply, MaxPooling1D, Layer\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras import initializers, regularizers, constraints\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def signaltonoise(a, axis=0, ddof=0):\n",
    "    a = np.asanyarray(a)\n",
    "    m = a.mean(axis)\n",
    "    sd = a.std(axis=axis, ddof=ddof)\n",
    "    return np.where(sd == 0, 0, m/sd)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {'step_dim': self.step_dim}\n",
    "        base_config = super(Attention,self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import *\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "class CyclicLR(Callback):\n",
    "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
    "    The method cycles the learning rate between two boundaries with\n",
    "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
    "    The amplitude of the cycle can be scaled on a per-iteration or \n",
    "    per-cycle basis.\n",
    "    This class has three built-in policies, as put forth in the paper.\n",
    "    \"triangular\":\n",
    "        A basic triangular cycle w/ no amplitude scaling.\n",
    "    \"triangular2\":\n",
    "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
    "    \"exp_range\":\n",
    "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n",
    "        cycle iteration.\n",
    "    For more detail, please see paper.\n",
    "    \n",
    "    # Example\n",
    "        ```python\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```\n",
    "    \n",
    "    Class also supports custom scaling functions:\n",
    "        ```python\n",
    "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., scale_fn=clr_fn,\n",
    "                                scale_mode='cycle')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```    \n",
    "    # Arguments\n",
    "        base_lr: initial learning rate which is the\n",
    "            lower boundary in the cycle.\n",
    "        max_lr: upper boundary in the cycle. Functionally,\n",
    "            it defines the cycle amplitude (max_lr - base_lr).\n",
    "            The lr at any cycle is the sum of base_lr\n",
    "            and some scaling of the amplitude; therefore \n",
    "            max_lr may not actually be reached depending on\n",
    "            scaling function.\n",
    "        step_size: number of training iterations per\n",
    "            half cycle. Authors suggest setting step_size\n",
    "            2-8 x training iterations in epoch.\n",
    "        mode: one of {triangular, triangular2, exp_range}.\n",
    "            Default 'triangular'.\n",
    "            Values correspond to policies detailed above.\n",
    "            If scale_fn is not None, this argument is ignored.\n",
    "        gamma: constant in 'exp_range' scaling function:\n",
    "            gamma**(cycle iterations)\n",
    "        scale_fn: Custom scaling policy defined by a single\n",
    "            argument lambda function, where \n",
    "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
    "            mode paramater is ignored \n",
    "        scale_mode: {'cycle', 'iterations'}.\n",
    "            Defines whether scale_fn is evaluated on \n",
    "            cycle number or cycle iterations (training\n",
    "            iterations since start of cycle). Default is 'cycle'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma**(x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        \"\"\"Resets cycle iterations.\n",
    "        Optional boundary/step size adjustment.\n",
    "        \"\"\"\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "        \n",
    "    def clr(self):\n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
    "            \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\deepak\\miniconda3\\envs\\dev\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "np.random.seed(54321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0  1\n",
      "textID         object  0\n",
      "text           object  1\n",
      "selected_text  object  1\n",
      "sentiment      object  0\n",
      "(27481, 4)\n",
      "{'textID': 27481, 'text': 27480, 'selected_text': 22463, 'sentiment': 3}\n",
      "            textID            text selected_text sentiment\n",
      "count   27481       27480           27480         27481   \n",
      "unique  27481       27480           22463         3       \n",
      "top     004eb1e239  sunburnt again  good          neutral \n",
      "freq    1           1               199           11118   \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                            text  \\\n",
       "0  cb774db0d1   I`d have responded, if I were going             \n",
       "1  549e992a42   Sooo SAD I will miss you here in San Diego!!!   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going  neutral   \n",
       "1  Sooo SAD                             negative  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\",\n",
    "                 encoding=\"utf8\")\n",
    "\n",
    "print(pd.concat((df.dtypes, df.isna().sum()), axis=1))\n",
    "print(df.shape)\n",
    "\n",
    "# Counts of various columns\n",
    "print({i:df[i].nunique() for i in df.columns})\n",
    "print(df.describe()) #.astype(int)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0  1\n",
      "textID     object  0\n",
      "text       object  0\n",
      "sentiment  object  0\n",
      "(3534, 3)\n",
      "{'textID': 3534, 'text': 3534, 'sentiment': 3}\n",
      "            textID  \\\n",
      "count   3534         \n",
      "unique  3534         \n",
      "top     40e1ca4ab0   \n",
      "freq    1            \n",
      "\n",
      "                                                                             text  \\\n",
      "count   3534                                                                        \n",
      "unique  3534                                                                        \n",
      "top     I`m gonna cry    I went bad at my History test ! I really hate History  !   \n",
      "freq    1                                                                           \n",
      "\n",
      "       sentiment  \n",
      "count   3534      \n",
      "unique  3         \n",
      "top     neutral   \n",
      "freq    1430      \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID  \\\n",
       "0  f87dea47db   \n",
       "1  96d74cb729   \n",
       "\n",
       "                                                                                                      text  \\\n",
       "0  Last session of the day  http://twitpic.com/67ezh                                                         \n",
       "1   Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).   \n",
       "\n",
       "  sentiment  \n",
       "0  neutral   \n",
       "1  positive  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"../data/test.csv\")\n",
    "print(pd.concat((test_df.dtypes, test_df.isna().sum()), axis=1))\n",
    "print(test_df.shape)\n",
    "\n",
    "# Counts of various columns\n",
    "print({i:test_df[i].nunique() for i in test_df.columns})\n",
    "print(test_df.describe())\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>c77717b103</td>\n",
       "      <td>I love to! But I`m only available from 5pm.  and where dear? Would love to help  convert her vids.ï¿½</td>\n",
       "      <td>I love to!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>28dbada620</td>\n",
       "      <td>*phew*  Will make a note in case anyone else runs into the same issueï¿½</td>\n",
       "      <td>*phew*  Will make a note in case anyone else runs into the same issueï¿½</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         textID  \\\n",
       "44   c77717b103   \n",
       "192  28dbada620   \n",
       "\n",
       "                                                                                                       text  \\\n",
       "44    I love to! But I`m only available from 5pm.  and where dear? Would love to help  convert her vids.ï¿½   \n",
       "192   *phew*  Will make a note in case anyone else runs into the same issueï¿½                                \n",
       "\n",
       "                                                                selected_text  \\\n",
       "44   I love to!                                                                 \n",
       "192  *phew*  Will make a note in case anyone else runs into the same issueï¿½   \n",
       "\n",
       "    sentiment  \n",
       "44   positive  \n",
       "192  neutral   "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['text'].astype('str').apply(lambda x : len(re.findall(pattern=\"ï¿½\", string=x))>0)].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>7223fdccc2</td>\n",
       "      <td>tikcets are only ï¿½91...each...BUT I SO WANT TO GO</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>43ad351369</td>\n",
       "      <td>AHHH - Whatchu talkinï¿½ baby?  HAHAHA I canï¿½t believe youu:O heh, actually I can. Life is worth taking risks... http://tumblr.com/xs81qy54s</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         textID  \\\n",
       "145  7223fdccc2   \n",
       "618  43ad351369   \n",
       "\n",
       "                                                                                                                                               text  \\\n",
       "145  tikcets are only ï¿½91...each...BUT I SO WANT TO GO                                                                                              \n",
       "618  AHHH - Whatchu talkinï¿½ baby?  HAHAHA I canï¿½t believe youu:O heh, actually I can. Life is worth taking risks... http://tumblr.com/xs81qy54s   \n",
       "\n",
       "    sentiment  \n",
       "145  positive  \n",
       "618  positive  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df['text'].astype('str').apply(lambda x : len(re.findall(pattern=\"ï¿½\", string=x))>0)].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment count in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>7781</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>11117</td>\n",
       "      <td>1430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>8582</td>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text  text\n",
       "sentiment             \n",
       "negative   7781   1001\n",
       "neutral    11117  1430\n",
       "positive   8582   1103"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df.groupby(\"sentiment\")[[\"text\"]].count(), test_df.groupby(\"sentiment\")[[\"text\"]].count()], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For traceability\n",
    "df[\"original_index\"] = df.index\n",
    "test_df[\"original_index\"] = test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27481, 5)\n",
      "(27480, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df[(~df.text.isna())]\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.copy()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment_code\"] = df[\"sentiment\"].astype(\"category\")\n",
    "X_sentiments = df[\"sentiment_code\"].cat.codes.values\n",
    "\n",
    "test_df[\"sentiment_code\"] = test_df[\"sentiment\"].astype(\"category\")\n",
    "X_sentiments_test = test_df[\"sentiment_code\"].cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "df[\"selected_text\"] = df[\"selected_text\"].astype(str)\n",
    "test_df[\"text\"] = test_df[\"text\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(x, extra_string=None):\n",
    "    x = x.lower()\n",
    "    x = re.sub('([!\"#$%&()*+,-./:;\\'<=>?@[\\\\]^_{|}~\\t\\n])', ' \\\\1 ', x) # Not including ` here since used in couldn`t, isn`t\n",
    "    x = x.strip()\n",
    "    x = re.sub(' +', ' ', x)\n",
    "    x = x.split(\" \")\n",
    "    if extra_string is not None:\n",
    "        x = [\"xxxSTART\"] + x + [\"xxxSENTIMENT\"] + [extra_string] + [\"xxxEND\"]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extremities(l_string, s_string, extra_string, print_it=False):\n",
    "    l_string = preprocess_text(l_string, extra_string)\n",
    "    s_string = preprocess_text(s_string, extra_string=None)\n",
    "    \n",
    "    len_l = len(l_string)\n",
    "    len_s = len(s_string)\n",
    "    \n",
    "    for i in range(len_l - len_s + 1):\n",
    "        if (i + len_s) <= len_l:\n",
    "            substring = l_string[i:i+len_s]\n",
    "            if substring == s_string:\n",
    "                if print_it:\n",
    "                    print(l_string)\n",
    "                    print(substring)\n",
    "                    print(i, i+len_s, substring)\n",
    "                \n",
    "                start_vector, end_vector = np.zeros(len_l, dtype=np.int16), np.zeros(len_l, dtype=np.int16)\n",
    "                att_vector = np.ones(len_l, dtype=np.int16)\n",
    "                start_vector[i], end_vector[i+len_s-1] = 1, 1\n",
    "                \n",
    "                return (l_string, s_string, start_vector, end_vector, att_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['xxxSTART',\n",
       "  '4am',\n",
       "  '.',\n",
       "  'and',\n",
       "  'im',\n",
       "  'on',\n",
       "  'the',\n",
       "  'beach',\n",
       "  '.',\n",
       "  'pretty',\n",
       "  'xxxSENTIMENT',\n",
       "  'positive',\n",
       "  'xxxEND'],\n",
       " ['pretty'],\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], dtype=int16),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], dtype=int16),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int16))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 100\n",
    "get_extremities(df.text[idx], df.selected_text[idx], df.sentiment[idx], print_it=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"text_mod\", \"selected_text_mod\", \"target_start\", \"target_stop\", \"target_atten\"]] = df.apply(lambda x: get_extremities(x.text, x.selected_text, x.sentiment), axis=1).apply(pd.Series)\n",
    "test_df[[\"text_mod\"]] = test_df.apply(lambda x: [preprocess_text(x.text, extra_string = x.sentiment)], axis=1).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID               0   \n",
       "text                 0   \n",
       "selected_text        0   \n",
       "sentiment            0   \n",
       "original_index       0   \n",
       "sentiment_code       0   \n",
       "text_mod             1476\n",
       "selected_text_mod    1476\n",
       "target_start         1476\n",
       "target_stop          1476\n",
       "target_atten         1476\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID            0\n",
       "text              0\n",
       "sentiment         0\n",
       "original_index    0\n",
       "sentiment_code    0\n",
       "text_mod          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>original_index</th>\n",
       "      <th>sentiment_code</th>\n",
       "      <th>text_mod</th>\n",
       "      <th>selected_text_mod</th>\n",
       "      <th>target_start</th>\n",
       "      <th>target_stop</th>\n",
       "      <th>target_atten</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[xxxSTART, i`d, have, responded, ,, if, i, were, going, xxxSENTIMENT, neutral, xxxEND]</td>\n",
       "      <td>[i`d, have, responded, ,, if, i, were, going]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>[xxxSTART, sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !, xxxSENTIMENT, negative, xxxEND]</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                            text  \\\n",
       "0  cb774db0d1   I`d have responded, if I were going             \n",
       "1  549e992a42   Sooo SAD I will miss you here in San Diego!!!   \n",
       "\n",
       "                         selected_text sentiment  original_index  \\\n",
       "0  I`d have responded, if I were going  neutral   0                \n",
       "1  Sooo SAD                             negative  1                \n",
       "\n",
       "  sentiment_code  \\\n",
       "0  neutral         \n",
       "1  negative        \n",
       "\n",
       "                                                                                                   text_mod  \\\n",
       "0  [xxxSTART, i`d, have, responded, ,, if, i, were, going, xxxSENTIMENT, neutral, xxxEND]                     \n",
       "1  [xxxSTART, sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !, xxxSENTIMENT, negative, xxxEND]   \n",
       "\n",
       "                               selected_text_mod  \\\n",
       "0  [i`d, have, responded, ,, if, i, were, going]   \n",
       "1  [sooo, sad]                                     \n",
       "\n",
       "                                          target_start  \\\n",
       "0  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]                  \n",
       "1  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                           target_stop  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]                  \n",
       "1  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                          target_atten  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]                 \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>original_index</th>\n",
       "      <th>sentiment_code</th>\n",
       "      <th>text_mod</th>\n",
       "      <th>selected_text_mod</th>\n",
       "      <th>target_start</th>\n",
       "      <th>target_stop</th>\n",
       "      <th>target_atten</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>af3fed7fc3</td>\n",
       "      <td>is back home now      gonna miss every one</td>\n",
       "      <td>onna</td>\n",
       "      <td>negative</td>\n",
       "      <td>18</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1c31703aef</td>\n",
       "      <td>If it is any consolation I got my BMI tested hahaha it says I am obesed  well so much for being unhappy for about 10 minutes.</td>\n",
       "      <td>well so much for being unhappy for about 10 minute</td>\n",
       "      <td>negative</td>\n",
       "      <td>32</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        textID  \\\n",
       "18  af3fed7fc3   \n",
       "32  1c31703aef   \n",
       "\n",
       "                                                                                                                              text  \\\n",
       "18  is back home now      gonna miss every one                                                                                       \n",
       "32   If it is any consolation I got my BMI tested hahaha it says I am obesed  well so much for being unhappy for about 10 minutes.   \n",
       "\n",
       "                                         selected_text sentiment  \\\n",
       "18  onna                                                negative   \n",
       "32  well so much for being unhappy for about 10 minute  negative   \n",
       "\n",
       "    original_index sentiment_code text_mod selected_text_mod target_start  \\\n",
       "18  18              negative       NaN      NaN               NaN           \n",
       "32  32              negative       NaN      NaN               NaN           \n",
       "\n",
       "   target_stop target_atten  \n",
       "18  NaN         NaN          \n",
       "32  NaN         NaN          "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[df.loc[df['target_start'].isna()].index].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>original_index</th>\n",
       "      <th>sentiment_code</th>\n",
       "      <th>text_mod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[xxxSTART, last, session, of, the, day, http, :, /, /, twitpic, ., com, /, 67ezh, xxxSENTIMENT, neutral, xxxEND]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>[xxxSTART, shanghai, is, also, really, exciting, (, precisely, -, -, skyscrapers, galore, ), ., good, tweeps, in, china, :, (, sh, ), (, bj, ), ., xxxSENTIMENT, positive, xxxEND]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID  \\\n",
       "0  f87dea47db   \n",
       "1  96d74cb729   \n",
       "\n",
       "                                                                                                      text  \\\n",
       "0  Last session of the day  http://twitpic.com/67ezh                                                         \n",
       "1   Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).   \n",
       "\n",
       "  sentiment  original_index sentiment_code  \\\n",
       "0  neutral   0               neutral         \n",
       "1  positive  1               positive        \n",
       "\n",
       "                                                                                                                                                                             text_mod  \n",
       "0  [xxxSTART, last, session, of, the, day, http, :, /, /, twitpic, ., com, /, 67ezh, xxxSENTIMENT, neutral, xxxEND]                                                                    \n",
       "1  [xxxSTART, shanghai, is, also, really, exciting, (, precisely, -, -, skyscrapers, galore, ), ., good, tweeps, in, china, :, (, sh, ), (, bj, ), ., xxxSENTIMENT, positive, xxxEND]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalous_idxs = df.loc[df['target_start'].isna()].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27480, 11)\n",
      "(26004, 11)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df[~df.index.isin(anomalous_idxs)]\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.copy()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " X_words: \t 26004 \n",
      " X_att: \t 26004 \n",
      " Y_words: \t 26004 \n",
      " Y_starts: \t 26004 \n",
      " Y_stops: \t 26004 \n",
      " X_words_test: \t 3534 \n",
      " X_att_test: \t 3534 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_words = df['text_mod'].apply(lambda x:list(x)).tolist()\n",
    "X_att = df['target_atten'].apply(lambda x:list(x)).tolist()\n",
    "\n",
    "X_words_test = test_df['text_mod'].apply(lambda x:list(x)).tolist()\n",
    "X_att_test = [[1 for j in i] for i in X_words_test]\n",
    "\n",
    "Y_words = df['selected_text_mod'].apply(lambda x:list(x)).tolist()\n",
    "Y_starts = df['target_start'].apply(lambda x:list(x)).tolist()\n",
    "Y_stops = df['target_stop'].apply(lambda x:list(x)).tolist()\n",
    "\n",
    "print(\"\\n\",\n",
    "    \"X_words:\",\"\\t\", len(X_words),\"\\n\",\n",
    "    \"X_att:\",\"\\t\", len(X_att),\"\\n\",\n",
    "    \"Y_words:\",\"\\t\", len(Y_words),\"\\n\",\n",
    "    \"Y_starts:\",\"\\t\", len(Y_starts),\"\\n\",\n",
    "    \"Y_stops:\",\"\\t\", len(Y_stops),\"\\n\",\n",
    "    \"X_words_test:\",\"\\t\", len(X_words_test),\"\\n\",\n",
    "    \"X_att_test:\",\"\\t\", len(X_att_test),\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3534\n",
      "26004\n"
     ]
    }
   ],
   "source": [
    "print(sum([len(i)==len(j) for i,j in zip(X_att_test, X_words_test)]))\n",
    "print(sum([len(i)==len(j) for i,j in zip(X_att, X_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 33619),\n",
       " ('xxxSTART', 26004),\n",
       " ('xxxSENTIMENT', 26004),\n",
       " ('xxxEND', 26004),\n",
       " ('!', 14379),\n",
       " ('i', 12615),\n",
       " ('neutral', 10941),\n",
       " ('to', 9447),\n",
       " ('the', 8445),\n",
       " (',', 7984)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "word_counts = Counter([j for i in X_words for j in i])\n",
    "\n",
    "X_unique_tokens = len(word_counts)\n",
    "word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_WORD_FREQ = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB reduced from 25847 to 10178\n"
     ]
    }
   ],
   "source": [
    "word_subset = [i for i,j in word_counts.items() if j >= MIN_WORD_FREQ]\n",
    "print(\"VOCAB reduced from\", len(word_counts), \"to\", len(word_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_of_words = set(sorted([j for i in X_words for j in i]))\n",
    "#Y_list_of_words = set(sorted([j for i in Y_words for j in i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_itos = {i+2:j for i,j in enumerate(word_subset)}\n",
    "vocab_stoi = {j:i+2 for i,j in enumerate(word_subset)}\n",
    "\n",
    "vocab_stoi[\"xxxUNK\"] = 1\n",
    "vocab_itos[1] = \"xxxUNK\"\n",
    "\n",
    "vocab_stoi[\"xxxNone\"] = 0\n",
    "vocab_itos[0] = \"xxxNone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_vocab(vocab, word):\n",
    "    try:\n",
    "        value = vocab[word]\n",
    "    except KeyError as k:\n",
    "        value = vocab_stoi[\"xxxUNK\"]\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[get_from_vocab(vocab_stoi,j) for j in i] for i in X_words]\n",
    "Y = [[get_from_vocab(vocab_stoi,j) for j in i] for i in Y_words]\n",
    "X_test = [[get_from_vocab(vocab_stoi,j) for j in i] for i in X_words_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10180 110\n"
     ]
    }
   ],
   "source": [
    "max_len = max([len(i) for i in X])\n",
    "VOCAB_SIZE = len(vocab_stoi)\n",
    "print(VOCAB_SIZE, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Validation  split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26004 20803 5201 26004\n"
     ]
    }
   ],
   "source": [
    "idx = [i for i in np.arange(len(Y))]\n",
    "np.random.shuffle(idx)\n",
    "train_idx, val_idx = idx[:round(TRAIN_SPLIT_RATIO*len(Y))], idx[round(TRAIN_SPLIT_RATIO * len(Y)):]\n",
    "\n",
    "print(len(idx), len(train_idx), len(val_idx), len(train_idx) + len(val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 20803 \t : X_train \n",
      " 20803 \t : X_att_train \n",
      " 20803 \t : Y_train \n",
      " 20803 \t : Y_starts_train \n",
      " 20803 \t : Y_stops_train \n",
      " 5201 \t : X_val \n",
      " 5201 \t : X_att_val \n",
      " 5201 \t : Y_val \n",
      " 5201 \t : Y_starts_val \n",
      " 5201 \t : Y_stops_val \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val = [X[i] for i in train_idx], [X[i] for i in val_idx]\n",
    "X_att_train, X_att_val = [X_att[i] for i in train_idx], [X_att[i] for i in val_idx]\n",
    "\n",
    "Y_train, Y_val = [Y[i] for i in train_idx], [Y[i] for i in val_idx]\n",
    "Y_starts_train, Y_starts_val = [Y_starts[i] for i in train_idx], [Y_starts[i] for i in val_idx]\n",
    "Y_stops_train, Y_stops_val = [Y_stops[i] for i in train_idx], [Y_stops[i] for i in val_idx]\n",
    "\n",
    "print(\"\\n\",\n",
    "    len(X_train),\"\\t\",\": X_train\",\"\\n\",\n",
    "    len(X_att_train),\"\\t\",\": X_att_train\",\"\\n\",\n",
    "    len(Y_train),\"\\t\",\": Y_train\",\"\\n\",\n",
    "    len(Y_starts_train),\"\\t\",\": Y_starts_train\",\"\\n\",\n",
    "    len(Y_stops_train),\"\\t\",\": Y_stops_train\",\"\\n\",\n",
    "    len(X_val),\"\\t\",\": X_val\",\"\\n\",\n",
    "    len(X_att_val),\"\\t\",\": X_att_val\",\"\\n\",\n",
    "    len(Y_val),\"\\t\",\": Y_val\",\"\\n\",\n",
    "    len(Y_starts_val),\"\\t\",\": Y_starts_val\",\"\\n\",\n",
    "    len(Y_stops_val),\"\\t\",\": Y_stops_val\",\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=max_len, padding=\"post\")\n",
    "X_att_train = pad_sequences(X_att_train, maxlen=max_len, padding=\"post\")\n",
    "Y_train = pad_sequences(Y_train, maxlen=max_len, padding=\"post\")\n",
    "Y_starts_train = pad_sequences(Y_starts_train, maxlen=max_len, padding=\"post\")\n",
    "Y_stops_train = pad_sequences(Y_stops_train, maxlen=max_len, padding=\"post\")\n",
    "\n",
    "X_val = pad_sequences(X_val, maxlen=max_len, padding=\"post\")\n",
    "X_att_val = pad_sequences(X_att_val, maxlen=max_len, padding=\"post\")\n",
    "Y_val = pad_sequences(Y_val, maxlen=max_len, padding=\"post\")\n",
    "Y_starts_val = pad_sequences(Y_starts_val, maxlen=max_len, padding=\"post\")\n",
    "Y_stops_val = pad_sequences(Y_stops_val, maxlen=max_len, padding=\"post\")\n",
    "\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding=\"post\")\n",
    "X_att_test = pad_sequences(X_att_test, maxlen=max_len, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " (20803, 110) \t: X_train  \n",
      " (20803, 110) \t: X_att_train  \n",
      " (20803, 110) \t: Y_train  \n",
      " (20803, 110) \t: Y_starts_train  \n",
      " (20803, 110) \t: Y_stops_train  \n",
      " (5201, 110) \t: X_val  \n",
      " (5201, 110) \t: X_att_val  \n",
      " (5201, 110) \t: Y_val  \n",
      " (5201, 110) \t: Y_starts_val  \n",
      " (5201, 110) \t: Y_stops_val  \n",
      " (3534, 110) \t: X_test  \n",
      " (3534, 110) \t: X_att_test  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\",\n",
    "     X_train.shape, \"\\t: X_train \", \"\\n\",\n",
    "     X_att_train.shape, \"\\t: X_att_train \", \"\\n\",\n",
    "     Y_train.shape, \"\\t: Y_train \", \"\\n\",\n",
    "     Y_starts_train.shape, \"\\t: Y_starts_train \", \"\\n\",\n",
    "     Y_stops_train.shape, \"\\t: Y_stops_train \", \"\\n\",\n",
    "\n",
    "     X_val.shape, \"\\t: X_val \", \"\\n\",\n",
    "     X_att_val.shape, \"\\t: X_att_val \", \"\\n\",\n",
    "     Y_val.shape, \"\\t: Y_val \", \"\\n\",\n",
    "     Y_starts_val.shape, \"\\t: Y_starts_val \", \"\\n\",\n",
    "     Y_stops_val.shape, \"\\t: Y_stops_val \", \"\\n\",\n",
    "\n",
    "     X_test.shape, \"\\t: X_test \", \"\\n\",\n",
    "     X_att_test.shape, \"\\t: X_att_test \", \"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for zero input vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 36\n",
      "0 36\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax([X_train.sum(axis=1)==0]), np.min([X_train.sum(axis=1)]))\n",
    "print(np.argmax([X_val.sum(axis=1)==0]), np.min([X_val.sum(axis=1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1, 1662, 0, 0],\n",
       " [87, 1, 648, 0, 0],\n",
       " [17, 1, 2533, 0, 0],\n",
       " [2174, 1, 7, 0, 0],\n",
       " [669, 1, 1685, 0, 0],\n",
       " [84, 1, 278, 0, 0],\n",
       " [1662, 1, 17, 1, 0],\n",
       " [648, 1, 229, 0, 0],\n",
       " [2533, 1, 4625, 0, 0],\n",
       " [7, 1, 116, 0, 0],\n",
       " [1685, 1, 44, 0, 0],\n",
       " [278, 1, 406, 0, 0],\n",
       " [17, 1, 8227, 0, 0],\n",
       " [229, 1, 0, 0, 0],\n",
       " [4625, 1, 0, 0, 0],\n",
       " [116, 1, 0, 0, 0],\n",
       " [44, 1, 0, 0, 0],\n",
       " [406, 1, 0, 0, 0],\n",
       " [8227, 1, 0, 0, 1],\n",
       " [7492, 1, 0, 0, 0],\n",
       " [10, 1, 0, 0, 0],\n",
       " [11, 1, 0, 0, 0],\n",
       " [12, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train\n",
    "num = 100\n",
    "[[i,j,k,l,m] for i,j,k,l,m in zip(X_train[num],\n",
    "                                  X_att_train[num],\n",
    "                                  Y_train[num],\n",
    "                                  Y_starts_train[num],\n",
    "                                  Y_stops_train[num])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1, 9890, 0, 0],\n",
       " [9890, 1, 8753, 1, 0],\n",
       " [8753, 1, 55, 0, 0],\n",
       " [55, 1, 4465, 0, 0],\n",
       " [4465, 1, 305, 0, 0],\n",
       " [305, 1, 1, 0, 0],\n",
       " [1, 1, 28, 0, 0],\n",
       " [28, 1, 0, 0, 1],\n",
       " [47, 1, 0, 0, 0],\n",
       " [48, 1, 0, 0, 0],\n",
       " [49, 1, 0, 0, 0],\n",
       " [49, 1, 0, 0, 0],\n",
       " [50, 1, 0, 0, 0],\n",
       " [28, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [28, 1, 0, 0, 0],\n",
       " [51, 1, 0, 0, 0],\n",
       " [49, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [49, 1, 0, 0, 0],\n",
       " [9890, 1, 0, 0, 0],\n",
       " [28, 1, 0, 0, 0],\n",
       " [7327, 1, 0, 0, 0],\n",
       " [10, 1, 0, 0, 0],\n",
       " [11, 1, 0, 0, 0],\n",
       " [12, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Val\n",
    "num = 100\n",
    "[[i,j,k,l,m] for i,j,k,l,m in zip(X_val[num],\n",
    "                                  X_att_val[num],\n",
    "                                  Y_val[num],\n",
    "                                  Y_starts_val[num],\n",
    "                                  Y_stops_val[num])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['xxxSTART', 2, 1],\n",
       " ['oooh', 3482, 1],\n",
       " [',', 5, 1],\n",
       " ['sunshine', 1726, 1],\n",
       " ['!', 22, 1],\n",
       " ['a', 142, 1],\n",
       " ['patch', 905, 1],\n",
       " ['of', 34, 1],\n",
       " ['sunshine', 1726, 1],\n",
       " ['!', 22, 1],\n",
       " ['and', 68, 1],\n",
       " ['it', 144, 1],\n",
       " ['will', 15, 1],\n",
       " ['be', 89, 1],\n",
       " ['gone', 544, 1],\n",
       " ['by', 106, 1],\n",
       " ['the', 42, 1],\n",
       " ['time', 504, 1],\n",
       " ['i', 7, 1],\n",
       " ['leave', 31, 1],\n",
       " ['work', 342, 1],\n",
       " ['and', 68, 1],\n",
       " ['replaced', 1, 1],\n",
       " ['with', 278, 1],\n",
       " ['rain', 1901, 1],\n",
       " ['.', 28, 1],\n",
       " ['/', 49, 1],\n",
       " ['vent', 9146, 1],\n",
       " ['xxxSENTIMENT', 10, 1],\n",
       " ['neutral', 11, 1],\n",
       " ['xxxEND', 12, 1]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "num = 100\n",
    "[[i,j,k] for i,j,k in zip(X_words_test[num],\n",
    "                          X_test[num],\n",
    "                          X_att_test[num])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_att_flags = Input((max_len), name=\"att_flags\")\n",
    "input_sequences = Input((max_len), name=\"words\")\n",
    "\n",
    "emb_sequences = Embedding(input_dim=VOCAB_SIZE, input_length=max_len, output_dim=64, mask_zero=True)(input_sequences)\n",
    "\n",
    "seq = Bidirectional(LSTM(32, activation=None, return_sequences=True))(emb_sequences)\n",
    "seq = BatchNormalization()(seq)\n",
    "seq = Activation(\"relu\")(seq)\n",
    "seq = Dropout(DROPOUT)(seq)\n",
    "\n",
    "seq = Bidirectional(LSTM(32, activation=None, return_sequences=True))(seq)\n",
    "seq = BatchNormalization()(seq)\n",
    "seq = Activation(\"relu\")(seq)\n",
    "seq = Dropout(DROPOUT)(seq)\n",
    "\n",
    "seq = Bidirectional(LSTM(32, activation=None, return_sequences=True))(seq)\n",
    "seq = Attention(max_len)(seq)\n",
    "seq = BatchNormalization()(seq)\n",
    "seq = Activation(\"relu\")(seq)\n",
    "seq = Dropout(DROPOUT)(seq)\n",
    "\n",
    "seq = Dense(max_len, activation=\"relu\")(seq)\n",
    "seq = BatchNormalization()(seq)\n",
    "seq = Dropout(DROPOUT)(seq)\n",
    "\n",
    "att = Dense(max_len, activation=\"relu\")(input_att_flags)\n",
    "att = BatchNormalization()(att)\n",
    "att = Dropout(DROPOUT)(att)\n",
    "\n",
    "convs = Conv1D(filters=32, kernel_size=8, padding=\"same\", activation=None)(emb_sequences)\n",
    "convs = BatchNormalization()(convs)\n",
    "convs = Activation(\"relu\")(convs)\n",
    "convs = MaxPooling1D(pool_size=2, strides=1)(convs)\n",
    "convs = Dropout(DROPOUT)(convs)\n",
    "\n",
    "convs = Conv1D(filters=32, kernel_size=8, padding=\"same\", activation=None)(convs)\n",
    "convs = BatchNormalization()(convs)\n",
    "convs = Activation(\"relu\")(convs)\n",
    "convs = MaxPooling1D(pool_size=2, strides=1)(convs)\n",
    "convs = Dropout(DROPOUT)(convs)\n",
    "\n",
    "convs = Conv1D(filters=32, kernel_size=8, padding=\"same\", activation=None)(convs)\n",
    "convs = BatchNormalization()(convs)\n",
    "convs = Activation(\"relu\")(convs)\n",
    "convs = MaxPooling1D(pool_size=2, strides=1)(convs)\n",
    "convs = Dropout(DROPOUT)(convs)\n",
    "\n",
    "convs = Flatten()(convs)\n",
    "convs = Dense(max_len, activation=None)(convs)\n",
    "convs = BatchNormalization()(convs)\n",
    "convs = Activation(\"relu\")(convs)\n",
    "convs = Dropout(DROPOUT)(convs)\n",
    "\n",
    "conv = Multiply()([att, convs])\n",
    "seq = Multiply()([att, seq])\n",
    "concat_layer = concatenate([conv, seq])\n",
    "\n",
    "output_starts = Dense(max_len, activation=None)(concat_layer)\n",
    "output_starts = BatchNormalization()(output_starts)\n",
    "output_starts = Activation(\"relu\")(output_starts)\n",
    "output_starts = Dropout(DROPOUT)(output_starts)\n",
    "\n",
    "output_starts = Dense(max_len, activation=None)(output_starts)\n",
    "output_starts = Activation(\"relu\")(output_starts)\n",
    "\n",
    "output_stops = Dense(max_len, activation=None)(concat_layer)\n",
    "output_stops = BatchNormalization()(output_stops)\n",
    "output_stops = Activation(\"relu\")(output_stops)\n",
    "output_stops = Dropout(DROPOUT)(output_stops)\n",
    "\n",
    "output_stops = Dense(max_len, activation=None)(output_stops)\n",
    "output_stops = Activation(\"relu\")(output_stops)\n",
    "\n",
    "output_starts = Dense(max_len, activation='softmax', name=\"starts\")(output_starts)\n",
    "output_stops = Dense(max_len, activation='softmax', name=\"stops\")(output_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words (InputLayer)              [(None, 110)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 110, 64)      651520      words[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 110, 32)      16416       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 110, 32)      128         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 110, 32)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 109, 32)      0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 109, 32)      0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 110, 64)      24832       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 109, 32)      8224        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 110, 64)      256         bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 109, 32)      128         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 110, 64)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 109, 32)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 110, 64)      0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 108, 32)      0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 110, 64)      24832       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 108, 32)      0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 110, 64)      256         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 108, 32)      8224        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 110, 64)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 108, 32)      128         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 110, 64)      0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 108, 32)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 110, 64)      24832       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 107, 32)      0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 64)           174         bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 107, 32)      0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64)           256         attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3424)         0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64)           0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "att_flags (InputLayer)          [(None, 110)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 110)          376750      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 110)          12210       att_flags[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 110)          440         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 110)          7150        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 110)          440         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 110)          0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 110)          440         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 110)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 110)          0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 110)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 110)          0           dropout_4[0][0]                  \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 110)          0           dropout_4[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 220)          0           multiply[0][0]                   \n",
      "                                                                 multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 110)          24310       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 110)          24310       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 110)          440         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 110)          440         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 110)          0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 110)          0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 110)          0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 110)          0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 110)          12210       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 110)          12210       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 110)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 110)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "starts (Dense)                  (None, 110)          12210       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "stops (Dense)                   (None, 110)          12210       activation_10[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,255,976\n",
      "Trainable params: 1,254,300\n",
      "Non-trainable params: 1,676\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([input_att_flags, input_sequences], [output_starts, output_stops])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=MIN_LR)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=adam , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks\n",
    "mcp = ModelCheckpoint(filepath=\"../results/\"+MODEL_PREFIX+\"BestCheckpoint.h5\",\n",
    "                      monitor='val_loss',\n",
    "                      mode=\"auto\",\n",
    "                      save_weights_only=False,\n",
    "                      save_best_only=True)\n",
    "\n",
    "clr = CyclicLR(mode=CLR_METHOD,\n",
    "               base_lr=MIN_LR,\n",
    "               max_lr=MAX_LR,\n",
    "               step_size= STEP_SIZE * (X_train.shape[0] // BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20803 samples, validate on 5201 samples\n",
      "Epoch 1/100\n",
      "20803/20803 [==============================] - 33s 2ms/sample - loss: 9.7259 - starts_loss: 4.8958 - stops_loss: 4.8268 - starts_accuracy: 0.0065 - stops_accuracy: 0.0101 - val_loss: 9.3942 - val_starts_loss: 4.6981 - val_stops_loss: 4.6955 - val_starts_accuracy: 0.0081 - val_stops_accuracy: 0.0406\n",
      "Epoch 2/100\n",
      "20803/20803 [==============================] - 18s 860us/sample - loss: 9.3171 - starts_loss: 4.6140 - stops_loss: 4.6894 - starts_accuracy: 0.0274 - stops_accuracy: 0.0237 - val_loss: 9.3201 - val_starts_loss: 4.6479 - val_stops_loss: 4.6718 - val_starts_accuracy: 0.2665 - val_stops_accuracy: 0.0461\n",
      "Epoch 3/100\n",
      "20803/20803 [==============================] - 18s 852us/sample - loss: 8.3595 - starts_loss: 3.9277 - stops_loss: 4.4009 - starts_accuracy: 0.3430 - stops_accuracy: 0.0532 - val_loss: 9.0809 - val_starts_loss: 4.4772 - val_stops_loss: 4.6035 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.0473\n",
      "Epoch 4/100\n",
      "20803/20803 [==============================] - 18s 861us/sample - loss: 6.8344 - starts_loss: 2.9060 - stops_loss: 3.8976 - starts_accuracy: 0.5937 - stops_accuracy: 0.0971 - val_loss: 8.3482 - val_starts_loss: 3.9408 - val_stops_loss: 4.4082 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.1071\n",
      "Epoch 5/100\n",
      "20803/20803 [==============================] - 18s 856us/sample - loss: 5.4054 - starts_loss: 2.1498 - stops_loss: 3.2329 - starts_accuracy: 0.5984 - stops_accuracy: 0.1698 - val_loss: 7.3746 - val_starts_loss: 3.3310 - val_stops_loss: 4.0497 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.1704\n",
      "Epoch 6/100\n",
      "20803/20803 [==============================] - 18s 850us/sample - loss: 4.5895 - starts_loss: 1.8974 - stops_loss: 2.6944 - starts_accuracy: 0.5984 - stops_accuracy: 0.2863 - val_loss: 6.6912 - val_starts_loss: 3.0326 - val_stops_loss: 3.6721 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.1973\n",
      "Epoch 7/100\n",
      "20803/20803 [==============================] - 18s 849us/sample - loss: 4.1541 - starts_loss: 1.7898 - stops_loss: 2.3546 - starts_accuracy: 0.5984 - stops_accuracy: 0.3660 - val_loss: 6.1018 - val_starts_loss: 2.7362 - val_stops_loss: 3.3886 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.2465\n",
      "Epoch 8/100\n",
      "20803/20803 [==============================] - 18s 845us/sample - loss: 3.8928 - starts_loss: 1.7257 - stops_loss: 2.1643 - starts_accuracy: 0.5985 - stops_accuracy: 0.4093 - val_loss: 5.7171 - val_starts_loss: 2.5213 - val_stops_loss: 3.2289 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.2396\n",
      "Epoch 9/100\n",
      "20803/20803 [==============================] - 18s 861us/sample - loss: 3.7296 - starts_loss: 1.6862 - stops_loss: 2.0404 - starts_accuracy: 0.5985 - stops_accuracy: 0.4420 - val_loss: 5.4747 - val_starts_loss: 2.3596 - val_stops_loss: 3.1551 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.1650\n",
      "Epoch 10/100\n",
      "20803/20803 [==============================] - 18s 862us/sample - loss: 3.6204 - starts_loss: 1.6587 - stops_loss: 1.9677 - starts_accuracy: 0.5985 - stops_accuracy: 0.4580 - val_loss: 5.3319 - val_starts_loss: 2.2551 - val_stops_loss: 3.1229 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.1281\n",
      "Epoch 11/100\n",
      "20803/20803 [==============================] - 18s 853us/sample - loss: 3.5424 - starts_loss: 1.6344 - stops_loss: 1.9044 - starts_accuracy: 0.5985 - stops_accuracy: 0.4795 - val_loss: 5.2423 - val_starts_loss: 2.1742 - val_stops_loss: 3.1181 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.0988\n",
      "Epoch 12/100\n",
      "20803/20803 [==============================] - 18s 860us/sample - loss: 3.4902 - starts_loss: 1.6189 - stops_loss: 1.8759 - starts_accuracy: 0.5985 - stops_accuracy: 0.4915 - val_loss: 5.1998 - val_starts_loss: 2.1374 - val_stops_loss: 3.1172 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.0740\n",
      "Epoch 13/100\n",
      "20803/20803 [==============================] - 18s 848us/sample - loss: 3.4487 - starts_loss: 1.6075 - stops_loss: 1.8353 - starts_accuracy: 0.5985 - stops_accuracy: 0.5058 - val_loss: 5.1319 - val_starts_loss: 2.1050 - val_stops_loss: 3.0816 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.0463\n",
      "Epoch 14/100\n",
      "20803/20803 [==============================] - 18s 854us/sample - loss: 3.3992 - starts_loss: 1.5947 - stops_loss: 1.8018 - starts_accuracy: 0.5985 - stops_accuracy: 0.5181 - val_loss: 5.0671 - val_starts_loss: 2.0829 - val_stops_loss: 3.0402 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.1100\n",
      "Epoch 15/100\n",
      "20803/20803 [==============================] - 18s 863us/sample - loss: 3.3750 - starts_loss: 1.5901 - stops_loss: 1.7856 - starts_accuracy: 0.5985 - stops_accuracy: 0.5253 - val_loss: 5.0319 - val_starts_loss: 2.0834 - val_stops_loss: 3.0054 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.1513\n",
      "Epoch 16/100\n",
      "20803/20803 [==============================] - 18s 878us/sample - loss: 3.3654 - starts_loss: 1.5935 - stops_loss: 1.7693 - starts_accuracy: 0.5985 - stops_accuracy: 0.5293 - val_loss: 4.9775 - val_starts_loss: 2.0698 - val_stops_loss: 2.9657 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.1657\n",
      "Epoch 17/100\n",
      "20803/20803 [==============================] - 18s 871us/sample - loss: 3.3484 - starts_loss: 1.5889 - stops_loss: 1.7634 - starts_accuracy: 0.5985 - stops_accuracy: 0.5356 - val_loss: 4.8845 - val_starts_loss: 2.0558 - val_stops_loss: 2.8850 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.2428\n",
      "Epoch 18/100\n",
      "20803/20803 [==============================] - 18s 873us/sample - loss: 3.3357 - starts_loss: 1.5837 - stops_loss: 1.7504 - starts_accuracy: 0.5984 - stops_accuracy: 0.5351 - val_loss: 4.8071 - val_starts_loss: 2.0579 - val_stops_loss: 2.8052 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.2899\n",
      "Epoch 19/100\n",
      "20803/20803 [==============================] - 18s 848us/sample - loss: 3.3313 - starts_loss: 1.5820 - stops_loss: 1.7460 - starts_accuracy: 0.5985 - stops_accuracy: 0.5354 - val_loss: 4.7095 - val_starts_loss: 2.0504 - val_stops_loss: 2.7150 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.3238\n",
      "Epoch 20/100\n",
      "20803/20803 [==============================] - 18s 851us/sample - loss: 3.3315 - starts_loss: 1.5822 - stops_loss: 1.7484 - starts_accuracy: 0.5985 - stops_accuracy: 0.5353 - val_loss: 4.5924 - val_starts_loss: 2.0401 - val_stops_loss: 2.6069 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.3534\n",
      "Epoch 21/100\n",
      "20803/20803 [==============================] - 18s 857us/sample - loss: 3.3191 - starts_loss: 1.5860 - stops_loss: 1.7442 - starts_accuracy: 0.5985 - stops_accuracy: 0.5391 - val_loss: 4.4878 - val_starts_loss: 2.0316 - val_stops_loss: 2.5090 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.3790\n",
      "Epoch 22/100\n",
      "20803/20803 [==============================] - 18s 865us/sample - loss: 3.3182 - starts_loss: 1.5801 - stops_loss: 1.7463 - starts_accuracy: 0.5985 - stops_accuracy: 0.5389 - val_loss: 4.3748 - val_starts_loss: 2.0149 - val_stops_loss: 2.4117 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4028\n",
      "Epoch 23/100\n",
      "20803/20803 [==============================] - 18s 856us/sample - loss: 3.3049 - starts_loss: 1.5764 - stops_loss: 1.7279 - starts_accuracy: 0.5985 - stops_accuracy: 0.5409 - val_loss: 4.2386 - val_starts_loss: 1.9933 - val_stops_loss: 2.2963 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4153\n",
      "Epoch 24/100\n",
      "20803/20803 [==============================] - 18s 848us/sample - loss: 3.3117 - starts_loss: 1.5715 - stops_loss: 1.7337 - starts_accuracy: 0.5985 - stops_accuracy: 0.5400 - val_loss: 4.1329 - val_starts_loss: 1.9750 - val_stops_loss: 2.2072 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4480\n",
      "Epoch 25/100\n",
      "20803/20803 [==============================] - 18s 860us/sample - loss: 3.2767 - starts_loss: 1.5722 - stops_loss: 1.7081 - starts_accuracy: 0.5985 - stops_accuracy: 0.5489 - val_loss: 3.9783 - val_starts_loss: 1.9504 - val_stops_loss: 2.0738 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4766\n",
      "Epoch 26/100\n",
      "20803/20803 [==============================] - 18s 863us/sample - loss: 3.2752 - starts_loss: 1.5739 - stops_loss: 1.7053 - starts_accuracy: 0.5985 - stops_accuracy: 0.5519 - val_loss: 3.8987 - val_starts_loss: 1.9147 - val_stops_loss: 2.0276 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4670\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "20803/20803 [==============================] - 18s 851us/sample - loss: 3.2531 - starts_loss: 1.5632 - stops_loss: 1.6910 - starts_accuracy: 0.5985 - stops_accuracy: 0.5523 - val_loss: 3.7717 - val_starts_loss: 1.8773 - val_stops_loss: 1.9375 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4880\n",
      "Epoch 28/100\n",
      "20803/20803 [==============================] - 18s 852us/sample - loss: 3.2288 - starts_loss: 1.5584 - stops_loss: 1.6673 - starts_accuracy: 0.5985 - stops_accuracy: 0.5579 - val_loss: 3.6738 - val_starts_loss: 1.8546 - val_stops_loss: 1.8614 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.5061\n",
      "Epoch 29/100\n",
      "20803/20803 [==============================] - 18s 863us/sample - loss: 3.2164 - starts_loss: 1.5529 - stops_loss: 1.6644 - starts_accuracy: 0.5985 - stops_accuracy: 0.5598 - val_loss: 3.5364 - val_starts_loss: 1.8160 - val_stops_loss: 1.7583 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.5334\n",
      "Epoch 30/100\n",
      "20803/20803 [==============================] - 18s 858us/sample - loss: 3.1934 - starts_loss: 1.5430 - stops_loss: 1.6442 - starts_accuracy: 0.5984 - stops_accuracy: 0.5624 - val_loss: 3.4744 - val_starts_loss: 1.7768 - val_stops_loss: 1.7341 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.5378\n",
      "Epoch 31/100\n",
      "20803/20803 [==============================] - 18s 844us/sample - loss: 3.1752 - starts_loss: 1.5398 - stops_loss: 1.6357 - starts_accuracy: 0.5984 - stops_accuracy: 0.5637 - val_loss: 3.3656 - val_starts_loss: 1.7342 - val_stops_loss: 1.6661 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.5589\n",
      "Epoch 32/100\n",
      "20803/20803 [==============================] - 18s 862us/sample - loss: 3.1451 - starts_loss: 1.5271 - stops_loss: 1.6083 - starts_accuracy: 0.5985 - stops_accuracy: 0.5708 - val_loss: 3.3380 - val_starts_loss: 1.7333 - val_stops_loss: 1.6397 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.5649\n",
      "Epoch 33/100\n",
      "20803/20803 [==============================] - 18s 842us/sample - loss: 3.1275 - starts_loss: 1.5267 - stops_loss: 1.5998 - starts_accuracy: 0.5984 - stops_accuracy: 0.5718 - val_loss: 3.3483 - val_starts_loss: 1.7502 - val_stops_loss: 1.6339 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.5666\n",
      "Epoch 34/100\n",
      "20803/20803 [==============================] - 18s 855us/sample - loss: 3.1020 - starts_loss: 1.5184 - stops_loss: 1.5900 - starts_accuracy: 0.5984 - stops_accuracy: 0.5801 - val_loss: 3.2327 - val_starts_loss: 1.6737 - val_stops_loss: 1.5890 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.5745\n",
      "Epoch 35/100\n",
      "20803/20803 [==============================] - 17s 841us/sample - loss: 3.0813 - starts_loss: 1.5092 - stops_loss: 1.5651 - starts_accuracy: 0.5985 - stops_accuracy: 0.5783 - val_loss: 3.2685 - val_starts_loss: 1.7031 - val_stops_loss: 1.5977 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.5732\n",
      "Epoch 36/100\n",
      "20803/20803 [==============================] - 18s 862us/sample - loss: 3.0806 - starts_loss: 1.5139 - stops_loss: 1.5720 - starts_accuracy: 0.5985 - stops_accuracy: 0.5780 - val_loss: 3.2150 - val_starts_loss: 1.6722 - val_stops_loss: 1.5738 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.5818\n",
      "Epoch 37/100\n",
      "20803/20803 [==============================] - 18s 855us/sample - loss: 3.0580 - starts_loss: 1.5002 - stops_loss: 1.5569 - starts_accuracy: 0.5983 - stops_accuracy: 0.5797 - val_loss: 3.1802 - val_starts_loss: 1.6469 - val_stops_loss: 1.5658 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.5828\n",
      "Epoch 38/100\n",
      "20803/20803 [==============================] - 18s 851us/sample - loss: 3.0500 - starts_loss: 1.5020 - stops_loss: 1.5494 - starts_accuracy: 0.5986 - stops_accuracy: 0.5787 - val_loss: 3.1645 - val_starts_loss: 1.6397 - val_stops_loss: 1.5570 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.5862\n",
      "Epoch 39/100\n",
      "20803/20803 [==============================] - 18s 852us/sample - loss: 3.0507 - starts_loss: 1.5049 - stops_loss: 1.5549 - starts_accuracy: 0.5983 - stops_accuracy: 0.5817 - val_loss: 3.1345 - val_starts_loss: 1.6183 - val_stops_loss: 1.5476 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.5864\n",
      "Epoch 40/100\n",
      "20803/20803 [==============================] - 18s 859us/sample - loss: 3.0448 - starts_loss: 1.4971 - stops_loss: 1.5472 - starts_accuracy: 0.5986 - stops_accuracy: 0.5819 - val_loss: 3.1337 - val_starts_loss: 1.6161 - val_stops_loss: 1.5497 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.5866\n",
      "Epoch 41/100\n",
      "20803/20803 [==============================] - 18s 852us/sample - loss: 3.0421 - starts_loss: 1.4956 - stops_loss: 1.5448 - starts_accuracy: 0.5985 - stops_accuracy: 0.5818 - val_loss: 3.1094 - val_starts_loss: 1.5981 - val_stops_loss: 1.5425 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.5874\n",
      "Epoch 42/100\n",
      "20803/20803 [==============================] - 18s 852us/sample - loss: 3.0387 - starts_loss: 1.4891 - stops_loss: 1.5457 - starts_accuracy: 0.5985 - stops_accuracy: 0.5816 - val_loss: 3.1185 - val_starts_loss: 1.6008 - val_stops_loss: 1.5513 - val_starts_accuracy: 0.5997 - val_stops_accuracy: 0.5870\n",
      "Epoch 43/100\n",
      "20803/20803 [==============================] - 18s 861us/sample - loss: 3.0254 - starts_loss: 1.4869 - stops_loss: 1.5339 - starts_accuracy: 0.5987 - stops_accuracy: 0.5820 - val_loss: 3.1062 - val_starts_loss: 1.5944 - val_stops_loss: 1.5438 - val_starts_accuracy: 0.5995 - val_stops_accuracy: 0.5882\n",
      "Epoch 44/100\n",
      "20803/20803 [==============================] - 18s 853us/sample - loss: 3.0114 - starts_loss: 1.4825 - stops_loss: 1.5296 - starts_accuracy: 0.5990 - stops_accuracy: 0.5876 - val_loss: 3.1124 - val_starts_loss: 1.5934 - val_stops_loss: 1.5545 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.5876\n",
      "Epoch 45/100\n",
      "20803/20803 [==============================] - 18s 857us/sample - loss: 3.0014 - starts_loss: 1.4780 - stops_loss: 1.5224 - starts_accuracy: 0.5982 - stops_accuracy: 0.5842 - val_loss: 3.1529 - val_starts_loss: 1.6277 - val_stops_loss: 1.5614 - val_starts_accuracy: 0.5983 - val_stops_accuracy: 0.5799\n",
      "Epoch 46/100\n",
      "20803/20803 [==============================] - 18s 846us/sample - loss: 2.9978 - starts_loss: 1.4796 - stops_loss: 1.5158 - starts_accuracy: 0.5986 - stops_accuracy: 0.5849 - val_loss: 3.1311 - val_starts_loss: 1.6133 - val_stops_loss: 1.5529 - val_starts_accuracy: 0.5966 - val_stops_accuracy: 0.5830\n",
      "Epoch 47/100\n",
      "20803/20803 [==============================] - 18s 862us/sample - loss: 2.9857 - starts_loss: 1.4637 - stops_loss: 1.5145 - starts_accuracy: 0.5979 - stops_accuracy: 0.5828 - val_loss: 3.0887 - val_starts_loss: 1.5728 - val_stops_loss: 1.5478 - val_starts_accuracy: 0.5972 - val_stops_accuracy: 0.5857\n",
      "Epoch 48/100\n",
      "20803/20803 [==============================] - 17s 833us/sample - loss: 2.9672 - starts_loss: 1.4623 - stops_loss: 1.5041 - starts_accuracy: 0.5986 - stops_accuracy: 0.5872 - val_loss: 3.0915 - val_starts_loss: 1.5709 - val_stops_loss: 1.5636 - val_starts_accuracy: 0.5987 - val_stops_accuracy: 0.5839\n",
      "Epoch 49/100\n",
      "20803/20803 [==============================] - 18s 842us/sample - loss: 2.9420 - starts_loss: 1.4523 - stops_loss: 1.4933 - starts_accuracy: 0.5986 - stops_accuracy: 0.5876 - val_loss: 3.1098 - val_starts_loss: 1.5834 - val_stops_loss: 1.5708 - val_starts_accuracy: 0.5941 - val_stops_accuracy: 0.5860\n",
      "Epoch 50/100\n",
      "20803/20803 [==============================] - 18s 844us/sample - loss: 2.9018 - starts_loss: 1.4354 - stops_loss: 1.4694 - starts_accuracy: 0.5996 - stops_accuracy: 0.5910 - val_loss: 3.1071 - val_starts_loss: 1.5888 - val_stops_loss: 1.5684 - val_starts_accuracy: 0.5924 - val_stops_accuracy: 0.5857\n",
      "Epoch 51/100\n",
      "20803/20803 [==============================] - 18s 843us/sample - loss: 2.8891 - starts_loss: 1.4318 - stops_loss: 1.4658 - starts_accuracy: 0.5992 - stops_accuracy: 0.5935 - val_loss: 3.1049 - val_starts_loss: 1.5796 - val_stops_loss: 1.5905 - val_starts_accuracy: 0.5955 - val_stops_accuracy: 0.5797\n",
      "Epoch 52/100\n",
      "20803/20803 [==============================] - 18s 852us/sample - loss: 2.8678 - starts_loss: 1.4207 - stops_loss: 1.4439 - starts_accuracy: 0.6000 - stops_accuracy: 0.5955 - val_loss: 3.1898 - val_starts_loss: 1.6236 - val_stops_loss: 1.6164 - val_starts_accuracy: 0.5935 - val_stops_accuracy: 0.5699\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20803/20803 [==============================] - 18s 847us/sample - loss: 2.8474 - starts_loss: 1.4072 - stops_loss: 1.4417 - starts_accuracy: 0.5996 - stops_accuracy: 0.5960 - val_loss: 3.2038 - val_starts_loss: 1.6611 - val_stops_loss: 1.5935 - val_starts_accuracy: 0.5893 - val_stops_accuracy: 0.5789\n",
      "Epoch 54/100\n",
      "20803/20803 [==============================] - 18s 854us/sample - loss: 2.8402 - starts_loss: 1.4091 - stops_loss: 1.4320 - starts_accuracy: 0.6006 - stops_accuracy: 0.5994 - val_loss: 3.1671 - val_starts_loss: 1.6273 - val_stops_loss: 1.5902 - val_starts_accuracy: 0.5899 - val_stops_accuracy: 0.5812\n",
      "Epoch 55/100\n",
      "20803/20803 [==============================] - 18s 846us/sample - loss: 2.8387 - starts_loss: 1.4032 - stops_loss: 1.4372 - starts_accuracy: 0.5994 - stops_accuracy: 0.5968 - val_loss: 3.1456 - val_starts_loss: 1.6102 - val_stops_loss: 1.5838 - val_starts_accuracy: 0.5908 - val_stops_accuracy: 0.5824\n",
      "Epoch 56/100\n",
      "20803/20803 [==============================] - 18s 847us/sample - loss: 2.8205 - starts_loss: 1.4003 - stops_loss: 1.4197 - starts_accuracy: 0.5999 - stops_accuracy: 0.6002 - val_loss: 3.1207 - val_starts_loss: 1.5936 - val_stops_loss: 1.5782 - val_starts_accuracy: 0.5932 - val_stops_accuracy: 0.5797\n",
      "Epoch 57/100\n",
      "20803/20803 [==============================] - 18s 852us/sample - loss: 2.8172 - starts_loss: 1.3964 - stops_loss: 1.4232 - starts_accuracy: 0.5997 - stops_accuracy: 0.5980 - val_loss: 3.1058 - val_starts_loss: 1.5907 - val_stops_loss: 1.5819 - val_starts_accuracy: 0.5935 - val_stops_accuracy: 0.5818\n",
      "Epoch 58/100\n",
      "20803/20803 [==============================] - 18s 848us/sample - loss: 2.8063 - starts_loss: 1.3991 - stops_loss: 1.4128 - starts_accuracy: 0.5994 - stops_accuracy: 0.6037 - val_loss: 3.0985 - val_starts_loss: 1.5852 - val_stops_loss: 1.5784 - val_starts_accuracy: 0.5928 - val_stops_accuracy: 0.5847\n",
      "Epoch 59/100\n",
      "20803/20803 [==============================] - 17s 836us/sample - loss: 2.8048 - starts_loss: 1.3955 - stops_loss: 1.4120 - starts_accuracy: 0.5992 - stops_accuracy: 0.6040 - val_loss: 3.1013 - val_starts_loss: 1.5868 - val_stops_loss: 1.5808 - val_starts_accuracy: 0.5899 - val_stops_accuracy: 0.5822\n",
      "Epoch 60/100\n",
      "20803/20803 [==============================] - 18s 845us/sample - loss: 2.8077 - starts_loss: 1.3908 - stops_loss: 1.4149 - starts_accuracy: 0.5997 - stops_accuracy: 0.5997 - val_loss: 3.1135 - val_starts_loss: 1.5929 - val_stops_loss: 1.5900 - val_starts_accuracy: 0.5939 - val_stops_accuracy: 0.5799\n",
      "Epoch 61/100\n",
      "20803/20803 [==============================] - 17s 838us/sample - loss: 2.8054 - starts_loss: 1.3931 - stops_loss: 1.4106 - starts_accuracy: 0.5998 - stops_accuracy: 0.6003 - val_loss: 3.1039 - val_starts_loss: 1.5946 - val_stops_loss: 1.5828 - val_starts_accuracy: 0.5924 - val_stops_accuracy: 0.5807\n",
      "Epoch 62/100\n",
      "20803/20803 [==============================] - 18s 851us/sample - loss: 2.7890 - starts_loss: 1.3904 - stops_loss: 1.4087 - starts_accuracy: 0.5998 - stops_accuracy: 0.6027 - val_loss: 3.1036 - val_starts_loss: 1.5884 - val_stops_loss: 1.5880 - val_starts_accuracy: 0.5912 - val_stops_accuracy: 0.5797\n",
      "Epoch 63/100\n",
      "20803/20803 [==============================] - 18s 873us/sample - loss: 2.7800 - starts_loss: 1.3869 - stops_loss: 1.4002 - starts_accuracy: 0.6005 - stops_accuracy: 0.6024 - val_loss: 3.1401 - val_starts_loss: 1.5842 - val_stops_loss: 1.6092 - val_starts_accuracy: 0.5957 - val_stops_accuracy: 0.5737\n",
      "Epoch 64/100\n",
      "20803/20803 [==============================] - 18s 854us/sample - loss: 2.7670 - starts_loss: 1.3742 - stops_loss: 1.3955 - starts_accuracy: 0.6009 - stops_accuracy: 0.6050 - val_loss: 3.1564 - val_starts_loss: 1.6014 - val_stops_loss: 1.6255 - val_starts_accuracy: 0.5945 - val_stops_accuracy: 0.5684\n",
      "Epoch 65/100\n",
      "20803/20803 [==============================] - 18s 853us/sample - loss: 2.8163 - starts_loss: 1.3921 - stops_loss: 1.4233 - starts_accuracy: 0.6010 - stops_accuracy: 0.5967 - val_loss: 3.3173 - val_starts_loss: 1.6145 - val_stops_loss: 1.7845 - val_starts_accuracy: 0.6003 - val_stops_accuracy: 0.5547\n",
      "Epoch 66/100\n",
      "20803/20803 [==============================] - 18s 841us/sample - loss: 2.8885 - starts_loss: 1.4127 - stops_loss: 1.4746 - starts_accuracy: 0.5986 - stops_accuracy: 0.5930 - val_loss: 3.1593 - val_starts_loss: 1.5631 - val_stops_loss: 1.6474 - val_starts_accuracy: 0.6005 - val_stops_accuracy: 0.5680\n",
      "Epoch 67/100\n",
      "20803/20803 [==============================] - 17s 839us/sample - loss: 2.8379 - starts_loss: 1.4015 - stops_loss: 1.4396 - starts_accuracy: 0.6018 - stops_accuracy: 0.5985 - val_loss: 3.1533 - val_starts_loss: 1.5767 - val_stops_loss: 1.6288 - val_starts_accuracy: 0.5949 - val_stops_accuracy: 0.5703\n",
      "Epoch 68/100\n",
      "20803/20803 [==============================] - 18s 858us/sample - loss: 2.8297 - starts_loss: 1.3975 - stops_loss: 1.4297 - starts_accuracy: 0.5999 - stops_accuracy: 0.6003 - val_loss: 3.2338 - val_starts_loss: 1.5676 - val_stops_loss: 1.7110 - val_starts_accuracy: 0.6005 - val_stops_accuracy: 0.5560\n",
      "Epoch 69/100\n",
      "20803/20803 [==============================] - 18s 861us/sample - loss: 2.7868 - starts_loss: 1.3763 - stops_loss: 1.4053 - starts_accuracy: 0.6015 - stops_accuracy: 0.6009 - val_loss: 3.0660 - val_starts_loss: 1.5371 - val_stops_loss: 1.5899 - val_starts_accuracy: 0.5970 - val_stops_accuracy: 0.5782\n",
      "Epoch 70/100\n",
      "20803/20803 [==============================] - 18s 855us/sample - loss: 2.7556 - starts_loss: 1.3643 - stops_loss: 1.3891 - starts_accuracy: 0.6018 - stops_accuracy: 0.6058 - val_loss: 3.0618 - val_starts_loss: 1.5436 - val_stops_loss: 1.5795 - val_starts_accuracy: 0.5933 - val_stops_accuracy: 0.5807\n",
      "Epoch 71/100\n",
      "20803/20803 [==============================] - 18s 853us/sample - loss: 2.7353 - starts_loss: 1.3531 - stops_loss: 1.3786 - starts_accuracy: 0.6028 - stops_accuracy: 0.6062 - val_loss: 3.0962 - val_starts_loss: 1.5564 - val_stops_loss: 1.5904 - val_starts_accuracy: 0.5951 - val_stops_accuracy: 0.5735\n",
      "Epoch 72/100\n",
      "20803/20803 [==============================] - 18s 849us/sample - loss: 2.7178 - starts_loss: 1.3492 - stops_loss: 1.3702 - starts_accuracy: 0.6039 - stops_accuracy: 0.6097 - val_loss: 3.0734 - val_starts_loss: 1.5474 - val_stops_loss: 1.5790 - val_starts_accuracy: 0.5937 - val_stops_accuracy: 0.5787\n",
      "Epoch 73/100\n",
      "20803/20803 [==============================] - 18s 852us/sample - loss: 2.6905 - starts_loss: 1.3302 - stops_loss: 1.3607 - starts_accuracy: 0.6036 - stops_accuracy: 0.6088 - val_loss: 3.1171 - val_starts_loss: 1.5776 - val_stops_loss: 1.5953 - val_starts_accuracy: 0.5949 - val_stops_accuracy: 0.5743\n",
      "Epoch 74/100\n",
      "20803/20803 [==============================] - 18s 870us/sample - loss: 2.6740 - starts_loss: 1.3292 - stops_loss: 1.3432 - starts_accuracy: 0.6037 - stops_accuracy: 0.6155 - val_loss: 3.1175 - val_starts_loss: 1.5746 - val_stops_loss: 1.6013 - val_starts_accuracy: 0.5958 - val_stops_accuracy: 0.5760\n",
      "Epoch 75/100\n",
      "20803/20803 [==============================] - 18s 853us/sample - loss: 2.6549 - starts_loss: 1.3243 - stops_loss: 1.3335 - starts_accuracy: 0.6031 - stops_accuracy: 0.6152 - val_loss: 3.1053 - val_starts_loss: 1.5658 - val_stops_loss: 1.5932 - val_starts_accuracy: 0.5941 - val_stops_accuracy: 0.5807\n",
      "Epoch 76/100\n",
      "20803/20803 [==============================] - 18s 857us/sample - loss: 2.6560 - starts_loss: 1.3205 - stops_loss: 1.3405 - starts_accuracy: 0.6040 - stops_accuracy: 0.6149 - val_loss: 3.1018 - val_starts_loss: 1.5644 - val_stops_loss: 1.5920 - val_starts_accuracy: 0.5939 - val_stops_accuracy: 0.5805\n",
      "Epoch 77/100\n",
      "20803/20803 [==============================] - 18s 850us/sample - loss: 2.6317 - starts_loss: 1.3060 - stops_loss: 1.3221 - starts_accuracy: 0.6040 - stops_accuracy: 0.6157 - val_loss: 3.0970 - val_starts_loss: 1.5592 - val_stops_loss: 1.5913 - val_starts_accuracy: 0.5943 - val_stops_accuracy: 0.5816\n",
      "Epoch 78/100\n",
      "20803/20803 [==============================] - 18s 853us/sample - loss: 2.6488 - starts_loss: 1.3155 - stops_loss: 1.3267 - starts_accuracy: 0.6045 - stops_accuracy: 0.6169 - val_loss: 3.1024 - val_starts_loss: 1.5557 - val_stops_loss: 1.5964 - val_starts_accuracy: 0.5962 - val_stops_accuracy: 0.5801\n",
      "Epoch 79/100\n",
      "20803/20803 [==============================] - 18s 857us/sample - loss: 3.9557 - starts_loss: 1.8608 - stops_loss: 2.0969 - starts_accuracy: 0.5961 - stops_accuracy: 0.4810 - val_loss: 5.1752 - val_starts_loss: 2.2948 - val_stops_loss: 2.9359 - val_starts_accuracy: 0.5805 - val_stops_accuracy: 0.2146\n",
      "Epoch 80/100\n",
      "20803/20803 [==============================] - 18s 847us/sample - loss: 3.9143 - starts_loss: 1.8477 - stops_loss: 2.0672 - starts_accuracy: 0.5981 - stops_accuracy: 0.5283 - val_loss: 5.0938 - val_starts_loss: 2.1375 - val_stops_loss: 3.0279 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.3705\n",
      "Epoch 81/100\n",
      "20803/20803 [==============================] - 18s 847us/sample - loss: 3.7825 - starts_loss: 1.8079 - stops_loss: 1.9798 - starts_accuracy: 0.5983 - stops_accuracy: 0.5610 - val_loss: 4.9981 - val_starts_loss: 2.0588 - val_stops_loss: 3.0171 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.3930\n",
      "Epoch 82/100\n",
      "20803/20803 [==============================] - 18s 846us/sample - loss: 3.7271 - starts_loss: 1.7866 - stops_loss: 1.9342 - starts_accuracy: 0.5984 - stops_accuracy: 0.5757 - val_loss: 4.9217 - val_starts_loss: 2.0322 - val_stops_loss: 2.9737 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.3911\n",
      "Epoch 83/100\n",
      "20803/20803 [==============================] - 18s 848us/sample - loss: 3.6864 - starts_loss: 1.7849 - stops_loss: 1.9075 - starts_accuracy: 0.5985 - stops_accuracy: 0.5833 - val_loss: 4.8608 - val_starts_loss: 1.9762 - val_stops_loss: 2.9699 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.3911\n",
      "Epoch 84/100\n",
      "20803/20803 [==============================] - 18s 851us/sample - loss: 3.6564 - starts_loss: 1.7773 - stops_loss: 1.8824 - starts_accuracy: 0.5985 - stops_accuracy: 0.5885 - val_loss: 4.7967 - val_starts_loss: 1.9543 - val_stops_loss: 2.9305 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.3926\n",
      "Epoch 85/100\n",
      "20803/20803 [==============================] - 18s 846us/sample - loss: 3.6426 - starts_loss: 1.7740 - stops_loss: 1.8749 - starts_accuracy: 0.5985 - stops_accuracy: 0.5921 - val_loss: 4.8580 - val_starts_loss: 1.9509 - val_stops_loss: 3.0093 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4147\n",
      "Epoch 86/100\n",
      "20803/20803 [==============================] - 18s 859us/sample - loss: 3.6203 - starts_loss: 1.7648 - stops_loss: 1.8532 - starts_accuracy: 0.5985 - stops_accuracy: 0.5964 - val_loss: 4.8748 - val_starts_loss: 1.9305 - val_stops_loss: 3.0590 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4142\n",
      "Epoch 87/100\n",
      "20803/20803 [==============================] - 18s 848us/sample - loss: 3.6037 - starts_loss: 1.7617 - stops_loss: 1.8364 - starts_accuracy: 0.5985 - stops_accuracy: 0.5984 - val_loss: 4.6261 - val_starts_loss: 1.8915 - val_stops_loss: 2.8365 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4290\n",
      "Epoch 88/100\n",
      "20803/20803 [==============================] - 18s 852us/sample - loss: 3.5984 - starts_loss: 1.7609 - stops_loss: 1.8359 - starts_accuracy: 0.5985 - stops_accuracy: 0.6001 - val_loss: 4.6571 - val_starts_loss: 1.8911 - val_stops_loss: 2.8717 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4138\n",
      "Epoch 89/100\n",
      "20803/20803 [==============================] - 18s 849us/sample - loss: 3.5836 - starts_loss: 1.7636 - stops_loss: 1.8303 - starts_accuracy: 0.5985 - stops_accuracy: 0.6025 - val_loss: 4.6327 - val_starts_loss: 1.8927 - val_stops_loss: 2.8471 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4418\n",
      "Epoch 90/100\n",
      "20803/20803 [==============================] - 18s 848us/sample - loss: 3.5752 - starts_loss: 1.7584 - stops_loss: 1.8208 - starts_accuracy: 0.5985 - stops_accuracy: 0.6030 - val_loss: 4.5845 - val_starts_loss: 1.8839 - val_stops_loss: 2.8089 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4272\n",
      "Epoch 91/100\n",
      "20803/20803 [==============================] - 18s 848us/sample - loss: 3.5700 - starts_loss: 1.7570 - stops_loss: 1.8142 - starts_accuracy: 0.5985 - stops_accuracy: 0.6044 - val_loss: 4.6055 - val_starts_loss: 1.8726 - val_stops_loss: 2.8427 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4407\n",
      "Epoch 92/100\n",
      "20803/20803 [==============================] - 18s 849us/sample - loss: 3.5616 - starts_loss: 1.7532 - stops_loss: 1.8138 - starts_accuracy: 0.5985 - stops_accuracy: 0.6049 - val_loss: 4.5034 - val_starts_loss: 1.8707 - val_stops_loss: 2.7393 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4434\n",
      "Epoch 93/100\n",
      "20803/20803 [==============================] - 18s 867us/sample - loss: 3.5452 - starts_loss: 1.7551 - stops_loss: 1.7941 - starts_accuracy: 0.5985 - stops_accuracy: 0.6048 - val_loss: 4.4324 - val_starts_loss: 1.8725 - val_stops_loss: 2.6634 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4418\n",
      "Epoch 94/100\n",
      "20803/20803 [==============================] - 18s 849us/sample - loss: 3.5513 - starts_loss: 1.7505 - stops_loss: 1.8106 - starts_accuracy: 0.5985 - stops_accuracy: 0.6052 - val_loss: 4.3614 - val_starts_loss: 1.8709 - val_stops_loss: 2.5938 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4420\n",
      "Epoch 95/100\n",
      "20803/20803 [==============================] - 17s 840us/sample - loss: 3.5435 - starts_loss: 1.7486 - stops_loss: 1.7944 - starts_accuracy: 0.5985 - stops_accuracy: 0.6066 - val_loss: 4.2516 - val_starts_loss: 1.8574 - val_stops_loss: 2.4915 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4580\n",
      "Epoch 96/100\n",
      "20803/20803 [==============================] - 18s 848us/sample - loss: 3.5473 - starts_loss: 1.7444 - stops_loss: 1.7958 - starts_accuracy: 0.5985 - stops_accuracy: 0.6071 - val_loss: 4.2611 - val_starts_loss: 1.8631 - val_stops_loss: 2.4965 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4580\n",
      "Epoch 97/100\n",
      "20803/20803 [==============================] - 18s 849us/sample - loss: 3.5505 - starts_loss: 1.7497 - stops_loss: 1.7987 - starts_accuracy: 0.5985 - stops_accuracy: 0.6057 - val_loss: 4.4412 - val_starts_loss: 1.8823 - val_stops_loss: 2.6672 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4572\n",
      "Epoch 98/100\n",
      "20803/20803 [==============================] - 18s 855us/sample - loss: 3.5474 - starts_loss: 1.7460 - stops_loss: 1.7975 - starts_accuracy: 0.5985 - stops_accuracy: 0.6063 - val_loss: 4.7035 - val_starts_loss: 1.9132 - val_stops_loss: 2.9087 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4276\n",
      "Epoch 99/100\n",
      "20803/20803 [==============================] - 18s 847us/sample - loss: 3.5493 - starts_loss: 1.7459 - stops_loss: 1.7957 - starts_accuracy: 0.5985 - stops_accuracy: 0.6058 - val_loss: 4.9707 - val_starts_loss: 1.9561 - val_stops_loss: 3.1446 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4130\n",
      "Epoch 100/100\n",
      "20803/20803 [==============================] - 18s 862us/sample - loss: 3.5497 - starts_loss: 1.7436 - stops_loss: 1.8032 - starts_accuracy: 0.5985 - stops_accuracy: 0.6062 - val_loss: 5.2943 - val_starts_loss: 2.0167 - val_stops_loss: 3.4290 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.4147\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x={\"att_flags\":X_att_train,\n",
    "                       \"words\":X_train},\n",
    "                    y={\"starts\":Y_starts_train.argmax(axis=1),\n",
    "                       \"stops\":Y_stops_train.argmax(axis=1)},\n",
    "                    shuffle=True,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    validation_data=({\"att_flags\":X_att_val, \"words\":X_val},\n",
    "                                     {\"starts\":Y_starts_val.argmax(axis=1), \"stops\":Y_stops_val.argmax(axis=1)}),\n",
    "                    verbose=1,\n",
    "                    callbacks=[clr, mcp]) #es, rlrop, tb, mcp,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#metric_names = ['loss' ,'accuracy']\n",
    "metric_names = [\"loss\", \"starts_loss\", \"stops_loss\", \"starts_accuracy\", \"stops_accuracy\"]\n",
    "\n",
    "for i, j in zip(metric_names, ['val_'+i for i in metric_names]):\n",
    "    plt.plot(history.history[i])\n",
    "    plt.plot(history.history[j])\n",
    "    plt.title('Model '+i)\n",
    "    plt.ylabel(i.upper())\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../results/\"+MODEL_PREFIX+\"EndCheckpoint.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = tf.keras.models.load_model(\n",
    "    filepath=\"../results/\"+MODEL_PREFIX+\"BestCheckpoint.h5\",\n",
    "    custom_objects={'Attention' : Attention},\n",
    "    compile=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5201/5201 [==============================] - 2s 374us/sample - loss: 3.0618 - starts_loss: 1.5141 - stops_loss: 1.5470 - starts_accuracy: 0.5933 - stops_accuracy: 0.5807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.06181281279014, 1.5141406, 1.5470133, 0.59334743, 0.58065754]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x = {\"att_flags\":X_att_val, \"words\":X_val},\n",
    "               y={\"starts\":Y_starts_val.argmax(axis=1), \"stops\":Y_stops_val.argmax(axis=1)},\n",
    "               batch_size=PREDICT_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(x = {\"att_flags\":X_att_train, \"words\":X_train},\n",
    "                           batch_size=PREDICT_BATCH_SIZE)\n",
    "pred_val = model.predict(x = {\"att_flags\":X_att_val, \"words\":X_val},\n",
    "                         batch_size=PREDICT_BATCH_SIZE)\n",
    "pred_test = model.predict(x = {\"att_flags\":X_att_test, \"words\":X_test},\n",
    "                          batch_size=PREDICT_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_starts_train, pred_stops_train = pred_train[0], pred_train[1]\n",
    "pred_starts_val, pred_stops_val = pred_val[0], pred_val[1]\n",
    "pred_starts_test, pred_stops_test = pred_test[0], pred_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20803, 110) (20803, 110)\n",
      "(5201, 110) (5201, 110)\n",
      "(3534, 110) (3534, 110)\n"
     ]
    }
   ],
   "source": [
    "print(pred_starts_train.shape, pred_stops_train.shape)\n",
    "print(pred_starts_val.shape, pred_stops_val.shape)\n",
    "print(pred_starts_test.shape, pred_stops_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = {\n",
    "    \"train\":{\n",
    "        \"starts\":{\n",
    "            \"y_true\":Y_starts_train.argmax(axis=1),\n",
    "            \"y_pred\":pred_starts_train.argmax(axis=1)\n",
    "        },\n",
    "        \"stops\":{\n",
    "            \"y_true\":Y_stops_train.argmax(axis=1),\n",
    "            \"y_pred\":pred_stops_train.argmax(axis=1)\n",
    "        }\n",
    "    },\n",
    "    \"valid\":{\n",
    "        \"starts\":{\n",
    "            \"y_true\":Y_starts_val.argmax(axis=1),\n",
    "            \"y_pred\":pred_starts_val.argmax(axis=1)\n",
    "        },\n",
    "        \"stops\":{\n",
    "            \"y_true\":Y_stops_train.argmax(axis=1),\n",
    "            \"y_pred\":pred_stops_train.argmax(axis=1)\n",
    "        }        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.68 \t|| train \t|| starts \t|| accuracy_score\n",
      "64.03 \t|| train \t|| stops \t|| accuracy_score\n",
      "59.33 \t|| valid \t|| starts \t|| accuracy_score\n",
      "64.03 \t|| valid \t|| stops \t|| accuracy_score\n",
      "================================================================\n",
      "7.08 \t|| train \t|| starts \t|| f1_score\n",
      "51.86 \t|| train \t|| stops \t|| f1_score\n",
      "5.10 \t|| valid \t|| starts \t|| f1_score\n",
      "51.86 \t|| valid \t|| stops \t|| f1_score\n",
      "================================================================\n",
      "9.68 \t|| train \t|| starts \t|| precision_score\n",
      "51.62 \t|| train \t|| stops \t|| precision_score\n",
      "5.71 \t|| valid \t|| starts \t|| precision_score\n",
      "51.62 \t|| valid \t|| stops \t|| precision_score\n",
      "================================================================\n",
      "7.97 \t|| train \t|| starts \t|| recall_score\n",
      "54.88 \t|| train \t|| stops \t|| recall_score\n",
      "6.08 \t|| valid \t|| starts \t|| recall_score\n",
      "54.88 \t|| valid \t|| stops \t|| recall_score\n",
      "================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\deepak\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t|| train \t|| starts \t|| confusion_matrix \t|| ../results/ConfusionMatrix_V13_train_starts.csv\n",
      "\t|| train \t|| stops \t|| confusion_matrix \t|| ../results/ConfusionMatrix_V13_train_stops.csv\n",
      "\t|| valid \t|| starts \t|| confusion_matrix \t|| ../results/ConfusionMatrix_V13_valid_starts.csv\n",
      "\t|| valid \t|| stops \t|| confusion_matrix \t|| ../results/ConfusionMatrix_V13_valid_stops.csv\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "def print_metrics():\n",
    "    funcs = [accuracy_score, f1_score, precision_score, recall_score, confusion_matrix]\n",
    "    for f in funcs:\n",
    "        for data_set in [\"train\",\"valid\"]:\n",
    "            for var in [\"starts\", \"stops\"]:\n",
    "                if f in [accuracy_score]:\n",
    "                    res = f(**preds[data_set][var])\n",
    "                    print(\"{:.2f}\".format(100 * res), \"\\t||\", data_set, \"\\t||\", var, \"\\t||\", f.__name__)\n",
    "                elif f in [confusion_matrix]:\n",
    "                    res = f(**preds[data_set][var], labels = np.arange(max_len))\n",
    "                    np.savetxt(X=res, fmt='%i', delimiter=\",\",\n",
    "                               fname=\"../results/ConfusionMatrix_\"+MODEL_PREFIX+\"_\"+data_set+\"_\"+var+\".csv\")\n",
    "                    print(\"\\t||\", data_set, \"\\t||\", var, \"\\t||\", f.__name__, \"\\t||\", \n",
    "                          \"../results/ConfusionMatrix_\"+MODEL_PREFIX+\"_\"+data_set+\"_\"+var+\".csv\")\n",
    "                else:\n",
    "                    res = f(**preds[data_set][var], average=\"macro\")\n",
    "                    print(\"{:.2f}\".format(100 * res), \"\\t||\", data_set, \"\\t||\", var, \"\\t||\", f.__name__)\n",
    "        print(\"================================================================\")\n",
    "\n",
    "print_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_words_train = [[vocab_itos[j] for j in i if j!=0] for num,i in enumerate(Y_train)]\n",
    "Y_words_val = [[vocab_itos[j] for j in i if j!=0] for num,i in enumerate(Y_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20557\n",
      "5161\n",
      "3499\n"
     ]
    }
   ],
   "source": [
    "print(sum([s<e for s,e in zip(pred_starts_train.argmax(axis=1), pred_stops_train.argmax(axis=1))]))\n",
    "print(sum([s<e for s,e in zip(pred_starts_val.argmax(axis=1), pred_stops_val.argmax(axis=1))]))\n",
    "print(sum([s<e for s,e in zip(pred_starts_test.argmax(axis=1), pred_stops_test.argmax(axis=1))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_words_train = [t[s:e+1] if s<e else t[e:-3] for t,s,e in zip([[vocab_itos[j] for j in i  if j!=0] for i in X_train], pred_starts_train.argmax(axis=1), pred_stops_train.argmax(axis=1))]\n",
    "pred_words_val = [t[s:e+1] if s<e else t[e:-3] for t,s,e in zip([[vocab_itos[j] for j in i  if j!=0] for i in X_val], pred_starts_val.argmax(axis=1), pred_stops_val.argmax(axis=1))]\n",
    "pred_words_test = [t[s:e+1] if s<e else t[e:-3] for t,s,e in zip([[vocab_itos[j] for j in i  if j!=0] for i in X_test], pred_starts_test.argmax(axis=1), pred_stops_test.argmax(axis=1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(str1, str2):\n",
    "    a = set(str1)\n",
    "    b = set(str2)\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Jaccard Score 0.6563696002060264\n",
      "Validation Jaccard Score 0.6136025498482669\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Jaccard Score\", np.mean([jaccard(str1=i, str2=j) for i,j in zip(Y_words_train, pred_words_train)]))\n",
    "print(\"Validation Jaccard Score\", np.mean([jaccard(str1=i, str2=j) for i,j in zip(Y_words_val, pred_words_val)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_labels = {i:j for i,j in enumerate(df.sentiment_code.cat.categories)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spot Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spot_check(index_to_check, mode):\n",
    "    print(\"================== Sample #\", index_to_check, \"==================\")\n",
    "    if mode == \"train\":\n",
    "        print(\"Selected_text:\")\n",
    "        print('\\t', Y_words[train_idx[index_to_check]])\n",
    "        print(\"Predicted_text:\")\n",
    "        print('\\t', pred_words_train[index_to_check])\n",
    "        print(\"Predictions:\")\n",
    "        print('\\t',*[[\"%.2f\"%j, \n",
    "                      \"%.2f\"%k,\n",
    "                      i,\n",
    "                      X_words[train_idx[index_to_check]][num]] for num, (i,j,k) in enumerate(zip(X_train[index_to_check].tolist(),\n",
    "                                                                                               pred_starts_train[index_to_check].tolist(),\n",
    "                                                                                               pred_stops_train[index_to_check].tolist())) if i!=0], sep=\"\\n\\t\")\n",
    "        \n",
    "    elif mode == \"validation\":\n",
    "        print(\"Selected_text:\")\n",
    "        print('\\t', Y_words[val_idx[index_to_check]])\n",
    "        print(\"Predicted_text:\")\n",
    "        print('\\t', pred_words_val[index_to_check])\n",
    "        print(\"Predictions:\")\n",
    "        print('\\t',*[[\"%.2f\"%j, \n",
    "                      \"%.2f\"%k,\n",
    "                      i,\n",
    "                      X_words[val_idx[index_to_check]][num]] for num, (i,j,k) in enumerate(zip(X_val[index_to_check].tolist(),\n",
    "                                                                                               pred_starts_val[index_to_check].tolist(),\n",
    "                                                                                               pred_stops_val[index_to_check].tolist())) if i!=0], sep=\"\\n\\t\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Selected_text:\")\n",
    "        print('\\t', \"Not Available\")\n",
    "        print(\"Predicted_text:\")\n",
    "        print('\\t', pred_words_test[index_to_check])\n",
    "        print(\"Predictions:\")\n",
    "        print('\\t',*[[\"%.2f\"%j, \n",
    "                      \"%.2f\"%k,\n",
    "                      i,\n",
    "                      X_words_test[index_to_check][num]] for num, (i,j,k) in enumerate(zip(X_test[index_to_check].tolist(),\n",
    "                                                                                               pred_starts_test[index_to_check].tolist(),\n",
    "                                                                                               pred_stops_test[index_to_check].tolist())) if i!=0], sep=\"\\n\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Sample # 10 ==================\n",
      "Selected_text:\n",
      "\t ['says', 'good', '(', 'or', 'should', 'i', 'say', 'bad', '?', ')', 'afternoon', '!']\n",
      "Predicted_text:\n",
      "\t ['says', 'good', '(', 'or', 'should', 'i', 'say', 'bad', '?', ')', 'afternoon', '!', 'http']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.82', '0.02', 1103, 'says']\n",
      "\t['0.02', '0.03', 448, 'good']\n",
      "\t['0.06', '0.03', 81, '(']\n",
      "\t['0.02', '0.03', 758, 'or']\n",
      "\t['0.02', '0.01', 350, 'should']\n",
      "\t['0.01', '0.03', 7, 'i']\n",
      "\t['0.01', '0.02', 460, 'say']\n",
      "\t['0.01', '0.03', 318, 'bad']\n",
      "\t['0.00', '0.04', 74, '?']\n",
      "\t['0.01', '0.05', 84, ')']\n",
      "\t['0.01', '0.07', 1434, 'afternoon']\n",
      "\t['0.00', '0.14', 22, '!']\n",
      "\t['0.00', '0.14', 47, 'http']\n",
      "\t['0.00', '0.03', 48, ':']\n",
      "\t['0.00', '0.01', 49, '/']\n",
      "\t['0.00', '0.01', 49, '/']\n",
      "\t['0.00', '0.02', 376, 'plurk']\n",
      "\t['0.00', '0.08', 28, '.']\n",
      "\t['0.00', '0.01', 51, 'com']\n",
      "\t['0.00', '0.00', 49, '/']\n",
      "\t['0.00', '0.01', 95, 'p']\n",
      "\t['0.00', '0.03', 49, '/']\n",
      "\t['0.00', '0.14', 1, 'wxpdj']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 11 ==================\n",
      "Selected_text:\n",
      "\t ['goodnight']\n",
      "Predicted_text:\n",
      "\t ['goodnight', 'all', 'in', 'the', 'twitterverse']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.71', '0.23', 2223, 'goodnight']\n",
      "\t['0.09', '0.19', 66, 'all']\n",
      "\t['0.10', '0.09', 19, 'in']\n",
      "\t['0.07', '0.08', 42, 'the']\n",
      "\t['0.03', '0.39', 2113, 'twitterverse']\n",
      "\t['0.00', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 12 ==================\n",
      "Selected_text:\n",
      "\t ['is', 'resting', '.', 'ahhhhh', '.', 'i', 'feel', 'good']\n",
      "Predicted_text:\n",
      "\t ['is', 'resting', '.', 'ahhhhh', '.', 'i', 'feel', 'good']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.18', '0.02', 26, 'is']\n",
      "\t['0.05', '0.04', 6136, 'resting']\n",
      "\t['0.07', '0.03', 28, '.']\n",
      "\t['0.08', '0.04', 3328, 'ahhhhh']\n",
      "\t['0.14', '0.03', 28, '.']\n",
      "\t['0.16', '0.07', 7, 'i']\n",
      "\t['0.17', '0.06', 338, 'feel']\n",
      "\t['0.09', '0.67', 448, 'good']\n",
      "\t['0.04', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.01', '0.01', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 13 ==================\n",
      "Selected_text:\n",
      "\t ['awww', ',', 'that`s', 'nice', '.']\n",
      "Predicted_text:\n",
      "\t ['awww', ',', 'that`s', 'nice', '.', 'you']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.33', '0.05', 2124, 'awww']\n",
      "\t['0.08', '0.08', 5, ',']\n",
      "\t['0.12', '0.09', 240, 'that`s']\n",
      "\t['0.14', '0.14', 397, 'nice']\n",
      "\t['0.14', '0.14', 28, '.']\n",
      "\t['0.08', '0.20', 17, 'you']\n",
      "\t['0.05', '0.08', 72, 'both']\n",
      "\t['0.02', '0.07', 237, 'make']\n",
      "\t['0.01', '0.03', 142, 'a']\n",
      "\t['0.01', '0.03', 102, 'really']\n",
      "\t['0.00', '0.02', 2048, 'beautiful']\n",
      "\t['0.00', '0.01', 912, 'couple']\n",
      "\t['0.00', '0.01', 5, ',']\n",
      "\t['0.00', '0.01', 17, 'you']\n",
      "\t['0.00', '0.00', 8708, 'balance']\n",
      "\t['0.00', '0.01', 1127, 'each']\n",
      "\t['0.00', '0.01', 353, 'other']\n",
      "\t['0.00', '0.02', 28, '.']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 14 ==================\n",
      "Selected_text:\n",
      "\t ['disappointed']\n",
      "Predicted_text:\n",
      "\t ['disappointed', 'she', 'didn`t', 'win', 'teh', 'xxxUNK', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.38', '0.09', 924, 'disappointed']\n",
      "\t['0.10', '0.12', 447, 'she']\n",
      "\t['0.11', '0.07', 475, 'didn`t']\n",
      "\t['0.11', '0.06', 738, 'win']\n",
      "\t['0.10', '0.07', 6019, 'teh']\n",
      "\t['0.11', '0.07', 1, 'glassez']\n",
      "\t['0.07', '0.49', 28, '.']\n",
      "\t['0.02', '0.02', 10, 'xxxSENTIMENT']\n",
      "\t['0.01', '0.01', 23, 'negative']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 15 ==================\n",
      "Selected_text:\n",
      "\t ['back', 'here', ',', 'i', 'was', 'busy', 'xd', 'wirting', 'stars', 'loves', ',', 'almos', '400', 'pages', 'xd', 'and', 'listenint', 'afh', 'and', 'tv']\n",
      "Predicted_text:\n",
      "\t ['back', 'here', ',', 'i', 'was', 'busy', 'xd', 'xxxUNK', 'stars', 'loves', ',', 'xxxUNK', '400', 'pages', 'xd', 'and', 'xxxUNK', 'xxxUNK', 'and', 'tv']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.77', '0.00', 224, 'back']\n",
      "\t['0.01', '0.00', 18, 'here']\n",
      "\t['0.04', '0.00', 5, ',']\n",
      "\t['0.01', '0.00', 7, 'i']\n",
      "\t['0.01', '0.00', 183, 'was']\n",
      "\t['0.01', '0.00', 275, 'busy']\n",
      "\t['0.00', '0.00', 2529, 'xd']\n",
      "\t['0.00', '0.00', 1, 'wirting']\n",
      "\t['0.00', '0.00', 2240, 'stars']\n",
      "\t['0.01', '0.00', 1482, 'loves']\n",
      "\t['0.03', '0.00', 5, ',']\n",
      "\t['0.00', '0.00', 1, 'almos']\n",
      "\t['0.01', '0.00', 5941, '400']\n",
      "\t['0.01', '0.00', 3439, 'pages']\n",
      "\t['0.01', '0.00', 2529, 'xd']\n",
      "\t['0.02', '0.00', 68, 'and']\n",
      "\t['0.01', '0.00', 1, 'listenint']\n",
      "\t['0.01', '0.00', 1, 'afh']\n",
      "\t['0.01', '0.02', 68, 'and']\n",
      "\t['0.01', '0.96', 1216, 'tv']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 16 ==================\n",
      "Selected_text:\n",
      "\t ['my', 'kind', 'of', 'night']\n",
      "Predicted_text:\n",
      "\t ['of', 'night']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.10', '0.01', 44, 'we']\n",
      "\t['0.01', '0.01', 406, 'got']\n",
      "\t['0.01', '0.01', 1, 'jojo']\n",
      "\t['0.01', '0.01', 19, 'in']\n",
      "\t['0.01', '0.01', 55, 'for']\n",
      "\t['0.01', '0.01', 197, 'free']\n",
      "\t['0.01', '0.02', 68, 'and']\n",
      "\t['0.03', '0.02', 197, 'free']\n",
      "\t['0.03', '0.01', 2813, 'drinks']\n",
      "\t['0.06', '0.02', 55, 'for']\n",
      "\t['0.09', '0.03', 932, 'mom']\n",
      "\t['0.12', '0.05', 22, '!']\n",
      "\t['0.14', '0.06', 24, 'my']\n",
      "\t['0.14', '0.10', 1543, 'kind']\n",
      "\t['0.14', '0.13', 34, 'of']\n",
      "\t['0.06', '0.46', 559, 'night']\n",
      "\t['0.03', '0.03', 10, 'xxxSENTIMENT']\n",
      "\t['0.01', '0.01', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 17 ==================\n",
      "Selected_text:\n",
      "\t ['just', 'got', 'home', 'from', 'the', 'last', 'day', 'of', 'school', '.', 'graduation', 'tomorrow', '.']\n",
      "Predicted_text:\n",
      "\t ['just', 'got', 'home', 'from', 'the', 'last', 'day', 'of', 'school', '.', 'graduation', 'tomorrow', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.94', '0.00', 77, 'just']\n",
      "\t['0.01', '0.00', 406, 'got']\n",
      "\t['0.02', '0.00', 228, 'home']\n",
      "\t['0.00', '0.00', 120, 'from']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.00', '0.00', 285, 'last']\n",
      "\t['0.00', '0.00', 286, 'day']\n",
      "\t['0.00', '0.00', 34, 'of']\n",
      "\t['0.00', '0.00', 288, 'school']\n",
      "\t['0.01', '0.00', 28, '.']\n",
      "\t['0.01', '0.00', 541, 'graduation']\n",
      "\t['0.00', '0.01', 251, 'tomorrow']\n",
      "\t['0.00', '0.98', 28, '.']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 18 ==================\n",
      "Selected_text:\n",
      "\t ['*', '*', '*', '*']\n",
      "Predicted_text:\n",
      "\t ['in', 'a', 'drill', 'xxxUNK', 'voice', ':', 'everybody', 'wake', 'the', '*']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.18', '0.03', 19, 'in']\n",
      "\t['0.03', '0.04', 142, 'a']\n",
      "\t['0.04', '0.03', 9548, 'drill']\n",
      "\t['0.04', '0.03', 1, 'sergeant`s']\n",
      "\t['0.04', '0.05', 118, 'voice']\n",
      "\t['0.06', '0.05', 48, ':']\n",
      "\t['0.09', '0.06', 1856, 'everybody']\n",
      "\t['0.11', '0.06', 1271, 'wake']\n",
      "\t['0.12', '0.05', 42, 'the']\n",
      "\t['0.10', '0.09', 35, '*']\n",
      "\t['0.06', '0.04', 35, '*']\n",
      "\t['0.04', '0.05', 35, '*']\n",
      "\t['0.03', '0.03', 35, '*']\n",
      "\t['0.02', '0.02', 225, 'up']\n",
      "\t['0.01', '0.03', 22, '!']\n",
      "\t['0.01', '0.03', 22, '!']\n",
      "\t['0.01', '0.02', 22, '!']\n",
      "\t['0.00', '0.06', 35, '*']\n",
      "\t['0.00', '0.02', 9838, 'flicks']\n",
      "\t['0.00', '0.02', 41, 'on']\n",
      "\t['0.00', '0.01', 3301, 'everyone`s']\n",
      "\t['0.00', '0.02', 8221, 'lights']\n",
      "\t['0.00', '0.02', 35, '*']\n",
      "\t['0.00', '0.02', 192, 'it`s']\n",
      "\t['0.00', '0.01', 5001, '500']\n",
      "\t['0.00', '0.01', 9839, 'est']\n",
      "\t['0.00', '0.00', 4080, 'rise']\n",
      "\t['0.00', '0.01', 68, 'and']\n",
      "\t['0.00', '0.00', 2998, 'shine']\n",
      "\t['0.00', '0.00', 1, 'beetches']\n",
      "\t['0.00', '0.00', 22, '!']\n",
      "\t['0.00', '0.01', 22, '!']\n",
      "\t['0.00', '0.01', 426, 'lol']\n",
      "\t['0.00', '0.02', 3953, 'jk']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 23, 'negative']\n",
      "\t['0.00', '0.01', 12, 'xxxEND']\n",
      "================== Sample # 19 ==================\n",
      "Selected_text:\n",
      "\t ['really', 'good', 'job', '!']\n",
      "Predicted_text:\n",
      "\t ['really', 'good', 'job', '!']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.05', '0.00', 1997, 'gave']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.00', '0.00', 3155, 'bikes']\n",
      "\t['0.00', '0.00', 142, 'a']\n",
      "\t['0.00', '0.00', 1, 'thorough']\n",
      "\t['0.00', '0.00', 2140, 'wash']\n",
      "\t['0.00', '0.00', 5, ',']\n",
      "\t['0.00', '0.00', 1, 'degrease']\n",
      "\t['0.00', '0.00', 144, 'it']\n",
      "\t['0.01', '0.00', 68, 'and']\n",
      "\t['0.03', '0.01', 3315, 'grease']\n",
      "\t['0.02', '0.01', 144, 'it']\n",
      "\t['0.02', '0.01', 28, '.']\n",
      "\t['0.04', '0.01', 425, 'think']\n",
      "\t['0.07', '0.01', 7, 'i']\n",
      "\t['0.09', '0.01', 765, 'did']\n",
      "\t['0.12', '0.02', 142, 'a']\n",
      "\t['0.18', '0.05', 102, 'really']\n",
      "\t['0.15', '0.16', 448, 'good']\n",
      "\t['0.09', '0.13', 167, 'job']\n",
      "\t['0.08', '0.55', 22, '!']\n",
      "\t['0.02', '0.02', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,20):\n",
    "    spot_check(i, mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Sample # 200 ==================\n",
      "Selected_text:\n",
      "\t ['bad', 'day', 'the', 'day', 'you', 'realize', 'what', 'mess', 'you`ve', 'put', 'me', 'through', 'will', 'be', 'one', 'of', 'the', 'happiest', 'days', 'of', 'my', 'life', '.', '.', '.']\n",
      "Predicted_text:\n",
      "\t ['bad', 'day', 'the', 'day', 'you', 'realize', 'what', 'mess', 'you`ve', 'put', 'me', 'through', 'will', 'be', 'one', 'of', 'the', 'happiest', 'days', 'of', 'my', 'life', '.', '.', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.90', '0.00', 318, 'bad']\n",
      "\t['0.00', '0.00', 286, 'day']\n",
      "\t['0.01', '0.00', 42, 'the']\n",
      "\t['0.00', '0.00', 286, 'day']\n",
      "\t['0.00', '0.00', 17, 'you']\n",
      "\t['0.00', '0.00', 972, 'realize']\n",
      "\t['0.00', '0.00', 29, 'what']\n",
      "\t['0.00', '0.00', 345, 'mess']\n",
      "\t['0.00', '0.00', 973, 'you`ve']\n",
      "\t['0.01', '0.00', 39, 'put']\n",
      "\t['0.00', '0.00', 27, 'me']\n",
      "\t['0.00', '0.00', 247, 'through']\n",
      "\t['0.00', '0.00', 15, 'will']\n",
      "\t['0.00', '0.00', 89, 'be']\n",
      "\t['0.00', '0.00', 310, 'one']\n",
      "\t['0.00', '0.00', 34, 'of']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.00', '0.00', 974, 'happiest']\n",
      "\t['0.00', '0.00', 136, 'days']\n",
      "\t['0.01', '0.00', 34, 'of']\n",
      "\t['0.01', '0.00', 24, 'my']\n",
      "\t['0.01', '0.00', 868, 'life']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.01', '0.01', 28, '.']\n",
      "\t['0.00', '0.98', 28, '.']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 201 ==================\n",
      "Selected_text:\n",
      "\t ['visiting', 'family', 'in', 'hospital', '=', 'not', 'fun']\n",
      "Predicted_text:\n",
      "\t ['visiting', 'family', 'in', 'hospital', '=', 'not', 'fun']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.25', '0.08', 346, 'visiting']\n",
      "\t['0.09', '0.11', 173, 'family']\n",
      "\t['0.10', '0.08', 19, 'in']\n",
      "\t['0.14', '0.09', 455, 'hospital']\n",
      "\t['0.15', '0.10', 94, '=']\n",
      "\t['0.14', '0.11', 149, 'not']\n",
      "\t['0.08', '0.38', 63, 'fun']\n",
      "\t['0.02', '0.02', 10, 'xxxSENTIMENT']\n",
      "\t['0.01', '0.01', 23, 'negative']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 202 ==================\n",
      "Selected_text:\n",
      "\t ['wish', 'me', 'luck']\n",
      "Predicted_text:\n",
      "\t ['wish', 'me', 'luck', '.', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.12', '0.02', 9, 'going']\n",
      "\t['0.02', '0.03', 88, 'to']\n",
      "\t['0.02', '0.02', 433, 'take']\n",
      "\t['0.02', '0.02', 24, 'my']\n",
      "\t['0.02', '0.02', 285, 'last']\n",
      "\t['0.03', '0.02', 1897, 'final']\n",
      "\t['0.06', '0.03', 28, '.']\n",
      "\t['0.08', '0.05', 28, '.']\n",
      "\t['0.09', '0.04', 28, '.']\n",
      "\t['0.14', '0.07', 520, 'wish']\n",
      "\t['0.12', '0.11', 27, 'me']\n",
      "\t['0.11', '0.10', 2010, 'luck']\n",
      "\t['0.09', '0.11', 28, '.']\n",
      "\t['0.05', '0.29', 28, '.']\n",
      "\t['0.03', '0.03', 10, 'xxxSENTIMENT']\n",
      "\t['0.01', '0.01', 69, 'positive']\n",
      "\t['0.01', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 203 ==================\n",
      "Selected_text:\n",
      "\t ['lol']\n",
      "Predicted_text:\n",
      "\t ['lol', 'simpsons', 'xxxUNK', ':', \"'\", 'first', 'day', 'at', 'your', 'new', 'school', ',', 'so', 'lisa', ':', 'have', 'fun', '!']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.09', '0.02', 426, 'lol']\n",
      "\t['0.02', '0.03', 1967, 'simpsons']\n",
      "\t['0.02', '0.03', 1, 's20e19']\n",
      "\t['0.02', '0.03', 48, ':']\n",
      "\t['0.01', '0.02', 332, \"'\"]\n",
      "\t['0.02', '0.03', 813, 'first']\n",
      "\t['0.02', '0.02', 286, 'day']\n",
      "\t['0.02', '0.02', 358, 'at']\n",
      "\t['0.03', '0.02', 305, 'your']\n",
      "\t['0.06', '0.03', 163, 'new']\n",
      "\t['0.05', '0.02', 288, 'school']\n",
      "\t['0.06', '0.04', 5, ',']\n",
      "\t['0.07', '0.02', 151, 'so']\n",
      "\t['0.06', '0.03', 3838, 'lisa']\n",
      "\t['0.08', '0.03', 48, ':']\n",
      "\t['0.06', '0.03', 4, 'have']\n",
      "\t['0.06', '0.05', 63, 'fun']\n",
      "\t['0.06', '0.10', 22, '!']\n",
      "\t['0.04', '0.05', 68, 'and']\n",
      "\t['0.04', '0.04', 8516, 'bart']\n",
      "\t['0.04', '0.03', 48, ':']\n",
      "\t['0.02', '0.06', 424, 'don`t']\n",
      "\t['0.01', '0.08', 22, '!']\n",
      "\t['0.01', '0.10', 332, \"'\"]\n",
      "\t['0.01', '0.02', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.01', 69, 'positive']\n",
      "\t['0.00', '0.01', 12, 'xxxEND']\n",
      "================== Sample # 204 ==================\n",
      "Selected_text:\n",
      "\t ['hahaha', 'sa', 'una', 'lang', 'yan', '!', 'i', 'started', 'with', '40', 'minutes', 'ng', '5k', '.', 'that', 'was', 'a', 'year', 'ago', '.']\n",
      "Predicted_text:\n",
      "\t ['hahaha', 'sa', 'una', 'lang', 'yan', '!', 'i', 'started', 'with', '40', 'minutes', 'ng', '5k', '.', 'that', 'was', 'a', 'year', 'ago', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.71', '0.00', 939, 'hahaha']\n",
      "\t['0.01', '0.00', 4426, 'sa']\n",
      "\t['0.04', '0.00', 8599, 'una']\n",
      "\t['0.01', '0.00', 2847, 'lang']\n",
      "\t['0.01', '0.00', 8600, 'yan']\n",
      "\t['0.01', '0.00', 22, '!']\n",
      "\t['0.00', '0.00', 7, 'i']\n",
      "\t['0.00', '0.00', 1877, 'started']\n",
      "\t['0.00', '0.00', 278, 'with']\n",
      "\t['0.01', '0.00', 2965, '40']\n",
      "\t['0.03', '0.00', 713, 'minutes']\n",
      "\t['0.00', '0.00', 2844, 'ng']\n",
      "\t['0.01', '0.00', 6604, '5k']\n",
      "\t['0.01', '0.00', 28, '.']\n",
      "\t['0.02', '0.00', 82, 'that']\n",
      "\t['0.04', '0.00', 183, 'was']\n",
      "\t['0.01', '0.00', 142, 'a']\n",
      "\t['0.02', '0.00', 882, 'year']\n",
      "\t['0.02', '0.02', 913, 'ago']\n",
      "\t['0.01', '0.96', 28, '.']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 205 ==================\n",
      "Selected_text:\n",
      "\t ['_', 'devil1', 'big', 'brother', 'quiz', '?', 'what', '?', '!', 'i`m', 'too', 'busy', 'rocking', 'out', 'on', 'guitar', 'hero', ',', 'i', 'didn`t', 'notice', 'any', 'such', 'thing']\n",
      "Predicted_text:\n",
      "\t ['_', 'xxxUNK', 'big', 'brother', 'quiz', '?', 'what', '?', '!', 'i`m', 'too', 'busy', 'rocking', 'out', 'on', 'guitar', 'hero', ',', 'i', 'didn`t', 'notice', 'any', 'such', 'thing']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.64', '0.00', 405, '_']\n",
      "\t['0.02', '0.00', 1, 'devil1']\n",
      "\t['0.05', '0.00', 292, 'big']\n",
      "\t['0.03', '0.00', 1087, 'brother']\n",
      "\t['0.02', '0.00', 3851, 'quiz']\n",
      "\t['0.01', '0.00', 74, '?']\n",
      "\t['0.02', '0.00', 29, 'what']\n",
      "\t['0.01', '0.00', 74, '?']\n",
      "\t['0.01', '0.00', 22, '!']\n",
      "\t['0.02', '0.00', 96, 'i`m']\n",
      "\t['0.02', '0.00', 227, 'too']\n",
      "\t['0.02', '0.00', 275, 'busy']\n",
      "\t['0.01', '0.00', 994, 'rocking']\n",
      "\t['0.01', '0.00', 215, 'out']\n",
      "\t['0.01', '0.00', 41, 'on']\n",
      "\t['0.01', '0.00', 2389, 'guitar']\n",
      "\t['0.01', '0.00', 261, 'hero']\n",
      "\t['0.01', '0.00', 5, ',']\n",
      "\t['0.01', '0.00', 7, 'i']\n",
      "\t['0.02', '0.00', 475, 'didn`t']\n",
      "\t['0.01', '0.00', 2396, 'notice']\n",
      "\t['0.02', '0.01', 853, 'any']\n",
      "\t['0.01', '0.07', 416, 'such']\n",
      "\t['0.00', '0.87', 311, 'thing']\n",
      "\t['0.00', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 206 ==================\n",
      "Selected_text:\n",
      "\t ['actually', ',', 'by', 'the', 'time', 'i', 'get', 'there', ',', 'the', 'train', 'would', 'have', 'arrived', '.', '.', '.']\n",
      "Predicted_text:\n",
      "\t ['actually', ',', 'by', 'the', 'time', 'i', 'get', 'there', ',', 'the', 'train', 'would', 'have', 'arrived', '.', '.', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.87', '0.00', 732, 'actually']\n",
      "\t['0.01', '0.00', 5, ',']\n",
      "\t['0.03', '0.00', 106, 'by']\n",
      "\t['0.01', '0.00', 42, 'the']\n",
      "\t['0.01', '0.00', 504, 'time']\n",
      "\t['0.02', '0.00', 7, 'i']\n",
      "\t['0.01', '0.00', 99, 'get']\n",
      "\t['0.01', '0.01', 216, 'there']\n",
      "\t['0.00', '0.00', 5, ',']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.00', '0.00', 1752, 'train']\n",
      "\t['0.00', '0.00', 145, 'would']\n",
      "\t['0.00', '0.01', 4, 'have']\n",
      "\t['0.00', '0.00', 3306, 'arrived']\n",
      "\t['0.00', '0.01', 28, '.']\n",
      "\t['0.00', '0.01', 28, '.']\n",
      "\t['0.00', '0.94', 28, '.']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 207 ==================\n",
      "Selected_text:\n",
      "\t ['sounds', 'good', ',', 'the', 'one', 'i', 'was', 'too', 'was', 'also', 'fun']\n",
      "Predicted_text:\n",
      "\t ['sounds', 'good', ',', 'the', 'one', 'i', 'was', 'too', 'was', 'also', 'fun']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.17', '0.04', 423, 'sounds']\n",
      "\t['0.03', '0.06', 448, 'good']\n",
      "\t['0.04', '0.04', 5, ',']\n",
      "\t['0.04', '0.05', 42, 'the']\n",
      "\t['0.06', '0.03', 310, 'one']\n",
      "\t['0.07', '0.05', 7, 'i']\n",
      "\t['0.11', '0.05', 183, 'was']\n",
      "\t['0.15', '0.04', 227, 'too']\n",
      "\t['0.16', '0.07', 183, 'was']\n",
      "\t['0.10', '0.09', 356, 'also']\n",
      "\t['0.04', '0.46', 63, 'fun']\n",
      "\t['0.01', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.01', '0.00', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 208 ==================\n",
      "Selected_text:\n",
      "\t ['decreasing']\n",
      "Predicted_text:\n",
      "\t ['showed', 'my', 'fluids', 'decreasing', 'slightly', '.', 'so', 'doesn`t', 'look']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.18', '0.03', 1112, 'showed']\n",
      "\t['0.04', '0.05', 24, 'my']\n",
      "\t['0.05', '0.03', 3935, 'fluids']\n",
      "\t['0.05', '0.04', 9167, 'decreasing']\n",
      "\t['0.07', '0.04', 1567, 'slightly']\n",
      "\t['0.10', '0.09', 28, '.']\n",
      "\t['0.14', '0.10', 151, 'so']\n",
      "\t['0.14', '0.16', 1279, 'doesn`t']\n",
      "\t['0.13', '0.16', 146, 'look']\n",
      "\t['0.05', '0.14', 103, 'like']\n",
      "\t['0.02', '0.06', 547, 'she`s']\n",
      "\t['0.01', '0.03', 4986, 'letting']\n",
      "\t['0.01', '0.03', 27, 'me']\n",
      "\t['0.00', '0.02', 215, 'out']\n",
      "\t['0.00', '0.01', 34, 'of']\n",
      "\t['0.00', '0.01', 276, 'this']\n",
      "\t['0.00', '0.00', 557, 'bed']\n",
      "\t['0.00', '0.00', 2022, 'anytime']\n",
      "\t['0.00', '0.00', 156, 'soon']\n",
      "\t['0.00', '0.00', 7, 'i']\n",
      "\t['0.00', '0.00', 4, 'have']\n",
      "\t['0.00', '0.00', 142, 'a']\n",
      "\t['0.00', '0.00', 1240, 'follow']\n",
      "\t['0.00', '0.00', 225, 'up']\n",
      "\t['0.00', '0.00', 76, 'u']\n",
      "\t['0.00', '0.00', 49, '/']\n",
      "\t['0.00', '0.00', 2148, 's']\n",
      "\t['0.00', '0.00', 574, 'next']\n",
      "\t['0.00', '0.00', 570, 'week']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 23, 'negative']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 209 ==================\n",
      "Selected_text:\n",
      "\t ['jealous', '*']\n",
      "Predicted_text:\n",
      "\t ['_', 'r', 'drive', '-', 'in', '!', '?', 'srsly', '!', '?', '*', 'jealous', '*', 'i', 'have', 'never', 'ever', 'been', 'to', 'one', '.', 'there', 'is']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.10', '0.01', 405, '_']\n",
      "\t['0.01', '0.01', 706, 'r']\n",
      "\t['0.02', '0.01', 731, 'drive']\n",
      "\t['0.02', '0.01', 52, '-']\n",
      "\t['0.02', '0.01', 19, 'in']\n",
      "\t['0.02', '0.02', 22, '!']\n",
      "\t['0.02', '0.02', 74, '?']\n",
      "\t['0.02', '0.02', 2036, 'srsly']\n",
      "\t['0.03', '0.02', 22, '!']\n",
      "\t['0.06', '0.02', 74, '?']\n",
      "\t['0.05', '0.02', 35, '*']\n",
      "\t['0.04', '0.03', 408, 'jealous']\n",
      "\t['0.05', '0.02', 35, '*']\n",
      "\t['0.05', '0.02', 7, 'i']\n",
      "\t['0.05', '0.02', 4, 'have']\n",
      "\t['0.04', '0.05', 97, 'never']\n",
      "\t['0.04', '0.02', 817, 'ever']\n",
      "\t['0.05', '0.04', 132, 'been']\n",
      "\t['0.03', '0.02', 88, 'to']\n",
      "\t['0.04', '0.04', 310, 'one']\n",
      "\t['0.04', '0.02', 28, '.']\n",
      "\t['0.04', '0.05', 216, 'there']\n",
      "\t['0.03', '0.06', 26, 'is']\n",
      "\t['0.02', '0.05', 310, 'one']\n",
      "\t['0.01', '0.04', 585, 'down']\n",
      "\t['0.01', '0.02', 42, 'the']\n",
      "\t['0.01', '0.01', 1675, 'rd']\n",
      "\t['0.01', '0.01', 5, ',']\n",
      "\t['0.01', '0.02', 116, 'but']\n",
      "\t['0.01', '0.02', 192, 'it`s']\n",
      "\t['0.01', '0.05', 204, 'no']\n",
      "\t['0.00', '0.02', 727, 'longer']\n",
      "\t['0.00', '0.01', 4367, 'operational']\n",
      "\t['0.00', '0.02', 48, ':']\n",
      "\t['0.00', '0.03', 2428, '|']\n",
      "\t['0.00', '0.02', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.02', 23, 'negative']\n",
      "\t['0.00', '0.02', 12, 'xxxEND']\n"
     ]
    }
   ],
   "source": [
    "for i in range(200,210):\n",
    "    spot_check(i, mode=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Sample # 0 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['last', 'session', 'of', 'the', 'day', 'http', ':', '/', '/', 'twitpic', '.', 'com', '/', 'xxxUNK']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.76', '0.05', 285, 'last']\n",
      "\t['0.04', '0.07', 7417, 'session']\n",
      "\t['0.10', '0.05', 34, 'of']\n",
      "\t['0.05', '0.06', 42, 'the']\n",
      "\t['0.04', '0.12', 286, 'day']\n",
      "\t['0.01', '0.06', 47, 'http']\n",
      "\t['0.01', '0.06', 48, ':']\n",
      "\t['0.00', '0.07', 49, '/']\n",
      "\t['0.00', '0.03', 49, '/']\n",
      "\t['0.00', '0.02', 914, 'twitpic']\n",
      "\t['0.00', '0.02', 28, '.']\n",
      "\t['0.00', '0.01', 51, 'com']\n",
      "\t['0.00', '0.03', 49, '/']\n",
      "\t['0.00', '0.34', 1, '67ezh']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 1 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['xxxUNK', 'is', 'also', 'really']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.30', '0.06', 1, 'shanghai']\n",
      "\t['0.08', '0.07', 26, 'is']\n",
      "\t['0.10', '0.12', 356, 'also']\n",
      "\t['0.11', '0.14', 102, 'really']\n",
      "\t['0.09', '0.08', 1285, 'exciting']\n",
      "\t['0.06', '0.09', 81, '(']\n",
      "\t['0.07', '0.07', 1, 'precisely']\n",
      "\t['0.04', '0.08', 52, '-']\n",
      "\t['0.03', '0.05', 52, '-']\n",
      "\t['0.02', '0.04', 1, 'skyscrapers']\n",
      "\t['0.01', '0.02', 5769, 'galore']\n",
      "\t['0.01', '0.01', 84, ')']\n",
      "\t['0.01', '0.01', 28, '.']\n",
      "\t['0.01', '0.02', 448, 'good']\n",
      "\t['0.01', '0.01', 3950, 'tweeps']\n",
      "\t['0.01', '0.01', 19, 'in']\n",
      "\t['0.01', '0.01', 4117, 'china']\n",
      "\t['0.00', '0.01', 48, ':']\n",
      "\t['0.00', '0.01', 81, '(']\n",
      "\t['0.01', '0.01', 5973, 'sh']\n",
      "\t['0.00', '0.01', 84, ')']\n",
      "\t['0.00', '0.01', 81, '(']\n",
      "\t['0.00', '0.01', 1, 'bj']\n",
      "\t['0.00', '0.01', 84, ')']\n",
      "\t['0.00', '0.02', 28, '.']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 2 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['shame', '!']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.12', '0.01', 5326, 'recession']\n",
      "\t['0.01', '0.01', 917, 'hit']\n",
      "\t['0.01', '0.01', 1, 'veronique']\n",
      "\t['0.01', '0.01', 1, 'branquinho']\n",
      "\t['0.01', '0.01', 5, ',']\n",
      "\t['0.02', '0.01', 447, 'she']\n",
      "\t['0.02', '0.02', 316, 'has']\n",
      "\t['0.03', '0.02', 88, 'to']\n",
      "\t['0.04', '0.01', 5419, 'quit']\n",
      "\t['0.05', '0.01', 155, 'her']\n",
      "\t['0.07', '0.02', 1524, 'company']\n",
      "\t['0.10', '0.03', 5, ',']\n",
      "\t['0.12', '0.04', 416, 'such']\n",
      "\t['0.12', '0.05', 142, 'a']\n",
      "\t['0.14', '0.10', 1214, 'shame']\n",
      "\t['0.08', '0.59', 22, '!']\n",
      "\t['0.04', '0.03', 10, 'xxxSENTIMENT']\n",
      "\t['0.02', '0.01', 23, 'negative']\n",
      "\t['0.01', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 3 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['happy', 'bday', '!']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.59', '0.18', 291, 'happy']\n",
      "\t['0.25', '0.23', 1251, 'bday']\n",
      "\t['0.12', '0.55', 22, '!']\n",
      "\t['0.03', '0.02', 10, 'xxxSENTIMENT']\n",
      "\t['0.01', '0.00', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 4 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['i', 'like', 'it', '!', '!']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.03', '0.00', 47, 'http']\n",
      "\t['0.00', '0.00', 48, ':']\n",
      "\t['0.00', '0.00', 49, '/']\n",
      "\t['0.00', '0.00', 49, '/']\n",
      "\t['0.00', '0.00', 914, 'twitpic']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.00', '0.00', 51, 'com']\n",
      "\t['0.01', '0.00', 49, '/']\n",
      "\t['0.01', '0.00', 1, '4w75p']\n",
      "\t['0.09', '0.01', 52, '-']\n",
      "\t['0.32', '0.02', 7, 'i']\n",
      "\t['0.27', '0.10', 103, 'like']\n",
      "\t['0.12', '0.03', 144, 'it']\n",
      "\t['0.09', '0.15', 22, '!']\n",
      "\t['0.06', '0.68', 22, '!']\n",
      "\t['0.00', '0.02', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 5 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['that`s', 'great', '!', '!', 'xxxUNK', '!', '!', 'xxxUNK', '!']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.28', '0.07', 240, 'that`s']\n",
      "\t['0.07', '0.10', 812, 'great']\n",
      "\t['0.08', '0.09', 22, '!']\n",
      "\t['0.08', '0.08', 22, '!']\n",
      "\t['0.13', '0.07', 1, 'weee']\n",
      "\t['0.11', '0.06', 22, '!']\n",
      "\t['0.11', '0.08', 22, '!']\n",
      "\t['0.08', '0.03', 1, 'visitors']\n",
      "\t['0.04', '0.40', 22, '!']\n",
      "\t['0.01', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.01', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 6 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['i', 'think', 'everyone', 'hates', 'me', 'on', 'here', 'lol']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.32', '0.11', 7, 'i']\n",
      "\t['0.10', '0.13', 425, 'think']\n",
      "\t['0.12', '0.12', 496, 'everyone']\n",
      "\t['0.13', '0.15', 1623, 'hates']\n",
      "\t['0.14', '0.11', 27, 'me']\n",
      "\t['0.09', '0.07', 41, 'on']\n",
      "\t['0.07', '0.09', 18, 'here']\n",
      "\t['0.02', '0.19', 426, 'lol']\n",
      "\t['0.01', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.01', 23, 'negative']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 7 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['soooooo', 'wish', 'i', 'could', ',', 'but', 'im', 'in', 'school', 'and', 'myspace', 'is', 'completely', 'blocked']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.19', '0.05', 284, 'soooooo']\n",
      "\t['0.05', '0.07', 520, 'wish']\n",
      "\t['0.06', '0.05', 7, 'i']\n",
      "\t['0.06', '0.05', 1039, 'could']\n",
      "\t['0.06', '0.06', 5, ',']\n",
      "\t['0.06', '0.07', 116, 'but']\n",
      "\t['0.09', '0.07', 200, 'im']\n",
      "\t['0.09', '0.09', 19, 'in']\n",
      "\t['0.08', '0.05', 288, 'school']\n",
      "\t['0.08', '0.05', 68, 'and']\n",
      "\t['0.05', '0.07', 862, 'myspace']\n",
      "\t['0.04', '0.03', 26, 'is']\n",
      "\t['0.04', '0.07', 2121, 'completely']\n",
      "\t['0.02', '0.17', 3826, 'blocked']\n",
      "\t['0.01', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.01', '0.01', 23, 'negative']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 8 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['and', 'within', 'a', 'short', 'time', 'of', 'the', 'last', 'clue', 'all', 'of', 'them']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.92', '0.00', 68, 'and']\n",
      "\t['0.01', '0.00', 4891, 'within']\n",
      "\t['0.03', '0.00', 142, 'a']\n",
      "\t['0.00', '0.00', 1006, 'short']\n",
      "\t['0.00', '0.00', 504, 'time']\n",
      "\t['0.00', '0.00', 34, 'of']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.00', '0.00', 285, 'last']\n",
      "\t['0.00', '0.00', 7316, 'clue']\n",
      "\t['0.01', '0.00', 66, 'all']\n",
      "\t['0.01', '0.02', 34, 'of']\n",
      "\t['0.00', '0.98', 40, 'them']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 9 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['what', 'did', 'you', 'get', '?', 'my', 'day', 'is', 'alright', '.', '.', 'haven`t', 'done', 'anything', 'yet', '.', 'leaving', 'soon', 'to', 'my', 'xxxUNK', 'though', '!']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.90', '0.00', 29, 'what']\n",
      "\t['0.00', '0.00', 765, 'did']\n",
      "\t['0.01', '0.00', 17, 'you']\n",
      "\t['0.00', '0.00', 99, 'get']\n",
      "\t['0.00', '0.00', 74, '?']\n",
      "\t['0.00', '0.00', 24, 'my']\n",
      "\t['0.00', '0.00', 286, 'day']\n",
      "\t['0.00', '0.00', 26, 'is']\n",
      "\t['0.00', '0.00', 2244, 'alright']\n",
      "\t['0.01', '0.00', 28, '.']\n",
      "\t['0.02', '0.00', 28, '.']\n",
      "\t['0.01', '0.00', 1016, 'haven`t']\n",
      "\t['0.01', '0.00', 628, 'done']\n",
      "\t['0.00', '0.00', 1578, 'anything']\n",
      "\t['0.01', '0.00', 1551, 'yet']\n",
      "\t['0.01', '0.00', 28, '.']\n",
      "\t['0.00', '0.00', 2015, 'leaving']\n",
      "\t['0.00', '0.00', 156, 'soon']\n",
      "\t['0.00', '0.00', 88, 'to']\n",
      "\t['0.01', '0.00', 24, 'my']\n",
      "\t['0.00', '0.00', 1, 'stepsister']\n",
      "\t['0.00', '0.02', 252, 'though']\n",
      "\t['0.00', '0.97', 22, '!']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 10 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['argh', 'total', 'bummer']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.06', '0.00', 24, 'my']\n",
      "\t['0.00', '0.01', 977, 'bike']\n",
      "\t['0.01', '0.01', 183, 'was']\n",
      "\t['0.01', '0.01', 39, 'put']\n",
      "\t['0.00', '0.00', 41, 'on']\n",
      "\t['0.00', '0.00', 3270, 'hold']\n",
      "\t['0.01', '0.00', 28, '.']\n",
      "\t['0.01', '0.00', 28, '.']\n",
      "\t['0.01', '0.00', 28, '.']\n",
      "\t['0.02', '0.01', 350, 'should']\n",
      "\t['0.03', '0.01', 4, 'have']\n",
      "\t['0.02', '0.01', 2467, 'known']\n",
      "\t['0.04', '0.01', 82, 'that']\n",
      "\t['0.05', '0.01', 28, '.']\n",
      "\t['0.08', '0.03', 28, '.']\n",
      "\t['0.10', '0.02', 28, '.']\n",
      "\t['0.10', '0.04', 28, '.']\n",
      "\t['0.13', '0.06', 1286, 'argh']\n",
      "\t['0.13', '0.10', 1291, 'total']\n",
      "\t['0.07', '0.56', 5242, 'bummer']\n",
      "\t['0.06', '0.05', 10, 'xxxSENTIMENT']\n",
      "\t['0.02', '0.04', 23, 'negative']\n",
      "\t['0.01', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 11 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['i', 'checked', '.', 'we', 'didn`t', 'win']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.94', '0.00', 7, 'i']\n",
      "\t['0.01', '0.00', 2486, 'checked']\n",
      "\t['0.03', '0.00', 28, '.']\n",
      "\t['0.01', '0.00', 44, 'we']\n",
      "\t['0.01', '0.00', 475, 'didn`t']\n",
      "\t['0.01', '0.99', 738, 'win']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 12 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['.', '.', 'and', 'you`re', 'on', 'twitter', '!', 'did', 'the', 'xxxUNK', 'xxxUNK', 'you', 'that', 'much', '?']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.94', '0.00', 28, '.']\n",
      "\t['0.01', '0.00', 28, '.']\n",
      "\t['0.02', '0.00', 68, 'and']\n",
      "\t['0.00', '0.00', 956, 'you`re']\n",
      "\t['0.00', '0.00', 41, 'on']\n",
      "\t['0.01', '0.00', 231, 'twitter']\n",
      "\t['0.00', '0.00', 22, '!']\n",
      "\t['0.00', '0.00', 765, 'did']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.01', '0.00', 1, 'tavern']\n",
      "\t['0.01', '0.00', 1, 'bore']\n",
      "\t['0.00', '0.00', 17, 'you']\n",
      "\t['0.00', '0.00', 82, 'that']\n",
      "\t['0.00', '0.00', 86, 'much']\n",
      "\t['0.00', '0.99', 74, '?']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 13 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['i`m', 'in', 'va', 'for', 'the', 'weekend', ',', 'my', 'xxxUNK', 'son', 'turns', '2', 'tomorrow', '.', '.', '.', '.', '.', '.', 'it', 'makes', 'me', 'kinda', 'sad']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.12', '0.01', 96, 'i`m']\n",
      "\t['0.01', '0.01', 19, 'in']\n",
      "\t['0.01', '0.01', 6180, 'va']\n",
      "\t['0.01', '0.01', 55, 'for']\n",
      "\t['0.01', '0.01', 42, 'the']\n",
      "\t['0.01', '0.01', 1231, 'weekend']\n",
      "\t['0.01', '0.01', 5, ',']\n",
      "\t['0.01', '0.01', 24, 'my']\n",
      "\t['0.01', '0.01', 1, 'youngest']\n",
      "\t['0.02', '0.01', 945, 'son']\n",
      "\t['0.02', '0.01', 1040, 'turns']\n",
      "\t['0.01', '0.01', 694, '2']\n",
      "\t['0.02', '0.01', 251, 'tomorrow']\n",
      "\t['0.02', '0.01', 28, '.']\n",
      "\t['0.02', '0.01', 28, '.']\n",
      "\t['0.03', '0.02', 28, '.']\n",
      "\t['0.04', '0.01', 28, '.']\n",
      "\t['0.05', '0.03', 28, '.']\n",
      "\t['0.05', '0.02', 28, '.']\n",
      "\t['0.06', '0.04', 144, 'it']\n",
      "\t['0.10', '0.02', 1151, 'makes']\n",
      "\t['0.08', '0.06', 27, 'me']\n",
      "\t['0.07', '0.08', 1814, 'kinda']\n",
      "\t['0.07', '0.13', 14, 'sad']\n",
      "\t['0.04', '0.08', 5, ',']\n",
      "\t['0.03', '0.04', 65, 'he']\n",
      "\t['0.02', '0.01', 26, 'is']\n",
      "\t['0.02', '0.02', 540, 'getting']\n",
      "\t['0.02', '0.03', 151, 'so']\n",
      "\t['0.01', '0.02', 292, 'big']\n",
      "\t['0.01', '0.09', 5, ',']\n",
      "\t['0.00', '0.03', 351, 'check']\n",
      "\t['0.00', '0.01', 215, 'out']\n",
      "\t['0.00', '0.03', 24, 'my']\n",
      "\t['0.00', '0.03', 1, 'twipics']\n",
      "\t['0.00', '0.02', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.02', 23, 'negative']\n",
      "\t['0.00', '0.01', 12, 'xxxEND']\n",
      "================== Sample # 14 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['its', 'coming', 'out', 'the', 'xxxUNK', 'i', 'feel', 'like', 'my', 'phones', 'hole', 'is', 'not', 'a', 'virgin', '.', 'that`s', 'how', 'loose']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.09', '0.02', 213, 'its']\n",
      "\t['0.01', '0.02', 277, 'coming']\n",
      "\t['0.02', '0.02', 215, 'out']\n",
      "\t['0.02', '0.02', 42, 'the']\n",
      "\t['0.01', '0.01', 1, 'socket']\n",
      "\t['0.01', '0.02', 7, 'i']\n",
      "\t['0.02', '0.03', 338, 'feel']\n",
      "\t['0.02', '0.02', 103, 'like']\n",
      "\t['0.03', '0.02', 24, 'my']\n",
      "\t['0.04', '0.03', 1682, 'phones']\n",
      "\t['0.04', '0.02', 5511, 'hole']\n",
      "\t['0.04', '0.02', 26, 'is']\n",
      "\t['0.05', '0.03', 149, 'not']\n",
      "\t['0.05', '0.03', 142, 'a']\n",
      "\t['0.06', '0.03', 10085, 'virgin']\n",
      "\t['0.06', '0.04', 28, '.']\n",
      "\t['0.06', '0.05', 240, 'that`s']\n",
      "\t['0.07', '0.09', 335, 'how']\n",
      "\t['0.05', '0.10', 4396, 'loose']\n",
      "\t['0.05', '0.07', 144, 'it']\n",
      "\t['0.05', '0.05', 26, 'is']\n",
      "\t['0.03', '0.07', 28, '.']\n",
      "\t['0.02', '0.03', 28, '.']\n",
      "\t['0.02', '0.05', 28, '.']\n",
      "\t['0.02', '0.02', 48, ':']\n",
      "\t['0.01', '0.03', 3541, '`']\n",
      "\t['0.01', '0.04', 81, '(']\n",
      "\t['0.00', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.01', 23, 'negative']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 15 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['such', 'a', 'bad', 'week']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.08', '0.00', 151, 'so']\n",
      "\t['0.01', '0.00', 1662, 'hot']\n",
      "\t['0.01', '0.00', 177, 'today']\n",
      "\t['0.01', '0.00', 94, '=']\n",
      "\t['0.00', '0.00', 405, '_']\n",
      "\t['0.01', '0.00', 94, '=']\n",
      "\t['0.01', '0.01', 424, 'don`t']\n",
      "\t['0.01', '0.00', 103, 'like']\n",
      "\t['0.01', '0.00', 144, 'it']\n",
      "\t['0.03', '0.01', 68, 'and']\n",
      "\t['0.04', '0.02', 7, 'i']\n",
      "\t['0.03', '0.01', 355, 'hate']\n",
      "\t['0.04', '0.02', 24, 'my']\n",
      "\t['0.05', '0.01', 163, 'new']\n",
      "\t['0.08', '0.01', 1, 'timetable']\n",
      "\t['0.08', '0.01', 5, ',']\n",
      "\t['0.09', '0.01', 830, 'having']\n",
      "\t['0.12', '0.03', 416, 'such']\n",
      "\t['0.09', '0.07', 142, 'a']\n",
      "\t['0.08', '0.05', 318, 'bad']\n",
      "\t['0.08', '0.70', 570, 'week']\n",
      "\t['0.03', '0.02', 10, 'xxxSENTIMENT']\n",
      "\t['0.01', '0.00', 23, 'negative']\n",
      "\t['0.01', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 16 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['miss', 'you']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.82', '0.19', 16, 'miss']\n",
      "\t['0.13', '0.80', 17, 'you']\n",
      "\t['0.03', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.01', '0.00', 23, 'negative']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 17 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['cramps', '.', '.', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.55', '0.12', 1896, 'cramps']\n",
      "\t['0.16', '0.10', 28, '.']\n",
      "\t['0.16', '0.09', 28, '.']\n",
      "\t['0.09', '0.67', 28, '.']\n",
      "\t['0.02', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.01', '0.00', 23, 'negative']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 18 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['nice', 'songs', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.11', '0.01', 17, 'you']\n",
      "\t['0.01', '0.01', 493, 'guys']\n",
      "\t['0.01', '0.01', 475, 'didn`t']\n",
      "\t['0.01', '0.00', 460, 'say']\n",
      "\t['0.01', '0.01', 461, 'hi']\n",
      "\t['0.01', '0.01', 758, 'or']\n",
      "\t['0.03', '0.01', 1677, 'answer']\n",
      "\t['0.04', '0.02', 24, 'my']\n",
      "\t['0.05', '0.01', 2614, 'questions']\n",
      "\t['0.12', '0.03', 453, 'yesterday']\n",
      "\t['0.16', '0.05', 116, 'but']\n",
      "\t['0.16', '0.06', 397, 'nice']\n",
      "\t['0.14', '0.08', 645, 'songs']\n",
      "\t['0.08', '0.67', 28, '.']\n",
      "\t['0.05', '0.02', 10, 'xxxSENTIMENT']\n",
      "\t['0.01', '0.01', 69, 'positive']\n",
      "\t['0.01', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 19 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['i`m', 'going', 'into', 'a', 'xxxUNK', 'xxxUNK', ',', 'its', 'xxxUNK', 'my', 'ego', '!', '.', 'i', 'now', 'realise', ',', 'i`m', 'not', 'all', 'that', 'great', '.', 'and', 'i`m', 'ok', 'with', 'that', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.80', '0.00', 96, 'i`m']\n",
      "\t['0.01', '0.00', 9, 'going']\n",
      "\t['0.03', '0.00', 150, 'into']\n",
      "\t['0.01', '0.00', 142, 'a']\n",
      "\t['0.01', '0.00', 1, 'spiritual']\n",
      "\t['0.00', '0.00', 1, 'stagnentation']\n",
      "\t['0.00', '0.00', 5, ',']\n",
      "\t['0.00', '0.00', 213, 'its']\n",
      "\t['0.00', '0.00', 1, 'exploding']\n",
      "\t['0.01', '0.00', 24, 'my']\n",
      "\t['0.01', '0.00', 5906, 'ego']\n",
      "\t['0.00', '0.00', 22, '!']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.01', '0.00', 7, 'i']\n",
      "\t['0.00', '0.00', 229, 'now']\n",
      "\t['0.01', '0.00', 2825, 'realise']\n",
      "\t['0.01', '0.00', 5, ',']\n",
      "\t['0.00', '0.00', 96, 'i`m']\n",
      "\t['0.01', '0.00', 149, 'not']\n",
      "\t['0.00', '0.00', 66, 'all']\n",
      "\t['0.00', '0.00', 82, 'that']\n",
      "\t['0.00', '0.00', 812, 'great']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.01', '0.00', 68, 'and']\n",
      "\t['0.00', '0.00', 96, 'i`m']\n",
      "\t['0.01', '0.00', 458, 'ok']\n",
      "\t['0.01', '0.00', 278, 'with']\n",
      "\t['0.01', '0.01', 82, 'that']\n",
      "\t['0.01', '0.98', 28, '.']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    spot_check(i, mode=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['start'] = pred_starts_test.argmax(axis=1)\n",
    "test_df['stop'] = pred_stops_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejoin(x, s, e):\n",
    "    return \" \".join(x[s:e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['selected_text'] = [rejoin(i,j,k+1) for i,j,k in zip(test_df['text_mod'], test_df['start'], test_df['stop'] )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>its at 3 am, im very tired but i can`t sleep  but i try it</td>\n",
       "      <td>negative</td>\n",
       "      <td>its at 3 am , im very tired but i can`t sleep but i try it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>All alone in this old house again.  Thanks for the net which keeps me alive and kicking! Whoever invented the net, i wanna kiss your hair!</td>\n",
       "      <td>positive</td>\n",
       "      <td>thanks for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531</th>\n",
       "      <td>I know what you mean. My little dog is sinking into depression... he wants to move someplace tropical</td>\n",
       "      <td>negative</td>\n",
       "      <td>. .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>_sutra what is your next youtube video gonna be about? I love your videos!</td>\n",
       "      <td>positive</td>\n",
       "      <td>your videos !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>http://twitpic.com/4woj2 - omgssh  ang cute ng bby.!</td>\n",
       "      <td>positive</td>\n",
       "      <td>omgssh ang cute ng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                            text  \\\n",
       "3529  its at 3 am, im very tired but i can`t sleep  but i try it                                                                                   \n",
       "3530  All alone in this old house again.  Thanks for the net which keeps me alive and kicking! Whoever invented the net, i wanna kiss your hair!   \n",
       "3531   I know what you mean. My little dog is sinking into depression... he wants to move someplace tropical                                       \n",
       "3532  _sutra what is your next youtube video gonna be about? I love your videos!                                                                   \n",
       "3533   http://twitpic.com/4woj2 - omgssh  ang cute ng bby.!                                                                                        \n",
       "\n",
       "     sentiment                                               selected_text  \n",
       "3529  negative  its at 3 am , im very tired but i can`t sleep but i try it  \n",
       "3530  positive  thanks for                                                  \n",
       "3531  negative  . .                                                         \n",
       "3532  positive  your videos !                                               \n",
       "3533  positive  omgssh ang cute ng                                          "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[[\"text\", \"sentiment\",\"selected_text\"]].tail(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
