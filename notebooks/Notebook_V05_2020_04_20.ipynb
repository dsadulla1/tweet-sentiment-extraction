{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do you need psuedo labels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You might need a token for space itself? start and stop tokens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification model with test as well in train? Will increase the vocab size as well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * https://www.tensorflow.org/tutorials/text/transformer\n",
    "# * https://pytorch.org/tutorials/beginner/transformer_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTROLS\n",
    "MODEL_PREFIX = \"V05\"\n",
    "MODEL_NUMBER = MODEL_PREFIX[-2:]\n",
    "TRAIN_SPLIT_RATIO = 0.8\n",
    "\n",
    "DROPOUT = 0.1\n",
    "MIN_LR = 1e-5\n",
    "MAX_LR = 1e-3\n",
    "BATCH_SIZE = 1024\n",
    "PREDICT_BATCH_SIZE = 2048\n",
    "STEP_SIZE = 20\n",
    "CLR_METHOD = \"triangular\" # exp_range, triangular, triangular2\n",
    "NUM_EPOCHS = 40\n",
    "MODE = \"binary\" # \"binary\", \"categorical\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler, LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import pickle, os, sys, re\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, LSTM, Embedding, Dense, concatenate, MaxPooling2D, Softmax, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout, Reshape, Activation, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def signaltonoise(a, axis=0, ddof=0):\n",
    "    a = np.asanyarray(a)\n",
    "    m = a.mean(axis)\n",
    "    sd = a.std(axis=axis, ddof=ddof)\n",
    "    return np.where(sd == 0, 0, m/sd)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import *\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "class CyclicLR(Callback):\n",
    "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
    "    The method cycles the learning rate between two boundaries with\n",
    "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
    "    The amplitude of the cycle can be scaled on a per-iteration or \n",
    "    per-cycle basis.\n",
    "    This class has three built-in policies, as put forth in the paper.\n",
    "    \"triangular\":\n",
    "        A basic triangular cycle w/ no amplitude scaling.\n",
    "    \"triangular2\":\n",
    "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
    "    \"exp_range\":\n",
    "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n",
    "        cycle iteration.\n",
    "    For more detail, please see paper.\n",
    "    \n",
    "    # Example\n",
    "        ```python\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```\n",
    "    \n",
    "    Class also supports custom scaling functions:\n",
    "        ```python\n",
    "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., scale_fn=clr_fn,\n",
    "                                scale_mode='cycle')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```    \n",
    "    # Arguments\n",
    "        base_lr: initial learning rate which is the\n",
    "            lower boundary in the cycle.\n",
    "        max_lr: upper boundary in the cycle. Functionally,\n",
    "            it defines the cycle amplitude (max_lr - base_lr).\n",
    "            The lr at any cycle is the sum of base_lr\n",
    "            and some scaling of the amplitude; therefore \n",
    "            max_lr may not actually be reached depending on\n",
    "            scaling function.\n",
    "        step_size: number of training iterations per\n",
    "            half cycle. Authors suggest setting step_size\n",
    "            2-8 x training iterations in epoch.\n",
    "        mode: one of {triangular, triangular2, exp_range}.\n",
    "            Default 'triangular'.\n",
    "            Values correspond to policies detailed above.\n",
    "            If scale_fn is not None, this argument is ignored.\n",
    "        gamma: constant in 'exp_range' scaling function:\n",
    "            gamma**(cycle iterations)\n",
    "        scale_fn: Custom scaling policy defined by a single\n",
    "            argument lambda function, where \n",
    "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
    "            mode paramater is ignored \n",
    "        scale_mode: {'cycle', 'iterations'}.\n",
    "            Defines whether scale_fn is evaluated on \n",
    "            cycle number or cycle iterations (training\n",
    "            iterations since start of cycle). Default is 'cycle'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma**(x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        \"\"\"Resets cycle iterations.\n",
    "        Optional boundary/step size adjustment.\n",
    "        \"\"\"\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "        \n",
    "    def clr(self):\n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
    "            \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\deepak\\miniconda3\\envs\\dev\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "np.random.seed(54321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0  1\n",
      "textID         object  0\n",
      "text           object  1\n",
      "selected_text  object  1\n",
      "sentiment      object  0\n",
      "(27481, 4)\n",
      "{'textID': 27481, 'text': 27480, 'selected_text': 22463, 'sentiment': 3}\n",
      "            textID                  text selected_text sentiment\n",
      "count   27481       27480                 27480         27481   \n",
      "unique  27481       27480                 22463         3       \n",
      "top     91137283e8  @_erica I know right  good          neutral \n",
      "freq    1           1                     199           11118   \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on the releases we already bought</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID  \\\n",
       "0  cb774db0d1   \n",
       "1  549e992a42   \n",
       "2  088c60f138   \n",
       "3  9642c003ef   \n",
       "4  358bd9e861   \n",
       "\n",
       "                                                                          text  \\\n",
       "0   I`d have responded, if I were going                                          \n",
       "1   Sooo SAD I will miss you here in San Diego!!!                                \n",
       "2  my boss is bullying me...                                                     \n",
       "3   what interview! leave me alone                                               \n",
       "4   Sons of ****, why couldn`t they put them on the releases we already bought   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going  neutral   \n",
       "1  Sooo SAD                             negative  \n",
       "2  bullying me                          negative  \n",
       "3  leave me alone                       negative  \n",
       "4  Sons of ****,                        negative  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\",\n",
    "                 dtype={\"time\":np.float64,\"signal\":np.float64,\"open_channels\":np.int16},\n",
    "                 encoding=\"utf8\")\n",
    "\n",
    "df2 = pd.read_csv(\"../data/train.csv\",\n",
    "                 dtype={\"time\":np.float64,\"signal\":np.float64,\"open_channels\":np.int16})\n",
    "\n",
    "print(pd.concat((df.dtypes, df.isna().sum()), axis=1))\n",
    "print(df.shape)\n",
    "\n",
    "# Counts of various columns\n",
    "print({i:df[i].nunique() for i in df.columns})\n",
    "print(df.describe()) #.astype(int)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0  1\n",
      "textID     object  0\n",
      "text       object  0\n",
      "sentiment  object  0\n",
      "(3534, 3)\n",
      "{'textID': 3534, 'text': 3534, 'sentiment': 3}\n",
      "            textID  \\\n",
      "count   3534         \n",
      "unique  3534         \n",
      "top     38148a3e98   \n",
      "freq    1            \n",
      "\n",
      "                                                                                               text  \\\n",
      "count   3534                                                                                          \n",
      "unique  3534                                                                                          \n",
      "top      yeah, so quick! And I`m using the 5mm addi`s I bought on Sat and it makes it even smoother   \n",
      "freq    1                                                                                             \n",
      "\n",
      "       sentiment  \n",
      "count   3534      \n",
      "unique  3         \n",
      "top     neutral   \n",
      "freq    1430      \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to quit her company, such a shame!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID  \\\n",
       "0  f87dea47db   \n",
       "1  96d74cb729   \n",
       "2  eee518ae67   \n",
       "3  01082688c6   \n",
       "4  33987a8ee5   \n",
       "\n",
       "                                                                                                      text  \\\n",
       "0  Last session of the day  http://twitpic.com/67ezh                                                         \n",
       "1   Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).   \n",
       "2  Recession hit Veronique Branquinho, she has to quit her company, such a shame!                            \n",
       "3   happy bday!                                                                                              \n",
       "4   http://twitpic.com/4w75p - I like it!!                                                                   \n",
       "\n",
       "  sentiment  \n",
       "0  neutral   \n",
       "1  positive  \n",
       "2  negative  \n",
       "3  positive  \n",
       "4  positive  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"../data/test.csv\", dtype={\"time\":np.float64,\"signal\":np.float64})\n",
    "print(pd.concat((test_df.dtypes, test_df.isna().sum()), axis=1))\n",
    "print(test_df.shape)\n",
    "\n",
    "# Counts of various columns\n",
    "print({i:test_df[i].nunique() for i in test_df.columns})\n",
    "print(test_df.describe())\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>c77717b103</td>\n",
       "      <td>I love to! But I`m only available from 5pm.  and where dear? Would love to help  convert her vids.ï¿½</td>\n",
       "      <td>I love to!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>28dbada620</td>\n",
       "      <td>*phew*  Will make a note in case anyone else runs into the same issueï¿½</td>\n",
       "      <td>*phew*  Will make a note in case anyone else runs into the same issueï¿½</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>1a88179ebb</td>\n",
       "      <td>I love mine, too . happy motherï¿½s day to your mom , John Taylor  . much love to you, too .</td>\n",
       "      <td>I love mine, too . happy motherï¿½s day to your mom , John Taylor  . much love to you, too</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>532d442071</td>\n",
       "      <td>meeting just in time that iï¿½m trying to win something  prize`s friday!</td>\n",
       "      <td>meeting just in time that iï¿½m trying to win something  prize`s friday!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>2617b9c9e3</td>\n",
       "      <td>Just got confirmed that itï¿½s pizza-time with some ex co-workers on friday...looking forward to it</td>\n",
       "      <td>looking forward to it</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26472</th>\n",
       "      <td>68a56eca92</td>\n",
       "      <td>..uuuups today is mother day???....sh***....iï¿½ve forgot it, my work doesnï¿½t have a end *sigh*....thank you for remind it</td>\n",
       "      <td>..uuuups today is mother day???....sh***....iï¿½ve forgot it, my work doesnï¿½t have a end *sigh*....thank you for remind it</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26745</th>\n",
       "      <td>bfe8f0ab98</td>\n",
       "      <td>i canï¿½t choose one  i love all the songs on LV&amp;TT;bt if u like... Read More: http://is.gd/JkVF</td>\n",
       "      <td>i love all the songs</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26882</th>\n",
       "      <td>336b9cfc93</td>\n",
       "      <td>XDXDXD you crazy little thing why didnï¿½t you get off the train and hug me????</td>\n",
       "      <td>DXD you crazy little thing why didnï¿½t you get off the train and hug me???</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27087</th>\n",
       "      <td>c2c5b285b9</td>\n",
       "      <td>Shared Kim Hï¿½ltermand - Portfolio: Shared by Kaare Finally a dane  IÂ´ve got the honor to do the amazing.. http://tinyurl.com/coypsl</td>\n",
       "      <td>honor</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27318</th>\n",
       "      <td>d370238b6b</td>\n",
       "      <td>just saw an advert for ATTICS TO EDEN on tv  out today and only ï¿½9.99 from HMV...so I`m not sure why I had to pay ï¿½13 at HMV...never mind</td>\n",
       "      <td>just saw an advert for ATTICS TO EDEN on tv  out today and only ï¿½9.99 from HMV...so I`m not sure why I had to pay ï¿½13 at HMV...never mind</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID  \\\n",
       "44     c77717b103   \n",
       "192    28dbada620   \n",
       "432    1a88179ebb   \n",
       "645    532d442071   \n",
       "854    2617b9c9e3   \n",
       "...           ...   \n",
       "26472  68a56eca92   \n",
       "26745  bfe8f0ab98   \n",
       "26882  336b9cfc93   \n",
       "27087  c2c5b285b9   \n",
       "27318  d370238b6b   \n",
       "\n",
       "                                                                                                                                                text  \\\n",
       "44      I love to! But I`m only available from 5pm.  and where dear? Would love to help  convert her vids.ï¿½                                          \n",
       "192     *phew*  Will make a note in case anyone else runs into the same issueï¿½                                                                       \n",
       "432     I love mine, too . happy motherï¿½s day to your mom , John Taylor  . much love to you, too .                                                   \n",
       "645    meeting just in time that iï¿½m trying to win something  prize`s friday!                                                                        \n",
       "854    Just got confirmed that itï¿½s pizza-time with some ex co-workers on friday...looking forward to it                                             \n",
       "...                                                                                                    ...                                             \n",
       "26472   ..uuuups today is mother day???....sh***....iï¿½ve forgot it, my work doesnï¿½t have a end *sigh*....thank you for remind it                   \n",
       "26745   i canï¿½t choose one  i love all the songs on LV&TT;bt if u like... Read More: http://is.gd/JkVF                                               \n",
       "26882     XDXDXD you crazy little thing why didnï¿½t you get off the train and hug me????                                                              \n",
       "27087  Shared Kim Hï¿½ltermand - Portfolio: Shared by Kaare Finally a dane  IÂ´ve got the honor to do the amazing.. http://tinyurl.com/coypsl          \n",
       "27318  just saw an advert for ATTICS TO EDEN on tv  out today and only ï¿½9.99 from HMV...so I`m not sure why I had to pay ï¿½13 at HMV...never mind   \n",
       "\n",
       "                                                                                                                                       selected_text  \\\n",
       "44     I love to!                                                                                                                                      \n",
       "192    *phew*  Will make a note in case anyone else runs into the same issueï¿½                                                                        \n",
       "432    I love mine, too . happy motherï¿½s day to your mom , John Taylor  . much love to you, too                                                      \n",
       "645    meeting just in time that iï¿½m trying to win something  prize`s friday!                                                                        \n",
       "854    looking forward to it                                                                                                                           \n",
       "...                      ...                                                                                                                           \n",
       "26472  ..uuuups today is mother day???....sh***....iï¿½ve forgot it, my work doesnï¿½t have a end *sigh*....thank you for remind it                    \n",
       "26745  i love all the songs                                                                                                                            \n",
       "26882  DXD you crazy little thing why didnï¿½t you get off the train and hug me???                                                                     \n",
       "27087  honor                                                                                                                                           \n",
       "27318  just saw an advert for ATTICS TO EDEN on tv  out today and only ï¿½9.99 from HMV...so I`m not sure why I had to pay ï¿½13 at HMV...never mind   \n",
       "\n",
       "      sentiment  \n",
       "44     positive  \n",
       "192    neutral   \n",
       "432    positive  \n",
       "645    neutral   \n",
       "854    positive  \n",
       "...         ...  \n",
       "26472  neutral   \n",
       "26745  positive  \n",
       "26882  neutral   \n",
       "27087  positive  \n",
       "27318  neutral   \n",
       "\n",
       "[155 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df2['text'].astype('str').apply(lambda x : len(re.findall(pattern=\"ï¿½\", string=x))>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>7223fdccc2</td>\n",
       "      <td>tikcets are only ï¿½91...each...BUT I SO WANT TO GO</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>43ad351369</td>\n",
       "      <td>AHHH - Whatchu talkinï¿½ baby?  HAHAHA I canï¿½t believe youu:O heh, actually I can. Life is worth taking risks... http://tumblr.com/xs81qy54s</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>f5e9c0eef2</td>\n",
       "      <td>I would vote for you Miley but I live in Ireland  You`ll be fine  Good luck! Slï¿½n!(bye in irish ) Sorcha xxxx</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>6e60ed6d59</td>\n",
       "      <td>So disappointed about the talent lineup for 'Reventï¿½n Super Estrella 2009'...hmm...Have the feeling I won`t get tix this time around.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>fc6128f4e5</td>\n",
       "      <td>ok i just spent like ï¿½50 on soundtracks, a galaxy class starship and EVE online. sigh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>440e8fc447</td>\n",
       "      <td>Hockey was so fukinï¿½ good  **** you hole! xD</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>2f8250d0df</td>\n",
       "      <td>the day goes on and on...i think im gonna write a song about it! still thinking itï¿½s impossible for me to get a true friend  why????</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>9d187014d5</td>\n",
       "      <td>Good morning... Iï¿½m soooo tierd</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>a9da40eedd</td>\n",
       "      <td>Oh, final msg - Why didn`t you review my boardgame Bookchaseï¿½ when you were on telly? We didn`t even get a nice letter..</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>e162b84433</td>\n",
       "      <td>Start of diet today  I think I have to face I will never get back down to 77kilos (unless I cut a leg off)ï¿½</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>96e77388b8</td>\n",
       "      <td>_Guy Me neither  But itï¿½s getting better</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>9a2689017d</td>\n",
       "      <td>Won a diamond for my compï¿½tition  , yaayy tomorow its the DIAMOND DANCE OFF !! Were the best  .. Still in montrï¿½al !!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3505</th>\n",
       "      <td>f66bda14c6</td>\n",
       "      <td>ï¿½ï¿½We are ready for the new generation!!...Oh yeah...We are a Backstreet fans and we are proud about it!!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID  \\\n",
       "145   7223fdccc2   \n",
       "618   43ad351369   \n",
       "800   f5e9c0eef2   \n",
       "1150  6e60ed6d59   \n",
       "1644  fc6128f4e5   \n",
       "1730  440e8fc447   \n",
       "1857  2f8250d0df   \n",
       "1864  9d187014d5   \n",
       "1976  a9da40eedd   \n",
       "1990  e162b84433   \n",
       "2100  96e77388b8   \n",
       "2124  9a2689017d   \n",
       "3505  f66bda14c6   \n",
       "\n",
       "                                                                                                                                                text  \\\n",
       "145   tikcets are only ï¿½91...each...BUT I SO WANT TO GO                                                                                              \n",
       "618   AHHH - Whatchu talkinï¿½ baby?  HAHAHA I canï¿½t believe youu:O heh, actually I can. Life is worth taking risks... http://tumblr.com/xs81qy54s   \n",
       "800    I would vote for you Miley but I live in Ireland  You`ll be fine  Good luck! Slï¿½n!(bye in irish ) Sorcha xxxx                                 \n",
       "1150  So disappointed about the talent lineup for 'Reventï¿½n Super Estrella 2009'...hmm...Have the feeling I won`t get tix this time around.          \n",
       "1644  ok i just spent like ï¿½50 on soundtracks, a galaxy class starship and EVE online. sigh                                                          \n",
       "1730  Hockey was so fukinï¿½ good  **** you hole! xD                                                                                                   \n",
       "1857  the day goes on and on...i think im gonna write a song about it! still thinking itï¿½s impossible for me to get a true friend  why????           \n",
       "1864  Good morning... Iï¿½m soooo tierd                                                                                                                \n",
       "1976   Oh, final msg - Why didn`t you review my boardgame Bookchaseï¿½ when you were on telly? We didn`t even get a nice letter..                      \n",
       "1990  Start of diet today  I think I have to face I will never get back down to 77kilos (unless I cut a leg off)ï¿½                                    \n",
       "2100  _Guy Me neither  But itï¿½s getting better                                                                                                       \n",
       "2124  Won a diamond for my compï¿½tition  , yaayy tomorow its the DIAMOND DANCE OFF !! Were the best  .. Still in montrï¿½al !!                        \n",
       "3505  ï¿½ï¿½We are ready for the new generation!!...Oh yeah...We are a Backstreet fans and we are proud about it!!                                     \n",
       "\n",
       "     sentiment  \n",
       "145   positive  \n",
       "618   positive  \n",
       "800   positive  \n",
       "1150  negative  \n",
       "1644  neutral   \n",
       "1730  neutral   \n",
       "1857  negative  \n",
       "1864  neutral   \n",
       "1976  negative  \n",
       "1990  negative  \n",
       "2100  positive  \n",
       "2124  positive  \n",
       "3505  positive  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df['text'].astype('str').apply(lambda x : len(re.findall(pattern=\"ï¿½\", string=x))>0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment count in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>7781</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>11117</td>\n",
       "      <td>1430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>8582</td>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text  text\n",
       "sentiment             \n",
       "negative   7781   1001\n",
       "neutral    11117  1430\n",
       "positive   8582   1103"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df.groupby(\"sentiment\")[[\"text\"]].count(), test_df.groupby(\"sentiment\")[[\"text\"]].count()], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalous_idxs = [27302, 18, 27, 149, 160, 251, 295, 309, 398, 458, 492, 581, 637, 639, 678, 757, 787, 863, 1077, 1096, 1157, 1376, 1393, 1420, 1515, 1518, 1693, 1696, 1728, 1754, 1798, 1929, 2008, 2056, 2124, 2136, 2187, 2213, 2324, 2364, 2392, 2401, 2439, 2440, 2785, 2787, 2986, 3319, 3363, 3369, 3399, 3400, 3411, 3473, 4148, 4369, 4404, 4576, 4639, 4654, 4747, 5167, 5189, 5196, 5213, 5241, 5358, 5361, 5510, 5530, 5560, 5687, 5697, 5712, 5751, 6113, 6131, 6230, 6261, 6360, 6528, 6540, 6627, 6686, 6724, 6759, 6804, 6859, 6948, 6987, 7024, 7040, 7331, 7409, 7438, 7442, 7506, 7513, 7530, 7642, 7663, 7818, 7837, 8005, 8049, 8052, 8153, 8161, 8235, 8249, 8497, 8569, 8594, 8624, 8691, 8706, 8720, 8749, 8803, 8999, 9113, 9190, 9374, 9442, 9449, 9496, 9535, 9539, 9594, 9631, 9696, 9882, 10007, 10050, 10070, 10164, 10293, 10411, 10492, 10508, 10521, 10530, 10672, 10747, 10813, 10935, 10968, 10981, 10986, 11176, 11228, 11300, 11323, 11349, 11353, 11480, 11588, 11643, 11698, 11706, 11745, 11861, 11963, 11985, 12138, 12205, 12283, 12356, 12397, 12416, 12474, 12522, 12563, 12576, 12662, 12736, 12803, 12843, 12972, 12977, 13004, 13124, 13237, 13365, 13379, 13605, 13637, 13704, 13796, 13803, 13907, 13965, 13975, 14058, 14213, 14230, 14257, 14275, 14571, 14611, 14779, 14855, 14880, 15010, 15056, 15165, 15207, 15372, 15462, 15528, 15562, 15660, 15998, 16117, 16175, 16352, 16372, 16391, 16423, 16493, 16500, 16570, 16643, 16665, 16720, 16726, 16876, 16915, 17013, 17029, 17062, 17160, 17404, 17412, 17417, 17513, 17530, 17531, 17600, 17627, 17729, 17762, 17893, 17945, 17986, 18003, 18086, 18099, 18314, 18342, 18355, 18375, 18536, 18616, 18778, 18862, 18908, 18912, 18930, 18997, 19028, 19057, 19162, 19213, 19239, 19274, 19279, 19405, 19431, 19481, 19486, 19536, 19562, 19634, 19651, 19754, 19963, 19985, 19988, 20014, 20216, 20299, 20394, 20440, 20451, 20506, 20644, 20865, 20895, 21013, 21018, 21114, 21205, 21316, 21331, 21349, 21376, 21556, 21737, 21755, 21876, 21923, 22117, 22205, 22234, 22280, 22363, 22365, 22378, 22383, 22387, 22536, 22588, 22717, 22744, 22768, 22769, 22836, 22864, 22938, 23081, 23108, 23145, 23199, 23205, 23290, 23352, 23372, 23528, 23617, 23630, 23680, 23690, 23733, 23746, 23784, 23842, 23959, 24026, 24046, 24274, 24378, 24476, 24490, 24502, 24504, 24597, 24682, 24753, 24766, 24886, 24909, 24996, 25104, 25267, 25338, 25380, 25422, 25446, 25486, 25499, 25601, 25691, 25712, 25732, 25760, 25908, 25947, 25996, 26017, 26025, 26256, 26268, 26625, 26643, 26677, 26687, 26762, 26781, 26830, 26870, 26882, 26927, 27067, 27121, 27209, 27229, 27280, 27349, 27362, 27386, 27401]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(~df.index.isin(anomalous_idxs)) & (~df.selected_text.isna())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"original_index\"] = df.index\n",
    "test_df[\"original_index\"] = test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment_code\"] = df[\"sentiment\"].astype(\"category\")\n",
    "X_sentiments = df[\"sentiment_code\"].cat.codes.values\n",
    "\n",
    "test_df[\"sentiment_code\"] = test_df[\"sentiment\"].astype(\"category\")\n",
    "X_sentiments_test = test_df[\"sentiment_code\"].cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "df[\"selected_text\"] = df[\"selected_text\"].astype(str)\n",
    "test_df[\"text\"] = test_df[\"text\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_special_tokens(x, is_target=False):\n",
    "    x = x.lower()\n",
    "    x = re.sub('([!\"#$%&()*+,-./:;<=>?@[\\\\]^_{|}~\\t\\n])', ' \\\\1 ', x) # Not including ` here since used in couldn`t isn`t\n",
    "    if is_target:\n",
    "        x = x.split(\" \")\n",
    "    else:\n",
    "        x = [\"xxxSTART\"] + x.split(\" \") + [\"xxxEND\"]\n",
    "    x = \" \".join(x)\n",
    "    x = re.sub(' +', ' ', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(lambda x: add_special_tokens(x, is_target=False))\n",
    "df[\"selected_text\"] = df[\"selected_text\"].apply(lambda x: add_special_tokens(x, is_target=True))\n",
    "test_df[\"text\"] = test_df[\"text\"].apply(lambda x: add_special_tokens(x, is_target=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "tokenizer = nlp.Defaults.create_tokenizer(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_t'] = df['text'].apply(lambda x: tokenizer(x))\n",
    "df['selected_text_t'] = df['selected_text'].apply(lambda x: tokenizer(x))\n",
    "test_df['text_t'] = test_df['text'].apply(lambda x: tokenizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27088 27088 3534\n"
     ]
    }
   ],
   "source": [
    "X_words = [[word.orth_ if not word.like_url else 'xxxURL' for word in row] for row in df['text_t']]\n",
    "Y_words = [[word.orth_ if not word.like_url else 'xxxURL' for word in row] for row in df['selected_text_t']]\n",
    "X_test_words = [[word.orth_ if not word.like_url else 'xxxURL' for word in row] for row in test_df['text_t']]\n",
    "\n",
    "print(len(X_words), len(Y_words), len(X_test_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 34974),\n",
       " ('xxxSTART', 27088),\n",
       " ('xxxEND', 27088),\n",
       " ('!', 15031),\n",
       " ('i', 14274),\n",
       " ('to', 9881),\n",
       " ('the', 8897),\n",
       " (',', 8374),\n",
       " ('a', 6714),\n",
       " ('my', 5487)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "word_counts = Counter([j for i in X_words for j in i])\n",
    "\n",
    "X_unique_tokens = len(word_counts)\n",
    "word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_words = set(sorted([j for i in X_words + X_test_words for j in i]))\n",
    "Y_list_of_words = set(sorted([j for i in Y_words for j in i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_itos = {i+2:j for i,j in enumerate(list_of_words)}\n",
    "vocab_stoi = {j:i+2 for i,j in enumerate(list_of_words)}\n",
    "\n",
    "vocab_stoi[\"xxxUNK\"] = 1\n",
    "vocab_itos[1] = \"xxxUNK\"\n",
    "\n",
    "vocab_stoi[\"xxxNone\"] = 0\n",
    "vocab_itos[0] = \"xxxNone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_vocab(vocab, word):\n",
    "    try:\n",
    "        value = vocab[word]\n",
    "    except KeyError as k:\n",
    "        value = vocab_stoi[\"xxxUNK\"]\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[get_from_vocab(vocab_stoi,j) for j in i] for i in X_words]\n",
    "Y = [[get_from_vocab(vocab_stoi,j) for j in i] for i in Y_words]\n",
    "Y2 = [[1 if j in y else 0 for j in X[i]] for i,y in enumerate(Y)]\n",
    "X_test = [[get_from_vocab(vocab_stoi,j) for j in i] for i in X_test_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 108\n"
     ]
    }
   ],
   "source": [
    "max_len = max([len(i) for i in X])\n",
    "max_len_y = max([len(i) for i in Y2])\n",
    "print(max_len, max_len_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28226\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(vocab_stoi)\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27088 21670 5418 27088\n"
     ]
    }
   ],
   "source": [
    "idx = [i for i in np.arange(len(Y))]\n",
    "np.random.shuffle(idx)\n",
    "train_idx, val_idx = idx[:round(TRAIN_SPLIT_RATIO*len(Y))], idx[round(TRAIN_SPLIT_RATIO * len(Y)):]\n",
    "\n",
    "print(len(idx), len(train_idx), len(val_idx), len(train_idx) + len(val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21670, 5418, 21670, 5418, 21670, 5418, 21670, 5418]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val = [X[i] for i in train_idx], [X[i] for i in val_idx]\n",
    "X_sentiments_train, X_sentiments_val = [X_sentiments[i] for i in train_idx], [X_sentiments[i] for i in val_idx]\n",
    "X_sentiments_train, X_sentiments_val = np.array(X_sentiments_train, dtype=np.int32), np.array(X_sentiments_val, dtype=np.int32)\n",
    "Y_train, Y_val = [Y[i] for i in train_idx], [Y[i] for i in val_idx]\n",
    "Y2_train, Y2_val = [Y2[i] for i in train_idx], [Y2[i] for i in val_idx]\n",
    "\n",
    "[len(i) for i in [X_train, X_val, X_sentiments_train, X_sentiments_val, Y_train, Y_val, Y2_train, Y2_val]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=max_len, padding=\"post\")\n",
    "Y_train = pad_sequences(Y_train, maxlen=max_len, padding=\"post\")\n",
    "Y2_train = pad_sequences(Y2_train, maxlen=max_len, padding=\"post\")\n",
    "\n",
    "X_val = pad_sequences(X_val, maxlen=max_len, padding=\"post\")\n",
    "Y_val = pad_sequences(Y_val, maxlen=max_len, padding=\"post\")\n",
    "Y2_val = pad_sequences(Y2_val, maxlen=max_len, padding=\"post\")\n",
    "\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21670, 108) (21670,) (5418, 108) (5418,) (3534, 108)\n",
      "(21670, 108) (21670, 108) (5418, 108) (5418, 108)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_sentiments_train.shape, X_val.shape, X_sentiments_val.shape, X_test.shape)\n",
    "print(Y_train.shape, Y2_train.shape, Y_val.shape, Y2_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for zero input vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_x_train = X_train.sum(axis=1) > 0\n",
    "X_train, Y_train = X_train[keep_x_train], Y_train[keep_x_train]\n",
    "X_sentiments_train, Y2_train = X_sentiments_train[keep_x_train], Y2_train[keep_x_train]\n",
    "\n",
    "keep_x_val = X_val.sum(axis=1) > 0\n",
    "X_val, Y_val = X_val[keep_x_val], Y_val[keep_x_val]\n",
    "X_sentiments_val, Y2_val = X_sentiments_val[keep_x_val], Y2_val[keep_x_val]\n",
    "\n",
    "keep_x_test = X_test.sum(axis=1) > 0\n",
    "test_df[\"kept\"] = keep_x_test\n",
    "X_test, X_sentiments_test = X_test[keep_x_test], X_sentiments_test[keep_x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 28753\n",
      "0 28889\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax([X_train.sum(axis=1)==0]), np.min([X_train.sum(axis=1)]))\n",
    "print(np.argmax([X_val.sum(axis=1)==0]), np.min([X_val.sum(axis=1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentiments = Input((max_len))\n",
    "\n",
    "emb_sentiments = Embedding(input_dim=VOCAB_SIZE, input_length=max_len, output_dim=32, mask_zero=True)(input_sentiments)\n",
    "\n",
    "sentiments = Bidirectional(LSTM(16, activation='relu', return_sequences=True))(emb_sentiments)\n",
    "sentiments = BatchNormalization()(sentiments)\n",
    "sentiments = Dropout(DROPOUT)(sentiments)\n",
    "\n",
    "sentiments = Bidirectional(LSTM(16, activation='relu', return_sequences=True))(sentiments)\n",
    "sentiments = BatchNormalization()(sentiments)\n",
    "sentiments = Dropout(DROPOUT)(sentiments)\n",
    "\n",
    "sentiments = Flatten()(sentiments)\n",
    "\n",
    "sentiments = Dense(16, activation=\"relu\")(sentiments)\n",
    "sentiments = BatchNormalization()(sentiments)\n",
    "\n",
    "output_sentiments = Dense(3, activation=\"softmax\")(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 108)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 108, 32)           903232    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 108, 32)           6272      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 108, 32)           128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 108, 32)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 108, 32)           6272      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 108, 32)           128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 108, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                55312     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 971,459\n",
      "Trainable params: 971,299\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_sentiments = Model(input_sentiments, output_sentiments)\n",
    "model_sentiments.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_sentiments = Adam(learning_rate=MIN_LR)\n",
    "\n",
    "model_sentiments.compile(loss='sparse_categorical_crossentropy',\n",
    "                         optimizer=adam_sentiments, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks\n",
    "mcp_sentiments = ModelCheckpoint(filepath=\"../results/SentimentModel_\"+MODEL_PREFIX+\"Checkpoint.h5\",\n",
    "                                 monitor='val_loss',\n",
    "                                 mode=\"auto\",\n",
    "                                 save_weights_only=False,\n",
    "                                 save_best_only=True)\n",
    "\n",
    "clr_sentiments = CyclicLR(mode=CLR_METHOD,\n",
    "                          base_lr=MIN_LR,\n",
    "                          max_lr=MAX_LR,\n",
    "                          step_size= STEP_SIZE * (np.concatenate((X_train,\n",
    "                                                                  X_test), axis=0).shape[0] // BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25204 samples, validate on 5418 samples\n",
      "Epoch 1/200\n",
      "25204/25204 [==============================] - 22s 861us/sample - loss: 1.6504 - accuracy: 0.3289 - val_loss: 1.1046 - val_accuracy: 0.2757\n",
      "Epoch 2/200\n",
      "25204/25204 [==============================] - 15s 591us/sample - loss: 1.3581 - accuracy: 0.3609 - val_loss: 1.1097 - val_accuracy: 0.2757\n",
      "Epoch 3/200\n",
      "25204/25204 [==============================] - 16s 618us/sample - loss: 1.1858 - accuracy: 0.3845 - val_loss: 1.1070 - val_accuracy: 0.2757\n",
      "Epoch 4/200\n",
      "25204/25204 [==============================] - 15s 580us/sample - loss: 1.1053 - accuracy: 0.4116 - val_loss: 1.1076 - val_accuracy: 0.2879\n",
      "Epoch 5/200\n",
      "25204/25204 [==============================] - 15s 585us/sample - loss: 1.0672 - accuracy: 0.4497 - val_loss: 1.1098 - val_accuracy: 0.3221\n",
      "Epoch 6/200\n",
      "25204/25204 [==============================] - 15s 600us/sample - loss: 1.0217 - accuracy: 0.4884 - val_loss: 1.1032 - val_accuracy: 0.3206\n",
      "Epoch 7/200\n",
      "25204/25204 [==============================] - 16s 625us/sample - loss: 0.9480 - accuracy: 0.5509 - val_loss: 1.0961 - val_accuracy: 0.4011\n",
      "Epoch 8/200\n",
      "25204/25204 [==============================] - 15s 597us/sample - loss: 0.8341 - accuracy: 0.6225 - val_loss: 1.0864 - val_accuracy: 0.4042\n",
      "Epoch 9/200\n",
      "25204/25204 [==============================] - 17s 670us/sample - loss: 0.7068 - accuracy: 0.7083 - val_loss: 1.0804 - val_accuracy: 0.4042\n",
      "Epoch 10/200\n",
      "25204/25204 [==============================] - 16s 644us/sample - loss: 0.5831 - accuracy: 0.7744 - val_loss: 1.0752 - val_accuracy: 0.4042\n",
      "Epoch 11/200\n",
      "25204/25204 [==============================] - 15s 590us/sample - loss: 0.4649 - accuracy: 0.8338 - val_loss: 1.0668 - val_accuracy: 0.4081\n",
      "Epoch 12/200\n",
      "25204/25204 [==============================] - 15s 609us/sample - loss: 0.3681 - accuracy: 0.8739 - val_loss: 1.0618 - val_accuracy: 0.5166\n",
      "Epoch 13/200\n",
      "25204/25204 [==============================] - 16s 626us/sample - loss: 0.2929 - accuracy: 0.9045 - val_loss: 1.0526 - val_accuracy: 0.5000\n",
      "Epoch 14/200\n",
      "25204/25204 [==============================] - 15s 598us/sample - loss: 0.2413 - accuracy: 0.9254 - val_loss: 1.0384 - val_accuracy: 0.4581\n",
      "Epoch 15/200\n",
      "25204/25204 [==============================] - 15s 588us/sample - loss: 0.2092 - accuracy: 0.9360 - val_loss: 1.0187 - val_accuracy: 0.4967\n",
      "Epoch 16/200\n",
      "25204/25204 [==============================] - 15s 600us/sample - loss: 0.1788 - accuracy: 0.9464 - val_loss: 1.0312 - val_accuracy: 0.4228\n",
      "Epoch 17/200\n",
      "25204/25204 [==============================] - 15s 580us/sample - loss: 0.1547 - accuracy: 0.9553 - val_loss: 1.0088 - val_accuracy: 0.4478\n",
      "Epoch 18/200\n",
      "25204/25204 [==============================] - 15s 579us/sample - loss: 0.1392 - accuracy: 0.9597 - val_loss: 1.1074 - val_accuracy: 0.4203\n",
      "Epoch 19/200\n",
      "25204/25204 [==============================] - 15s 596us/sample - loss: 0.1227 - accuracy: 0.9653 - val_loss: 1.0345 - val_accuracy: 0.4585\n",
      "Epoch 20/200\n",
      "25204/25204 [==============================] - 15s 593us/sample - loss: 0.1158 - accuracy: 0.9656 - val_loss: 1.1799 - val_accuracy: 0.4408\n",
      "Epoch 21/200\n",
      "25204/25204 [==============================] - 15s 609us/sample - loss: 0.1063 - accuracy: 0.9691 - val_loss: 1.0944 - val_accuracy: 0.4825\n",
      "Epoch 22/200\n",
      "25204/25204 [==============================] - 15s 597us/sample - loss: 0.0913 - accuracy: 0.9747 - val_loss: 1.1010 - val_accuracy: 0.5094\n",
      "Epoch 23/200\n",
      "25204/25204 [==============================] - 15s 601us/sample - loss: 0.0849 - accuracy: 0.9764 - val_loss: 1.0585 - val_accuracy: 0.5546\n",
      "Epoch 24/200\n",
      "25204/25204 [==============================] - 15s 614us/sample - loss: 0.0746 - accuracy: 0.9793 - val_loss: 1.1131 - val_accuracy: 0.5661\n",
      "Epoch 25/200\n",
      "25204/25204 [==============================] - 15s 593us/sample - loss: 0.0685 - accuracy: 0.9814 - val_loss: 1.0343 - val_accuracy: 0.5987\n",
      "Epoch 26/200\n",
      "25204/25204 [==============================] - 15s 578us/sample - loss: 0.0617 - accuracy: 0.9837 - val_loss: 1.1058 - val_accuracy: 0.6034\n",
      "Epoch 27/200\n",
      "25204/25204 [==============================] - 15s 577us/sample - loss: 0.0563 - accuracy: 0.9850 - val_loss: 1.1176 - val_accuracy: 0.6196\n",
      "Epoch 28/200\n",
      "25204/25204 [==============================] - 15s 608us/sample - loss: 0.0524 - accuracy: 0.9862 - val_loss: 1.2384 - val_accuracy: 0.6122\n",
      "Epoch 29/200\n",
      "25204/25204 [==============================] - 15s 585us/sample - loss: 0.0481 - accuracy: 0.9875 - val_loss: 1.2778 - val_accuracy: 0.6159\n",
      "Epoch 30/200\n",
      "25204/25204 [==============================] - 15s 582us/sample - loss: 0.0455 - accuracy: 0.9879 - val_loss: 1.3613 - val_accuracy: 0.6203\n",
      "Epoch 31/200\n",
      "25204/25204 [==============================] - 15s 577us/sample - loss: 0.0414 - accuracy: 0.9892 - val_loss: 1.3386 - val_accuracy: 0.6292\n",
      "Epoch 32/200\n",
      "25204/25204 [==============================] - 15s 578us/sample - loss: 0.0374 - accuracy: 0.9914 - val_loss: 1.3931 - val_accuracy: 0.6285\n",
      "Epoch 33/200\n",
      "25204/25204 [==============================] - 15s 579us/sample - loss: 0.0364 - accuracy: 0.9910 - val_loss: 1.3990 - val_accuracy: 0.6318\n",
      "Epoch 34/200\n",
      "25204/25204 [==============================] - 15s 600us/sample - loss: 0.0346 - accuracy: 0.9920 - val_loss: 1.4337 - val_accuracy: 0.6340\n",
      "Epoch 35/200\n",
      "25204/25204 [==============================] - 15s 588us/sample - loss: 0.0337 - accuracy: 0.9919 - val_loss: 1.4753 - val_accuracy: 0.6325\n",
      "Epoch 36/200\n",
      "25204/25204 [==============================] - 14s 568us/sample - loss: 0.0315 - accuracy: 0.9927 - val_loss: 1.5291 - val_accuracy: 0.6279\n",
      "Epoch 37/200\n",
      "25204/25204 [==============================] - 15s 584us/sample - loss: 0.0313 - accuracy: 0.9930 - val_loss: 1.5304 - val_accuracy: 0.6329\n",
      "Epoch 38/200\n",
      "25204/25204 [==============================] - 14s 575us/sample - loss: 0.0302 - accuracy: 0.9932 - val_loss: 1.5417 - val_accuracy: 0.6301\n",
      "Epoch 39/200\n",
      "25204/25204 [==============================] - 14s 569us/sample - loss: 0.0286 - accuracy: 0.9937 - val_loss: 1.5516 - val_accuracy: 0.6318\n",
      "Epoch 40/200\n",
      "25204/25204 [==============================] - 14s 569us/sample - loss: 0.0297 - accuracy: 0.9929 - val_loss: 1.5671 - val_accuracy: 0.6318\n",
      "Epoch 41/200\n",
      "25204/25204 [==============================] - 15s 577us/sample - loss: 0.0295 - accuracy: 0.9933 - val_loss: 1.5823 - val_accuracy: 0.6290\n",
      "Epoch 42/200\n",
      "25204/25204 [==============================] - 14s 569us/sample - loss: 0.0298 - accuracy: 0.9931 - val_loss: 1.5997 - val_accuracy: 0.6299\n",
      "Epoch 43/200\n",
      "25204/25204 [==============================] - 14s 574us/sample - loss: 0.0303 - accuracy: 0.9925 - val_loss: 1.6010 - val_accuracy: 0.6283\n",
      "Epoch 44/200\n",
      "25204/25204 [==============================] - 14s 572us/sample - loss: 0.0285 - accuracy: 0.9938 - val_loss: 1.6137 - val_accuracy: 0.6298\n",
      "Epoch 45/200\n",
      "25204/25204 [==============================] - 14s 573us/sample - loss: 0.0300 - accuracy: 0.9925 - val_loss: 1.6547 - val_accuracy: 0.6277\n",
      "Epoch 46/200\n",
      "25204/25204 [==============================] - 14s 560us/sample - loss: 0.0301 - accuracy: 0.9927 - val_loss: 1.6861 - val_accuracy: 0.6235\n",
      "Epoch 47/200\n",
      "25204/25204 [==============================] - 14s 572us/sample - loss: 0.0305 - accuracy: 0.9922 - val_loss: 1.7179 - val_accuracy: 0.6213\n",
      "Epoch 48/200\n",
      "25204/25204 [==============================] - 14s 562us/sample - loss: 0.0309 - accuracy: 0.9915 - val_loss: 1.7287 - val_accuracy: 0.6303\n",
      "Epoch 49/200\n",
      "25204/25204 [==============================] - 14s 566us/sample - loss: 0.0304 - accuracy: 0.9920 - val_loss: 1.7280 - val_accuracy: 0.6203\n",
      "Epoch 50/200\n",
      "25204/25204 [==============================] - 14s 573us/sample - loss: 0.0326 - accuracy: 0.9912 - val_loss: 1.8530 - val_accuracy: 0.6155\n",
      "Epoch 51/200\n",
      "25204/25204 [==============================] - 15s 578us/sample - loss: 0.0333 - accuracy: 0.9909 - val_loss: 1.8565 - val_accuracy: 0.6172\n",
      "Epoch 52/200\n",
      "25204/25204 [==============================] - 15s 582us/sample - loss: 0.0355 - accuracy: 0.9895 - val_loss: 1.8328 - val_accuracy: 0.6170\n",
      "Epoch 53/200\n",
      "25204/25204 [==============================] - 18s 706us/sample - loss: 0.0413 - accuracy: 0.9875 - val_loss: 2.0279 - val_accuracy: 0.6141\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25204/25204 [==============================] - 18s 726us/sample - loss: 0.0424 - accuracy: 0.9868 - val_loss: 1.9325 - val_accuracy: 0.6251\n",
      "Epoch 55/200\n",
      "25204/25204 [==============================] - 17s 675us/sample - loss: 0.0450 - accuracy: 0.9860 - val_loss: 1.9359 - val_accuracy: 0.6229\n",
      "Epoch 56/200\n",
      "25204/25204 [==============================] - 16s 625us/sample - loss: 0.0458 - accuracy: 0.9850 - val_loss: 2.0180 - val_accuracy: 0.6185\n",
      "Epoch 57/200\n",
      "25204/25204 [==============================] - 15s 606us/sample - loss: 0.0489 - accuracy: 0.9842 - val_loss: 2.2431 - val_accuracy: 0.6250\n",
      "Epoch 58/200\n",
      "25204/25204 [==============================] - 15s 599us/sample - loss: 0.0514 - accuracy: 0.9822 - val_loss: 1.9468 - val_accuracy: 0.6266\n",
      "Epoch 59/200\n",
      "25204/25204 [==============================] - 15s 595us/sample - loss: 0.0491 - accuracy: 0.9835 - val_loss: 1.9675 - val_accuracy: 0.6262\n",
      "Epoch 60/200\n",
      "25204/25204 [==============================] - 15s 599us/sample - loss: 0.0427 - accuracy: 0.9863 - val_loss: 2.0000 - val_accuracy: 0.6331\n",
      "Epoch 61/200\n",
      "25204/25204 [==============================] - 15s 580us/sample - loss: 0.0362 - accuracy: 0.9888 - val_loss: 2.0440 - val_accuracy: 0.6279\n",
      "Epoch 62/200\n",
      "25204/25204 [==============================] - 14s 567us/sample - loss: 0.0304 - accuracy: 0.9914 - val_loss: 1.9894 - val_accuracy: 0.6314\n",
      "Epoch 63/200\n",
      "25204/25204 [==============================] - 15s 600us/sample - loss: 0.0262 - accuracy: 0.9922 - val_loss: 1.9969 - val_accuracy: 0.6323\n",
      "Epoch 64/200\n",
      "25204/25204 [==============================] - 15s 600us/sample - loss: 0.0230 - accuracy: 0.9937 - val_loss: 1.9717 - val_accuracy: 0.6270\n",
      "Epoch 65/200\n",
      "25204/25204 [==============================] - 14s 572us/sample - loss: 0.0207 - accuracy: 0.9949 - val_loss: 1.9764 - val_accuracy: 0.6333\n",
      "Epoch 66/200\n",
      "25204/25204 [==============================] - 14s 575us/sample - loss: 0.0186 - accuracy: 0.9953 - val_loss: 1.9929 - val_accuracy: 0.6301\n",
      "Epoch 67/200\n",
      "25204/25204 [==============================] - 14s 575us/sample - loss: 0.0190 - accuracy: 0.9950 - val_loss: 1.9980 - val_accuracy: 0.6292\n",
      "Epoch 68/200\n",
      "25204/25204 [==============================] - 14s 562us/sample - loss: 0.0156 - accuracy: 0.9965 - val_loss: 1.9532 - val_accuracy: 0.6333\n",
      "Epoch 69/200\n",
      "25204/25204 [==============================] - 15s 576us/sample - loss: 0.0152 - accuracy: 0.9963 - val_loss: 1.9796 - val_accuracy: 0.6305\n",
      "Epoch 70/200\n",
      "25204/25204 [==============================] - 14s 566us/sample - loss: 0.0147 - accuracy: 0.9958 - val_loss: 2.0020 - val_accuracy: 0.6296\n",
      "Epoch 71/200\n",
      "25204/25204 [==============================] - 14s 569us/sample - loss: 0.0150 - accuracy: 0.9959 - val_loss: 2.0190 - val_accuracy: 0.6286\n",
      "Epoch 72/200\n",
      "25204/25204 [==============================] - 14s 574us/sample - loss: 0.0119 - accuracy: 0.9973 - val_loss: 2.0321 - val_accuracy: 0.6285\n",
      "Epoch 73/200\n",
      "25204/25204 [==============================] - 14s 572us/sample - loss: 0.0125 - accuracy: 0.9968 - val_loss: 2.0372 - val_accuracy: 0.6286\n",
      "Epoch 74/200\n",
      "25204/25204 [==============================] - 14s 563us/sample - loss: 0.0117 - accuracy: 0.9975 - val_loss: 2.0184 - val_accuracy: 0.6333\n",
      "Epoch 75/200\n",
      "25204/25204 [==============================] - 15s 602us/sample - loss: 0.0116 - accuracy: 0.9977 - val_loss: 2.0346 - val_accuracy: 0.6316\n",
      "Epoch 76/200\n",
      "25204/25204 [==============================] - 14s 569us/sample - loss: 0.0113 - accuracy: 0.9972 - val_loss: 2.0373 - val_accuracy: 0.6322\n",
      "Epoch 77/200\n",
      "25204/25204 [==============================] - 14s 567us/sample - loss: 0.0106 - accuracy: 0.9977 - val_loss: 2.0347 - val_accuracy: 0.6298\n",
      "Epoch 78/200\n",
      "25204/25204 [==============================] - 14s 570us/sample - loss: 0.0109 - accuracy: 0.9977 - val_loss: 2.0362 - val_accuracy: 0.6305\n",
      "Epoch 79/200\n",
      "25204/25204 [==============================] - 14s 570us/sample - loss: 0.0115 - accuracy: 0.9975 - val_loss: 2.0454 - val_accuracy: 0.6294\n",
      "Epoch 80/200\n",
      "25204/25204 [==============================] - 15s 576us/sample - loss: 0.0104 - accuracy: 0.9977 - val_loss: 2.0322 - val_accuracy: 0.6283\n",
      "Epoch 81/200\n",
      "25204/25204 [==============================] - 15s 581us/sample - loss: 0.0102 - accuracy: 0.9975 - val_loss: 2.0539 - val_accuracy: 0.6296\n",
      "Epoch 82/200\n",
      "25204/25204 [==============================] - 15s 606us/sample - loss: 0.0108 - accuracy: 0.9973 - val_loss: 2.0683 - val_accuracy: 0.6299\n",
      "Epoch 83/200\n",
      "25204/25204 [==============================] - 16s 641us/sample - loss: 0.0111 - accuracy: 0.9971 - val_loss: 2.0744 - val_accuracy: 0.6285\n",
      "Epoch 84/200\n",
      "25204/25204 [==============================] - 16s 636us/sample - loss: 0.0113 - accuracy: 0.9971 - val_loss: 2.0872 - val_accuracy: 0.6286\n",
      "Epoch 85/200\n",
      "25204/25204 [==============================] - 15s 611us/sample - loss: 0.0121 - accuracy: 0.9966 - val_loss: 2.0892 - val_accuracy: 0.6277\n",
      "Epoch 86/200\n",
      "25204/25204 [==============================] - 15s 612us/sample - loss: 0.0127 - accuracy: 0.9965 - val_loss: 2.1788 - val_accuracy: 0.6257\n",
      "Epoch 87/200\n",
      "25204/25204 [==============================] - 15s 599us/sample - loss: 0.0128 - accuracy: 0.9966 - val_loss: 2.1798 - val_accuracy: 0.6314\n",
      "Epoch 88/200\n",
      "25204/25204 [==============================] - 14s 572us/sample - loss: 0.0131 - accuracy: 0.9966 - val_loss: 2.2153 - val_accuracy: 0.6226\n",
      "Epoch 89/200\n",
      "25204/25204 [==============================] - 14s 558us/sample - loss: 0.0135 - accuracy: 0.9962 - val_loss: 2.1928 - val_accuracy: 0.6244\n",
      "Epoch 90/200\n",
      "25204/25204 [==============================] - 15s 582us/sample - loss: 0.0142 - accuracy: 0.9961 - val_loss: 2.2466 - val_accuracy: 0.6174\n",
      "Epoch 91/200\n",
      "25204/25204 [==============================] - 14s 574us/sample - loss: 0.0156 - accuracy: 0.9954 - val_loss: 2.2262 - val_accuracy: 0.6216\n",
      "Epoch 92/200\n",
      "25204/25204 [==============================] - 14s 561us/sample - loss: 0.0179 - accuracy: 0.9944 - val_loss: 2.2070 - val_accuracy: 0.6233\n",
      "Epoch 93/200\n",
      "25204/25204 [==============================] - 14s 574us/sample - loss: 0.0204 - accuracy: 0.9934 - val_loss: 2.4551 - val_accuracy: 0.6181\n",
      "Epoch 94/200\n",
      "25204/25204 [==============================] - 14s 570us/sample - loss: 0.0222 - accuracy: 0.9931 - val_loss: 2.3961 - val_accuracy: 0.6214\n",
      "Epoch 95/200\n",
      "25204/25204 [==============================] - 14s 574us/sample - loss: 0.0277 - accuracy: 0.9905 - val_loss: 2.4075 - val_accuracy: 0.6238\n",
      "Epoch 96/200\n",
      "25204/25204 [==============================] - 14s 572us/sample - loss: 0.0313 - accuracy: 0.9889 - val_loss: 2.5411 - val_accuracy: 0.6170\n",
      "Epoch 97/200\n",
      "25204/25204 [==============================] - 14s 564us/sample - loss: 0.0373 - accuracy: 0.9868 - val_loss: 2.4368 - val_accuracy: 0.6163\n",
      "Epoch 98/200\n",
      "25204/25204 [==============================] - 15s 576us/sample - loss: 0.0325 - accuracy: 0.9890 - val_loss: 2.5850 - val_accuracy: 0.6270\n",
      "Epoch 99/200\n",
      "25204/25204 [==============================] - 14s 565us/sample - loss: 0.0299 - accuracy: 0.9898 - val_loss: 2.4105 - val_accuracy: 0.6218\n",
      "Epoch 100/200\n",
      "25204/25204 [==============================] - 14s 575us/sample - loss: 0.0253 - accuracy: 0.9917 - val_loss: 2.5431 - val_accuracy: 0.6283\n",
      "Epoch 101/200\n",
      "25204/25204 [==============================] - 14s 572us/sample - loss: 0.0217 - accuracy: 0.9930 - val_loss: 2.2684 - val_accuracy: 0.6275\n",
      "Epoch 102/200\n",
      "25204/25204 [==============================] - 14s 571us/sample - loss: 0.0185 - accuracy: 0.9943 - val_loss: 2.3154 - val_accuracy: 0.6314\n",
      "Epoch 103/200\n",
      "25204/25204 [==============================] - 15s 599us/sample - loss: 0.0149 - accuracy: 0.9957 - val_loss: 2.3176 - val_accuracy: 0.6338\n",
      "Epoch 104/200\n",
      "25204/25204 [==============================] - 16s 641us/sample - loss: 0.0138 - accuracy: 0.9962 - val_loss: 2.2471 - val_accuracy: 0.6305\n",
      "Epoch 105/200\n",
      "25204/25204 [==============================] - 16s 643us/sample - loss: 0.0128 - accuracy: 0.9963 - val_loss: 2.3158 - val_accuracy: 0.6292\n",
      "Epoch 106/200\n",
      "25204/25204 [==============================] - 16s 643us/sample - loss: 0.0110 - accuracy: 0.9969 - val_loss: 2.2791 - val_accuracy: 0.6314\n",
      "Epoch 107/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25204/25204 [==============================] - 16s 623us/sample - loss: 0.0106 - accuracy: 0.9967 - val_loss: 2.2558 - val_accuracy: 0.6318\n",
      "Epoch 108/200\n",
      "25204/25204 [==============================] - 16s 617us/sample - loss: 0.0090 - accuracy: 0.9982 - val_loss: 2.3319 - val_accuracy: 0.6305\n",
      "Epoch 109/200\n",
      "25204/25204 [==============================] - 16s 616us/sample - loss: 0.0082 - accuracy: 0.9978 - val_loss: 2.3122 - val_accuracy: 0.6301\n",
      "Epoch 110/200\n",
      "25204/25204 [==============================] - 15s 610us/sample - loss: 0.0082 - accuracy: 0.9980 - val_loss: 2.3161 - val_accuracy: 0.6325\n",
      "Epoch 111/200\n",
      "25204/25204 [==============================] - 15s 601us/sample - loss: 0.0079 - accuracy: 0.9980 - val_loss: 2.3331 - val_accuracy: 0.6309\n",
      "Epoch 112/200\n",
      "25204/25204 [==============================] - 15s 590us/sample - loss: 0.0071 - accuracy: 0.9980 - val_loss: 2.2814 - val_accuracy: 0.6299\n",
      "Epoch 113/200\n",
      "25204/25204 [==============================] - 15s 594us/sample - loss: 0.0072 - accuracy: 0.9979 - val_loss: 2.2832 - val_accuracy: 0.6292\n",
      "Epoch 114/200\n",
      "25204/25204 [==============================] - 15s 603us/sample - loss: 0.0067 - accuracy: 0.9982 - val_loss: 2.2952 - val_accuracy: 0.6290\n",
      "Epoch 115/200\n",
      "25204/25204 [==============================] - 15s 577us/sample - loss: 0.0067 - accuracy: 0.9985 - val_loss: 2.3059 - val_accuracy: 0.6286\n",
      "Epoch 116/200\n",
      "25204/25204 [==============================] - 14s 573us/sample - loss: 0.0063 - accuracy: 0.9983 - val_loss: 2.3132 - val_accuracy: 0.6294\n",
      "Epoch 117/200\n",
      "25204/25204 [==============================] - 14s 561us/sample - loss: 0.0065 - accuracy: 0.9985 - val_loss: 2.3234 - val_accuracy: 0.6303\n",
      "Epoch 118/200\n",
      "25204/25204 [==============================] - 14s 572us/sample - loss: 0.0068 - accuracy: 0.9980 - val_loss: 2.3446 - val_accuracy: 0.6292\n",
      "Epoch 119/200\n",
      "25204/25204 [==============================] - 14s 567us/sample - loss: 0.0062 - accuracy: 0.9985 - val_loss: 2.3373 - val_accuracy: 0.6320\n",
      "Epoch 120/200\n",
      "25204/25204 [==============================] - 14s 564us/sample - loss: 0.0061 - accuracy: 0.9985 - val_loss: 2.3426 - val_accuracy: 0.6283\n",
      "Epoch 121/200\n",
      "25204/25204 [==============================] - 14s 564us/sample - loss: 0.0064 - accuracy: 0.9984 - val_loss: 2.3485 - val_accuracy: 0.6310\n",
      "Epoch 122/200\n",
      "25204/25204 [==============================] - 14s 572us/sample - loss: 0.0070 - accuracy: 0.9982 - val_loss: 2.3619 - val_accuracy: 0.6316\n",
      "Epoch 123/200\n",
      "25204/25204 [==============================] - 15s 579us/sample - loss: 0.0067 - accuracy: 0.9985 - val_loss: 2.4030 - val_accuracy: 0.6310\n",
      "Epoch 124/200\n",
      "25204/25204 [==============================] - 16s 633us/sample - loss: 0.0075 - accuracy: 0.9976 - val_loss: 2.3984 - val_accuracy: 0.6283\n",
      "Epoch 125/200\n",
      "25204/25204 [==============================] - 14s 569us/sample - loss: 0.0078 - accuracy: 0.9979 - val_loss: 2.3919 - val_accuracy: 0.6270\n",
      "Epoch 126/200\n",
      "25204/25204 [==============================] - 15s 575us/sample - loss: 0.0081 - accuracy: 0.9978 - val_loss: 2.4614 - val_accuracy: 0.6251\n",
      "Epoch 127/200\n",
      "25204/25204 [==============================] - 15s 589us/sample - loss: 0.0091 - accuracy: 0.9974 - val_loss: 2.4514 - val_accuracy: 0.6279\n",
      "Epoch 128/200\n",
      "25204/25204 [==============================] - 14s 573us/sample - loss: 0.0085 - accuracy: 0.9975 - val_loss: 2.4678 - val_accuracy: 0.6292\n",
      "Epoch 129/200\n",
      "25204/25204 [==============================] - 14s 569us/sample - loss: 0.0096 - accuracy: 0.9973 - val_loss: 2.5669 - val_accuracy: 0.6229\n",
      "Epoch 130/200\n",
      "25204/25204 [==============================] - 15s 584us/sample - loss: 0.0112 - accuracy: 0.9967 - val_loss: 2.5595 - val_accuracy: 0.6310\n",
      "Epoch 131/200\n",
      "25204/25204 [==============================] - 15s 587us/sample - loss: 0.0125 - accuracy: 0.9957 - val_loss: 2.5746 - val_accuracy: 0.6298\n",
      "Epoch 132/200\n",
      "25204/25204 [==============================] - 15s 589us/sample - loss: 0.0149 - accuracy: 0.9949 - val_loss: 2.6907 - val_accuracy: 0.6305\n",
      "Epoch 133/200\n",
      "25204/25204 [==============================] - 15s 583us/sample - loss: 0.0172 - accuracy: 0.9937 - val_loss: 2.5257 - val_accuracy: 0.6283\n",
      "Epoch 134/200\n",
      "25204/25204 [==============================] - 15s 580us/sample - loss: 0.0205 - accuracy: 0.9931 - val_loss: 2.6759 - val_accuracy: 0.6299\n",
      "Epoch 135/200\n",
      "25204/25204 [==============================] - 14s 570us/sample - loss: 0.0244 - accuracy: 0.9911 - val_loss: 2.9412 - val_accuracy: 0.6305\n",
      "Epoch 136/200\n",
      "25204/25204 [==============================] - 14s 570us/sample - loss: 0.0259 - accuracy: 0.9909 - val_loss: 2.8447 - val_accuracy: 0.6303\n",
      "Epoch 137/200\n",
      "25204/25204 [==============================] - 14s 571us/sample - loss: 0.0271 - accuracy: 0.9903 - val_loss: 2.8407 - val_accuracy: 0.6238\n",
      "Epoch 138/200\n",
      "25204/25204 [==============================] - 15s 580us/sample - loss: 0.0225 - accuracy: 0.9923 - val_loss: 2.6565 - val_accuracy: 0.6259\n",
      "Epoch 139/200\n",
      "25204/25204 [==============================] - 14s 563us/sample - loss: 0.0207 - accuracy: 0.9931 - val_loss: 2.7216 - val_accuracy: 0.6309\n",
      "Epoch 140/200\n",
      "25204/25204 [==============================] - 14s 571us/sample - loss: 0.0167 - accuracy: 0.9947 - val_loss: 2.6422 - val_accuracy: 0.6301\n",
      "Epoch 141/200\n",
      "25204/25204 [==============================] - 15s 588us/sample - loss: 0.0122 - accuracy: 0.9962 - val_loss: 2.6370 - val_accuracy: 0.6294\n",
      "Epoch 142/200\n",
      "25204/25204 [==============================] - 15s 595us/sample - loss: 0.0102 - accuracy: 0.9969 - val_loss: 2.6628 - val_accuracy: 0.6312\n",
      "Epoch 143/200\n",
      "25204/25204 [==============================] - 14s 573us/sample - loss: 0.0102 - accuracy: 0.9967 - val_loss: 2.6007 - val_accuracy: 0.6281\n",
      "Epoch 144/200\n",
      "25204/25204 [==============================] - 14s 566us/sample - loss: 0.0107 - accuracy: 0.9963 - val_loss: 2.6838 - val_accuracy: 0.6303\n",
      "Epoch 145/200\n",
      "25204/25204 [==============================] - 14s 570us/sample - loss: 0.0079 - accuracy: 0.9978 - val_loss: 2.6372 - val_accuracy: 0.6285\n",
      "Epoch 146/200\n",
      "25204/25204 [==============================] - 14s 572us/sample - loss: 0.0067 - accuracy: 0.9981 - val_loss: 2.6135 - val_accuracy: 0.6355\n",
      "Epoch 147/200\n",
      "25204/25204 [==============================] - 15s 577us/sample - loss: 0.0067 - accuracy: 0.9982 - val_loss: 2.6028 - val_accuracy: 0.6346\n",
      "Epoch 148/200\n",
      "25204/25204 [==============================] - 15s 577us/sample - loss: 0.0058 - accuracy: 0.9984 - val_loss: 2.6187 - val_accuracy: 0.6336\n",
      "Epoch 149/200\n",
      "25204/25204 [==============================] - 14s 570us/sample - loss: 0.0059 - accuracy: 0.9986 - val_loss: 2.6154 - val_accuracy: 0.6340\n",
      "Epoch 150/200\n",
      "25204/25204 [==============================] - 14s 575us/sample - loss: 0.0061 - accuracy: 0.9985 - val_loss: 2.6125 - val_accuracy: 0.6331\n",
      "Epoch 151/200\n",
      "25204/25204 [==============================] - 14s 566us/sample - loss: 0.0051 - accuracy: 0.9986 - val_loss: 2.5985 - val_accuracy: 0.6344\n",
      "Epoch 152/200\n",
      "25204/25204 [==============================] - 14s 575us/sample - loss: 0.0057 - accuracy: 0.9984 - val_loss: 2.5975 - val_accuracy: 0.6333\n",
      "Epoch 153/200\n",
      "25204/25204 [==============================] - 14s 565us/sample - loss: 0.0053 - accuracy: 0.9983 - val_loss: 2.6053 - val_accuracy: 0.6323\n",
      "Epoch 154/200\n",
      "25204/25204 [==============================] - 14s 572us/sample - loss: 0.0044 - accuracy: 0.9989 - val_loss: 2.6056 - val_accuracy: 0.6320\n",
      "Epoch 155/200\n",
      "25204/25204 [==============================] - 14s 570us/sample - loss: 0.0053 - accuracy: 0.9985 - val_loss: 2.6112 - val_accuracy: 0.6325\n",
      "Epoch 156/200\n",
      "25204/25204 [==============================] - 14s 566us/sample - loss: 0.0047 - accuracy: 0.9987 - val_loss: 2.6108 - val_accuracy: 0.6322\n",
      "Epoch 157/200\n",
      "25204/25204 [==============================] - 14s 575us/sample - loss: 0.0050 - accuracy: 0.9984 - val_loss: 2.6183 - val_accuracy: 0.6325\n",
      "Epoch 158/200\n",
      "25204/25204 [==============================] - 14s 562us/sample - loss: 0.0050 - accuracy: 0.9985 - val_loss: 2.6377 - val_accuracy: 0.6358\n",
      "Epoch 159/200\n",
      "25204/25204 [==============================] - 14s 575us/sample - loss: 0.0055 - accuracy: 0.9983 - val_loss: 2.6196 - val_accuracy: 0.6357\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25204/25204 [==============================] - 14s 574us/sample - loss: 0.0046 - accuracy: 0.9987 - val_loss: 2.6001 - val_accuracy: 0.6333\n",
      "Epoch 161/200\n",
      "25204/25204 [==============================] - 14s 569us/sample - loss: 0.0050 - accuracy: 0.9985 - val_loss: 2.5870 - val_accuracy: 0.6316\n",
      "Epoch 162/200\n",
      "25204/25204 [==============================] - 14s 563us/sample - loss: 0.0057 - accuracy: 0.9981 - val_loss: 2.6852 - val_accuracy: 0.6303\n",
      "Epoch 163/200\n",
      "25204/25204 [==============================] - 14s 571us/sample - loss: 0.0055 - accuracy: 0.9981 - val_loss: 2.6301 - val_accuracy: 0.6355\n",
      "Epoch 164/200\n",
      "25204/25204 [==============================] - 14s 572us/sample - loss: 0.0057 - accuracy: 0.9981 - val_loss: 2.7006 - val_accuracy: 0.6347\n",
      "Epoch 165/200\n",
      "25204/25204 [==============================] - 14s 574us/sample - loss: 0.0057 - accuracy: 0.9983 - val_loss: 2.7287 - val_accuracy: 0.6303\n",
      "Epoch 166/200\n",
      "25204/25204 [==============================] - 15s 591us/sample - loss: 0.0058 - accuracy: 0.9983 - val_loss: 2.7313 - val_accuracy: 0.6305\n",
      "Epoch 167/200\n",
      "25204/25204 [==============================] - 14s 573us/sample - loss: 0.0059 - accuracy: 0.9980 - val_loss: 2.7452 - val_accuracy: 0.6322\n",
      "Epoch 168/200\n",
      "25204/25204 [==============================] - 14s 570us/sample - loss: 0.0064 - accuracy: 0.9981 - val_loss: 2.8492 - val_accuracy: 0.6303\n",
      "Epoch 169/200\n",
      "25204/25204 [==============================] - 14s 572us/sample - loss: 0.0076 - accuracy: 0.9975 - val_loss: 2.8644 - val_accuracy: 0.6303\n",
      "Epoch 170/200\n",
      "25204/25204 [==============================] - 15s 585us/sample - loss: 0.0081 - accuracy: 0.9976 - val_loss: 2.8583 - val_accuracy: 0.6310\n",
      "Epoch 171/200\n",
      "25204/25204 [==============================] - 15s 580us/sample - loss: 0.0090 - accuracy: 0.9971 - val_loss: 2.9619 - val_accuracy: 0.6325\n",
      "Epoch 172/200\n",
      "25204/25204 [==============================] - 15s 578us/sample - loss: 0.0102 - accuracy: 0.9967 - val_loss: 3.0699 - val_accuracy: 0.6312\n",
      "Epoch 173/200\n",
      "25204/25204 [==============================] - 15s 582us/sample - loss: 0.0163 - accuracy: 0.9944 - val_loss: 3.1033 - val_accuracy: 0.6272\n",
      "Epoch 174/200\n",
      "25204/25204 [==============================] - 15s 600us/sample - loss: 0.0239 - accuracy: 0.9917 - val_loss: 3.1490 - val_accuracy: 0.6288\n",
      "Epoch 175/200\n",
      "25204/25204 [==============================] - 15s 590us/sample - loss: 0.0267 - accuracy: 0.9913 - val_loss: 3.0103 - val_accuracy: 0.6266\n",
      "Epoch 176/200\n",
      "25204/25204 [==============================] - 15s 576us/sample - loss: 0.0216 - accuracy: 0.9929 - val_loss: 2.9740 - val_accuracy: 0.6351\n",
      "Epoch 177/200\n",
      "25204/25204 [==============================] - 14s 570us/sample - loss: 0.0191 - accuracy: 0.9931 - val_loss: 2.9181 - val_accuracy: 0.6305\n",
      "Epoch 178/200\n",
      "25204/25204 [==============================] - 14s 570us/sample - loss: 0.0154 - accuracy: 0.9949 - val_loss: 2.9785 - val_accuracy: 0.6394\n",
      "Epoch 179/200\n",
      "25204/25204 [==============================] - 14s 565us/sample - loss: 0.0123 - accuracy: 0.9958 - val_loss: 2.9602 - val_accuracy: 0.6283\n",
      "Epoch 180/200\n",
      "25204/25204 [==============================] - 14s 563us/sample - loss: 0.0107 - accuracy: 0.9963 - val_loss: 2.9088 - val_accuracy: 0.6346\n",
      "Epoch 181/200\n",
      "25204/25204 [==============================] - 14s 573us/sample - loss: 0.0089 - accuracy: 0.9969 - val_loss: 2.7857 - val_accuracy: 0.6272\n",
      "Epoch 182/200\n",
      "25204/25204 [==============================] - 14s 571us/sample - loss: 0.0069 - accuracy: 0.9977 - val_loss: 2.7831 - val_accuracy: 0.6377\n",
      "Epoch 183/200\n",
      "25204/25204 [==============================] - 14s 571us/sample - loss: 0.0068 - accuracy: 0.9979 - val_loss: 2.7993 - val_accuracy: 0.6251\n",
      "Epoch 184/200\n",
      "25204/25204 [==============================] - 15s 577us/sample - loss: 0.0054 - accuracy: 0.9985 - val_loss: 2.8023 - val_accuracy: 0.6357\n",
      "Epoch 185/200\n",
      "25204/25204 [==============================] - 15s 576us/sample - loss: 0.0057 - accuracy: 0.9980 - val_loss: 2.7587 - val_accuracy: 0.6342\n",
      "Epoch 186/200\n",
      "25204/25204 [==============================] - 14s 568us/sample - loss: 0.0052 - accuracy: 0.9986 - val_loss: 2.7917 - val_accuracy: 0.6305\n",
      "Epoch 187/200\n",
      "25204/25204 [==============================] - 14s 567us/sample - loss: 0.0048 - accuracy: 0.9985 - val_loss: 2.8115 - val_accuracy: 0.6310\n",
      "Epoch 188/200\n",
      "25204/25204 [==============================] - 15s 575us/sample - loss: 0.0040 - accuracy: 0.9990 - val_loss: 2.8123 - val_accuracy: 0.6316\n",
      "Epoch 189/200\n",
      "25204/25204 [==============================] - 14s 566us/sample - loss: 0.0050 - accuracy: 0.9983 - val_loss: 2.7933 - val_accuracy: 0.6305\n",
      "Epoch 190/200\n",
      "25204/25204 [==============================] - 14s 565us/sample - loss: 0.0044 - accuracy: 0.9986 - val_loss: 2.7977 - val_accuracy: 0.6307\n",
      "Epoch 191/200\n",
      "25204/25204 [==============================] - 14s 565us/sample - loss: 0.0035 - accuracy: 0.9991 - val_loss: 2.8135 - val_accuracy: 0.6303\n",
      "Epoch 192/200\n",
      "25204/25204 [==============================] - 15s 578us/sample - loss: 0.0041 - accuracy: 0.9988 - val_loss: 2.8158 - val_accuracy: 0.6307\n",
      "Epoch 193/200\n",
      "25204/25204 [==============================] - 15s 577us/sample - loss: 0.0037 - accuracy: 0.9989 - val_loss: 2.8135 - val_accuracy: 0.6310\n",
      "Epoch 194/200\n",
      "25204/25204 [==============================] - 14s 573us/sample - loss: 0.0040 - accuracy: 0.9987 - val_loss: 2.8197 - val_accuracy: 0.6307\n",
      "Epoch 195/200\n",
      "25204/25204 [==============================] - 14s 573us/sample - loss: 0.0037 - accuracy: 0.9988 - val_loss: 2.8178 - val_accuracy: 0.6314\n",
      "Epoch 196/200\n",
      "25204/25204 [==============================] - 14s 575us/sample - loss: 0.0040 - accuracy: 0.9988 - val_loss: 2.8219 - val_accuracy: 0.6327\n",
      "Epoch 197/200\n",
      "25204/25204 [==============================] - 15s 577us/sample - loss: 0.0036 - accuracy: 0.9988 - val_loss: 2.8654 - val_accuracy: 0.6366\n",
      "Epoch 198/200\n",
      "25204/25204 [==============================] - 14s 561us/sample - loss: 0.0038 - accuracy: 0.9988 - val_loss: 2.8247 - val_accuracy: 0.6364\n",
      "Epoch 199/200\n",
      "25204/25204 [==============================] - 14s 566us/sample - loss: 0.0040 - accuracy: 0.9988 - val_loss: 2.7952 - val_accuracy: 0.6316\n",
      "Epoch 200/200\n",
      "25204/25204 [==============================] - 14s 571us/sample - loss: 0.0041 - accuracy: 0.9984 - val_loss: 2.8401 - val_accuracy: 0.6320\n"
     ]
    }
   ],
   "source": [
    "history_sentiments = model_sentiments.fit(x=np.concatenate((X_train,\n",
    "                                                            X_test), axis=0),\n",
    "                                          y=np.concatenate((X_sentiments_train,\n",
    "                                                            X_sentiments_test), axis=0),\n",
    "                                          shuffle=True,\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          epochs=NUM_EPOCHS,\n",
    "                                          validation_data=(X_val, X_sentiments_val),\n",
    "                                          verbose=1,\n",
    "                                          callbacks=[clr_sentiments, mcp_sentiments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric_names = ['loss' ,'accuracy']\n",
    "\n",
    "for i, j in zip(metric_names, ['val_'+i for i in metric_names]):\n",
    "    plt.plot(history_sentiments.history[i])\n",
    "    plt.plot(history_sentiments.history[j])\n",
    "    plt.title('Model '+i)\n",
    "    plt.ylabel(i.upper())\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model_embeddings = model_sentiments.layers[1].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_train = confusion_matrix(X_sentiments_train,\n",
    "                                  model_sentiments.predict(X_train, batch_size=2048).argmax(axis=1))\n",
    "\n",
    "conf_mat_val = confusion_matrix(X_sentiments_val,\n",
    "                                model_sentiments.predict(X_val, batch_size=2048).argmax(axis=1))\n",
    "\n",
    "conf_mat_test = confusion_matrix(X_sentiments_test,\n",
    "                                 model_sentiments.predict(X_test, batch_size=2048).argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[6156,    1,    1],\n",
       "        [   0, 8837,    4],\n",
       "        [   1,    1, 6669]], dtype=int64),\n",
       " array([[ 907,  468,  119],\n",
       "        [ 423, 1348,  419],\n",
       "        [ 117,  448, 1169]], dtype=int64),\n",
       " array([[1001,    0,    0],\n",
       "        [   1, 1429,    0],\n",
       "        [   0,    2, 1101]], dtype=int64))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat_train, conf_mat_val, conf_mat_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentiment = Input((1))\n",
    "input_sequences = Input((max_len))\n",
    "\n",
    "emb_sequences = Embedding(input_dim=VOCAB_SIZE, input_length=max_len, output_dim=32,\n",
    "                          weights=[sentiment_model_embeddings], mask_zero=True)(input_sequences)\n",
    "\n",
    "seq = Bidirectional(LSTM(16, activation='relu', return_sequences=True))(emb_sequences)\n",
    "seq = BatchNormalization()(seq)\n",
    "seq = Dropout(DROPOUT)(seq)\n",
    "\n",
    "seq = Bidirectional(LSTM(16, activation='relu', return_sequences=True))(seq)\n",
    "seq = BatchNormalization()(seq)\n",
    "seq = Dropout(DROPOUT)(seq)\n",
    "\n",
    "seq = TimeDistributed(Dense(16, activation=\"relu\"))(seq)\n",
    "seq = BatchNormalization()(seq)\n",
    "seq = Dropout(DROPOUT)(seq)\n",
    "\n",
    "#seq = Flatten()(seq)\n",
    "\n",
    "#emb_sentiment = Embedding(input_dim=3, input_length=1, output_dim=5)(input_sentiment)\n",
    "senti = Dense(8, activation=\"relu\")(input_sentiment)\n",
    "senti = BatchNormalization()(senti)\n",
    "senti = Dropout(DROPOUT)(senti)\n",
    "senti = RepeatVector(max_len)(senti)\n",
    "\n",
    "concat_layer = concatenate([senti, seq])\n",
    "\n",
    "output = TimeDistributed(Dense(max_len, activation=\"relu\"))(concat_layer)\n",
    "output = TimeDistributed(Dense(1, activation=\"sigmoid\"))(output)\n",
    "output = Flatten()(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_41 (InputLayer)           [(None, 108)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_22 (Embedding)        (None, 108, 32)      903232      input_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_40 (Bidirectional (None, 108, 32)      6272        embedding_22[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "input_40 (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 108, 32)      128         bidirectional_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 8)            16          input_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 108, 32)      0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8)            32          dense_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_41 (Bidirectional (None, 108, 32)      6272        dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 8)            0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 108, 32)      128         bidirectional_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_15 (RepeatVector) (None, 108, 8)       0           dropout_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 108, 32)      0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 108, 40)      0           repeat_vector_15[0][0]           \n",
      "                                                                 dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_42 (Bidirectional (None, 108, 32)      7296        concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 108, 32)      128         bidirectional_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 108, 32)      0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_36 (TimeDistri (None, 108, 108)     3564        dropout_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_37 (TimeDistri (None, 108, 1)       109         time_distributed_36[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 108)          0           time_distributed_37[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 927,177\n",
      "Trainable params: 926,969\n",
      "Non-trainable params: 208\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([input_sentiment, input_sequences], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=MIN_LR)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks\n",
    "mcp = ModelCheckpoint(filepath=\"../results/\"+MODEL_PREFIX+\"Checkpoint.h5\",\n",
    "                      monitor='val_loss',\n",
    "                      mode=\"auto\",\n",
    "                      save_weights_only=False,\n",
    "                      save_best_only=True)\n",
    "\n",
    "clr = CyclicLR(mode=CLR_METHOD,\n",
    "               base_lr=MIN_LR,\n",
    "               max_lr=MAX_LR,\n",
    "               step_size= STEP_SIZE * (X_train.shape[0] // BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21670 samples, validate on 5418 samples\n",
      "Epoch 1/40\n",
      "21670/21670 [==============================] - 20s 927us/sample - loss: 0.6738 - accuracy: 0.6677 - val_loss: 0.6869 - val_accuracy: 0.6236\n",
      "Epoch 2/40\n",
      "21670/21670 [==============================] - 13s 604us/sample - loss: 0.6258 - accuracy: 0.8574 - val_loss: 0.6540 - val_accuracy: 0.9162\n",
      "Epoch 3/40\n",
      "21670/21670 [==============================] - 13s 610us/sample - loss: 0.5533 - accuracy: 0.9204 - val_loss: 0.6033 - val_accuracy: 0.9162\n",
      "Epoch 4/40\n",
      "21670/21670 [==============================] - 13s 609us/sample - loss: 0.4684 - accuracy: 0.9257 - val_loss: 0.5426 - val_accuracy: 0.9162\n",
      "Epoch 5/40\n",
      "21670/21670 [==============================] - 14s 625us/sample - loss: 0.3809 - accuracy: 0.9287 - val_loss: 0.4735 - val_accuracy: 0.9162\n",
      "Epoch 6/40\n",
      "21670/21670 [==============================] - 13s 615us/sample - loss: 0.2974 - accuracy: 0.9319 - val_loss: 0.4028 - val_accuracy: 0.9162\n",
      "Epoch 7/40\n",
      "21670/21670 [==============================] - 13s 619us/sample - loss: 0.2278 - accuracy: 0.9337 - val_loss: 0.3343 - val_accuracy: 0.9162\n",
      "Epoch 8/40\n",
      "21670/21670 [==============================] - 13s 617us/sample - loss: 0.1793 - accuracy: 0.9362 - val_loss: 0.2780 - val_accuracy: 0.9162\n",
      "Epoch 9/40\n",
      "21670/21670 [==============================] - 13s 610us/sample - loss: 0.1489 - accuracy: 0.9402 - val_loss: 0.2371 - val_accuracy: 0.9162\n",
      "Epoch 10/40\n",
      "21670/21670 [==============================] - 13s 622us/sample - loss: 0.1297 - accuracy: 0.9447 - val_loss: 0.2113 - val_accuracy: 0.9162\n",
      "Epoch 11/40\n",
      "21670/21670 [==============================] - 13s 621us/sample - loss: 0.1149 - accuracy: 0.9505 - val_loss: 0.1970 - val_accuracy: 0.9162\n",
      "Epoch 12/40\n",
      "21670/21670 [==============================] - 14s 627us/sample - loss: 0.1026 - accuracy: 0.9562 - val_loss: 0.1882 - val_accuracy: 0.9162\n",
      "Epoch 13/40\n",
      "21670/21670 [==============================] - 14s 624us/sample - loss: 0.0911 - accuracy: 0.9616 - val_loss: 0.1819 - val_accuracy: 0.9162\n",
      "Epoch 14/40\n",
      "21670/21670 [==============================] - 13s 617us/sample - loss: 0.0811 - accuracy: 0.9663 - val_loss: 0.1756 - val_accuracy: 0.9162\n",
      "Epoch 15/40\n",
      "21670/21670 [==============================] - 14s 623us/sample - loss: 0.0720 - accuracy: 0.9704 - val_loss: 0.1682 - val_accuracy: 0.9162\n",
      "Epoch 16/40\n",
      "21670/21670 [==============================] - 13s 620us/sample - loss: 0.0645 - accuracy: 0.9739 - val_loss: 0.1617 - val_accuracy: 0.9162\n",
      "Epoch 17/40\n",
      "21670/21670 [==============================] - 14s 624us/sample - loss: 0.0587 - accuracy: 0.9762 - val_loss: 0.1522 - val_accuracy: 0.9163\n",
      "Epoch 18/40\n",
      "21670/21670 [==============================] - 13s 613us/sample - loss: 0.0537 - accuracy: 0.9784 - val_loss: 0.1433 - val_accuracy: 0.9175\n",
      "Epoch 19/40\n",
      "21670/21670 [==============================] - 13s 620us/sample - loss: 0.0501 - accuracy: 0.9798 - val_loss: 0.1383 - val_accuracy: 0.9200\n",
      "Epoch 20/40\n",
      "21670/21670 [==============================] - 13s 616us/sample - loss: 0.0468 - accuracy: 0.9812 - val_loss: 0.1310 - val_accuracy: 0.9244\n",
      "Epoch 21/40\n",
      "21670/21670 [==============================] - 14s 634us/sample - loss: 0.0441 - accuracy: 0.9822 - val_loss: 0.1264 - val_accuracy: 0.9284\n",
      "Epoch 22/40\n",
      "21670/21670 [==============================] - 14s 639us/sample - loss: 0.0420 - accuracy: 0.9831 - val_loss: 0.1152 - val_accuracy: 0.9355\n",
      "Epoch 23/40\n",
      "21670/21670 [==============================] - 13s 611us/sample - loss: 0.0398 - accuracy: 0.9840 - val_loss: 0.1163 - val_accuracy: 0.9365\n",
      "Epoch 24/40\n",
      "21670/21670 [==============================] - 13s 610us/sample - loss: 0.0380 - accuracy: 0.9849 - val_loss: 0.1190 - val_accuracy: 0.9367\n",
      "Epoch 25/40\n",
      "21670/21670 [==============================] - 13s 607us/sample - loss: 0.0365 - accuracy: 0.9854 - val_loss: 0.1169 - val_accuracy: 0.9401\n",
      "Epoch 26/40\n",
      "21670/21670 [==============================] - 13s 610us/sample - loss: 0.0353 - accuracy: 0.9859 - val_loss: 0.1209 - val_accuracy: 0.9414\n",
      "Epoch 27/40\n",
      "21670/21670 [==============================] - 13s 609us/sample - loss: 0.0340 - accuracy: 0.9864 - val_loss: 0.1282 - val_accuracy: 0.9413\n",
      "Epoch 28/40\n",
      "21670/21670 [==============================] - 13s 614us/sample - loss: 0.0329 - accuracy: 0.9869 - val_loss: 0.1349 - val_accuracy: 0.9417\n",
      "Epoch 29/40\n",
      "21670/21670 [==============================] - 14s 626us/sample - loss: 0.0322 - accuracy: 0.9872 - val_loss: 0.1437 - val_accuracy: 0.9415\n",
      "Epoch 30/40\n",
      "21670/21670 [==============================] - 14s 632us/sample - loss: 0.0315 - accuracy: 0.9875 - val_loss: 0.1483 - val_accuracy: 0.9414\n",
      "Epoch 31/40\n",
      "21670/21670 [==============================] - 14s 625us/sample - loss: 0.0314 - accuracy: 0.9875 - val_loss: 0.1545 - val_accuracy: 0.9416\n",
      "Epoch 32/40\n",
      "21670/21670 [==============================] - 14s 631us/sample - loss: 0.0307 - accuracy: 0.9878 - val_loss: 0.1693 - val_accuracy: 0.9417\n",
      "Epoch 33/40\n",
      "21670/21670 [==============================] - 14s 626us/sample - loss: 0.0301 - accuracy: 0.9881 - val_loss: 0.1726 - val_accuracy: 0.9415\n",
      "Epoch 34/40\n",
      "21670/21670 [==============================] - 14s 629us/sample - loss: 0.0293 - accuracy: 0.9884 - val_loss: 0.1777 - val_accuracy: 0.9414\n",
      "Epoch 35/40\n",
      "21670/21670 [==============================] - 14s 631us/sample - loss: 0.0289 - accuracy: 0.9885 - val_loss: 0.1821 - val_accuracy: 0.9414\n",
      "Epoch 36/40\n",
      "21670/21670 [==============================] - 13s 613us/sample - loss: 0.0286 - accuracy: 0.9887 - val_loss: 0.1909 - val_accuracy: 0.9413\n",
      "Epoch 37/40\n",
      "21670/21670 [==============================] - 13s 615us/sample - loss: 0.0284 - accuracy: 0.9887 - val_loss: 0.1941 - val_accuracy: 0.9413\n",
      "Epoch 38/40\n",
      "21670/21670 [==============================] - 14s 625us/sample - loss: 0.0282 - accuracy: 0.9888 - val_loss: 0.1978 - val_accuracy: 0.9413\n",
      "Epoch 39/40\n",
      "21670/21670 [==============================] - 13s 621us/sample - loss: 0.0281 - accuracy: 0.9888 - val_loss: 0.1990 - val_accuracy: 0.9412\n",
      "Epoch 40/40\n",
      "21670/21670 [==============================] - 13s 608us/sample - loss: 0.0279 - accuracy: 0.9890 - val_loss: 0.2000 - val_accuracy: 0.9411\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[X_sentiments_train, X_train],\n",
    "                    y=Y2_train,\n",
    "                    shuffle=True,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    validation_data=([X_sentiments_val, X_val], Y2_val),\n",
    "                    verbose=1,\n",
    "                    callbacks=[clr, mcp]) #es, rlrop, tb, mcp, \n",
    "\n",
    "## Might need a callback as described here \n",
    "##https://stackoverflow.com/questions/51728648/how-do-masked-values-affect-the-metrics-in-keras\n",
    "#history = model.fit(x=[X_sentiments_train, X_train],\n",
    "#                    y=Y_train,\n",
    "#                    shuffle=True,\n",
    "#                    batch_size=BATCH_SIZE,\n",
    "#                    epochs=NUM_EPOCHS,\n",
    "#                    validation_data=([X_sentiments_val, X_val], Y_val),\n",
    "#                    verbose=1,\n",
    "#                    callbacks=[clr, mcp]) #es, rlrop, tb, mcp, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxU9dX48c/JZCMbkBVIgLBDwpJABMUNQVRcwaWCWqW25cHWLj+ftmpXu/h0s32sj22tW+1iS92galUUFFHcWARkJyCQsCbBkITsyfn9cScwhOzkZiaZ83695jUzd5uTq8yZ+73f7/mKqmKMMSZ4hfg7AGOMMf5licAYY4KcJQJjjAlylgiMMSbIWSIwxpggZ4nAGGOCnCUCY9pARNJFREUktA3bzheRd8/0OMZ0FUsEpscRkT0iUi0iiY2Wr/d+Caf7JzJjApMlAtNTfQrMa3gjIuOAXv4Lx5jAZYnA9FR/A271eX8b8FffDUSkt4j8VUQKRGSviHxfREK86zwi8oCIFIrIbuCKJvZ9QkQOish+EfmZiHjaG6SIDBCRF0XkqIjkisiXfdZNFpE1IlIiIodF5Lfe5ZEi8ncRKRKRYhFZLSIp7f1sYxpYIjA91QdAnIiM8X5B3wj8vdE2/wf0BoYCF+Ikji94130ZuBLIBnKA6xvt+xegFhju3eYS4EsdiPOfQD4wwPsZ/yMiM7zrfgf8TlXjgGHAM97lt3njHggkAAuBig58tjGAJQLTszVcFcwEtgH7G1b4JId7VbVUVfcAvwE+793kc8CDqpqnqkeBn/vsmwLMAr6pqsdV9Qjwv8Dc9gQnIgOB84C7VbVSVdcDj/vEUAMMF5FEVS1T1Q98licAw1W1TlXXqmpJez7bGF+WCExP9jfgJmA+jZqFgEQgHNjrs2wvkOp9PQDIa7SuwWAgDDjobZopBv4EJLczvgHAUVUtbSaGLwIjgW3e5p8rff6upcAiETkgIr8SkbB2frYxJ1giMD2Wqu7FuWl8OfBCo9WFOL+sB/ssG8TJq4aDOE0vvusa5AFVQKKq9vE+4lQ1s50hHgDiRSS2qRhUdaeqzsNJML8EnhORaFWtUdUfq2oGMBWnCetWjOkgSwSmp/siMF1Vj/suVNU6nDb3+0UkVkQGA3dx8j7CM8DXRSRNRPoC9/jsexB4HfiNiMSJSIiIDBORC9sTmKrmAe8BP/feAB7vjfdpABG5RUSSVLUeKPbuViciF4nIOG/zVglOQqtrz2cb48sSgenRVHWXqq5pZvXXgOPAbuBd4B/Ak951j+E0v2wA1nH6FcWtOE1LW4DPgOeA/h0IcR6QjnN1sBj4kaq+4V13GbBZRMpwbhzPVdVKoJ/380qArcDbnH4j3Jg2E5uYxhhjgptdERhjTJCzRGCMMUHOEoExxgQ5SwTGGBPkul0p3MTERE1PT/d3GMYY062sXbu2UFWTmlrX7RJBeno6a9Y01xvQGGNMU0Rkb3PrrGnIGGOCnKuJQEQuE5Ht3vK69zSx/tveyULWi8gmEakTkXg3YzLGGHMq1xKBd/j773GqNGYA80Qkw3cbVf21qmapahZwL/C2t9KjMcaYLuLmPYLJQK6q7gYQkUXANThD8psyD6c2uzEmSNTU1JCfn09lZaW/Q+kxIiMjSUtLIyys7QVp3UwEqZxaxjcfmNLUhiIShVNX5c5m1i8AFgAMGjSoqU2MMd1Qfn4+sbGxpKenIyL+DqfbU1WKiorIz89nyJAhbd7PzXsETf1Xba6w0VXAquaahVT1UVXNUdWcpKQmez8ZY7qhyspKEhISLAl0EhEhISGh3VdYbiaCfE6t556GU2GxKXOxZiFjgpIlgc7VkfPpZiJYDYwQkSEiEo7zZf9i441EpDfOfLH/djEWKD0Mr94DtdWufowxxnQ3riUCVa3FafNfilMz/RlV3SwiC0Vkoc+mc4DXG08c0unyPoAP/whLv+vqxxhjuo+ioiKysrLIysqiX79+pKamnnhfXd3yj8Y1a9bw9a9/vYsidVe3m48gJydHOzyyeOn34P2HYfYfIeumzg3MGNNuW7duZcyYMf4OA4D77ruPmJgYvvWtb51YVltbS2hotyvA0OR5FZG1qprT1PbBNbL44h9D+vnw8v+DA+v9HY0xJgDNnz+fu+66i4suuoi7776bjz76iKlTp5Kdnc3UqVPZvn07ACtWrODKK68EnCRy++23M23aNIYOHcpDDz3kzz+h3bpfquugHYdLeXTlbu6f8wQRT0yHf30eFqyA6AR/h2aMAX780ma2HCjp1GNmDIjjR1dltnu/HTt2sGzZMjweDyUlJaxcuZLQ0FCWLVvGd7/7XZ5//vnT9tm2bRtvvfUWpaWljBo1ijvuuKNdffn9KWgSwZGSKp5bm8/ofrF86ca/wpOz4Pnb4ebnwRM0p8EY0wY33HADHo8HgGPHjnHbbbexc+dORISampom97niiiuIiIggIiKC5ORkDh8+TFpaWleG3WFB8w143ohEzh+RyMNv5XJDzkX0vuI38OKd8OZPYeaP/R2eMUGvI7/c3RIdHX3i9Q9+8AMuuugiFi9ezJ49e5g2bVqT+0RERJx47fF4qK2tdTvMThNU9wjumTWaYxU1PPL2Lpj4eci5HVY9CJuX+Ds0Y0yAOnbsGKmpqQA89dRT/g3GJUGVCDIH9GZ2VipPvvspB49VwGW/gLSzYMlX4Mg2f4dnjAlA3/nOd7j33ns599xzqaur83c4rgiu7qNA3tFyZvzmbWZnD+BX10+AkgPwpwshIhYWvAWRvTsxWmNMSwKp+2hPYt1HWzEwPorPnzOY59bms+NwKcQNgM/9BYr3wuI7oJslRmOMOVNBlwgA7rxoONERofzyVW9z0OCpMOOHsP0/sHuFX2MzxpiuFpSJoG90OHdMG8bybUf4cHeRs3DKQohLg7fut6sCY0xQCcpEAHD7uUPoFxfJz1/dhqpCaARc8C3IXw073/B3eMYY02WCNhFEhnm4a+ZI1ucV8+qmQ87C7Fugbzq89TO7KjDGBI2gTQQA101KY2RKDL9eup2aunrwhMGFd8PBDbDtZX+HZ4wxXSKoE4EnRLj7stF8WnicRR/tcxaO+xwkDIe3/gfq6/0boDHGVdOmTWPp0qWnLHvwwQf5yle+0uz2Dd3XL7/8coqLi0/b5r777uOBBx5o8XOXLFnCli0np2//4Q9/yLJly9obfqcJ6kQAMH10MpOHxPO75Tspq6p16g5NuxeObIEti/0dnjHGRfPmzWPRokWnLFu0aBHz5s1rdd9XXnmFPn36dOhzGyeCn/zkJ1x88cUdOlZnCPpEICLcO2s0hWXVPLZyt7Mw81pIGgNv/Rzquk+9EGNM+1x//fW8/PLLVFVVAbBnzx4OHDjAP/7xD3JycsjMzORHP/pRk/ump6dTWFgIwP3338+oUaO4+OKLT5SpBnjsscc466yzmDBhAtdddx3l5eW89957vPjii3z7298mKyuLXbt2MX/+fJ577jkAli9fTnZ2NuPGjeP2228/EVt6ejo/+tGPmDhxIuPGjWPbts6rhhA0Redakj2oL7PG9uPxd3az4IKhREeEwkX3wjO3wifPQlbrvw6MMWfo1Xvg0Cede8x+42DWL5pdnZCQwOTJk3nttde45pprWLRoETfeeCP33nsv8fHx1NXVMWPGDDZu3Mj48eObPMbatWtZtGgRH3/8MbW1tUycOJFJkyYBcO211/LlL38ZgO9///s88cQTfO1rX+Pqq6/myiuv5Prrrz/lWJWVlcyfP5/ly5czcuRIbr31Vv74xz/yzW9+E4DExETWrVvHH/7wBx544AEef/zxzjhLdkXQYP7UdI5X1/HGlsPOgtFXQb/x8PYvoK7psrPGmO7Pt3mooVnomWeeYeLEiWRnZ7N58+ZTmnEae+edd5gzZw5RUVHExcVx9dVXn1i3adMmzj//fMaNG8fTTz/N5s2bW4xl+/btDBkyhJEjRwJw2223sXLlyhPrr732WgAmTZrEnj17Ovonn8auCLzOSo8ntU8vlqzfz+zsVAgJgYu+B/+8Edb/Aybd5u8QjenZWvjl7qbZs2dz1113sW7dOioqKujbty8PPPAAq1evpm/fvsyfP5/KysoWjyEiTS6fP38+S5YsYcKECTz11FOsWLGixeO0VvutodR1Z5e5tisCr5AQ4ZqsAbyzs5CCUqdNjpGXQmoOrPw11Fb5N0BjjCtiYmKYNm0at99+O/PmzaOkpITo6Gh69+7N4cOHefXVV1vc/4ILLmDx4sVUVFRQWlrKSy+9dGJdaWkp/fv3p6amhqeffvrE8tjYWEpLS0871ujRo9mzZw+5ubkA/O1vf+PCCy/spL+0eZYIfMzJTqWuXnl54wFngQhc9F04lgfr/urf4Iwxrpk3bx4bNmxg7ty5TJgwgezsbDIzM7n99ts599xzW9x34sSJ3HjjjWRlZXHddddx/vnnn1j305/+lClTpjBz5kxGjx59YvncuXP59a9/TXZ2Nrt27TqxPDIykj//+c/ccMMNjBs3jpCQEBYuXNj5f3AjrpahFpHLgN8BHuBxVT3t2k9EpgEPAmFAoaq2mP7OtAx1a6546B1CQ4R/33mes0AV/jwLjn4K31gPYb1c+2xjgo2VoXZHwJShFhEP8HtgFpABzBORjEbb9AH+AFytqpnADW7F01azs1LZkH+M3QVlzgIR515B2SFY86R/gzPGGBe42TQ0GchV1d2qWg0sAq5ptM1NwAuqug9AVY+4GE+bXJ01ABFYsv7AyYVDzof082HVQ9aDyBjT47iZCFKBPJ/3+d5lvkYCfUVkhYisFZFbmzqQiCwQkTUisqagoMClcB0pcZGcOyyRJR/vP/UO/tSvOVcFW1909fONCTbdbZbEQNeR8+lmImiqP1XjCEOBScAVwKXAD0Rk5Gk7qT6qqjmqmpOUlNT5kTYyOzuVfUfLWbfPp47I8JnQdwh8+CfXP9+YYBEZGUlRUZElg06iqhQVFREZGdmu/dwcR5APDPR5nwYcaGKbQlU9DhwXkZXABGCHi3G16tLMFL6/JIQlH+9n0uC+zsKQEJi8AJbeC/vXQepEf4ZoTI+QlpZGfn4+bl/pB5PIyEjS0tLatY+biWA1MEJEhgD7gbk49wR8/Rt4WERCgXBgCvC/LsbUJrGRYczM6MfLGw/wgyszCA/1Xjhl3wxv/gw+ehTmPOLfII3pAcLCwhgyZIi/wwh6rjUNqWotcCewFNgKPKOqm0VkoYgs9G6zFXgN2Ah8hNPFdJNbMbXHnOwBfFZew8odPr9UIntD1k2w6Xkos18wxpiewdUBZar6iqqOVNVhqnq/d9kjqvqIzza/VtUMVR2rqg+6GU97nD8iifjocJas33/qiskLoK4a1j7ll7iMMaaz2cjiZoR5QrhyfH/e2HKY0kqfLqNJI2HYdFjzhHUlNcb0CJYIWjA7O5Wq2npea5jTuMGUhVB60LqSGmN6BEsELcge2IfBCVGnNw9ZV1JjTA9iiaAFIsLsrFTe21XEoWM+ZWhDQmDKf0Heh3DgY/8FaIwxncASQStmZ6eiCi9taDQEIusmCIuGDx/1T2DGGNNJLBG0YkhiNBMG9mHxx42ah050JX3OupIaY7o1SwRtMCdrAFsOlrD9UKOJJKwrqTGmB7BE0AZXThiAJ0ROv2lsXUmNMT2AJYI2SIyJ4Lzhiby88cDpxbGsK6kxppuzRNBGl2b2I+9oBTsOl526wrqSGmO6OUsEbXTxmGQAlm09fOoK60pqjOnmLBG0UXJcJBMG9uH1LYdPX9nQlXT1410fmDHGnCFLBO0wc0wyG/KKOVJSeeqKyN4wdg5sXgLVx/0TnDHGdJAlgnaYmdEPgOXbmphaOesWqC6DLXbT2BjTvVgiaIeRKTEMjO/FG001Dw0627lpvP7prg/MGGPOgCWCdhARZo7px7u5hZRX1zZeCVk3w5534LM9fonPGGM6whJBO12ckUx1bT0rdxSevnLCXEBgw6Iuj8sYYzrKEkE7nZUeT+9eYad3IwXoMxCGXug0D9XXd31wxhjTAZYI2inME8JFo5J4c9sR6ur19A2yboHifbB3VdcHZ4wxHWCJoANmZvTj6PFq1u377PSVo6+AiDhY/4+uD8wYYzrAEkEHXDAykTCPsKyp3kPhUTD2WtiyBKpKT19vjDEBxtVEICKXich2EckVkXuaWD9NRI6JyHrv44duxtNZYiPDOHtoQtPdSMHpPVRTDlv+3bWBGWNMB7iWCETEA/wemAVkAPNEJKOJTd9R1Szv4yduxdPZLslIYXfhcXYVlJ2+Mu0sSBgBH9uYAmNM4HPzimAykKuqu1W1GlgEXOPi53WpGWNSAJq+KhBx6g/tew+KdnVxZMYY0z5uJoJUIM/nfb53WWPniMgGEXlVRDKbOpCILBCRNSKypqAgMKaFHNCnF2NT45q+TwDOmAIJsTEFxpiA52YikCaWNe5vuQ4YrKoTgP8DljR1IFV9VFVzVDUnKSmpk8PsuIvHpLB232cUllWdvjJugDN72YZ/2pgCY0xAczMR5AMDfd6nAQd8N1DVElUt875+BQgTkUQXY+pUMzNSUIU3mypCB07z0LE82LOyawMzxph2cDMRrAZGiMgQEQkH5gKnlOYUkX4iIt7Xk73xFLkYU6fK6B9Hap9mitABjLrCKVFtN42NMQHMtUSgqrXAncBSYCvwjKpuFpGFIrLQu9n1wCYR2QA8BMzV0yYFDlwiwsVjknlnZwGVNXWnbxAWCWOvh60vQeWxrg/QGGPawNVxBKr6iqqOVNVhqnq/d9kjqvqI9/XDqpqpqhNU9WxVfc/NeNxwcUYKlTX1rMptoggdOGMKaiucSWuMMSYA2cjiMzRlSAKxEaHNNw+lToSk0TZPgTEmYFkiOEPhoSFcOCqJZVuPUN9UEbqGMQV5H0JhbtcHaIwxrbBE0AlmZqRQWFbF+vzipjcY3zCmwArRGWMCjyWCTjBtZDKhIdJ881BsCgybARufsTEFxpiAY4mgE/SOCuOs9Hjeam48ATgjjY/lwd53uy4wY4xpA0sEnWTGmGS2HSol/7PypjdomKfASk4YYwKMJYJOMn10MtDCKOOwXpA52ylNXX28CyMzxpiWWSLoJEOTYhiaGM3yrS01D82D6jLY+nLXBWaMMa2wRNCJpo9O5v1dRRyvqm16g4FnQ5/BTiE6Y4wJEJYIOtH0MclU17UwyjgkxLkq2L0CSg40vY0xxnQxSwSd6Kz0eGIjQpu/TwAw4UZAYeO/uiwuY4xpiSWCThTmCeGCUUks39bMKGOA+KFOE9GGRdB96usZY3owSwSdbMboZApKq9h0oIVqoxPmQsE2OLi+6wIzxphmWCLoZNNGJRMitNx7KHMOeCJsTIExJiBYIuhk8dHhTBzUt+X7BL36wOjL4ZNnoba664IzxpgmWCJwwfQxyXyy/xiHSyqb32jCPCgvgtxlXReYMcY0wRKBC2aMTgFoufbQsBkQnWRjCowxfmeJwAUjU2JI7dOL5S0lAk8ojPsc7HgNyo92XXDGGNOIJQIXiAgzxiTz7s7CpucybjBhLtRVw+YXui44Y4xpxBKBS6aPTqaipo73dxc1v1G/cZCcab2HjDF+ZYnAJWcPTSAq3MObLXUjFYGseZC/2qaxNMb4jauJQEQuE5HtIpIrIve0sN1ZIlInIte7GU9XigzzcN7wRN7cdgRtaQTxuBucaSw32lWBMcY/XEsEIuIBfg/MAjKAeSKS0cx2vwSWuhWLv8wYk8z+4gq2Hy5tfqPYfjBsutM8ZNNYGmP8wM0rgslArqruVtVqYBFwTRPbfQ14HmihDaV7umiUM1lNi6OMwRlTYNNYGmP8xM1EkArk+bzP9y47QURSgTnAIy0dSEQWiMgaEVlTUFDQ6YG6JTkukvFpvVm+tZlJ7RuMvgIiesPHT3dNYMYY48PNRCBNLGvcWP4gcLeqttDHElT1UVXNUdWcpKSkTguwK0wfnczHecUUlVU1v1FYLxh3nTONZWVJ1wVnjDG4mwjygYE+79OAxrOx5ACLRGQPcD3wBxGZ7WJMXW7G6BRUYcX2Vq5ksm6B2gobU2CM6XJuJoLVwAgRGSIi4cBc4EXfDVR1iKqmq2o68BzwFVVd4mJMXW5sahwpcREtF6EDSJ0ISaOtecgY0+VaTAQicpWIDPZ5/0MR2SAiL4rIkJb2VdVa4E6c3kBbgWdUdbOILBSRhZ0RfHcgIkwfnczKHQVU17bQK0gEsm6G/I+gYEfXBWiMCXqtXRHcDxQAiMiVwC3A7Ti/7Fu8wQugqq+o6khVHaaq93uXPaKqp+2rqvNV9bn2/gHdwfTRKZRW1bJ6Tys1hcbfCOKB9XZVYIzpOq0lAlXVcu/ra4EnVHWtqj4OdK+7tn507vAEIkJDeGNLK72HYlNgxCXOmIK62q4JzhgT9FpLBCIiMSISAswAlvusi3QvrJ4lKjyU80ck8caWwy2PMgbIvhnKDsGuN7smOGNM0GstETwIrAfWAFtVdQ2AiGQDB12OrUe5JCOF/cUVbD7QSvfQEZdCVAKs/3vXBGaMCXotJgJVfRK4EPgicLnPqoPAF1yMq8eZMcaZy7jV5qHQcBg/F7a9AsdbqFxqjDGdpLVeQ4OBMlX9WFXrReQiEfkdcBNwqEsi7CESYiLIGRzP660lAnCah+prnDmNjTHGZa01DT0DRAOISBbwLLAPmAD8wd3Qep5LMlPYerCEvKPlLW+Ykgn9s6x5yBjTJVpLBL1UtWE08C3Ak6r6G5xmocmuRtYDzcxw5jJu21XBLXDoEzi40eWojDHBrtVeQz6vp+PtNaSqVi+5AwYnRDMqJZY3trShVW3sdeAJtzEFxhjXtZYI3hSRZ7z3BfoCbwKISH+g2u3geqJLMlP46NOjfHa8ldMXFe9UJd34DNTaqTbGuKe1RPBN4AVgD3CeqtZ4l/cDvudiXD3WJRn9qFdY3lrtIXAK0VUchR2vuh+YMSZotdZ9VFV1EbAEyBaRK0RkqLcXUY+bUawrjE2No3/vSF7f3IbmoWEXQewAK0RnjHFVa91H40TkGWAZTo2hLwHLRORZEYnrigB7GhFhZkYKK3cWUFHd4jQMEOJxJrfPfQNKbPyeMcYdrTUNPQRsAUao6rWqOgcYBnwCPOx2cD3VJRn9qKyp593cwtY3zroZtN4mtzfGuKa1RHCuqt7n20vI21z0E+Acd0PruaYMjSc2MrRtzUMJw2DQOU7zUGt1iowxpgPa033UdJIwTwgzRiezbOthauva0BN30nwo2gm5y1yPzRgTfFpLBKu8k9GckhBE5AfAB+6F1fPNzOjHZ+U1rN37WesbZ14Lcamw6nfuB2aMCTqtJYKvAeOAXBF5XkSeE5FdOCUm7nQ9uh7swlFJhHvaMEcBOIXozvkq7HkH8te6H5wxJqi01n20RFVvAC4BngL+Clyiqtdj1UfPSExEKOcOT+D1tsxRADDxVojsDasedD84Y0xQadPk9aq6S1VfUtUXVXWXd/FdLsYVFC7J7Me+o+VsP1za+sYRsXDWl2DrS1C0q/XtjTGmjdqUCJphN5LP0IwxyYjA65vb0DwEMGWhU3/ovf9zNzBjTFA5k0RgfRnPUHJsJNkD+7TtPgFATDJk3QTr/wGlbdzHGGNa0drI4lIRKWniUQoMaO3gInKZiGwXkVwRuaeJ9deIyEYRWS8ia0TkvDP4W7qlSzL78cn+YxwormjbDlO/BnXV8NGf3A3MGBM0WrtZHKuqcU08YlU1tKV9RcQD/B6YBWQA80Qko9Fmy4EJqpqFU8Li8Y7/Kd3TJd45Ctp8VZAwDMZcBasfh6o23FswxphWnEnTUGsmA7mqultVq4FFwDW+G6hqmZ7sMhNNEDY3DU2KYVhSNK+3ZY6CBud9EyqPwdq/uBeYMSZouJkIUoE8n/f53mWnEJE5IrIN+A/OVcFpRGSBt+loTUFBgSvB+tMlmf34cPdRjpXXtL4xQOokSD8fPviDzVVgjDljbiaCpnoVnfaLX1UXq+poYDbw06YOpKqPqmqOquYkJSV1cpj+d/nY/tTWK//5pB0VRs/9BpTsh03PuxeYMSYouJkI8oGBPu/TgAPNbIuqrgSGiUiiizEFpLGpcYxIjuG5tXmtb9xg+MWQnOmUnbBidMaYM+BmIlgNjBCRISISDswFXvTdQESGN9QxEpGJQDhQ5GJMAUlEuH5SGuv2FbO7oKytOzlXBQVbYefr7gZojOnRXEsEqlqLU49oKbAVeEZVN4vIQhFZ6N3sOmCTiKzH6WF0o7ap3kLPMyc7lRCB59flt32nsddCXJoVozPGnBE3rwhQ1VdUdaSqDlPV+73LHlHVR7yvf6mqmaqaparnqOq7bsYTyJLjIrlgZBIvrNtPXX0bc6EnzClGt3cV5K12N0BjTI/laiIw7XP9pDQOHqvk/V3taB2beCtE9oF3fuNeYMaYHs0SQQC5eEwKcZGh7btpHBHj3CvY8Spse8W94IwxPZYlggASGebhqgkDeG3zIUor2zimAJyyE8mZ8J//hsoS9wI0xvRIlggCzHWT0qisqeeV9owp8ITB1Q9B6UFY/hP3gjPG9EiWCAJM9sA+DE2K5vm1+9u3Y1oOTPkvpwZR3kfuBGeM6ZEsEQQYEeG6iWl8tOcoewqPt2/n6d935jZ+8etWesIY02aWCALQtRNTEYEX2jOmAJxZzK78rTPIzKa0NMa0kSWCANS/dy/OG57I8+v2U9/WMQUNRl4KmdfCyl9DwQ53AjTG9CiWCALU9ZPS2F9cwQefdqDixqxfQlgUvPQNqK/v/OCMMT2KJYIAdUlGP2IjQtt/0xicKS0v+Rnsew/W2ZwFxpiWWSIIUL3CPVwxvj+vbjrI8ara9h8g+xZnzoI3fgSl7Zj0xhgTdCwRBLDrJ6VRXl3XvjEFDUTgqt9BbSW8+p3OD84Y02NYIghgkwb3JT0hqn0VSX0lDINpd8OWfzsPY4xpgiWCANYwpuCD3UfJO1resYNM/Tr0z4IXFkDu8s4N0BjTI1giCHDXTkrzjinowE1jcMpP3PICJI6Af86Dncs6N0BjTLdniSDApfbpxTlDE3huXV7b5yloLDoBbn0RkuZIrVMAABmMSURBVEbBonmwY2nnBmmM6dYsEXQDt54zmLyjFR2/VwAQFQ+3/huSM2DRzbD91c4L0BjTrVki6AYuzezHhLTePPjGDipr6jp+oKh4uHUJ9BsH//o8bPtP5wVpjOm2LBF0AyLC3bNGc+BYJX97f++ZHaxXX/j8Yug/AZ65Fba+1DlBGmO6LUsE3cTUYYlcMDKJh9/K5VhFOyataUqvPvD5F2BANjw737qWGhPkLBF0I3dfNopjFTX86e1dZ36wyN5Ob6LUSfDsF2DFL6G6nWWvjTE9gquJQEQuE5HtIpIrIvc0sf5mEdnofbwnIhPcjKe7yxzQm2uyBvDkqk85XFJ55geMjINbnocxV8GK/4GHJsK6v0L9GdyHMMZ0O64lAhHxAL8HZgEZwDwRyWi02afAhao6Hvgp8Khb8fQU/z1zFHX1yoPLdnbOASNi4XN/gduXQp+B8OLX4JHznfEG2sHuqsaYbiXUxWNPBnJVdTeAiCwCrgG2NGygqu/5bP8BkOZiPD3CoIQobp4ymL99sJcvnT+EYUkxnXTgs+GLb8CWJbDsPnj6Ohg6DWb+FPqP75zPMMacShVqKpxm2ZrjUF3uvK8pd+qE1fi8r6lwqgSkn9vpYbiZCFKBPJ/3+cCUFrb/ItBk53YRWQAsABg0aFBnxddt3Tl9OM+uyeOBpdv54y2TOu/AIpA5B0ZdAWuegLd/CX+6AMbfCDlfgLTJEGK3lYxpVV0tHMuDo7udR9Eu57n0gPOlX13ufS4D2nHlPfXr3S4RSBPLmvyLReQinERwXlPrVfVRvM1GOTk5Qd9ekRgTwZcvGMqDy3ayPq+YrIF9OvcDQsPh7Dtgwlx457fw0aOwcZEzH3LGbBh7rXOTWZr6T2xMEFCF4wVQnAfFe50v/eI8KN4HR3fBZ3uh3qd3X1g0xA+F3qkQHgPh0T7PPo+wXs62Yb2cyaXCekFYpM/rKFf+HFGX2oFF5BzgPlW91Pv+XgBV/Xmj7cYDi4FZqtrq3Io5OTm6Zs0aFyLuXsqqarnwV28xIiWGf375bMTNL+WqUmck8qYXYNdyqKuG3oMgc7ZzBTEg25KC6dnKjsDWF53yLEd3w7F8p+nGV0Rv6DMI4oc4lX/jh0L8MOd1TIrf/42IyFpVzWlynYuJIBTYAcwA9gOrgZtUdbPPNoOAN4FbG90vaJYlgpOeWvUp9720hae+cBbTRiV3zYdWFMP2V2DzYtj1JtTXOkkh/TwYfA4MPtf5B2CJwXR3x4ucL//Ni2HPO6D1kDACUjKdjhW9B3mfBzrPkb39HXGL/JIIvB98OfAg4AGeVNX7RWQhgKo+IiKPA9cBDcNla5sLtIElgpOqa+uZ8dsVxESE8Z+vnUdISBd/+ZYfdcpU7HgN9r0P5d75lWNSYJA3KQw+B5Iz7d6C6R4a/p/evBh2rwCtc37Vj70WMq+F5DHd9keO3xKBGywRnOrf6/fzjUXr+d3cLK7JSvVfIKpQuAP2roK978Pe96DEWyQvsjcMmgqDpzrJof8E8Lh5e8qYVtRUQMF2OLIVjmzxPm89+f9s33Tniz9zjlObq5t++fuyRNCD1dcrVz38LodLqljy1amk9XXnZlKHFO9zEsLeVc5zUa6zPCwaBk05mRhSc5wb1Ma4oawADm6Ag+ud58ObnXb+hr4rnghIGulU5k0eA0Mu7JH3vSwR9HC5R0qZ84f3GNC7F8/ecQ5xkWH+DqlppYe8icGbHI54h5SERcPQC2H4xTBipnPDzZj2qq1ybuIWbPd+8XsfpQdObhM/zGnjT8l0vvSTM6DvkKC4QrVEEARW5RZy25Mfcc6wBJ6cfxZhnm7QJl9+1EkIu950RjIf2+csTxzlJIThFztXDaER/o3TBI7aaud+1Gd7nCvO4n1O983ifVB68OR2EgKJI51myP4TnIFY/cY5ZVWClCWCIPGv1fu4+/lPuGnKIO6fPdbdLqWdreEew843IHeZkyDqqp2rhcHnOL2S0s/33l8I0Cse4x5Vp1PC0u85/fQBxOP0y+8z2PsY5DwSvL/6w6P9G3OAaSkR9PzroSBy41mD2FNUzh9X7CI9IYoFFwzzd0htJ+JMpZk0Cqbe6Yy6/PQdJynseccpewHe+wtnn0wMA7IsMfR0hzfD0u86vXgSR8INf4HUiRA7ICiadLqCncUe5tuXjGJfUTk/f3Ubg+KjuGxsf3+H1DHh0TDqMucBzg2/vatgz7vOY/mPvdvFwpgrnTIYQy6AEI//Yjadq6wA3rof1v0FIuJg1q8g53ZL/C6wpqEeqLKmjnmPfcDWgyUsWnBO55egCAQNiSF3mTOxTlWJ8wtx/A0wfi6kNC50a7qN2ir48BFY+YBTbO2sL8GFdztTrZoOs3sEQaiwrIrZv19FZU194HUr7Ww1FU4JjI3/chJDfa1zY3DCPBh7PcSm+DtC05qSg85N4H0fwI5XnZu/Iy6FS37mdO00Z8wSQZBq6Fbav3ckz90xNXC7lXamsgLY9LxTJO/Ax07vkfTznZGhY662X5WBoKFjQMMX/973nJ4/4BRVSzsLzv2602vMdBpLBEGsoVvpiJRYHr4pu/PmL+gOCrbDJ886xfKO7oKQUGeOhbHXwegrAr42TI9QXQ4FW50bvg2PQ59AZbGzPirRufk/6Bynd1i/8XYPwCWWCILcW9uPcNe/1lNVW8/PZo/l2olBNv+PKhza6FwpbFrsjFfwhDu/OEfNcvqYJ4220c2doTjPKdSW95F3BO8up1gbOL/2kzOcrp1pOc6Xf8LwHjeCN1BZIjAcPFbBNxat56NPj3LdxDR+ck0m0RFB2GlMFfavda4SNi8+Oeo0JMwZaXpiANIE64veVsfynRv2m5dA/kfOsr7pkDLW+/CO5O07xIoP+pElAgNAbV09D72Zy/+9uZMhidE8PG8iGQOCd6Ql9fVOzZlDDeUINjrPFUed9RLi3HQefjEMmwEDJ1uzRYOSA94v/8WQ96GzrN94Z46KjNnOoC4TUCwRmFO8t6uQby5aT3FFDT+4Ygy3nD24e41CdpMqlOz3JoX1zqC2vA+dcsThsU5NpGHTYfgM51dvsKg+7lSV/fRt+HSlc27ASZQZ3gmK7Ms/oFkiMKcpLKviv5/ZwNs7Cpg1th/3zxlHfLS1kTep8pjz5Ze7DHLfPFkTKWG408OloekjZSzEdNEEQW6rrYL81c7f/elK53V9rXNvJW0yDJsGGXMgcbi/IzVtZInANKm+Xnnsnd38eul2osI9fH3GCG49J53wUGvHbZaqU047dxnsesu5Ce1b7Cwq8WRS6D8eRl3ePQqd+f5ductgzyqorXCaxwZkO6O2h1wAA8+G8B48JqUHs0RgWrTjcCk/fXkL7+wsZEhiNN+7fAwzxiRbc1FbHS+CIw3dIzc5z0e2OV+k4bGQfTNMXhB4TSdVpT5XOsucQVzgTMc4bLrT1XbwVOjVA0emByFLBKZVqsqK7QX87D9b2FVwnHOHJ/D9KzIY078b/JoNRPV1zoC2jx5zuq3W18DwmTBlofMleya9Z2qroeyw0+0yKgHCerUSS70z81bhTudXf+FOJ1nlf+Q094THOF/6wXjvI4hYIjBtVlNXz9Mf7OV/l+2ktLKGG88axH9fMpLEGJsToMNKD8Pap2DNE84XeMJwmPxfTl0kxKmnU1Ph3JCtKXce1eVQ8ZnT7FRy4NTn4wWnHj8s2kkIUfEQnei8juwDZYegaJfzqK04uX1Eb0gcAUPOd3pEpU22MRRBwBKBabfi8mp+t3wnf3t/L5FhHm49ZzC3nzfEEsKZqK12ulx++Ajsb8f/w1EJTkG9uP4Q2x/iBkBsP0CgvNCZ4Od4IZQXed8XQflnEJPkNPMkjnCST+JI53V0kg3iCkKWCEyH7Soo47ev7+CVTQcJ94Qw96yBfPmCoT27iF1XyF/rdMUMjXSadsKjneewqJOvI3s7X/w2Q5vpBH5LBCJyGfA7wAM8rqq/aLR+NPBnYCLwPVV9oLVjWiLwj10FZfzp7V28sG4/ANdkpXLHtKEMT471c2TGmLbwSyIQEQ+wA5gJ5AOrgXmqusVnm2RgMDAb+MwSQeDbX1zBYyt3s2j1Pqpq67k0ox9fuWgY49OsZ4kxgaylROBmh/HJQK6q7lbVamARcI3vBqp6RFVXAzUuxmE6UWqfXtx3dSar7p7OV6cNZ9WuQq5+eBWfe+R9Xtt0iLr67tXUaIxxNxGkAnk+7/O9y9pNRBaIyBoRWVNQUND6DsZ1CTERfOvSUay6Zzrfu3wM+4srWPj3tVz0wAqefPdTSisttxvTXbiZCJrqltChn4uq+qiq5qhqTlJS0hmGZTpTXGQYX75gKG9/exp/uHkiSbER/OTlLUz9+Zv89OUt5B0t93eIxphWuFmHOB8Y6PM+DTjg4ucZPwr1hHD5uP5cPq4/6/OKefLdT/nLe3v486pPuXhMCjeeNZALRyYR6rHyFcYEGjcTwWpghIgMAfYDc4GbXPw8EyCyBvbhoXnZ3Hv5aP76/l6eXZPH61sOkxIXwXUT0/hczkDSE63OvzGBwu3uo5cDD+J0H31SVe8XkYUAqvqIiPQD1gBxQD1QBmSoaklzx7ReQ91PTV09y7ce4Zk1eazYfoR6hSlD4rnxrIHMGtufXuEef4doTI9nA8pMwDh0rJLn1+XzzJo89haVExsZypXj+3PVhAFMGZKAJ8RGvBrjBksEJuDU1ysffnqUZ9fk8drmQ5RX15EcG8GV4wdwddYAJqT1tuqnxnQiSwQmoFVU17F822FeXH+AFdsLqK6rZ1B8FFdN6M/VE1IZ1c9GLxtzpiwRmG7jWEUNSzcf4qUNB1iVW0i9QnpCFNNGJXPR6GSmDIknMszuKRjTXpYITLdUUFrFa5sO8ua2I7y3q4iq2np6hXk4d3jCicSQ2qeVWvzGGMASgekBKmvqeH9XEW9tP8Kb246Q/5lTX39kSgw56fFMHNSXiYP6MCQx2u4tGNMESwSmR1FVdhWU8da2AlbuLGD9vmJKq2oB6BMVRvbAPk5iGNyXCQP7EBPh5nAZY7qHlhKB/Qsx3Y6IMDw5luHJsXz5gqHU1Su5R8r4eN9nrNv3Gev2FfPW9gLvtpCeEE3GgDgyB8SR0T+OzAG9SYq1Gv/GNLArAtMjHauoYX1eMRvyitl84BhbDpaQd/TkdI3JsRFkDohjZL9YhiREMzghmvTEKFJiIwmxsQymB7IrAhN0evcK48KRSVw48mSRwmMVNWw5UHIiMWw5UMK7uYXU1J38MRQZFsLg+GgGJ0SRnhjNwPgo0vr2YmDfXqT1jbIeS6ZHskRggkbvXmGcMyyBc4YlnFhWV68cKK5gb1E5e4qOs6fwOHuKyvm08DgrdhRQXVt/yjESYyIYGO8khbS+vejfO5Lk2EhS4iJIiYskKTaCMCusZ7oZSwQmqHlChIHxUQyMj+K8EYmnrKuvV46UVpH/WTn5n1WQd9R5zi8uZ0NeMa9+cpDaRhPxiEBCdAQpcREkx0aQEBNBQnQ48d5HQkw48dEnl0WFe6yXk/E7SwTGNCMkROjXO5J+vSPJST99fV29UnS8iiMlVRwpreRwSRWHS5znIyWVHC6tZPuhUgqPV592ZdEgMiyEhOgIEmLCSYgOP5E4EmLC6RvlPPpEhdEnKozevcLp3SuM8FC74jCdyxKBMR3kCRGSY52mIejd7HaqyvHqOo6WVVN0vIqjx6spOl5NUVk1R49XnXhdWFbdauIAiA730CcqnNjIUOIiw4iJDCU2MpSYiFBiI8OI9b6PCg8lOtxDVITz3CvcQ3R4KFERznOvMI/dGDeAJQJjXCcixEQ4X9SDEqJa3d43cRyrqKG4opri8hqKK2ooPl5NcUUNn5VXU1pZS2llDUdKK9lVUEtZZS2llbVU1zWfRBprSBQxEaFEhXuI9iaN6AgnUUSFe+gV7qzrFeYkk6hwD5FhHsI9IYSH+jw8J58jwhqePUSEhhAaItYEFsAsERgTYHwTR0dU1tRRWllLRXUdx6trKa+upby6juNVdT6vTz4fr67leNXJ14Vl1ew9Wk5FdR3l1XVUVNe1K7k0/TdBRGgIEaEewkND8IggcnI+24YkIQIhIoR65ERiCfOEEOYRwjxOcgnzWR4eGkJEqLPeSUIewkLlxOdE+CSrCO9zaEgIoR7BEyKEhjQ8h+AJObkspOFZTn3vCZETMYaIIN6Yu3uSs0RgTA8TGebp9G6utXX1lNfUUdmQHGrqqKmrp7rWeVR5X5+yrLaeqto6n9cNy+uoq1cahjApoAqKgkK9KjX1So33eDV1SnVdPWVVtSeOX1OnJ45b4/PZjW/ed5WTycFJCiECgvMc4k16ISENieNkAvHufSIp+h7D95gNx5g3eRBfOn9op8dvicAY06pQTwhxnhDiIsP8HUqL6uudpNGQdKrr6qmqca5ofBNHXb2eeNSe8lxPXT2Nnp119eo8qzrNd/XepOX7vu6U987rk9s52yinJ0Fo2M/Ztt73GJw8RmKMOyPiLREYY3qMkBAhMqTzr4h6OuuHZowxQc4SgTHGBDlLBMYYE+RcTQQicpmIbBeRXBG5p4n1IiIPeddvFJGJbsZjjDHmdK4lAhHxAL8HZgEZwDwRyWi02SxghPexAPijW/EYY4xpmptXBJOBXFXdrarVwCLgmkbbXAP8VR0fAH1EpL+LMRljjGnEzUSQCuT5vM/3LmvvNojIAhFZIyJrCgoKOj1QY4wJZm4mgqbGXDce9teWbVDVR1U1R1VzkpKSmtjFGGNMR7k5oCwfGOjzPg040IFtTrF27dpCEdnbwZgSgcIO7us2i61jAjk2COz4LLaO6a6xDW5uJzcTwWpghIgMAfYDc4GbGm3zInCniCwCpgDHVPVgSwdV1Q5fEojImubm7PQ3i61jAjk2COz4LLaO6YmxuZYIVLVWRO4ElgIe4ElV3SwiC73rHwFeAS4HcoFy4AtuxWOMMaZprtYaUtVXcL7sfZc94vNaga+6GYMxxpiWBdvI4kf9HUALLLaOCeTYILDjs9g6psfFJqr+qd9tjDEmMATbFYExxphGLBEYY0yQC5pE0FoBPH8SkT0i8omIrBeRNX6O5UkROSIim3yWxYvIGyKy0/vcN4Biu09E9nvP3XoRudxPsQ0UkbdEZKuIbBaRb3iX+/3ctRCb38+diESKyEcissEb24+9ywPhvDUXm9/Pm0+MHhH5WERe9r7v0HkLinsE3gJ4O4CZOIPYVgPzVHWLXwPzEpE9QI6q+n2QiohcAJTh1IAa6132K+Coqv7Cm0T7qurdARLbfUCZqj7Q1fE0iq0/0F9V14lILLAWmA3Mx8/nroXYPoefz504s75Hq2qZiIQB7wLfAK7F/+etudguIwD+nwMQkbuAHCBOVa/s6L/VYLkiaEsBPAOo6krgaKPF1wB/8b7+C86XSJdrJraAoKoHVXWd93UpsBWnbpbfz10Lsfmdt+BkmfdtmPehBMZ5ay62gCAiacAVwOM+izt03oIlEbSpuJ0fKfC6iKwVkQX+DqYJKQ0jvr3PyX6Op7E7vfNZPOmvZitfIpIOZAMfEmDnrlFsEADnztu8sR44AryhqgFz3pqJDQLgvAEPAt8B6n2Wdei8BUsiaFNxOz86V1Un4szP8FVvE4hpmz8Cw4As4CDwG38GIyIxwPPAN1W1xJ+xNNZEbAFx7lS1TlWzcGqNTRaRsf6IoynNxOb38yYiVwJHVHVtZxwvWBJBu4vbdSVVPeB9PgIsxmnKCiSHve3MDe3NR/wczwmqetj7j7UeeAw/njtvO/LzwNOq+oJ3cUCcu6ZiC6Rz542nGFiB0wYfEOetgW9sAXLezgWu9t5fXARMF5G/08HzFiyJ4EQBPBEJxymA96KfYwJARKK9N/AQkWjgEmBTy3t1uReB27yvbwP+7cdYTiGnTmQ0Bz+dO++NxSeArar6W59Vfj93zcUWCOdORJJEpI/3dS/gYmAbgXHemowtEM6bqt6rqmmqmo7zffamqt5CR8+bqgbFA6e43Q5gF/A9f8fjE9dQYIP3sdnfsQH/xLncrcG5kvoikAAsB3Z6n+MDKLa/AZ8AG73/CPr7KbbzcJobNwLrvY/LA+HctRCb388dMB742BvDJuCH3uWBcN6ai83v561RnNOAl8/kvAVF91FjjDHNC5amIWOMMc2wRGCMMUHOEoExxgQ5SwTGGBPkLBEYY0yQs0RgTCMiUudTWXK9dGK1WhFJF5/qqcYEAlfnLDamm6pQp6yAMUHBrgiMaSNx5o34pbdG/UciMty7fLCILPcWIVsuIoO8y1NEZLG3nv0GEZnqPZRHRB7z1rh/3Ttq1Ri/sURgzOl6NWoautFnXYmqTgYexqn+iPf1X1V1PPA08JB3+UPA26o6AZiIM3IcYATwe1XNBIqB61z+e4xpkY0sNqYRESlT1Zgmlu8Bpqvqbm8Rt0OqmiAihThlBmq8yw+qaqKIFABpqlrlc4x0nHLGI7zv7wbCVPVn7v9lxjTNrgiMaR9t5nVz2zSlyud1HXavzviZJQJj2udGn+f3va/fw6kACXAzzpSG4BT9ugNOTHAS11VBGtMe9kvEmNP18s5K1eA1VW3oQhohIh/i/Iia5132deBJEfk2UAB8wbv8G8CjIvJFnF/+d+BUTzUmoNg9AmPayHuPIEdVC/0dizGdyZqGjDEmyNkVgTHGBDm7IjDGmCBnicAYY4KcJQJjjAlylgiMMSbIWSIwxpgg9/8BVAGhsIKvqjMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric_names = ['loss' ,'accuracy']\n",
    "#metric_names = ['loss']\n",
    "\n",
    "for i, j in zip(metric_names, ['val_'+i for i in metric_names]):\n",
    "    plt.plot(history.history[i])\n",
    "    plt.plot(history.history[j])\n",
    "    plt.title('Model '+i)\n",
    "    plt.ylabel(i.upper())\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = tf.keras.models.load_model(\n",
    "    filepath=\"../results/\"+MODEL_PREFIX+\"Checkpoint.h5\",\n",
    "    compile=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5418/5418 [==============================] - 1s 194us/sample - loss: 0.1152 - accuracy: 0.9355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11519232092527676, 0.93551505]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x = [X_sentiments_val, X_val], y=Y2_val, batch_size=PREDICT_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(x = [X_sentiments_train, X_train], batch_size=PREDICT_BATCH_SIZE)\n",
    "pred_val = model.predict(x = [X_sentiments_val, X_val], batch_size=PREDICT_BATCH_SIZE)\n",
    "pred_test = model.predict(x = [X_sentiments_test, X_test], batch_size=PREDICT_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21670, 108), (21670, 108), (21670, 108))"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, pred_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Accuracy: TRAINING: \t 0.9182993214719103\n",
      "Min Accuracy: VALIDATION: \t 0.918165443036244\n"
     ]
    }
   ],
   "source": [
    "# Accuracy is not a good metric\n",
    "print(\"Min Accuracy: TRAINING: \\t\", np.sum(Y_train == 0) / (Y_train.shape[0] * Y_train.shape[1]))\n",
    "print(\"Min Accuracy: VALIDATION: \\t\", np.sum(Y_val == 0) / (Y_val.shape[0] * Y_val.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_labels = {i:j for i,j in enumerate(df.sentiment_code.cat.categories)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_words = [i[j>0.5].tolist() for i,j in zip(X_train, pred_train)]\n",
    "pred_val_words = [i[j>0.5].tolist() for i,j in zip(X_val, pred_val)]\n",
    "pred_test_words = [i[j>0.5].tolist() for i,j in zip(X_test, pred_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spot Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spot_check(index_to_check, mode):\n",
    "    print(\"================== Sample #\", index_to_check, \"==================\")\n",
    "    if mode == \"train\":\n",
    "        print(\"Sentiment:\")\n",
    "        print('\\t', sent_labels[X_sentiments_train[index_to_check]])\n",
    "        print(\"Selected_text:\")\n",
    "        print('\\t', Y_words[train_idx[index_to_check]])\n",
    "        print(\"Predicted_text:\")\n",
    "        print('\\t', [get_from_vocab(vocab_itos,j) for j in pred_train_words[index_to_check]])\n",
    "        print(\"Predictions:\")\n",
    "        print('\\t',*[[\"%.2f\"%j,\n",
    "                      i,\n",
    "                      X_words[train_idx[index_to_check]][num]] for num, (i,j) in enumerate(zip(X_train[index_to_check].tolist(),\n",
    "                                                                                               pred_train[index_to_check].tolist())) if i!=0], sep=\"\\n\\t\")\n",
    "        \n",
    "    elif mode == \"validation\":\n",
    "        print(\"Sentiment:\")\n",
    "        print('\\t', sent_labels[X_sentiments_val[index_to_check]])\n",
    "        print(\"Selected_text:\")\n",
    "        print('\\t', Y_words[val_idx[index_to_check]])\n",
    "        print(\"Predicted_text:\")\n",
    "        print('\\t', [get_from_vocab(vocab_itos,j) for j in pred_val_words[index_to_check]])\n",
    "        print(\"Predictions:\")\n",
    "        print('\\t',*[[\"%.2f\"%j,\n",
    "                      i,\n",
    "                      X_words[val_idx[index_to_check]][num]] for num, (i,j) in enumerate(zip(X_val[index_to_check].tolist(),\n",
    "                                                                                             pred_val[index_to_check].tolist())) if i!=0], sep=\"\\n\\t\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Sentiment:\")\n",
    "        print('\\t', sent_labels[X_sentiments_test[index_to_check]])\n",
    "        print(\"Selected_text:\")\n",
    "        print('\\t', \"Not Available\")\n",
    "        print(\"Predicted_text:\")\n",
    "        print('\\t', [get_from_vocab(vocab_itos,j) for j in pred_test_words[index_to_check]])\n",
    "        print(\"Predictions:\")\n",
    "        print('\\t',*[[\"%.2f\"%j,\n",
    "                      i,\n",
    "                      X_test_words[index_to_check][num]] for num, (i,j) in enumerate(zip(X_test[index_to_check].tolist(),\n",
    "                                                                                         pred_test[index_to_check].tolist())) if i!=0], sep=\"\\n\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Sample # 10 ==================\n",
      "Sentiment:\n",
      "\t positive\n",
      "Selected_text:\n",
      "\t ['love']\n",
      "Predicted_text:\n",
      "\t []\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.00', 16352, 'digging']\n",
      "\t['0.00', 26841, 'a']\n",
      "\t['0.00', 20091, 'downloaded']\n",
      "\t['0.00', 25241, 'film']\n",
      "\t['0.01', 18963, 'with']\n",
      "\t['0.01', 6073, 'mi']\n",
      "\t['0.01', 13146, 'familia']\n",
      "\t['0.02', 11591, '.']\n",
      "\t['0.02', 12445, 'we']\n",
      "\t['0.04', 9847, 'love']\n",
      "\t['0.02', 11703, 'itunes']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 11 ==================\n",
      "Sentiment:\n",
      "\t negative\n",
      "Selected_text:\n",
      "\t ['b', 'i', 'missed', 'it', '.']\n",
      "Predicted_text:\n",
      "\t ['missed']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.01', 23478, 'shoot']\n",
      "\t['0.07', 4383, ',']\n",
      "\t['0.19', 10601, 'rob']\n",
      "\t['0.33', 18663, 'i']\n",
      "\t['0.51', 22257, 'missed']\n",
      "\t['0.41', 13522, 'it']\n",
      "\t['0.35', 11591, '.']\n",
      "\t['0.26', 5766, 'just']\n",
      "\t['0.21', 28035, 'got']\n",
      "\t['0.26', 394, 'home']\n",
      "\t['0.19', 11591, '.']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 12 ==================\n",
      "Sentiment:\n",
      "\t positive\n",
      "Selected_text:\n",
      "\t ['super', 'happy']\n",
      "Predicted_text:\n",
      "\t []\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.01', 11591, '.']\n",
      "\t['0.02', 11591, '.']\n",
      "\t['0.03', 11591, '.']\n",
      "\t['0.04', 2993, 'definitely']\n",
      "\t['0.03', 25399, 'the']\n",
      "\t['0.03', 403, 'first']\n",
      "\t['0.03', 5111, 'time']\n",
      "\t['0.03', 8759, 'i`ve']\n",
      "\t['0.03', 24556, 'felt']\n",
      "\t['0.02', 23860, 'alive']\n",
      "\t['0.02', 27190, 'again']\n",
      "\t['0.02', 14081, 'in']\n",
      "\t['0.02', 22904, 'years']\n",
      "\t['0.04', 11591, '.']\n",
      "\t['0.05', 14551, 'super']\n",
      "\t['0.18', 392, 'happy']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 13 ==================\n",
      "Sentiment:\n",
      "\t neutral\n",
      "Selected_text:\n",
      "\t ['man', '!', 'i', 'can`t', 'stop', 'being', 'freakin', '`', 'hungry', '!']\n",
      "Predicted_text:\n",
      "\t ['man', '!', 'i', 'can`t', 'stop', 'being', 'freakin', '`', 'hungry', '!']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.58', 27825, 'man']\n",
      "\t['0.92', 5455, '!']\n",
      "\t['0.95', 18663, 'i']\n",
      "\t['0.97', 20891, 'can`t']\n",
      "\t['0.95', 12425, 'stop']\n",
      "\t['0.95', 3204, 'being']\n",
      "\t['0.97', 18753, 'freakin']\n",
      "\t['0.95', 3227, '`']\n",
      "\t['0.91', 12338, 'hungry']\n",
      "\t['0.81', 5455, '!']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 14 ==================\n",
      "Sentiment:\n",
      "\t negative\n",
      "Selected_text:\n",
      "\t ['oh', 'man', ',']\n",
      "Predicted_text:\n",
      "\t []\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.01', 12022, 'oh']\n",
      "\t['0.04', 27825, 'man']\n",
      "\t['0.06', 4383, ',']\n",
      "\t['0.07', 15464, 'there']\n",
      "\t['0.11', 15743, 'are']\n",
      "\t['0.10', 13327, 'dead']\n",
      "\t['0.01', 20801, 'deer']\n",
      "\t['0.01', 7043, 'everywhere']\n",
      "\t['0.01', 14081, 'in']\n",
      "\t['0.01', 22834, 'michigan']\n",
      "\t['0.01', 11591, '.']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 15 ==================\n",
      "Sentiment:\n",
      "\t neutral\n",
      "Selected_text:\n",
      "\t ['2night', '-', 'dance', 'parties', ',', 'fun', 'times', ',', '&', 'awkward', 'situations', 'highlight', '-', 'driving', 'w', '/', 'nims', 'and', 'annie', 'listening', 'to', 'satellite', 'windows', 'downnnn']\n",
      "Predicted_text:\n",
      "\t ['2night', '-', 'dance', 'parties', ',', 'fun', 'times', ',', '&', 'awkward', 'situations', 'highlight', '-', 'driving', 'w', '/', 'nims', 'and', 'annie', 'listening', 'to', 'satellite', 'windows', 'downnnn']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['1.00', 19207, '2night']\n",
      "\t['1.00', 24104, '-']\n",
      "\t['1.00', 14459, 'dance']\n",
      "\t['1.00', 8076, 'parties']\n",
      "\t['1.00', 4383, ',']\n",
      "\t['1.00', 25057, 'fun']\n",
      "\t['1.00', 6182, 'times']\n",
      "\t['1.00', 4383, ',']\n",
      "\t['1.00', 26245, '&']\n",
      "\t['1.00', 109, 'awkward']\n",
      "\t['1.00', 747, 'situations']\n",
      "\t['1.00', 23546, 'highlight']\n",
      "\t['1.00', 24104, '-']\n",
      "\t['1.00', 124, 'driving']\n",
      "\t['1.00', 25207, 'w']\n",
      "\t['1.00', 19634, '/']\n",
      "\t['0.99', 6077, 'nims']\n",
      "\t['0.98', 19192, 'and']\n",
      "\t['0.92', 19839, 'annie']\n",
      "\t['0.85', 25679, 'listening']\n",
      "\t['0.76', 37, 'to']\n",
      "\t['0.73', 21114, 'satellite']\n",
      "\t['0.87', 26909, 'windows']\n",
      "\t['0.67', 3636, 'downnnn']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 16 ==================\n",
      "Sentiment:\n",
      "\t positive\n",
      "Selected_text:\n",
      "\t ['thank', 'god']\n",
      "Predicted_text:\n",
      "\t ['hurt', 'to', 'thank']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.02', 28035, 'got']\n",
      "\t['0.06', 10960, 'my']\n",
      "\t['0.08', 26339, 'tattoo']\n",
      "\t['0.09', 756, 'fixed']\n",
      "\t['0.10', 14958, 'today']\n",
      "\t['0.12', 4383, ',']\n",
      "\t['0.16', 19192, 'and']\n",
      "\t['0.27', 13522, 'it']\n",
      "\t['0.46', 14737, 'didn`t']\n",
      "\t['0.63', 2856, 'hurt']\n",
      "\t['0.50', 37, 'to']\n",
      "\t['0.49', 27840, 'much']\n",
      "\t['0.48', 4383, ',']\n",
      "\t['0.54', 27200, 'thank']\n",
      "\t['0.48', 18716, 'god']\n",
      "\t['0.41', 20891, 'can`t']\n",
      "\t['0.36', 24487, 'wait']\n",
      "\t['0.24', 37, 'to']\n",
      "\t['0.17', 15865, 'get']\n",
      "\t['0.12', 25399, 'the']\n",
      "\t['0.08', 18898, 'next']\n",
      "\t['0.08', 25899, 'one']\n",
      "\t['0.06', 11591, '.']\n",
      "\t['0.02', 19416, '$']\n",
      "\t['0.01', 19416, '$']\n",
      "\t['0.01', 19416, '$']\n",
      "\t['0.01', 11591, '.']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 17 ==================\n",
      "Sentiment:\n",
      "\t neutral\n",
      "Selected_text:\n",
      "\t ['its', 'already', 'been', 'a', 'crazy', 'morning', 'and', 'its', 'only', '1030']\n",
      "Predicted_text:\n",
      "\t ['its', 'already', 'been', 'a', 'crazy', 'morning', 'and', 'its', 'only', '1030']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.89', 20398, 'its']\n",
      "\t['0.98', 9209, 'already']\n",
      "\t['0.99', 1904, 'been']\n",
      "\t['1.00', 26841, 'a']\n",
      "\t['1.00', 5928, 'crazy']\n",
      "\t['1.00', 4050, 'morning']\n",
      "\t['1.00', 19192, 'and']\n",
      "\t['1.00', 20398, 'its']\n",
      "\t['1.00', 19016, 'only']\n",
      "\t['0.99', 19532, '1030']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 18 ==================\n",
      "Sentiment:\n",
      "\t positive\n",
      "Selected_text:\n",
      "\t ['d', 'she', 'very', 'graceful', 'accepted', 'it']\n",
      "Predicted_text:\n",
      "\t ['graceful']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.01', 11591, '.']\n",
      "\t['0.03', 11591, '.']\n",
      "\t['0.06', 11591, '.']\n",
      "\t['0.08', 11591, '.']\n",
      "\t['0.07', 20610, 'nope']\n",
      "\t['0.07', 11591, '.']\n",
      "\t['0.06', 11591, '.']\n",
      "\t['0.05', 20398, 'its']\n",
      "\t['0.04', 4178, 'for']\n",
      "\t['0.04', 25399, 'the']\n",
      "\t['0.03', 27209, '1st']\n",
      "\t['0.03', 5111, 'time']\n",
      "\t['0.02', 12445, 'we']\n",
      "\t['0.02', 27726, 'invited']\n",
      "\t['0.03', 18315, 'her']\n",
      "\t['0.02', 1093, 'at']\n",
      "\t['0.03', 18819, 'ssm']\n",
      "\t['0.06', 19192, 'and']\n",
      "\t['0.14', 23831, 'she']\n",
      "\t['0.32', 10533, 'very']\n",
      "\t['0.58', 24063, 'graceful']\n",
      "\t['0.50', 10579, 'accepted']\n",
      "\t['0.25', 13522, 'it']\n",
      "\t['0.11', 5455, '!']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 19 ==================\n",
      "Sentiment:\n",
      "\t positive\n",
      "Selected_text:\n",
      "\t [' ', ':', 'i', 'admire', 'you', '!', 'you`re', 'amazing', '!', 'you', 'inspire', 'me', 'to', 'write', '<', '3']\n",
      "Predicted_text:\n",
      "\t ['i', 'admire', 'you', '!', 'you`re', 'amazing', '!', 'you', 'inspire', 'me', 'to', 'write', '<']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.02', 18663, 'i']\n",
      "\t['0.03', 18880, 'created']\n",
      "\t['0.03', 10960, 'my']\n",
      "\t['0.04', 5611, 'account']\n",
      "\t['0.04', 5766, 'just']\n",
      "\t['0.05', 37, 'to']\n",
      "\t['0.05', 15865, 'get']\n",
      "\t['0.06', 26841, 'a']\n",
      "\t['0.14', 22436, 'chance']\n",
      "\t['0.22', 37, 'to']\n",
      "\t['0.23', 20444, 'chat']\n",
      "\t['0.20', 18963, 'with']\n",
      "\t['0.21', 13241, 'you']\n",
      "\t['0.22', 17577, '(']\n",
      "\t['0.27', 28214, ':']\n",
      "\t['0.53', 18663, 'i']\n",
      "\t['0.91', 10001, 'admire']\n",
      "\t['0.91', 13241, 'you']\n",
      "\t['0.93', 5455, '!']\n",
      "\t['0.95', 26998, 'you`re']\n",
      "\t['0.96', 15263, 'amazing']\n",
      "\t['0.92', 5455, '!']\n",
      "\t['0.86', 13241, 'you']\n",
      "\t['0.84', 24273, 'inspire']\n",
      "\t['0.90', 11921, 'me']\n",
      "\t['0.89', 37, 'to']\n",
      "\t['0.91', 13638, 'write']\n",
      "\t['0.83', 6524, '<']\n",
      "\t['0.37', 13717, '3']\n",
      "\t['0.00', 13577, 'xxxEND']\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,20):\n",
    "    spot_check(i, mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Sample # 100 ==================\n",
      "Sentiment:\n",
      "\t neutral\n",
      "Selected_text:\n",
      "\t ['fun', 'who', 'did', 'you', 'go', 'with', '?', '?', '?', 'another', 'park', 'no', 'invite', '!', 'lol']\n",
      "Predicted_text:\n",
      "\t ['fun', 'who', 'did', 'you', 'go', 'with', '?', '?', '?', 'another', 'park', 'no', 'invite', '!', 'lol']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.93', 25057, 'fun']\n",
      "\t['0.95', 6520, 'who']\n",
      "\t['0.96', 13843, 'did']\n",
      "\t['0.94', 13241, 'you']\n",
      "\t['0.89', 13983, 'go']\n",
      "\t['0.83', 18963, 'with']\n",
      "\t['0.75', 23515, '?']\n",
      "\t['0.74', 23515, '?']\n",
      "\t['0.77', 23515, '?']\n",
      "\t['0.82', 7886, 'another']\n",
      "\t['0.93', 8160, 'park']\n",
      "\t['0.98', 25710, 'no']\n",
      "\t['0.99', 6652, 'invite']\n",
      "\t['0.98', 5455, '!']\n",
      "\t['0.92', 6614, 'lol']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 101 ==================\n",
      "Sentiment:\n",
      "\t neutral\n",
      "Selected_text:\n",
      "\t ['just', 'had', 'kfc']\n",
      "Predicted_text:\n",
      "\t []\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.04', 5766, 'just']\n",
      "\t['0.07', 22266, 'had']\n",
      "\t['0.05', 20570, 'kfc']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 102 ==================\n",
      "Sentiment:\n",
      "\t neutral\n",
      "Selected_text:\n",
      "\t ['hmm', '.', '.', '.', 'i', 'should', 'go', 'make', 'a', 'time', 'machine', 'to', 'go', 'forward', 'to', '12', ':', '00', 'god', 'i', 'm', 'genius', '.', '.', 'oh', 'yeh', 'i', 'do', 'nt', 'no', 'how', 'too', '.', '.', '.', 'x']\n",
      "Predicted_text:\n",
      "\t ['hmm', '.', '.', '.', 'i', 'should', 'go', 'make', 'a', 'time', 'machine', 'to', 'go', 'forward', 'to', '12', ':', '00', 'god', 'i', 'm', 'genius', '.', '.', 'oh', 'yeh', 'i', 'do', 'nt', 'no', 'how', 'too', '.', '.', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.94', 19984, 'hmm']\n",
      "\t['0.99', 11591, '.']\n",
      "\t['1.00', 11591, '.']\n",
      "\t['1.00', 11591, '.']\n",
      "\t['1.00', 18663, 'i']\n",
      "\t['1.00', 22826, 'should']\n",
      "\t['1.00', 13983, 'go']\n",
      "\t['1.00', 10170, 'make']\n",
      "\t['1.00', 26841, 'a']\n",
      "\t['1.00', 5111, 'time']\n",
      "\t['1.00', 27337, 'machine']\n",
      "\t['1.00', 37, 'to']\n",
      "\t['1.00', 13983, 'go']\n",
      "\t['1.00', 19459, 'forward']\n",
      "\t['1.00', 37, 'to']\n",
      "\t['0.99', 8591, '12']\n",
      "\t['0.99', 28214, ':']\n",
      "\t['0.99', 25768, '00']\n",
      "\t['0.99', 18716, 'god']\n",
      "\t['1.00', 18663, 'i']\n",
      "\t['1.00', 9296, 'm']\n",
      "\t['1.00', 25016, 'genius']\n",
      "\t['1.00', 11591, '.']\n",
      "\t['1.00', 11591, '.']\n",
      "\t['1.00', 12022, 'oh']\n",
      "\t['1.00', 12572, 'yeh']\n",
      "\t['1.00', 18663, 'i']\n",
      "\t['1.00', 7455, 'do']\n",
      "\t['1.00', 19089, 'nt']\n",
      "\t['1.00', 25710, 'no']\n",
      "\t['1.00', 17442, 'how']\n",
      "\t['1.00', 10279, 'too']\n",
      "\t['1.00', 11591, '.']\n",
      "\t['0.99', 11591, '.']\n",
      "\t['0.98', 11591, '.']\n",
      "\t['0.47', 10445, 'x']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 103 ==================\n",
      "Sentiment:\n",
      "\t negative\n",
      "Selected_text:\n",
      "\t [' ', '.', '.', 'overdue']\n",
      "Predicted_text:\n",
      "\t ['.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.01', 2747, 'need']\n",
      "\t['0.08', 26841, 'a']\n",
      "\t['0.19', 9770, 'tickettttt']\n",
      "\t['0.48', 25402, 'gah']\n",
      "\t['0.53', 11591, '.']\n",
      "\t['0.49', 20215, 'ya']\n",
      "\t['0.29', 27917, 'you`ve']\n",
      "\t['0.24', 28035, 'got']\n",
      "\t['0.19', 11921, 'me']\n",
      "\t['0.09', 10432, 'on']\n",
      "\t['0.06', 15464, 'there']\n",
      "\t['0.08', 4383, ',']\n",
      "\t['0.13', 22501, 'reason346']\n",
      "\t['0.19', 11591, '.']\n",
      "\t['0.18', 11591, '.']\n",
      "\t['0.19', 17471, 'haven`t']\n",
      "\t['0.16', 20773, 'listened']\n",
      "\t['0.13', 37, 'to']\n",
      "\t['0.08', 10775, 'dear']\n",
      "\t['0.06', 10240, 'elliott']\n",
      "\t['0.07', 4178, 'for']\n",
      "\t['0.08', 26841, 'a']\n",
      "\t['0.06', 2920, 'few']\n",
      "\t['0.08', 26232, 'weeks']\n",
      "\t['0.08', 11591, '.']\n",
      "\t['0.09', 11591, '.']\n",
      "\t['0.08', 11591, '.']\n",
      "\t['0.06', 19443, 'overdue']\n",
      "\t['0.16', 11591, '.']\n",
      "\t['0.11', 11591, '.']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 104 ==================\n",
      "Sentiment:\n",
      "\t negative\n",
      "Selected_text:\n",
      "\t ['i`m', 'lost']\n",
      "Predicted_text:\n",
      "\t []\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.01', 13241, 'you']\n",
      "\t['0.02', 7460, 'could']\n",
      "\t['0.04', 12116, 'say']\n",
      "\t['0.08', 25259, 'that']\n",
      "\t['0.12', 11591, '.']\n",
      "\t['0.18', 18663, 'i']\n",
      "\t['0.19', 17061, 'left']\n",
      "\t['0.11', 13522, 'it']\n",
      "\t['0.07', 14081, 'in']\n",
      "\t['0.05', 19186, 'vt']\n",
      "\t['0.04', 19192, 'and']\n",
      "\t['0.04', 22865, 'have']\n",
      "\t['0.04', 1904, 'been']\n",
      "\t['0.04', 15952, 'blackberryless']\n",
      "\t['0.03', 23433, 'since']\n",
      "\t['0.03', 12614, 'tuesday']\n",
      "\t['0.06', 4056, 'night']\n",
      "\t['0.08', 11591, '.']\n",
      "\t['0.13', 73, 'i`m']\n",
      "\t['0.13', 6774, 'lost']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 105 ==================\n",
      "Sentiment:\n",
      "\t positive\n",
      "Selected_text:\n",
      "\t ['thought', 'provoking']\n",
      "Predicted_text:\n",
      "\t []\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.02', 19108, 'totally']\n",
      "\t['0.07', 5455, '!']\n",
      "\t['0.07', 8759, 'i`ve']\n",
      "\t['0.08', 1904, 'been']\n",
      "\t['0.06', 13461, 'waitin']\n",
      "\t['0.02', 4178, 'for']\n",
      "\t['0.02', 16148, 'somethin']\n",
      "\t['0.06', 25827, 'new']\n",
      "\t['0.06', 19192, 'and']\n",
      "\t['0.06', 24532, 'thought']\n",
      "\t['0.05', 26772, 'provoking']\n",
      "\t['0.04', 1093, 'at']\n",
      "\t['0.03', 8559, 'mj']\n",
      "\t['0.03', 11591, '.']\n",
      "\t['0.01', 26675, 'name']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 106 ==================\n",
      "Sentiment:\n",
      "\t positive\n",
      "Selected_text:\n",
      "\t ['wish']\n",
      "Predicted_text:\n",
      "\t []\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.03', 22751, 'wish']\n",
      "\t['0.05', 13241, 'you']\n",
      "\t['0.07', 23580, 'were']\n",
      "\t['0.09', 27132, 'sluttin']\n",
      "\t['0.09', 13522, 'it']\n",
      "\t['0.10', 9148, 'up']\n",
      "\t['0.10', 25207, 'w']\n",
      "\t['0.14', 11921, 'me']\n",
      "\t['0.21', 17987, 'waaaaaaaaahhhh']\n",
      "\t['0.20', 5455, '!']\n",
      "\t['0.18', 5455, '!']\n",
      "\t['0.10', 5455, '!']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 107 ==================\n",
      "Sentiment:\n",
      "\t positive\n",
      "Selected_text:\n",
      "\t ['good']\n",
      "Predicted_text:\n",
      "\t []\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.18', 9121, 'good']\n",
      "\t['0.08', 4050, 'morning']\n",
      "\t['0.08', 2341, 'chairman']\n",
      "\t['0.06', 25709, 'of']\n",
      "\t['0.05', 25399, 'the']\n",
      "\t['0.04', 14949, 'board']\n",
      "\t['0.03', 5455, '!']\n",
      "\t['0.01', 26959, 'www']\n",
      "\t['0.01', 11591, '.']\n",
      "\t['0.01', 2693, 'youtube']\n",
      "\t['0.01', 11591, '.']\n",
      "\t['0.00', 16523, 'com']\n",
      "\t['0.00', 19634, '/']\n",
      "\t['0.00', 11909, 'watch']\n",
      "\t['0.00', 23515, '?']\n",
      "\t['0.01', 2594, 'v']\n",
      "\t['0.01', 7620, '=']\n",
      "\t['0.01', 9462, 'ivfm0pyyucy']\n",
      "\t['0.01', 20398, 'its']\n",
      "\t['0.01', 26841, 'a']\n",
      "\t['0.03', 6620, 'living']\n",
      "\t['0.07', 10958, 'thing']\n",
      "\t['0.12', 11591, '.']\n",
      "\t['0.15', 11591, '.']\n",
      "\t['0.16', 11591, '.']\n",
      "\t['0.14', 11591, '.']\n",
      "\t['0.09', 5455, '!']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 108 ==================\n",
      "Sentiment:\n",
      "\t positive\n",
      "Selected_text:\n",
      "\t ['would', 'love', 'to']\n",
      "Predicted_text:\n",
      "\t []\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.02', 18663, 'i']\n",
      "\t['0.07', 13843, 'did']\n",
      "\t['0.08', 4178, 'for']\n",
      "\t['0.07', 22904, 'years']\n",
      "\t['0.06', 19192, 'and']\n",
      "\t['0.07', 14240, 'then']\n",
      "\t['0.05', 17835, 'moved']\n",
      "\t['0.06', 23470, 'over']\n",
      "\t['0.07', 37, 'to']\n",
      "\t['0.10', 868, 'an']\n",
      "\t['0.13', 14245, 'ibm']\n",
      "\t['0.11', 11646, 'compatible']\n",
      "\t['0.15', 11591, '.']\n",
      "\t['0.21', 16046, 'would']\n",
      "\t['0.34', 9847, 'love']\n",
      "\t['0.20', 37, 'to']\n",
      "\t['0.14', 22865, 'have']\n",
      "\t['0.12', 17303, 'both']\n",
      "\t['0.10', 10432, 'on']\n",
      "\t['0.11', 10960, 'my']\n",
      "\t['0.12', 22540, 'desk']\n",
      "\t['0.16', 5455, '!']\n",
      "\t['0.16', 19989, 'can']\n",
      "\t['0.18', 13241, 'you']\n",
      "\t['0.21', 6938, 'call']\n",
      "\t['0.17', 11921, 'me']\n",
      "\t['0.15', 26841, 'a']\n",
      "\t['0.04', 7303, 'techie']\n",
      "\t['0.02', 23515, '?']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 109 ==================\n",
      "Sentiment:\n",
      "\t negative\n",
      "Selected_text:\n",
      "\t ['sucks']\n",
      "Predicted_text:\n",
      "\t []\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.00', 8759, 'i`ve']\n",
      "\t['0.01', 1904, 'been']\n",
      "\t['0.02', 13327, 'dead']\n",
      "\t['0.03', 25399, 'the']\n",
      "\t['0.05', 8401, 'past']\n",
      "\t['0.03', 2721, '2']\n",
      "\t['0.03', 1393, 'days']\n",
      "\t['0.04', 11591, '.']\n",
      "\t['0.05', 11591, '.']\n",
      "\t['0.07', 11591, '.']\n",
      "\t['0.08', 25399, 'the']\n",
      "\t['0.09', 24918, 'flu']\n",
      "\t['0.43', 25645, 'sucks']\n",
      "\t['0.00', 13577, 'xxxEND']\n"
     ]
    }
   ],
   "source": [
    "for i in range(100,110):\n",
    "    spot_check(i, mode=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Sample # 10 ==================\n",
      "Sentiment:\n",
      "\t negative\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t []\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.01', 10960, 'my']\n",
      "\t['0.01', 1480, 'bike']\n",
      "\t['0.01', 8676, 'was']\n",
      "\t['0.01', 11283, 'put']\n",
      "\t['0.01', 10432, 'on']\n",
      "\t['0.01', 7587, 'hold']\n",
      "\t['0.01', 11591, '.']\n",
      "\t['0.02', 11591, '.']\n",
      "\t['0.02', 11591, '.']\n",
      "\t['0.02', 22826, 'should']\n",
      "\t['0.01', 22865, 'have']\n",
      "\t['0.01', 6977, 'known']\n",
      "\t['0.01', 25259, 'that']\n",
      "\t['0.01', 11591, '.']\n",
      "\t['0.01', 11591, '.']\n",
      "\t['0.03', 11591, '.']\n",
      "\t['0.07', 11591, '.']\n",
      "\t['0.20', 3957, 'argh']\n",
      "\t['0.08', 5405, 'total']\n",
      "\t['0.08', 21426, 'bummer']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 11 ==================\n",
      "Sentiment:\n",
      "\t neutral\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t []\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.04', 18663, 'i']\n",
      "\t['0.10', 10599, 'checked']\n",
      "\t['0.31', 11591, '.']\n",
      "\t['0.31', 12445, 'we']\n",
      "\t['0.37', 14737, 'didn`t']\n",
      "\t['0.19', 25530, 'win']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 12 ==================\n",
      "Sentiment:\n",
      "\t neutral\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['.', '.', 'and', 'you`re', 'on', 'twitter', '!', 'did', 'the', 'tavern', 'bore', 'you', 'that', 'much', '?']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.70', 11591, '.']\n",
      "\t['0.93', 11591, '.']\n",
      "\t['0.96', 19192, 'and']\n",
      "\t['0.98', 26998, 'you`re']\n",
      "\t['0.99', 10432, 'on']\n",
      "\t['0.99', 15935, 'twitter']\n",
      "\t['1.00', 5455, '!']\n",
      "\t['1.00', 13843, 'did']\n",
      "\t['1.00', 25399, 'the']\n",
      "\t['1.00', 22066, 'tavern']\n",
      "\t['0.99', 26349, 'bore']\n",
      "\t['0.98', 13241, 'you']\n",
      "\t['0.98', 25259, 'that']\n",
      "\t['0.98', 27840, 'much']\n",
      "\t['0.94', 23515, '?']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 13 ==================\n",
      "Sentiment:\n",
      "\t negative\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['makes', 'me', 'kinda', 'sad', ',', 'he', 'is', 'getting']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.02', 73, 'i`m']\n",
      "\t['0.03', 14081, 'in']\n",
      "\t['0.03', 16570, 'va']\n",
      "\t['0.04', 4178, 'for']\n",
      "\t['0.06', 25399, 'the']\n",
      "\t['0.06', 9559, 'weekend']\n",
      "\t['0.10', 4383, ',']\n",
      "\t['0.14', 10960, 'my']\n",
      "\t['0.24', 27367, 'youngest']\n",
      "\t['0.28', 13381, 'son']\n",
      "\t['0.30', 22315, 'turns']\n",
      "\t['0.20', 2721, '2']\n",
      "\t['0.19', 20365, 'tomorrow']\n",
      "\t['0.25', 11591, '.']\n",
      "\t['0.28', 11591, '.']\n",
      "\t['0.31', 11591, '.']\n",
      "\t['0.34', 11591, '.']\n",
      "\t['0.38', 11591, '.']\n",
      "\t['0.42', 11591, '.']\n",
      "\t['0.45', 13522, 'it']\n",
      "\t['0.51', 11691, 'makes']\n",
      "\t['0.66', 11921, 'me']\n",
      "\t['0.88', 20404, 'kinda']\n",
      "\t['0.94', 12118, 'sad']\n",
      "\t['0.80', 4383, ',']\n",
      "\t['0.68', 24934, 'he']\n",
      "\t['0.61', 23691, 'is']\n",
      "\t['0.50', 23490, 'getting']\n",
      "\t['0.46', 9599, 'so']\n",
      "\t['0.44', 16284, 'big']\n",
      "\t['0.34', 4383, ',']\n",
      "\t['0.25', 3811, 'check']\n",
      "\t['0.18', 5433, 'out']\n",
      "\t['0.12', 10960, 'my']\n",
      "\t['0.05', 26604, 'twipics']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 14 ==================\n",
      "Sentiment:\n",
      "\t negative\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t []\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.00', 20398, 'its']\n",
      "\t['0.00', 4756, 'coming']\n",
      "\t['0.00', 5433, 'out']\n",
      "\t['0.01', 25399, 'the']\n",
      "\t['0.01', 12558, 'socket']\n",
      "\t['0.02', 18663, 'i']\n",
      "\t['0.03', 19464, 'feel']\n",
      "\t['0.03', 13176, 'like']\n",
      "\t['0.03', 10960, 'my']\n",
      "\t['0.02', 21148, 'phones']\n",
      "\t['0.01', 7134, 'hole']\n",
      "\t['0.01', 23691, 'is']\n",
      "\t['0.01', 20934, 'not']\n",
      "\t['0.01', 26841, 'a']\n",
      "\t['0.01', 25275, 'virgin']\n",
      "\t['0.01', 11591, '.']\n",
      "\t['0.01', 18543, 'that`s']\n",
      "\t['0.01', 17442, 'how']\n",
      "\t['0.02', 2526, 'loose']\n",
      "\t['0.02', 13522, 'it']\n",
      "\t['0.02', 23691, 'is']\n",
      "\t['0.04', 11591, '.']\n",
      "\t['0.05', 11591, '.']\n",
      "\t['0.06', 11591, '.']\n",
      "\t['0.04', 28214, ':']\n",
      "\t['0.03', 3227, '`']\n",
      "\t['0.02', 17577, '(']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 15 ==================\n",
      "Sentiment:\n",
      "\t negative\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t []\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.00', 9599, 'so']\n",
      "\t['0.00', 2073, 'hot']\n",
      "\t['0.01', 14958, 'today']\n",
      "\t['0.01', 7620, '=']\n",
      "\t['0.01', 5828, '_']\n",
      "\t['0.01', 7620, '=']\n",
      "\t['0.01', 7220, 'don`t']\n",
      "\t['0.01', 13176, 'like']\n",
      "\t['0.01', 13522, 'it']\n",
      "\t['0.01', 19192, 'and']\n",
      "\t['0.01', 18663, 'i']\n",
      "\t['0.02', 1806, 'hate']\n",
      "\t['0.01', 10960, 'my']\n",
      "\t['0.00', 25827, 'new']\n",
      "\t['0.00', 15461, 'timetable']\n",
      "\t['0.01', 4383, ',']\n",
      "\t['0.02', 17311, 'having']\n",
      "\t['0.03', 13682, 'such']\n",
      "\t['0.03', 26841, 'a']\n",
      "\t['0.07', 13084, 'bad']\n",
      "\t['0.02', 23404, 'week']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 16 ==================\n",
      "Sentiment:\n",
      "\t negative\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t []\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.12', 11552, 'miss']\n",
      "\t['0.06', 13241, 'you']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 17 ==================\n",
      "Sentiment:\n",
      "\t negative\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t []\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.06', 20085, 'cramps']\n",
      "\t['0.18', 11591, '.']\n",
      "\t['0.18', 11591, '.']\n",
      "\t['0.09', 11591, '.']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 18 ==================\n",
      "Sentiment:\n",
      "\t positive\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t []\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.01', 13241, 'you']\n",
      "\t['0.02', 715, 'guys']\n",
      "\t['0.04', 14737, 'didn`t']\n",
      "\t['0.03', 12116, 'say']\n",
      "\t['0.02', 1435, 'hi']\n",
      "\t['0.02', 10331, 'or']\n",
      "\t['0.03', 17900, 'answer']\n",
      "\t['0.03', 10960, 'my']\n",
      "\t['0.03', 6610, 'questions']\n",
      "\t['0.08', 24919, 'yesterday']\n",
      "\t['0.10', 27101, 'but']\n",
      "\t['0.28', 10500, 'nice']\n",
      "\t['0.12', 13483, 'songs']\n",
      "\t['0.08', 11591, '.']\n",
      "\t['0.00', 13577, 'xxxEND']\n",
      "================== Sample # 19 ==================\n",
      "Sentiment:\n",
      "\t neutral\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['i`m', 'going', 'into', 'a', 'spiritual', 'stagnentation', ',', 'its', 'exploding', 'my', 'ego', '!', '.', 'i', 'now', 'realise', ',', 'i`m', 'not', 'all', 'that', 'great', '.', 'and', 'i`m', 'ok', 'with', 'that', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', 14768, 'xxxSTART']\n",
      "\t['0.98', 73, 'i`m']\n",
      "\t['1.00', 26503, 'going']\n",
      "\t['1.00', 16058, 'into']\n",
      "\t['1.00', 26841, 'a']\n",
      "\t['1.00', 1761, 'spiritual']\n",
      "\t['0.99', 13214, 'stagnentation']\n",
      "\t['0.98', 4383, ',']\n",
      "\t['0.98', 20398, 'its']\n",
      "\t['0.96', 2248, 'exploding']\n",
      "\t['0.97', 10960, 'my']\n",
      "\t['0.98', 1536, 'ego']\n",
      "\t['0.94', 5455, '!']\n",
      "\t['0.94', 11591, '.']\n",
      "\t['0.95', 18663, 'i']\n",
      "\t['0.95', 3505, 'now']\n",
      "\t['0.97', 27324, 'realise']\n",
      "\t['0.96', 4383, ',']\n",
      "\t['0.97', 73, 'i`m']\n",
      "\t['0.98', 20934, 'not']\n",
      "\t['0.98', 617, 'all']\n",
      "\t['0.99', 25259, 'that']\n",
      "\t['0.99', 10101, 'great']\n",
      "\t['0.99', 11591, '.']\n",
      "\t['0.99', 19192, 'and']\n",
      "\t['0.98', 73, 'i`m']\n",
      "\t['0.98', 3738, 'ok']\n",
      "\t['0.96', 18963, 'with']\n",
      "\t['0.93', 25259, 'that']\n",
      "\t['0.79', 11591, '.']\n",
      "\t['0.00', 13577, 'xxxEND']\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,20):\n",
    "    spot_check(i, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(str1, str2): \n",
    "    a = set(str1) \n",
    "    b = set(str2)\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Jaccard Score 0.49741662375264584\n",
      "Validation Jaccard Score 0.32293804276534066\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Jaccard Score\", np.mean([jaccard(str1=i[i>0], str2=j) for i,j in zip(Y_train,pred_train_words)]))\n",
    "print(\"Validation Jaccard Score\", np.mean([jaccard(str1=i[i>0], str2=j) for i,j in zip(Y_val,pred_val_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    27088.000000\n",
       "mean     8.826565    \n",
       "std      8.630794    \n",
       "min      1.000000    \n",
       "25%      2.000000    \n",
       "50%      6.000000    \n",
       "75%      13.000000   \n",
       "max      106.000000  \n",
       "dtype: float64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average number of words in selected text?\n",
    "pd.Series([len(i) for i in Y]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46093712464715814"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is it generally predicting words that are in itself??\n",
    "np.mean([sum([1  if (k in j) else 0 for k in i])/len(i) if len(i)!=0 else 0 for i,j in zip(pred_val_words, Y_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(sent_labels[X_sentiments_test[num]], [get_from_vocab(vocab_itos,j) for j in i]) for num, i in enumerate(pred_test_words[:5])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(x):\n",
    "    x = \"\".join(x)\n",
    "    x = re.sub(pattern=\"xxxSTART\", repl=\"\", string=x)\n",
    "    x = re.sub(pattern=\"xxxEND\", repl=\"\", string=x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_words = [[get_from_vocab(vocab_itos,j) for j in i] for i in pred_train_words]\n",
    "pred_val_words = [[get_from_vocab(vocab_itos,j) for j in i] for i in pred_val_words]\n",
    "pred_test_words = [[get_from_vocab(vocab_itos,j) for j in i] for i in pred_test_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pred_val_words[300]\n",
    "print([vocab_itos[i] for i in X_val[300] if i!=0])\n",
    "print([vocab_itos[i] for i in Y_val[300] if i!=0])\n",
    "print(pred_val_words[300])\n",
    "print(post_process(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_process(pred_test_words[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[post_process(i)] for num, i in enumerate(pred_test_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(str1, str2):\n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_idx), keep_x_train.shape, pred_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\n",
    "    \"pred_selected_text\" : pred_train_words + pred_val_words,\n",
    "    \"original_index\" : np.concatenate((np.array(train_idx, dtype=np.int64)[keep_x_train],\n",
    "                                       np.array(val_idx, dtype=np.int64)[keep_x_val])),\n",
    "    \"set\" : [\"train\" for i in range(sum(keep_x_train))] + [\"val\" for i in range(sum(keep_x_val))]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (predictions.original_index.min(), predictions.original_index.max()) == (df.original_index.min(), df.original_index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape, predictions.shape)\n",
    "results = pd.merge(df, predictions, on = \"original_index\", how=\"inner\")\n",
    "print(df.shape, predictions.shape, results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[results.set==\"val\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc[results.set==\"train\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_train = confusion_matrix(Y_train.argmax(axis=1).reshape(-1), pred_train.reshape(-1))\n",
    "conf_mat_val = confusion_matrix(Y_val.argmax(axis=1).reshape(-1), pred_val.reshape(-1))\n",
    "print(\"The train accuracy is\\t\",np.round(100 * np.sum(np.diag(conf_mat_train)) / np.sum(conf_mat_train),2))\n",
    "print(\"The valid accuracy is\\t\",np.round(100 * np.sum(np.diag(conf_mat_val)) / np.sum(conf_mat_val),2))\n",
    "\n",
    "np.savetxt(X=conf_mat_train, fname=\"../results/ConfMatrix_train_\" + MODEL_PREFIX + \".txt\")\n",
    "np.savetxt(X=conf_mat_val, fname=\"../results/ConfMatrix_val_\" + MODEL_PREFIX + \".txt\")\n",
    "\n",
    "f1_train = f1_score(Y_train.argmax(axis=1).reshape(-1), pred_train.reshape(-1), average='macro')\n",
    "f1_val = f1_score(Y_val.argmax(axis=1).reshape(-1), pred_val.reshape(-1), average='macro')\n",
    "print(\"The train macro f1score is\\t\",np.round(f1_train,2))\n",
    "print(\"The valid macro f1score is\\t\",np.round(f1_val,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'time':test_df['time'],'open_channels':pred_test.reshape(-1)})\n",
    "submission.to_csv(\"../results/submission_20200412V\"+MODEL_NUMBER+\".csv\", index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "best_model = tf.keras.models.load_model(\n",
    "    filepath=\"../results/\"+MODEL_PREFIX+\"Checkpoint.h5\",\n",
    "    compile=True,\n",
    "    custom_objects = {'macro_soft_f1':macro_soft_f1, 'macro_f1':macro_f1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = best_model.predict(x = X_train, batch_size=PREDICT_BATCH_SIZE)\n",
    "pred_val = best_model.predict(x = X_val, batch_size=PREDICT_BATCH_SIZE)\n",
    "pred_test = best_model.predict(x = X_test, batch_size=PREDICT_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = pred_train.argmax(axis=1)\n",
    "pred_val = pred_val.argmax(axis=1)\n",
    "pred_test = pred_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_train = confusion_matrix(Y_train.argmax(axis=1).reshape(-1), pred_train.reshape(-1))\n",
    "conf_mat_val = confusion_matrix(Y_val.argmax(axis=1).reshape(-1), pred_val.reshape(-1))\n",
    "\n",
    "print(\"The train accuracy is\\t\",np.round(100 * np.sum(np.diag(conf_mat_train)) / np.sum(conf_mat_train),2))\n",
    "print(\"The valid accuracy is\\t\",np.round(100 * np.sum(np.diag(conf_mat_val)) / np.sum(conf_mat_val),2))\n",
    "\n",
    "np.savetxt(X=conf_mat_train, fname=\"../results/BestConfMatrix_train_\" + MODEL_PREFIX + \".txt\")\n",
    "np.savetxt(X=conf_mat_val, fname=\"../results/BestConfMatrix_val_\" + MODEL_PREFIX + \".txt\")\n",
    "\n",
    "f1_train = f1_score(Y_train.argmax(axis=1).reshape(-1), pred_train.reshape(-1), average='macro')\n",
    "f1_val = f1_score(Y_train.argmax(axis=1).reshape(-1), pred_train.reshape(-1), average='macro')\n",
    "print(\"The train macro f1score is\\t\",np.round(f1_train,2))\n",
    "print(\"The valid macro f1score is\\t\",np.round(f1_val,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'time':test_df['time'],'open_channels':pred_test.reshape(-1)})\n",
    "submission.to_csv(\"../results/best_submission_20200412V\"+MODEL_NUMBER+\".csv\", index=False, float_format='%.4f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
