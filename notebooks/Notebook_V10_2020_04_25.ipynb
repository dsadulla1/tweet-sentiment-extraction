{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do you need psuedo labels?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# You might need a token for space itself? start and stop tokens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification model with test as well in train? Will increase the vocab size as well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * https://www.tensorflow.org/tutorials/text/transformer\n",
    "# * https://pytorch.org/tutorials/beginner/transformer_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTROLS\n",
    "MODEL_PREFIX = \"V10\"\n",
    "MODEL_NUMBER = MODEL_PREFIX[-2:]\n",
    "TRAIN_SPLIT_RATIO = 0.8\n",
    "\n",
    "DROPOUT = 0.3\n",
    "MIN_LR = 1e-6\n",
    "MAX_LR = 1e-3\n",
    "BATCH_SIZE = 1024\n",
    "PREDICT_BATCH_SIZE = 2048\n",
    "STEP_SIZE = 10\n",
    "CLR_METHOD = \"triangular2\" # exp_range, triangular, triangular2\n",
    "NUM_EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler, LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import pickle, os, sys, re\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, LSTM, Embedding, Dense, concatenate, MaxPooling2D, Softmax, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout, Reshape, Activation, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.layers import RepeatVector, Multiply\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "def signaltonoise(a, axis=0, ddof=0):\n",
    "    a = np.asanyarray(a)\n",
    "    m = a.mean(axis)\n",
    "    sd = a.std(axis=axis, ddof=ddof)\n",
    "    return np.where(sd == 0, 0, m/sd)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import *\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "class CyclicLR(Callback):\n",
    "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
    "    The method cycles the learning rate between two boundaries with\n",
    "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
    "    The amplitude of the cycle can be scaled on a per-iteration or \n",
    "    per-cycle basis.\n",
    "    This class has three built-in policies, as put forth in the paper.\n",
    "    \"triangular\":\n",
    "        A basic triangular cycle w/ no amplitude scaling.\n",
    "    \"triangular2\":\n",
    "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
    "    \"exp_range\":\n",
    "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n",
    "        cycle iteration.\n",
    "    For more detail, please see paper.\n",
    "    \n",
    "    # Example\n",
    "        ```python\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```\n",
    "    \n",
    "    Class also supports custom scaling functions:\n",
    "        ```python\n",
    "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., scale_fn=clr_fn,\n",
    "                                scale_mode='cycle')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```    \n",
    "    # Arguments\n",
    "        base_lr: initial learning rate which is the\n",
    "            lower boundary in the cycle.\n",
    "        max_lr: upper boundary in the cycle. Functionally,\n",
    "            it defines the cycle amplitude (max_lr - base_lr).\n",
    "            The lr at any cycle is the sum of base_lr\n",
    "            and some scaling of the amplitude; therefore \n",
    "            max_lr may not actually be reached depending on\n",
    "            scaling function.\n",
    "        step_size: number of training iterations per\n",
    "            half cycle. Authors suggest setting step_size\n",
    "            2-8 x training iterations in epoch.\n",
    "        mode: one of {triangular, triangular2, exp_range}.\n",
    "            Default 'triangular'.\n",
    "            Values correspond to policies detailed above.\n",
    "            If scale_fn is not None, this argument is ignored.\n",
    "        gamma: constant in 'exp_range' scaling function:\n",
    "            gamma**(cycle iterations)\n",
    "        scale_fn: Custom scaling policy defined by a single\n",
    "            argument lambda function, where \n",
    "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
    "            mode paramater is ignored \n",
    "        scale_mode: {'cycle', 'iterations'}.\n",
    "            Defines whether scale_fn is evaluated on \n",
    "            cycle number or cycle iterations (training\n",
    "            iterations since start of cycle). Default is 'cycle'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma**(x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        \"\"\"Resets cycle iterations.\n",
    "        Optional boundary/step size adjustment.\n",
    "        \"\"\"\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "        \n",
    "    def clr(self):\n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
    "            \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\deepak\\miniconda3\\envs\\dev\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "np.random.seed(54321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0  1\n",
      "textID         object  0\n",
      "text           object  1\n",
      "selected_text  object  1\n",
      "sentiment      object  0\n",
      "(27481, 4)\n",
      "{'textID': 27481, 'text': 27480, 'selected_text': 22463, 'sentiment': 3}\n",
      "            textID                                                   text  \\\n",
      "count   27481       27480                                                   \n",
      "unique  27481       27480                                                   \n",
      "top     233197e487   ok... maybe not angry... just with very little sense   \n",
      "freq    1           1                                                       \n",
      "\n",
      "       selected_text sentiment  \n",
      "count   27480         27481     \n",
      "unique  22463         3         \n",
      "top     good          neutral   \n",
      "freq    199           11118     \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                            text  \\\n",
       "0  cb774db0d1   I`d have responded, if I were going             \n",
       "1  549e992a42   Sooo SAD I will miss you here in San Diego!!!   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going  neutral   \n",
       "1  Sooo SAD                             negative  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\",\n",
    "                 dtype={\"time\":np.float64,\"signal\":np.float64,\"open_channels\":np.int16},\n",
    "                 encoding=\"utf8\")\n",
    "\n",
    "df2 = pd.read_csv(\"../data/train.csv\",\n",
    "                 dtype={\"time\":np.float64,\"signal\":np.float64,\"open_channels\":np.int16})\n",
    "\n",
    "print(pd.concat((df.dtypes, df.isna().sum()), axis=1))\n",
    "print(df.shape)\n",
    "\n",
    "# Counts of various columns\n",
    "print({i:df[i].nunique() for i in df.columns})\n",
    "print(df.describe()) #.astype(int)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0  1\n",
      "textID     object  0\n",
      "text       object  0\n",
      "sentiment  object  0\n",
      "(3534, 3)\n",
      "{'textID': 3534, 'text': 3534, 'sentiment': 3}\n",
      "            textID  \\\n",
      "count   3534         \n",
      "unique  3534         \n",
      "top     f7835156a5   \n",
      "freq    1            \n",
      "\n",
      "                                                                                                                                            text  \\\n",
      "count   3534                                                                                                                                       \n",
      "unique  3534                                                                                                                                       \n",
      "top     spirit week! Tuesday have to be in make up by eight so I can die later. School wednesday and thursday then, finally sleep in on Friday!!   \n",
      "freq    1                                                                                                                                          \n",
      "\n",
      "       sentiment  \n",
      "count   3534      \n",
      "unique  3         \n",
      "top     neutral   \n",
      "freq    1430      \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID  \\\n",
       "0  f87dea47db   \n",
       "1  96d74cb729   \n",
       "\n",
       "                                                                                                      text  \\\n",
       "0  Last session of the day  http://twitpic.com/67ezh                                                         \n",
       "1   Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).   \n",
       "\n",
       "  sentiment  \n",
       "0  neutral   \n",
       "1  positive  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"../data/test.csv\", dtype={\"time\":np.float64,\"signal\":np.float64})\n",
    "print(pd.concat((test_df.dtypes, test_df.isna().sum()), axis=1))\n",
    "print(test_df.shape)\n",
    "\n",
    "# Counts of various columns\n",
    "print({i:test_df[i].nunique() for i in test_df.columns})\n",
    "print(test_df.describe())\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>c77717b103</td>\n",
       "      <td>I love to! But I`m only available from 5pm.  and where dear? Would love to help  convert her vids.ï¿½</td>\n",
       "      <td>I love to!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>28dbada620</td>\n",
       "      <td>*phew*  Will make a note in case anyone else runs into the same issueï¿½</td>\n",
       "      <td>*phew*  Will make a note in case anyone else runs into the same issueï¿½</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         textID  \\\n",
       "44   c77717b103   \n",
       "192  28dbada620   \n",
       "\n",
       "                                                                                                       text  \\\n",
       "44    I love to! But I`m only available from 5pm.  and where dear? Would love to help  convert her vids.ï¿½   \n",
       "192   *phew*  Will make a note in case anyone else runs into the same issueï¿½                                \n",
       "\n",
       "                                                                selected_text  \\\n",
       "44   I love to!                                                                 \n",
       "192  *phew*  Will make a note in case anyone else runs into the same issueï¿½   \n",
       "\n",
       "    sentiment  \n",
       "44   positive  \n",
       "192  neutral   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df2['text'].astype('str').apply(lambda x : len(re.findall(pattern=\"ï¿½\", string=x))>0)].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>7223fdccc2</td>\n",
       "      <td>tikcets are only ï¿½91...each...BUT I SO WANT TO GO</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>43ad351369</td>\n",
       "      <td>AHHH - Whatchu talkinï¿½ baby?  HAHAHA I canï¿½t believe youu:O heh, actually I can. Life is worth taking risks... http://tumblr.com/xs81qy54s</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         textID  \\\n",
       "145  7223fdccc2   \n",
       "618  43ad351369   \n",
       "\n",
       "                                                                                                                                               text  \\\n",
       "145  tikcets are only ï¿½91...each...BUT I SO WANT TO GO                                                                                              \n",
       "618  AHHH - Whatchu talkinï¿½ baby?  HAHAHA I canï¿½t believe youu:O heh, actually I can. Life is worth taking risks... http://tumblr.com/xs81qy54s   \n",
       "\n",
       "    sentiment  \n",
       "145  positive  \n",
       "618  positive  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.loc[test_df['text'].astype('str').apply(lambda x : len(re.findall(pattern=\"ï¿½\", string=x))>0)].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment count in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>7781</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>11117</td>\n",
       "      <td>1430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>8582</td>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text  text\n",
       "sentiment             \n",
       "negative   7781   1001\n",
       "neutral    11117  1430\n",
       "positive   8582   1103"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df.groupby(\"sentiment\")[[\"text\"]].count(), test_df.groupby(\"sentiment\")[[\"text\"]].count()], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For traceability\n",
    "df[\"original_index\"] = df.index\n",
    "test_df[\"original_index\"] = test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27481, 5)\n",
      "(27480, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df[(~df.text.isna())]\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.copy()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment_code\"] = df[\"sentiment\"].astype(\"category\")\n",
    "X_sentiments = df[\"sentiment_code\"].cat.codes.values\n",
    "\n",
    "test_df[\"sentiment_code\"] = test_df[\"sentiment\"].astype(\"category\")\n",
    "X_sentiments_test = test_df[\"sentiment_code\"].cat.codes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "df[\"selected_text\"] = df[\"selected_text\"].astype(str)\n",
    "test_df[\"text\"] = test_df[\"text\"].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(x, extra_string=None):\n",
    "    x = x.lower()\n",
    "    x = re.sub('([!\"#$%&()*+,-./:;\\'<=>?@[\\\\]^_{|}~\\t\\n])', ' \\\\1 ', x) # Not including ` here since used in couldn`t, isn`t\n",
    "    x = x.strip()\n",
    "    x = re.sub(' +', ' ', x)\n",
    "    x = x.split(\" \")\n",
    "    if extra_string is not None:\n",
    "        x = [\"xxxSTART\"] + x + [\"xxxSENTIMENT\"] + [extra_string] + [\"xxxEND\"]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extremities(l_string, s_string, extra_string, print_it=False):\n",
    "    l_string = preprocess_text(l_string, extra_string)\n",
    "    s_string = preprocess_text(s_string, extra_string=None)\n",
    "    \n",
    "    len_l = len(l_string)\n",
    "    len_s = len(s_string)\n",
    "    \n",
    "    for i in range(len_l - len_s + 1):\n",
    "        if (i + len_s) <= len_l:\n",
    "            substring = l_string[i:i+len_s]\n",
    "            if substring == s_string:\n",
    "                if print_it:\n",
    "                    print(l_string)\n",
    "                    print(substring)\n",
    "                    print(i, i+len_s, substring)\n",
    "                \n",
    "                start_vector, end_vector = np.zeros(len_l, dtype=np.int16), np.zeros(len_l, dtype=np.int16)\n",
    "                att_vector = np.ones(len_l, dtype=np.int16)\n",
    "                start_vector[i], end_vector[i+len_s-1] = 1, 1\n",
    "                \n",
    "                return (l_string, s_string, start_vector, end_vector, att_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['xxxSTART',\n",
       "  '4am',\n",
       "  '.',\n",
       "  'and',\n",
       "  'im',\n",
       "  'on',\n",
       "  'the',\n",
       "  'beach',\n",
       "  '.',\n",
       "  'pretty',\n",
       "  'xxxSENTIMENT',\n",
       "  'positive',\n",
       "  'xxxEND'],\n",
       " ['pretty'],\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], dtype=int16),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], dtype=int16),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int16))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 100\n",
    "get_extremities(df.text[idx], df.selected_text[idx], df.sentiment[idx], print_it=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"text_mod\", \"selected_text_mod\", \"target_start\", \"target_stop\", \"target_atten\"]] = df.apply(lambda x: get_extremities(x.text, x.selected_text, x.sentiment), axis=1).apply(pd.Series)\n",
    "test_df[[\"text_mod\"]] = test_df.apply(lambda x: [preprocess_text(x.text, extra_string = x.sentiment)], axis=1).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID               0   \n",
       "text                 0   \n",
       "selected_text        0   \n",
       "sentiment            0   \n",
       "original_index       0   \n",
       "sentiment_code       0   \n",
       "text_mod             1476\n",
       "selected_text_mod    1476\n",
       "target_start         1476\n",
       "target_stop          1476\n",
       "target_atten         1476\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textID            0\n",
       "text              0\n",
       "sentiment         0\n",
       "original_index    0\n",
       "sentiment_code    0\n",
       "text_mod          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>original_index</th>\n",
       "      <th>sentiment_code</th>\n",
       "      <th>text_mod</th>\n",
       "      <th>selected_text_mod</th>\n",
       "      <th>target_start</th>\n",
       "      <th>target_stop</th>\n",
       "      <th>target_atten</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[xxxSTART, i`d, have, responded, ,, if, i, were, going, xxxSENTIMENT, neutral, xxxEND]</td>\n",
       "      <td>[i`d, have, responded, ,, if, i, were, going]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>[xxxSTART, sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !, xxxSENTIMENT, negative, xxxEND]</td>\n",
       "      <td>[sooo, sad]</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                            text  \\\n",
       "0  cb774db0d1   I`d have responded, if I were going             \n",
       "1  549e992a42   Sooo SAD I will miss you here in San Diego!!!   \n",
       "\n",
       "                         selected_text sentiment  original_index  \\\n",
       "0  I`d have responded, if I were going  neutral   0                \n",
       "1  Sooo SAD                             negative  1                \n",
       "\n",
       "  sentiment_code  \\\n",
       "0  neutral         \n",
       "1  negative        \n",
       "\n",
       "                                                                                                   text_mod  \\\n",
       "0  [xxxSTART, i`d, have, responded, ,, if, i, were, going, xxxSENTIMENT, neutral, xxxEND]                     \n",
       "1  [xxxSTART, sooo, sad, i, will, miss, you, here, in, san, diego, !, !, !, xxxSENTIMENT, negative, xxxEND]   \n",
       "\n",
       "                               selected_text_mod  \\\n",
       "0  [i`d, have, responded, ,, if, i, were, going]   \n",
       "1  [sooo, sad]                                     \n",
       "\n",
       "                                          target_start  \\\n",
       "0  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]                  \n",
       "1  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                           target_stop  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]                  \n",
       "1  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                          target_atten  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]                 \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>original_index</th>\n",
       "      <th>sentiment_code</th>\n",
       "      <th>text_mod</th>\n",
       "      <th>selected_text_mod</th>\n",
       "      <th>target_start</th>\n",
       "      <th>target_stop</th>\n",
       "      <th>target_atten</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>af3fed7fc3</td>\n",
       "      <td>is back home now      gonna miss every one</td>\n",
       "      <td>onna</td>\n",
       "      <td>negative</td>\n",
       "      <td>18</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1c31703aef</td>\n",
       "      <td>If it is any consolation I got my BMI tested hahaha it says I am obesed  well so much for being unhappy for about 10 minutes.</td>\n",
       "      <td>well so much for being unhappy for about 10 minute</td>\n",
       "      <td>negative</td>\n",
       "      <td>32</td>\n",
       "      <td>negative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        textID  \\\n",
       "18  af3fed7fc3   \n",
       "32  1c31703aef   \n",
       "\n",
       "                                                                                                                              text  \\\n",
       "18  is back home now      gonna miss every one                                                                                       \n",
       "32   If it is any consolation I got my BMI tested hahaha it says I am obesed  well so much for being unhappy for about 10 minutes.   \n",
       "\n",
       "                                         selected_text sentiment  \\\n",
       "18  onna                                                negative   \n",
       "32  well so much for being unhappy for about 10 minute  negative   \n",
       "\n",
       "    original_index sentiment_code text_mod selected_text_mod target_start  \\\n",
       "18  18              negative       NaN      NaN               NaN           \n",
       "32  32              negative       NaN      NaN               NaN           \n",
       "\n",
       "   target_stop target_atten  \n",
       "18  NaN         NaN          \n",
       "32  NaN         NaN          "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[df.loc[df['target_start'].isna()].index].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>original_index</th>\n",
       "      <th>sentiment_code</th>\n",
       "      <th>text_mod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[xxxSTART, last, session, of, the, day, http, :, /, /, twitpic, ., com, /, 67ezh, xxxSENTIMENT, neutral, xxxEND]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>[xxxSTART, shanghai, is, also, really, exciting, (, precisely, -, -, skyscrapers, galore, ), ., good, tweeps, in, china, :, (, sh, ), (, bj, ), ., xxxSENTIMENT, positive, xxxEND]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID  \\\n",
       "0  f87dea47db   \n",
       "1  96d74cb729   \n",
       "\n",
       "                                                                                                      text  \\\n",
       "0  Last session of the day  http://twitpic.com/67ezh                                                         \n",
       "1   Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).   \n",
       "\n",
       "  sentiment  original_index sentiment_code  \\\n",
       "0  neutral   0               neutral         \n",
       "1  positive  1               positive        \n",
       "\n",
       "                                                                                                                                                                             text_mod  \n",
       "0  [xxxSTART, last, session, of, the, day, http, :, /, /, twitpic, ., com, /, 67ezh, xxxSENTIMENT, neutral, xxxEND]                                                                    \n",
       "1  [xxxSTART, shanghai, is, also, really, exciting, (, precisely, -, -, skyscrapers, galore, ), ., good, tweeps, in, china, :, (, sh, ), (, bj, ), ., xxxSENTIMENT, positive, xxxEND]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalous_idxs = df.loc[df['target_start'].isna()].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27480, 11)\n",
      "(26004, 11)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df[~df.index.isin(anomalous_idxs)]\n",
    "df = df.reset_index(drop=True)\n",
    "df = df.copy()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " X_words: \t 26004 \n",
      " X_att: \t 26004 \n",
      " Y_words: \t 26004 \n",
      " Y_starts: \t 26004 \n",
      " Y_stops: \t 26004 \n",
      " X_words_test: \t 3534 \n",
      " X_att_test: \t 3534 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_words = df['text_mod'].apply(lambda x:list(x)).tolist()\n",
    "X_att = df['target_atten'].apply(lambda x:list(x)).tolist()\n",
    "\n",
    "X_words_test = test_df['text_mod'].apply(lambda x:list(x)).tolist()\n",
    "X_att_test = [[1 for j in i] for i in X_words_test]\n",
    "\n",
    "Y_words = df['selected_text_mod'].apply(lambda x:list(x)).tolist()\n",
    "Y_starts = df['target_start'].apply(lambda x:list(x)).tolist()\n",
    "Y_stops = df['target_stop'].apply(lambda x:list(x)).tolist()\n",
    "\n",
    "print(\"\\n\",\n",
    "    \"X_words:\",\"\\t\", len(X_words),\"\\n\",\n",
    "    \"X_att:\",\"\\t\", len(X_att),\"\\n\",\n",
    "    \"Y_words:\",\"\\t\", len(Y_words),\"\\n\",\n",
    "    \"Y_starts:\",\"\\t\", len(Y_starts),\"\\n\",\n",
    "    \"Y_stops:\",\"\\t\", len(Y_stops),\"\\n\",\n",
    "    \"X_words_test:\",\"\\t\", len(X_words_test),\"\\n\",\n",
    "    \"X_att_test:\",\"\\t\", len(X_att_test),\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3534\n",
      "26004\n"
     ]
    }
   ],
   "source": [
    "print(sum([len(i)==len(j) for i,j in zip(X_att_test, X_words_test)]))\n",
    "print(sum([len(i)==len(j) for i,j in zip(X_att, X_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 33619),\n",
       " ('xxxSTART', 26004),\n",
       " ('xxxSENTIMENT', 26004),\n",
       " ('xxxEND', 26004),\n",
       " ('!', 14379),\n",
       " ('i', 12615),\n",
       " ('neutral', 10941),\n",
       " ('to', 9447),\n",
       " ('the', 8445),\n",
       " (',', 7984)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "word_counts = Counter([j for i in X_words for j in i])\n",
    "\n",
    "X_unique_tokens = len(word_counts)\n",
    "word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_WORD_FREQ = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB reduced from 25847 to 10178\n"
     ]
    }
   ],
   "source": [
    "word_subset = [i for i,j in word_counts.items() if j >= MIN_WORD_FREQ]\n",
    "print(\"VOCAB reduced from\", len(word_counts), \"to\", len(word_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_of_words = set(sorted([j for i in X_words for j in i]))\n",
    "#Y_list_of_words = set(sorted([j for i in Y_words for j in i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_itos = {i+2:j for i,j in enumerate(word_subset)}\n",
    "vocab_stoi = {j:i+2 for i,j in enumerate(word_subset)}\n",
    "\n",
    "vocab_stoi[\"xxxUNK\"] = 1\n",
    "vocab_itos[1] = \"xxxUNK\"\n",
    "\n",
    "vocab_stoi[\"xxxNone\"] = 0\n",
    "vocab_itos[0] = \"xxxNone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_vocab(vocab, word):\n",
    "    try:\n",
    "        value = vocab[word]\n",
    "    except KeyError as k:\n",
    "        value = vocab_stoi[\"xxxUNK\"]\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[get_from_vocab(vocab_stoi,j) for j in i] for i in X_words]\n",
    "Y = [[get_from_vocab(vocab_stoi,j) for j in i] for i in Y_words]\n",
    "X_test = [[get_from_vocab(vocab_stoi,j) for j in i] for i in X_words_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10180 110\n"
     ]
    }
   ],
   "source": [
    "max_len = max([len(i) for i in X])\n",
    "VOCAB_SIZE = len(vocab_stoi)\n",
    "print(VOCAB_SIZE, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Validation  split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26004 20803 5201 26004\n"
     ]
    }
   ],
   "source": [
    "idx = [i for i in np.arange(len(Y))]\n",
    "np.random.shuffle(idx)\n",
    "train_idx, val_idx = idx[:round(TRAIN_SPLIT_RATIO*len(Y))], idx[round(TRAIN_SPLIT_RATIO * len(Y)):]\n",
    "\n",
    "print(len(idx), len(train_idx), len(val_idx), len(train_idx) + len(val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 20803 \t : X_train \n",
      " 20803 \t : X_att_train \n",
      " 20803 \t : Y_train \n",
      " 20803 \t : Y_starts_train \n",
      " 20803 \t : Y_stops_train \n",
      " 5201 \t : X_val \n",
      " 5201 \t : X_att_val \n",
      " 5201 \t : Y_val \n",
      " 5201 \t : Y_starts_val \n",
      " 5201 \t : Y_stops_val \n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val = [X[i] for i in train_idx], [X[i] for i in val_idx]\n",
    "X_att_train, X_att_val = [X_att[i] for i in train_idx], [X_att[i] for i in val_idx]\n",
    "\n",
    "Y_train, Y_val = [Y[i] for i in train_idx], [Y[i] for i in val_idx]\n",
    "Y_starts_train, Y_starts_val = [Y_starts[i] for i in train_idx], [Y_starts[i] for i in val_idx]\n",
    "Y_stops_train, Y_stops_val = [Y_stops[i] for i in train_idx], [Y_stops[i] for i in val_idx]\n",
    "\n",
    "print(\"\\n\",\n",
    "    len(X_train),\"\\t\",\": X_train\",\"\\n\",\n",
    "    len(X_att_train),\"\\t\",\": X_att_train\",\"\\n\",\n",
    "    len(Y_train),\"\\t\",\": Y_train\",\"\\n\",\n",
    "    len(Y_starts_train),\"\\t\",\": Y_starts_train\",\"\\n\",\n",
    "    len(Y_stops_train),\"\\t\",\": Y_stops_train\",\"\\n\",\n",
    "    len(X_val),\"\\t\",\": X_val\",\"\\n\",\n",
    "    len(X_att_val),\"\\t\",\": X_att_val\",\"\\n\",\n",
    "    len(Y_val),\"\\t\",\": Y_val\",\"\\n\",\n",
    "    len(Y_starts_val),\"\\t\",\": Y_starts_val\",\"\\n\",\n",
    "    len(Y_stops_val),\"\\t\",\": Y_stops_val\",\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=max_len, padding=\"post\")\n",
    "X_att_train = pad_sequences(X_att_train, maxlen=max_len, padding=\"post\")\n",
    "Y_train = pad_sequences(Y_train, maxlen=max_len, padding=\"post\")\n",
    "Y_starts_train = pad_sequences(Y_starts_train, maxlen=max_len, padding=\"post\")\n",
    "Y_stops_train = pad_sequences(Y_stops_train, maxlen=max_len, padding=\"post\")\n",
    "\n",
    "X_val = pad_sequences(X_val, maxlen=max_len, padding=\"post\")\n",
    "X_att_val = pad_sequences(X_att_val, maxlen=max_len, padding=\"post\")\n",
    "Y_val = pad_sequences(Y_val, maxlen=max_len, padding=\"post\")\n",
    "Y_starts_val = pad_sequences(Y_starts_val, maxlen=max_len, padding=\"post\")\n",
    "Y_stops_val = pad_sequences(Y_stops_val, maxlen=max_len, padding=\"post\")\n",
    "\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding=\"post\")\n",
    "X_att_test = pad_sequences(X_att_test, maxlen=max_len, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " (20803, 110) \t: X_train  \n",
      " (20803, 110) \t: X_att_train  \n",
      " (20803, 110) \t: Y_train  \n",
      " (20803, 110) \t: Y_starts_train  \n",
      " (20803, 110) \t: Y_stops_train  \n",
      " (5201, 110) \t: X_val  \n",
      " (5201, 110) \t: X_att_val  \n",
      " (5201, 110) \t: Y_val  \n",
      " (5201, 110) \t: Y_starts_val  \n",
      " (5201, 110) \t: Y_stops_val  \n",
      " (3534, 110) \t: X_test  \n",
      " (3534, 110) \t: X_att_test  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\",\n",
    "     X_train.shape, \"\\t: X_train \", \"\\n\",\n",
    "     X_att_train.shape, \"\\t: X_att_train \", \"\\n\",\n",
    "     Y_train.shape, \"\\t: Y_train \", \"\\n\",\n",
    "     Y_starts_train.shape, \"\\t: Y_starts_train \", \"\\n\",\n",
    "     Y_stops_train.shape, \"\\t: Y_stops_train \", \"\\n\",\n",
    "\n",
    "     X_val.shape, \"\\t: X_val \", \"\\n\",\n",
    "     X_att_val.shape, \"\\t: X_att_val \", \"\\n\",\n",
    "     Y_val.shape, \"\\t: Y_val \", \"\\n\",\n",
    "     Y_starts_val.shape, \"\\t: Y_starts_val \", \"\\n\",\n",
    "     Y_stops_val.shape, \"\\t: Y_stops_val \", \"\\n\",\n",
    "\n",
    "     X_test.shape, \"\\t: X_test \", \"\\n\",\n",
    "     X_att_test.shape, \"\\t: X_att_test \", \"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for zero input vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 36\n",
      "0 36\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax([X_train.sum(axis=1)==0]), np.min([X_train.sum(axis=1)]))\n",
    "print(np.argmax([X_val.sum(axis=1)==0]), np.min([X_val.sum(axis=1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1, 1662, 0, 0],\n",
       " [87, 1, 648, 0, 0],\n",
       " [17, 1, 2533, 0, 0],\n",
       " [2174, 1, 7, 0, 0],\n",
       " [669, 1, 1685, 0, 0],\n",
       " [84, 1, 278, 0, 0],\n",
       " [1662, 1, 17, 1, 0],\n",
       " [648, 1, 229, 0, 0],\n",
       " [2533, 1, 4625, 0, 0],\n",
       " [7, 1, 116, 0, 0],\n",
       " [1685, 1, 44, 0, 0],\n",
       " [278, 1, 406, 0, 0],\n",
       " [17, 1, 8227, 0, 0],\n",
       " [229, 1, 0, 0, 0],\n",
       " [4625, 1, 0, 0, 0],\n",
       " [116, 1, 0, 0, 0],\n",
       " [44, 1, 0, 0, 0],\n",
       " [406, 1, 0, 0, 0],\n",
       " [8227, 1, 0, 0, 1],\n",
       " [7492, 1, 0, 0, 0],\n",
       " [10, 1, 0, 0, 0],\n",
       " [11, 1, 0, 0, 0],\n",
       " [12, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train\n",
    "num = 100\n",
    "[[i,j,k,l,m] for i,j,k,l,m in zip(X_train[num],\n",
    "                                  X_att_train[num],\n",
    "                                  Y_train[num],\n",
    "                                  Y_starts_train[num],\n",
    "                                  Y_stops_train[num])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1, 9890, 0, 0],\n",
       " [9890, 1, 8753, 1, 0],\n",
       " [8753, 1, 55, 0, 0],\n",
       " [55, 1, 4465, 0, 0],\n",
       " [4465, 1, 305, 0, 0],\n",
       " [305, 1, 1, 0, 0],\n",
       " [1, 1, 28, 0, 0],\n",
       " [28, 1, 0, 0, 1],\n",
       " [47, 1, 0, 0, 0],\n",
       " [48, 1, 0, 0, 0],\n",
       " [49, 1, 0, 0, 0],\n",
       " [49, 1, 0, 0, 0],\n",
       " [50, 1, 0, 0, 0],\n",
       " [28, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [28, 1, 0, 0, 0],\n",
       " [51, 1, 0, 0, 0],\n",
       " [49, 1, 0, 0, 0],\n",
       " [1, 1, 0, 0, 0],\n",
       " [49, 1, 0, 0, 0],\n",
       " [9890, 1, 0, 0, 0],\n",
       " [28, 1, 0, 0, 0],\n",
       " [7327, 1, 0, 0, 0],\n",
       " [10, 1, 0, 0, 0],\n",
       " [11, 1, 0, 0, 0],\n",
       " [12, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Val\n",
    "num = 100\n",
    "[[i,j,k,l,m] for i,j,k,l,m in zip(X_val[num],\n",
    "                                  X_att_val[num],\n",
    "                                  Y_val[num],\n",
    "                                  Y_starts_val[num],\n",
    "                                  Y_stops_val[num])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['xxxSTART', 2, 1],\n",
       " ['oooh', 3482, 1],\n",
       " [',', 5, 1],\n",
       " ['sunshine', 1726, 1],\n",
       " ['!', 22, 1],\n",
       " ['a', 142, 1],\n",
       " ['patch', 905, 1],\n",
       " ['of', 34, 1],\n",
       " ['sunshine', 1726, 1],\n",
       " ['!', 22, 1],\n",
       " ['and', 68, 1],\n",
       " ['it', 144, 1],\n",
       " ['will', 15, 1],\n",
       " ['be', 89, 1],\n",
       " ['gone', 544, 1],\n",
       " ['by', 106, 1],\n",
       " ['the', 42, 1],\n",
       " ['time', 504, 1],\n",
       " ['i', 7, 1],\n",
       " ['leave', 31, 1],\n",
       " ['work', 342, 1],\n",
       " ['and', 68, 1],\n",
       " ['replaced', 1, 1],\n",
       " ['with', 278, 1],\n",
       " ['rain', 1901, 1],\n",
       " ['.', 28, 1],\n",
       " ['/', 49, 1],\n",
       " ['vent', 9146, 1],\n",
       " ['xxxSENTIMENT', 10, 1],\n",
       " ['neutral', 11, 1],\n",
       " ['xxxEND', 12, 1]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test\n",
    "num = 100\n",
    "[[i,j,k] for i,j,k in zip(X_words_test[num],\n",
    "                          X_test[num],\n",
    "                          X_att_test[num])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_att_flags = Input((max_len), name=\"att_flags\")\n",
    "input_sequences = Input((max_len), name=\"words\")\n",
    "\n",
    "emb_sequences = Embedding(input_dim=VOCAB_SIZE, input_length=max_len, output_dim=64, mask_zero=True)(input_sequences)\n",
    "\n",
    "seq = Bidirectional(LSTM(16, activation=None, return_sequences=True))(emb_sequences)\n",
    "seq = BatchNormalization()(seq)\n",
    "seq = Activation(\"relu\")(seq)\n",
    "seq = Dropout(DROPOUT)(seq)\n",
    "\n",
    "seq = Bidirectional(LSTM(16, activation=None, return_sequences=False))(seq)\n",
    "seq = BatchNormalization()(seq)\n",
    "seq = Activation(\"relu\")(seq)\n",
    "seq = Dropout(DROPOUT)(seq)\n",
    "\n",
    "seq = Dense(max_len, activation=\"relu\")(seq)\n",
    "seq = BatchNormalization()(seq)\n",
    "seq = Dropout(DROPOUT)(seq)\n",
    "\n",
    "att = Dense(max_len, activation=\"relu\")(input_att_flags)\n",
    "att = BatchNormalization()(att)\n",
    "att = Dropout(DROPOUT)(att)\n",
    "\n",
    "convs = Conv1D(filters=32, kernel_size=8, padding=\"causal\", activation=None)(emb_sequences)\n",
    "convs = BatchNormalization()(convs)\n",
    "convs = Activation(\"relu\")(convs)\n",
    "convs = Dropout(DROPOUT)(convs)\n",
    "\n",
    "convs = Conv1D(filters=32, kernel_size=8, padding=\"causal\", activation=None)(convs)\n",
    "convs = BatchNormalization()(convs)\n",
    "convs = Activation(\"relu\")(convs)\n",
    "convs = Dropout(DROPOUT)(convs)\n",
    "\n",
    "convs = Flatten()(convs)\n",
    "convs = Dense(max_len, activation='relu')(convs)\n",
    "\n",
    "seq = Multiply()([convs, seq])\n",
    "seq = Multiply()([att, seq])\n",
    "\n",
    "output_starts = Dense(max_len, activation='softmax', name=\"starts\")(seq)\n",
    "output_stops = Dense(max_len, activation='softmax', name=\"stops\")(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "words (InputLayer)              [(None, 110)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 110, 64)      651520      words[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 110, 32)      10368       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 110, 32)      16416       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 110, 32)      128         bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 110, 32)      128         conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 110, 32)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 110, 32)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 110, 32)      0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 110, 32)      0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 32)           6272        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 110, 32)      8224        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32)           128         bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 110, 32)      128         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32)           0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 110, 32)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "att_flags (InputLayer)          [(None, 110)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 110, 32)      0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 110)          3630        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 110)          12210       att_flags[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3520)         0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 110)          440         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 110)          440         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 110)          387310      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 110)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 110)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 110)          0           dense_2[0][0]                    \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 110)          0           dropout_3[0][0]                  \n",
      "                                                                 multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "starts (Dense)                  (None, 110)          12210       multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "stops (Dense)                   (None, 110)          12210       multiply_1[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,121,762\n",
      "Trainable params: 1,121,066\n",
      "Non-trainable params: 696\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([input_att_flags, input_sequences], [output_starts, output_stops])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=MIN_LR)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=adam , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks\n",
    "mcp = ModelCheckpoint(filepath=\"../results/\"+MODEL_PREFIX+\"Checkpoint.h5\",\n",
    "                      monitor='val_loss',\n",
    "                      mode=\"auto\",\n",
    "                      save_weights_only=False,\n",
    "                      save_best_only=True)\n",
    "\n",
    "clr = CyclicLR(mode=CLR_METHOD,\n",
    "               base_lr=MIN_LR,\n",
    "               max_lr=MAX_LR,\n",
    "               step_size= STEP_SIZE * (X_train.shape[0] // BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20803 samples, validate on 5201 samples\n",
      "Epoch 1/1000\n",
      "20803/20803 [==============================] - 23s 1ms/sample - loss: 9.9363 - starts_loss: 4.9446 - stops_loss: 4.9783 - starts_accuracy: 0.0136 - stops_accuracy: 0.0086 - val_loss: 9.3978 - val_starts_loss: 4.6988 - val_stops_loss: 4.6990 - val_starts_accuracy: 0.0925 - val_stops_accuracy: 0.0506\n",
      "Epoch 2/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 9.4409 - starts_loss: 4.7132 - stops_loss: 4.7254 - starts_accuracy: 0.0314 - stops_accuracy: 0.0164 - val_loss: 9.3887 - val_starts_loss: 4.6941 - val_stops_loss: 4.6946 - val_starts_accuracy: 0.0410 - val_stops_accuracy: 0.0931\n",
      "Epoch 3/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 9.3605 - starts_loss: 4.6701 - stops_loss: 4.6893 - starts_accuracy: 0.1129 - stops_accuracy: 0.0329 - val_loss: 9.3752 - val_starts_loss: 4.6877 - val_stops_loss: 4.6877 - val_starts_accuracy: 0.0521 - val_stops_accuracy: 0.0863\n",
      "Epoch 4/1000\n",
      "20803/20803 [==============================] - 13s 623us/sample - loss: 9.2451 - starts_loss: 4.5738 - stops_loss: 4.6678 - starts_accuracy: 0.1674 - stops_accuracy: 0.0373 - val_loss: 9.3619 - val_starts_loss: 4.6829 - val_stops_loss: 4.6791 - val_starts_accuracy: 0.0565 - val_stops_accuracy: 0.0315\n",
      "Epoch 5/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 8.8687 - starts_loss: 4.2817 - stops_loss: 4.5750 - starts_accuracy: 0.2708 - stops_accuracy: 0.0429 - val_loss: 9.3414 - val_starts_loss: 4.6746 - val_stops_loss: 4.6675 - val_starts_accuracy: 0.2223 - val_stops_accuracy: 0.0315\n",
      "Epoch 6/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 7.7251 - starts_loss: 3.4433 - stops_loss: 4.2479 - starts_accuracy: 0.4461 - stops_accuracy: 0.0657 - val_loss: 9.1958 - val_starts_loss: 4.5776 - val_stops_loss: 4.6217 - val_starts_accuracy: 0.3392 - val_stops_accuracy: 0.0983\n",
      "Epoch 7/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 6.2603 - starts_loss: 2.6015 - stops_loss: 3.6362 - starts_accuracy: 0.5474 - stops_accuracy: 0.1180 - val_loss: 8.8103 - val_starts_loss: 4.3289 - val_stops_loss: 4.4912 - val_starts_accuracy: 0.3782 - val_stops_accuracy: 0.0500\n",
      "Epoch 8/1000\n",
      "20803/20803 [==============================] - 13s 619us/sample - loss: 5.3748 - starts_loss: 2.1176 - stops_loss: 3.2511 - starts_accuracy: 0.5803 - stops_accuracy: 0.1808 - val_loss: 8.3429 - val_starts_loss: 4.0456 - val_stops_loss: 4.3143 - val_starts_accuracy: 0.3884 - val_stops_accuracy: 0.0746\n",
      "Epoch 9/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 4.6084 - starts_loss: 1.9422 - stops_loss: 2.6568 - starts_accuracy: 0.5809 - stops_accuracy: 0.2781 - val_loss: 8.1087 - val_starts_loss: 3.9229 - val_stops_loss: 4.2059 - val_starts_accuracy: 0.4101 - val_stops_accuracy: 0.0975\n",
      "Epoch 10/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 4.1660 - starts_loss: 1.8598 - stops_loss: 2.3156 - starts_accuracy: 0.5757 - stops_accuracy: 0.3854 - val_loss: 7.7115 - val_starts_loss: 3.6949 - val_stops_loss: 4.0429 - val_starts_accuracy: 0.4628 - val_stops_accuracy: 0.0948\n",
      "Epoch 11/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 3.8641 - starts_loss: 1.7830 - stops_loss: 2.0757 - starts_accuracy: 0.5834 - stops_accuracy: 0.4636 - val_loss: 7.4588 - val_starts_loss: 3.5695 - val_stops_loss: 3.9182 - val_starts_accuracy: 0.5382 - val_stops_accuracy: 0.1715\n",
      "Epoch 12/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 3.6734 - starts_loss: 1.7302 - stops_loss: 1.9415 - starts_accuracy: 0.5850 - stops_accuracy: 0.5060 - val_loss: 7.0505 - val_starts_loss: 3.3345 - val_stops_loss: 3.7496 - val_starts_accuracy: 0.5778 - val_stops_accuracy: 0.2069\n",
      "Epoch 13/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 3.5651 - starts_loss: 1.6804 - stops_loss: 1.8840 - starts_accuracy: 0.5902 - stops_accuracy: 0.5199 - val_loss: 6.9358 - val_starts_loss: 3.2843 - val_stops_loss: 3.6857 - val_starts_accuracy: 0.5980 - val_stops_accuracy: 0.2251\n",
      "Epoch 14/1000\n",
      "20803/20803 [==============================] - 13s 620us/sample - loss: 3.4800 - starts_loss: 1.6551 - stops_loss: 1.8237 - starts_accuracy: 0.5904 - stops_accuracy: 0.5383 - val_loss: 6.7636 - val_starts_loss: 3.2070 - val_stops_loss: 3.5928 - val_starts_accuracy: 0.5983 - val_stops_accuracy: 0.2348\n",
      "Epoch 15/1000\n",
      "20803/20803 [==============================] - 13s 620us/sample - loss: 3.4125 - starts_loss: 1.6231 - stops_loss: 1.7854 - starts_accuracy: 0.5921 - stops_accuracy: 0.5427 - val_loss: 6.6186 - val_starts_loss: 3.1440 - val_stops_loss: 3.5113 - val_starts_accuracy: 0.5985 - val_stops_accuracy: 0.2348\n",
      "Epoch 16/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 3.3755 - starts_loss: 1.6122 - stops_loss: 1.7624 - starts_accuracy: 0.5931 - stops_accuracy: 0.5528 - val_loss: 6.3390 - val_starts_loss: 2.9994 - val_stops_loss: 3.3782 - val_starts_accuracy: 0.5987 - val_stops_accuracy: 0.2382\n",
      "Epoch 17/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 3.3317 - starts_loss: 1.5970 - stops_loss: 1.7320 - starts_accuracy: 0.5937 - stops_accuracy: 0.5554 - val_loss: 6.1899 - val_starts_loss: 2.9323 - val_stops_loss: 3.2984 - val_starts_accuracy: 0.5983 - val_stops_accuracy: 0.2448\n",
      "Epoch 18/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 3.2874 - starts_loss: 1.5713 - stops_loss: 1.7087 - starts_accuracy: 0.5953 - stops_accuracy: 0.5606 - val_loss: 5.9980 - val_starts_loss: 2.8448 - val_stops_loss: 3.1952 - val_starts_accuracy: 0.5983 - val_stops_accuracy: 0.2821\n",
      "Epoch 19/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 3.2846 - starts_loss: 1.5784 - stops_loss: 1.7053 - starts_accuracy: 0.5943 - stops_accuracy: 0.5590 - val_loss: 5.7858 - val_starts_loss: 2.7437 - val_stops_loss: 3.0851 - val_starts_accuracy: 0.5985 - val_stops_accuracy: 0.3149\n",
      "Epoch 20/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 3.2919 - starts_loss: 1.5843 - stops_loss: 1.7146 - starts_accuracy: 0.5933 - stops_accuracy: 0.5609 - val_loss: 5.5603 - val_starts_loss: 2.6367 - val_stops_loss: 2.9673 - val_starts_accuracy: 0.5982 - val_stops_accuracy: 0.3545\n",
      "Epoch 21/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 3.2768 - starts_loss: 1.5773 - stops_loss: 1.7006 - starts_accuracy: 0.5937 - stops_accuracy: 0.5636 - val_loss: 5.3255 - val_starts_loss: 2.5277 - val_stops_loss: 2.8419 - val_starts_accuracy: 0.5987 - val_stops_accuracy: 0.4205\n",
      "Epoch 22/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 3.2693 - starts_loss: 1.5712 - stops_loss: 1.6974 - starts_accuracy: 0.5951 - stops_accuracy: 0.5609 - val_loss: 5.0819 - val_starts_loss: 2.4088 - val_stops_loss: 2.7172 - val_starts_accuracy: 0.5976 - val_stops_accuracy: 0.4468\n",
      "Epoch 23/1000\n",
      "20803/20803 [==============================] - 13s 624us/sample - loss: 3.2543 - starts_loss: 1.5675 - stops_loss: 1.6914 - starts_accuracy: 0.5930 - stops_accuracy: 0.5681 - val_loss: 4.8632 - val_starts_loss: 2.3077 - val_stops_loss: 2.5994 - val_starts_accuracy: 0.5953 - val_stops_accuracy: 0.4674\n",
      "Epoch 24/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 3.2345 - starts_loss: 1.5569 - stops_loss: 1.6758 - starts_accuracy: 0.5949 - stops_accuracy: 0.5671 - val_loss: 4.6632 - val_starts_loss: 2.2216 - val_stops_loss: 2.4841 - val_starts_accuracy: 0.5941 - val_stops_accuracy: 0.4795\n",
      "Epoch 25/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 3.2165 - starts_loss: 1.5461 - stops_loss: 1.6652 - starts_accuracy: 0.5956 - stops_accuracy: 0.5670 - val_loss: 4.3990 - val_starts_loss: 2.0999 - val_stops_loss: 2.3405 - val_starts_accuracy: 0.5968 - val_stops_accuracy: 0.4938\n",
      "Epoch 26/1000\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 3.1755 - starts_loss: 1.5284 - stops_loss: 1.6415 - starts_accuracy: 0.5961 - stops_accuracy: 0.5714 - val_loss: 4.1494 - val_starts_loss: 1.9905 - val_stops_loss: 2.1991 - val_starts_accuracy: 0.5966 - val_stops_accuracy: 0.5074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 3.1437 - starts_loss: 1.5167 - stops_loss: 1.6318 - starts_accuracy: 0.5973 - stops_accuracy: 0.5754 - val_loss: 4.0053 - val_starts_loss: 1.9217 - val_stops_loss: 2.1232 - val_starts_accuracy: 0.5970 - val_stops_accuracy: 0.5062\n",
      "Epoch 28/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 3.1065 - starts_loss: 1.5000 - stops_loss: 1.6091 - starts_accuracy: 0.5973 - stops_accuracy: 0.5742 - val_loss: 3.8365 - val_starts_loss: 1.8586 - val_stops_loss: 2.0153 - val_starts_accuracy: 0.5953 - val_stops_accuracy: 0.5189\n",
      "Epoch 29/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 3.0565 - starts_loss: 1.4800 - stops_loss: 1.5799 - starts_accuracy: 0.5982 - stops_accuracy: 0.5817 - val_loss: 3.7033 - val_starts_loss: 1.8060 - val_stops_loss: 1.9324 - val_starts_accuracy: 0.5974 - val_stops_accuracy: 0.5401\n",
      "Epoch 30/1000\n",
      "20803/20803 [==============================] - 13s 628us/sample - loss: 3.0031 - starts_loss: 1.4524 - stops_loss: 1.5567 - starts_accuracy: 0.5999 - stops_accuracy: 0.5822 - val_loss: 3.5781 - val_starts_loss: 1.7502 - val_stops_loss: 1.8623 - val_starts_accuracy: 0.5960 - val_stops_accuracy: 0.5505\n",
      "Epoch 31/1000\n",
      "20803/20803 [==============================] - 13s 628us/sample - loss: 2.9473 - starts_loss: 1.4307 - stops_loss: 1.5218 - starts_accuracy: 0.6008 - stops_accuracy: 0.5894 - val_loss: 3.4294 - val_starts_loss: 1.6928 - val_stops_loss: 1.7685 - val_starts_accuracy: 0.5985 - val_stops_accuracy: 0.5703\n",
      "Epoch 32/1000\n",
      "20803/20803 [==============================] - 13s 617us/sample - loss: 2.9057 - starts_loss: 1.4107 - stops_loss: 1.4918 - starts_accuracy: 0.6040 - stops_accuracy: 0.5922 - val_loss: 3.3254 - val_starts_loss: 1.6475 - val_stops_loss: 1.7098 - val_starts_accuracy: 0.5980 - val_stops_accuracy: 0.5766\n",
      "Epoch 33/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.8600 - starts_loss: 1.3880 - stops_loss: 1.4692 - starts_accuracy: 0.6049 - stops_accuracy: 0.5947 - val_loss: 3.2190 - val_starts_loss: 1.6034 - val_stops_loss: 1.6456 - val_starts_accuracy: 0.5991 - val_stops_accuracy: 0.5880\n",
      "Epoch 34/1000\n",
      "20803/20803 [==============================] - 13s 621us/sample - loss: 2.8165 - starts_loss: 1.3709 - stops_loss: 1.4475 - starts_accuracy: 0.6056 - stops_accuracy: 0.5999 - val_loss: 3.1456 - val_starts_loss: 1.5654 - val_stops_loss: 1.6132 - val_starts_accuracy: 0.5976 - val_stops_accuracy: 0.5835\n",
      "Epoch 35/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.7849 - starts_loss: 1.3566 - stops_loss: 1.4312 - starts_accuracy: 0.6090 - stops_accuracy: 0.5996 - val_loss: 3.0950 - val_starts_loss: 1.5461 - val_stops_loss: 1.5773 - val_starts_accuracy: 0.6003 - val_stops_accuracy: 0.5930\n",
      "Epoch 36/1000\n",
      "20803/20803 [==============================] - 13s 617us/sample - loss: 2.7602 - starts_loss: 1.3484 - stops_loss: 1.4141 - starts_accuracy: 0.6107 - stops_accuracy: 0.6041 - val_loss: 3.0231 - val_starts_loss: 1.5149 - val_stops_loss: 1.5381 - val_starts_accuracy: 0.5991 - val_stops_accuracy: 0.5941\n",
      "Epoch 37/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.7426 - starts_loss: 1.3410 - stops_loss: 1.4118 - starts_accuracy: 0.6093 - stops_accuracy: 0.6052 - val_loss: 2.9873 - val_starts_loss: 1.5020 - val_stops_loss: 1.5142 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.5976\n",
      "Epoch 38/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.7240 - starts_loss: 1.3296 - stops_loss: 1.3928 - starts_accuracy: 0.6116 - stops_accuracy: 0.6077 - val_loss: 2.9644 - val_starts_loss: 1.4928 - val_stops_loss: 1.4998 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.6007\n",
      "Epoch 39/1000\n",
      "20803/20803 [==============================] - 13s 617us/sample - loss: 2.7243 - starts_loss: 1.3271 - stops_loss: 1.3906 - starts_accuracy: 0.6122 - stops_accuracy: 0.6089 - val_loss: 2.9533 - val_starts_loss: 1.4883 - val_stops_loss: 1.4921 - val_starts_accuracy: 0.5999 - val_stops_accuracy: 0.6014\n",
      "Epoch 40/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.7207 - starts_loss: 1.3274 - stops_loss: 1.3902 - starts_accuracy: 0.6129 - stops_accuracy: 0.6067 - val_loss: 2.9440 - val_starts_loss: 1.4855 - val_stops_loss: 1.4846 - val_starts_accuracy: 0.6003 - val_stops_accuracy: 0.6030\n",
      "Epoch 41/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.7049 - starts_loss: 1.3237 - stops_loss: 1.3826 - starts_accuracy: 0.6124 - stops_accuracy: 0.6108 - val_loss: 2.9413 - val_starts_loss: 1.4841 - val_stops_loss: 1.4830 - val_starts_accuracy: 0.6003 - val_stops_accuracy: 0.6039\n",
      "Epoch 42/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.7033 - starts_loss: 1.3211 - stops_loss: 1.3846 - starts_accuracy: 0.6111 - stops_accuracy: 0.6104 - val_loss: 2.9384 - val_starts_loss: 1.4867 - val_stops_loss: 1.4764 - val_starts_accuracy: 0.6008 - val_stops_accuracy: 0.6053\n",
      "Epoch 43/1000\n",
      "20803/20803 [==============================] - 13s 646us/sample - loss: 2.6858 - starts_loss: 1.3113 - stops_loss: 1.3747 - starts_accuracy: 0.6117 - stops_accuracy: 0.6102 - val_loss: 2.9360 - val_starts_loss: 1.4809 - val_stops_loss: 1.4792 - val_starts_accuracy: 0.5989 - val_stops_accuracy: 0.6051\n",
      "Epoch 44/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.6636 - starts_loss: 1.3083 - stops_loss: 1.3592 - starts_accuracy: 0.6129 - stops_accuracy: 0.6151 - val_loss: 2.9294 - val_starts_loss: 1.4803 - val_stops_loss: 1.4715 - val_starts_accuracy: 0.6003 - val_stops_accuracy: 0.6064\n",
      "Epoch 45/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.6594 - starts_loss: 1.2961 - stops_loss: 1.3547 - starts_accuracy: 0.6150 - stops_accuracy: 0.6152 - val_loss: 2.9356 - val_starts_loss: 1.4771 - val_stops_loss: 1.4792 - val_starts_accuracy: 0.5983 - val_stops_accuracy: 0.6047\n",
      "Epoch 46/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.6488 - starts_loss: 1.2947 - stops_loss: 1.3516 - starts_accuracy: 0.6147 - stops_accuracy: 0.6163 - val_loss: 2.9295 - val_starts_loss: 1.4872 - val_stops_loss: 1.4611 - val_starts_accuracy: 0.6024 - val_stops_accuracy: 0.6112\n",
      "Epoch 47/1000\n",
      "20803/20803 [==============================] - 13s 618us/sample - loss: 2.6083 - starts_loss: 1.2769 - stops_loss: 1.3319 - starts_accuracy: 0.6186 - stops_accuracy: 0.6222 - val_loss: 2.9252 - val_starts_loss: 1.4869 - val_stops_loss: 1.4624 - val_starts_accuracy: 0.6018 - val_stops_accuracy: 0.6095\n",
      "Epoch 48/1000\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 2.5687 - starts_loss: 1.2652 - stops_loss: 1.3024 - starts_accuracy: 0.6203 - stops_accuracy: 0.6260 - val_loss: 2.9195 - val_starts_loss: 1.4889 - val_stops_loss: 1.4555 - val_starts_accuracy: 0.6020 - val_stops_accuracy: 0.6068\n",
      "Epoch 49/1000\n",
      "20803/20803 [==============================] - 13s 617us/sample - loss: 2.5443 - starts_loss: 1.2599 - stops_loss: 1.2883 - starts_accuracy: 0.6182 - stops_accuracy: 0.6286 - val_loss: 2.9169 - val_starts_loss: 1.4939 - val_stops_loss: 1.4490 - val_starts_accuracy: 0.6024 - val_stops_accuracy: 0.6124\n",
      "Epoch 50/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.5196 - starts_loss: 1.2460 - stops_loss: 1.2840 - starts_accuracy: 0.6237 - stops_accuracy: 0.6291 - val_loss: 2.9391 - val_starts_loss: 1.5008 - val_stops_loss: 1.4641 - val_starts_accuracy: 0.6033 - val_stops_accuracy: 0.6105\n",
      "Epoch 51/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.4799 - starts_loss: 1.2269 - stops_loss: 1.2500 - starts_accuracy: 0.6244 - stops_accuracy: 0.6379 - val_loss: 2.9091 - val_starts_loss: 1.4864 - val_stops_loss: 1.4495 - val_starts_accuracy: 0.6039 - val_stops_accuracy: 0.6130\n",
      "Epoch 52/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.4609 - starts_loss: 1.2187 - stops_loss: 1.2404 - starts_accuracy: 0.6262 - stops_accuracy: 0.6395 - val_loss: 2.9225 - val_starts_loss: 1.4752 - val_stops_loss: 1.4711 - val_starts_accuracy: 0.6010 - val_stops_accuracy: 0.6107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.4455 - starts_loss: 1.2077 - stops_loss: 1.2360 - starts_accuracy: 0.6265 - stops_accuracy: 0.6458 - val_loss: 2.8970 - val_starts_loss: 1.4783 - val_stops_loss: 1.4453 - val_starts_accuracy: 0.6055 - val_stops_accuracy: 0.6135\n",
      "Epoch 54/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.4245 - starts_loss: 1.1984 - stops_loss: 1.2219 - starts_accuracy: 0.6305 - stops_accuracy: 0.6471 - val_loss: 2.9064 - val_starts_loss: 1.4861 - val_stops_loss: 1.4469 - val_starts_accuracy: 0.6045 - val_stops_accuracy: 0.6151\n",
      "Epoch 55/1000\n",
      "20803/20803 [==============================] - 12s 592us/sample - loss: 2.4037 - starts_loss: 1.1919 - stops_loss: 1.2119 - starts_accuracy: 0.6324 - stops_accuracy: 0.6436 - val_loss: 2.9057 - val_starts_loss: 1.4825 - val_stops_loss: 1.4494 - val_starts_accuracy: 0.6072 - val_stops_accuracy: 0.6153\n",
      "Epoch 56/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.4031 - starts_loss: 1.1875 - stops_loss: 1.2133 - starts_accuracy: 0.6326 - stops_accuracy: 0.6460 - val_loss: 2.9083 - val_starts_loss: 1.4837 - val_stops_loss: 1.4490 - val_starts_accuracy: 0.6062 - val_stops_accuracy: 0.6176\n",
      "Epoch 57/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.3948 - starts_loss: 1.1843 - stops_loss: 1.2082 - starts_accuracy: 0.6336 - stops_accuracy: 0.6467 - val_loss: 2.9127 - val_starts_loss: 1.4898 - val_stops_loss: 1.4475 - val_starts_accuracy: 0.6068 - val_stops_accuracy: 0.6178\n",
      "Epoch 58/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.3881 - starts_loss: 1.1900 - stops_loss: 1.1929 - starts_accuracy: 0.6325 - stops_accuracy: 0.6504 - val_loss: 2.9186 - val_starts_loss: 1.4885 - val_stops_loss: 1.4543 - val_starts_accuracy: 0.6060 - val_stops_accuracy: 0.6168\n",
      "Epoch 59/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.3799 - starts_loss: 1.1748 - stops_loss: 1.1992 - starts_accuracy: 0.6345 - stops_accuracy: 0.6523 - val_loss: 2.9270 - val_starts_loss: 1.4840 - val_stops_loss: 1.4657 - val_starts_accuracy: 0.6045 - val_stops_accuracy: 0.6164\n",
      "Epoch 60/1000\n",
      "20803/20803 [==============================] - 13s 617us/sample - loss: 2.3849 - starts_loss: 1.1898 - stops_loss: 1.1943 - starts_accuracy: 0.6337 - stops_accuracy: 0.6502 - val_loss: 2.9273 - val_starts_loss: 1.4945 - val_stops_loss: 1.4571 - val_starts_accuracy: 0.6066 - val_stops_accuracy: 0.6180\n",
      "Epoch 61/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.3844 - starts_loss: 1.1815 - stops_loss: 1.1973 - starts_accuracy: 0.6328 - stops_accuracy: 0.6482 - val_loss: 2.9353 - val_starts_loss: 1.4946 - val_stops_loss: 1.4648 - val_starts_accuracy: 0.6062 - val_stops_accuracy: 0.6176\n",
      "Epoch 62/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.3764 - starts_loss: 1.1774 - stops_loss: 1.1987 - starts_accuracy: 0.6339 - stops_accuracy: 0.6501 - val_loss: 2.9331 - val_starts_loss: 1.4840 - val_stops_loss: 1.4731 - val_starts_accuracy: 0.6041 - val_stops_accuracy: 0.6168\n",
      "Epoch 63/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.3732 - starts_loss: 1.1770 - stops_loss: 1.1960 - starts_accuracy: 0.6355 - stops_accuracy: 0.6531 - val_loss: 2.9672 - val_starts_loss: 1.4924 - val_stops_loss: 1.4970 - val_starts_accuracy: 0.6020 - val_stops_accuracy: 0.6112\n",
      "Epoch 64/1000\n",
      "20803/20803 [==============================] - 12s 601us/sample - loss: 2.3400 - starts_loss: 1.1661 - stops_loss: 1.1717 - starts_accuracy: 0.6373 - stops_accuracy: 0.6550 - val_loss: 2.9307 - val_starts_loss: 1.4975 - val_stops_loss: 1.4591 - val_starts_accuracy: 0.6068 - val_stops_accuracy: 0.6172\n",
      "Epoch 65/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.3508 - starts_loss: 1.1720 - stops_loss: 1.1907 - starts_accuracy: 0.6394 - stops_accuracy: 0.6524 - val_loss: 2.9328 - val_starts_loss: 1.5004 - val_stops_loss: 1.4567 - val_starts_accuracy: 0.6080 - val_stops_accuracy: 0.6172\n",
      "Epoch 66/1000\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 2.3250 - starts_loss: 1.1522 - stops_loss: 1.1674 - starts_accuracy: 0.6386 - stops_accuracy: 0.6585 - val_loss: 2.9470 - val_starts_loss: 1.4821 - val_stops_loss: 1.4808 - val_starts_accuracy: 0.6045 - val_stops_accuracy: 0.6168\n",
      "Epoch 67/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.3127 - starts_loss: 1.1519 - stops_loss: 1.1661 - starts_accuracy: 0.6422 - stops_accuracy: 0.6566 - val_loss: 2.9304 - val_starts_loss: 1.4833 - val_stops_loss: 1.4691 - val_starts_accuracy: 0.6066 - val_stops_accuracy: 0.6170\n",
      "Epoch 68/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.3002 - starts_loss: 1.1467 - stops_loss: 1.1512 - starts_accuracy: 0.6419 - stops_accuracy: 0.6652 - val_loss: 2.9202 - val_starts_loss: 1.4852 - val_stops_loss: 1.4587 - val_starts_accuracy: 0.6080 - val_stops_accuracy: 0.6172\n",
      "Epoch 69/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 2.2781 - starts_loss: 1.1343 - stops_loss: 1.1424 - starts_accuracy: 0.6466 - stops_accuracy: 0.6626 - val_loss: 2.9244 - val_starts_loss: 1.4846 - val_stops_loss: 1.4656 - val_starts_accuracy: 0.6074 - val_stops_accuracy: 0.6168\n",
      "Epoch 70/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.2710 - starts_loss: 1.1328 - stops_loss: 1.1318 - starts_accuracy: 0.6435 - stops_accuracy: 0.6637 - val_loss: 2.9066 - val_starts_loss: 1.4848 - val_stops_loss: 1.4493 - val_starts_accuracy: 0.6099 - val_stops_accuracy: 0.6214\n",
      "Epoch 71/1000\n",
      "20803/20803 [==============================] - 13s 629us/sample - loss: 2.2603 - starts_loss: 1.1258 - stops_loss: 1.1345 - starts_accuracy: 0.6461 - stops_accuracy: 0.6654 - val_loss: 2.9408 - val_starts_loss: 1.4868 - val_stops_loss: 1.4781 - val_starts_accuracy: 0.6080 - val_stops_accuracy: 0.6193\n",
      "Epoch 72/1000\n",
      "20803/20803 [==============================] - 13s 624us/sample - loss: 2.2364 - starts_loss: 1.1244 - stops_loss: 1.1182 - starts_accuracy: 0.6469 - stops_accuracy: 0.6701 - val_loss: 2.9254 - val_starts_loss: 1.4860 - val_stops_loss: 1.4657 - val_starts_accuracy: 0.6095 - val_stops_accuracy: 0.6210\n",
      "Epoch 73/1000\n",
      "20803/20803 [==============================] - 14s 663us/sample - loss: 2.2406 - starts_loss: 1.1233 - stops_loss: 1.1249 - starts_accuracy: 0.6462 - stops_accuracy: 0.6698 - val_loss: 2.9159 - val_starts_loss: 1.4830 - val_stops_loss: 1.4605 - val_starts_accuracy: 0.6101 - val_stops_accuracy: 0.6216\n",
      "Epoch 74/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.2276 - starts_loss: 1.1253 - stops_loss: 1.1042 - starts_accuracy: 0.6500 - stops_accuracy: 0.6748 - val_loss: 2.9307 - val_starts_loss: 1.4874 - val_stops_loss: 1.4708 - val_starts_accuracy: 0.6097 - val_stops_accuracy: 0.6218\n",
      "Epoch 75/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.2388 - starts_loss: 1.1156 - stops_loss: 1.1222 - starts_accuracy: 0.6474 - stops_accuracy: 0.6719 - val_loss: 2.9291 - val_starts_loss: 1.4901 - val_stops_loss: 1.4679 - val_starts_accuracy: 0.6097 - val_stops_accuracy: 0.6218\n",
      "Epoch 76/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.2234 - starts_loss: 1.1098 - stops_loss: 1.1113 - starts_accuracy: 0.6506 - stops_accuracy: 0.6706 - val_loss: 2.9336 - val_starts_loss: 1.4912 - val_stops_loss: 1.4711 - val_starts_accuracy: 0.6095 - val_stops_accuracy: 0.6220\n",
      "Epoch 77/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.2259 - starts_loss: 1.1143 - stops_loss: 1.1130 - starts_accuracy: 0.6467 - stops_accuracy: 0.6726 - val_loss: 2.9384 - val_starts_loss: 1.4915 - val_stops_loss: 1.4752 - val_starts_accuracy: 0.6087 - val_stops_accuracy: 0.6214\n",
      "Epoch 78/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.2216 - starts_loss: 1.1092 - stops_loss: 1.1106 - starts_accuracy: 0.6494 - stops_accuracy: 0.6728 - val_loss: 2.9422 - val_starts_loss: 1.4889 - val_stops_loss: 1.4809 - val_starts_accuracy: 0.6097 - val_stops_accuracy: 0.6230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.2129 - starts_loss: 1.1179 - stops_loss: 1.1049 - starts_accuracy: 0.6503 - stops_accuracy: 0.6694 - val_loss: 2.9451 - val_starts_loss: 1.4914 - val_stops_loss: 1.4809 - val_starts_accuracy: 0.6107 - val_stops_accuracy: 0.6220\n",
      "Epoch 80/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.2158 - starts_loss: 1.1081 - stops_loss: 1.0995 - starts_accuracy: 0.6495 - stops_accuracy: 0.6760 - val_loss: 2.9424 - val_starts_loss: 1.4903 - val_stops_loss: 1.4800 - val_starts_accuracy: 0.6107 - val_stops_accuracy: 0.6231\n",
      "Epoch 81/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.2182 - starts_loss: 1.1033 - stops_loss: 1.1127 - starts_accuracy: 0.6508 - stops_accuracy: 0.6729 - val_loss: 2.9434 - val_starts_loss: 1.4901 - val_stops_loss: 1.4810 - val_starts_accuracy: 0.6108 - val_stops_accuracy: 0.6216\n",
      "Epoch 82/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.2091 - starts_loss: 1.1040 - stops_loss: 1.1063 - starts_accuracy: 0.6515 - stops_accuracy: 0.6759 - val_loss: 2.9541 - val_starts_loss: 1.4930 - val_stops_loss: 1.4879 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6222\n",
      "Epoch 83/1000\n",
      "20803/20803 [==============================] - 12s 593us/sample - loss: 2.2195 - starts_loss: 1.1078 - stops_loss: 1.1176 - starts_accuracy: 0.6524 - stops_accuracy: 0.6725 - val_loss: 2.9533 - val_starts_loss: 1.4979 - val_stops_loss: 1.4842 - val_starts_accuracy: 0.6112 - val_stops_accuracy: 0.6222\n",
      "Epoch 84/1000\n",
      "20803/20803 [==============================] - 12s 591us/sample - loss: 2.2022 - starts_loss: 1.1076 - stops_loss: 1.0949 - starts_accuracy: 0.6510 - stops_accuracy: 0.6746 - val_loss: 2.9962 - val_starts_loss: 1.5004 - val_stops_loss: 1.5196 - val_starts_accuracy: 0.6091 - val_stops_accuracy: 0.6178\n",
      "Epoch 85/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.1941 - starts_loss: 1.1052 - stops_loss: 1.0914 - starts_accuracy: 0.6527 - stops_accuracy: 0.6788 - val_loss: 2.9640 - val_starts_loss: 1.4969 - val_stops_loss: 1.4966 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6220\n",
      "Epoch 86/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.1906 - starts_loss: 1.0927 - stops_loss: 1.0940 - starts_accuracy: 0.6536 - stops_accuracy: 0.6783 - val_loss: 2.9728 - val_starts_loss: 1.4934 - val_stops_loss: 1.5057 - val_starts_accuracy: 0.6099 - val_stops_accuracy: 0.6170\n",
      "Epoch 87/1000\n",
      "20803/20803 [==============================] - 12s 595us/sample - loss: 2.1724 - starts_loss: 1.0864 - stops_loss: 1.0833 - starts_accuracy: 0.6538 - stops_accuracy: 0.6803 - val_loss: 2.9614 - val_starts_loss: 1.4923 - val_stops_loss: 1.4971 - val_starts_accuracy: 0.6126 - val_stops_accuracy: 0.6205\n",
      "Epoch 88/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.1584 - starts_loss: 1.0833 - stops_loss: 1.0752 - starts_accuracy: 0.6588 - stops_accuracy: 0.6787 - val_loss: 2.9431 - val_starts_loss: 1.4974 - val_stops_loss: 1.4794 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6237\n",
      "Epoch 89/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.1670 - starts_loss: 1.0869 - stops_loss: 1.0836 - starts_accuracy: 0.6546 - stops_accuracy: 0.6785 - val_loss: 2.9517 - val_starts_loss: 1.5051 - val_stops_loss: 1.4811 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6239\n",
      "Epoch 90/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.1639 - starts_loss: 1.0840 - stops_loss: 1.0804 - starts_accuracy: 0.6563 - stops_accuracy: 0.6793 - val_loss: 2.9429 - val_starts_loss: 1.4997 - val_stops_loss: 1.4765 - val_starts_accuracy: 0.6141 - val_stops_accuracy: 0.6251\n",
      "Epoch 91/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.1657 - starts_loss: 1.0886 - stops_loss: 1.0759 - starts_accuracy: 0.6553 - stops_accuracy: 0.6798 - val_loss: 2.9454 - val_starts_loss: 1.5029 - val_stops_loss: 1.4778 - val_starts_accuracy: 0.6141 - val_stops_accuracy: 0.6247\n",
      "Epoch 92/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.1472 - starts_loss: 1.0807 - stops_loss: 1.0747 - starts_accuracy: 0.6581 - stops_accuracy: 0.6843 - val_loss: 2.9520 - val_starts_loss: 1.4993 - val_stops_loss: 1.4867 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6245\n",
      "Epoch 93/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.1361 - starts_loss: 1.0756 - stops_loss: 1.0622 - starts_accuracy: 0.6580 - stops_accuracy: 0.6808 - val_loss: 2.9643 - val_starts_loss: 1.5000 - val_stops_loss: 1.4977 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6243\n",
      "Epoch 94/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.1578 - starts_loss: 1.0812 - stops_loss: 1.0783 - starts_accuracy: 0.6578 - stops_accuracy: 0.6824 - val_loss: 2.9638 - val_starts_loss: 1.5026 - val_stops_loss: 1.4958 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6243\n",
      "Epoch 95/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.1516 - starts_loss: 1.0798 - stops_loss: 1.0740 - starts_accuracy: 0.6581 - stops_accuracy: 0.6818 - val_loss: 2.9598 - val_starts_loss: 1.5036 - val_stops_loss: 1.4914 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6245\n",
      "Epoch 96/1000\n",
      "20803/20803 [==============================] - 12s 595us/sample - loss: 2.1509 - starts_loss: 1.0787 - stops_loss: 1.0683 - starts_accuracy: 0.6581 - stops_accuracy: 0.6782 - val_loss: 2.9635 - val_starts_loss: 1.5035 - val_stops_loss: 1.4949 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6241\n",
      "Epoch 97/1000\n",
      "20803/20803 [==============================] - 13s 618us/sample - loss: 2.1399 - starts_loss: 1.0758 - stops_loss: 1.0591 - starts_accuracy: 0.6554 - stops_accuracy: 0.6846 - val_loss: 2.9705 - val_starts_loss: 1.5028 - val_stops_loss: 1.5018 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6231\n",
      "Epoch 98/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 2.1462 - starts_loss: 1.0711 - stops_loss: 1.0747 - starts_accuracy: 0.6606 - stops_accuracy: 0.6848 - val_loss: 2.9824 - val_starts_loss: 1.5035 - val_stops_loss: 1.5117 - val_starts_accuracy: 0.6116 - val_stops_accuracy: 0.6218\n",
      "Epoch 99/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.1412 - starts_loss: 1.0771 - stops_loss: 1.0666 - starts_accuracy: 0.6603 - stops_accuracy: 0.6824 - val_loss: 2.9719 - val_starts_loss: 1.5028 - val_stops_loss: 1.5028 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6239\n",
      "Epoch 100/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.1503 - starts_loss: 1.0793 - stops_loss: 1.0693 - starts_accuracy: 0.6588 - stops_accuracy: 0.6809 - val_loss: 2.9710 - val_starts_loss: 1.5047 - val_stops_loss: 1.4999 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6233\n",
      "Epoch 101/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.1526 - starts_loss: 1.0804 - stops_loss: 1.0734 - starts_accuracy: 0.6585 - stops_accuracy: 0.6821 - val_loss: 2.9619 - val_starts_loss: 1.5041 - val_stops_loss: 1.4924 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6233\n",
      "Epoch 102/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.1417 - starts_loss: 1.0718 - stops_loss: 1.0609 - starts_accuracy: 0.6556 - stops_accuracy: 0.6851 - val_loss: 2.9713 - val_starts_loss: 1.5022 - val_stops_loss: 1.5008 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6233\n",
      "Epoch 103/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.1372 - starts_loss: 1.0733 - stops_loss: 1.0633 - starts_accuracy: 0.6579 - stops_accuracy: 0.6821 - val_loss: 2.9670 - val_starts_loss: 1.5033 - val_stops_loss: 1.4965 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6251\n",
      "Epoch 104/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.1320 - starts_loss: 1.0752 - stops_loss: 1.0551 - starts_accuracy: 0.6608 - stops_accuracy: 0.6835 - val_loss: 2.9748 - val_starts_loss: 1.5028 - val_stops_loss: 1.5028 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.1484 - starts_loss: 1.0735 - stops_loss: 1.0749 - starts_accuracy: 0.6567 - stops_accuracy: 0.6830 - val_loss: 2.9693 - val_starts_loss: 1.5058 - val_stops_loss: 1.4957 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6245\n",
      "Epoch 106/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.1196 - starts_loss: 1.0563 - stops_loss: 1.0581 - starts_accuracy: 0.6632 - stops_accuracy: 0.6846 - val_loss: 2.9818 - val_starts_loss: 1.5028 - val_stops_loss: 1.5095 - val_starts_accuracy: 0.6118 - val_stops_accuracy: 0.6220\n",
      "Epoch 107/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.1252 - starts_loss: 1.0741 - stops_loss: 1.0497 - starts_accuracy: 0.6578 - stops_accuracy: 0.6860 - val_loss: 2.9705 - val_starts_loss: 1.5053 - val_stops_loss: 1.4965 - val_starts_accuracy: 0.6126 - val_stops_accuracy: 0.6251\n",
      "Epoch 108/1000\n",
      "20803/20803 [==============================] - 14s 681us/sample - loss: 2.1151 - starts_loss: 1.0673 - stops_loss: 1.0468 - starts_accuracy: 0.6583 - stops_accuracy: 0.6892 - val_loss: 2.9746 - val_starts_loss: 1.5116 - val_stops_loss: 1.4958 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6249\n",
      "Epoch 109/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.1274 - starts_loss: 1.0607 - stops_loss: 1.0600 - starts_accuracy: 0.6648 - stops_accuracy: 0.6852 - val_loss: 2.9872 - val_starts_loss: 1.5095 - val_stops_loss: 1.5087 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6245\n",
      "Epoch 110/1000\n",
      "20803/20803 [==============================] - 12s 595us/sample - loss: 2.1082 - starts_loss: 1.0675 - stops_loss: 1.0468 - starts_accuracy: 0.6644 - stops_accuracy: 0.6880 - val_loss: 2.9846 - val_starts_loss: 1.5097 - val_stops_loss: 1.5064 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6233\n",
      "Epoch 111/1000\n",
      "20803/20803 [==============================] - 12s 588us/sample - loss: 2.1180 - starts_loss: 1.0668 - stops_loss: 1.0593 - starts_accuracy: 0.6602 - stops_accuracy: 0.6887 - val_loss: 2.9842 - val_starts_loss: 1.5087 - val_stops_loss: 1.5074 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6251\n",
      "Epoch 112/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.1175 - starts_loss: 1.0684 - stops_loss: 1.0524 - starts_accuracy: 0.6633 - stops_accuracy: 0.6873 - val_loss: 2.9840 - val_starts_loss: 1.5087 - val_stops_loss: 1.5076 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6255\n",
      "Epoch 113/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.1061 - starts_loss: 1.0559 - stops_loss: 1.0456 - starts_accuracy: 0.6620 - stops_accuracy: 0.6841 - val_loss: 2.9841 - val_starts_loss: 1.5097 - val_stops_loss: 1.5069 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6253\n",
      "Epoch 114/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.1080 - starts_loss: 1.0665 - stops_loss: 1.0450 - starts_accuracy: 0.6586 - stops_accuracy: 0.6874 - val_loss: 2.9817 - val_starts_loss: 1.5101 - val_stops_loss: 1.5046 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6249\n",
      "Epoch 115/1000\n",
      "20803/20803 [==============================] - 12s 592us/sample - loss: 2.1134 - starts_loss: 1.0596 - stops_loss: 1.0492 - starts_accuracy: 0.6615 - stops_accuracy: 0.6863 - val_loss: 2.9833 - val_starts_loss: 1.5101 - val_stops_loss: 1.5061 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6243\n",
      "Epoch 116/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.1149 - starts_loss: 1.0626 - stops_loss: 1.0559 - starts_accuracy: 0.6639 - stops_accuracy: 0.6873 - val_loss: 2.9837 - val_starts_loss: 1.5093 - val_stops_loss: 1.5069 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6235\n",
      "Epoch 117/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.1009 - starts_loss: 1.0641 - stops_loss: 1.0387 - starts_accuracy: 0.6626 - stops_accuracy: 0.6902 - val_loss: 2.9873 - val_starts_loss: 1.5089 - val_stops_loss: 1.5106 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6249\n",
      "Epoch 118/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.1106 - starts_loss: 1.0598 - stops_loss: 1.0484 - starts_accuracy: 0.6609 - stops_accuracy: 0.6905 - val_loss: 2.9899 - val_starts_loss: 1.5093 - val_stops_loss: 1.5126 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6241\n",
      "Epoch 119/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0949 - starts_loss: 1.0581 - stops_loss: 1.0323 - starts_accuracy: 0.6614 - stops_accuracy: 0.6894 - val_loss: 2.9818 - val_starts_loss: 1.5091 - val_stops_loss: 1.5056 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6235\n",
      "Epoch 120/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.1153 - starts_loss: 1.0637 - stops_loss: 1.0531 - starts_accuracy: 0.6609 - stops_accuracy: 0.6903 - val_loss: 2.9966 - val_starts_loss: 1.5095 - val_stops_loss: 1.5183 - val_starts_accuracy: 0.6120 - val_stops_accuracy: 0.6226\n",
      "Epoch 121/1000\n",
      "20803/20803 [==============================] - 12s 591us/sample - loss: 2.1019 - starts_loss: 1.0570 - stops_loss: 1.0400 - starts_accuracy: 0.6630 - stops_accuracy: 0.6913 - val_loss: 2.9921 - val_starts_loss: 1.5093 - val_stops_loss: 1.5145 - val_starts_accuracy: 0.6126 - val_stops_accuracy: 0.6222\n",
      "Epoch 122/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.1148 - starts_loss: 1.0581 - stops_loss: 1.0518 - starts_accuracy: 0.6632 - stops_accuracy: 0.6877 - val_loss: 2.9829 - val_starts_loss: 1.5088 - val_stops_loss: 1.5065 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6235\n",
      "Epoch 123/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0958 - starts_loss: 1.0531 - stops_loss: 1.0377 - starts_accuracy: 0.6648 - stops_accuracy: 0.6860 - val_loss: 2.9961 - val_starts_loss: 1.5103 - val_stops_loss: 1.5169 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6230\n",
      "Epoch 124/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0969 - starts_loss: 1.0585 - stops_loss: 1.0399 - starts_accuracy: 0.6634 - stops_accuracy: 0.6912 - val_loss: 2.9936 - val_starts_loss: 1.5106 - val_stops_loss: 1.5145 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6235\n",
      "Epoch 125/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.1144 - starts_loss: 1.0562 - stops_loss: 1.0532 - starts_accuracy: 0.6647 - stops_accuracy: 0.6867 - val_loss: 2.9876 - val_starts_loss: 1.5090 - val_stops_loss: 1.5103 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6233\n",
      "Epoch 126/1000\n",
      "20803/20803 [==============================] - 12s 595us/sample - loss: 2.0931 - starts_loss: 1.0537 - stops_loss: 1.0362 - starts_accuracy: 0.6653 - stops_accuracy: 0.6902 - val_loss: 2.9979 - val_starts_loss: 1.5082 - val_stops_loss: 1.5198 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6226\n",
      "Epoch 127/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.1003 - starts_loss: 1.0567 - stops_loss: 1.0383 - starts_accuracy: 0.6611 - stops_accuracy: 0.6908 - val_loss: 2.9846 - val_starts_loss: 1.5108 - val_stops_loss: 1.5062 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6255\n",
      "Epoch 128/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.1075 - starts_loss: 1.0559 - stops_loss: 1.0453 - starts_accuracy: 0.6679 - stops_accuracy: 0.6899 - val_loss: 2.9816 - val_starts_loss: 1.5113 - val_stops_loss: 1.5037 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6247\n",
      "Epoch 129/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0849 - starts_loss: 1.0558 - stops_loss: 1.0378 - starts_accuracy: 0.6672 - stops_accuracy: 0.6906 - val_loss: 2.9881 - val_starts_loss: 1.5108 - val_stops_loss: 1.5105 - val_starts_accuracy: 0.6126 - val_stops_accuracy: 0.6233\n",
      "Epoch 130/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.1075 - starts_loss: 1.0600 - stops_loss: 1.0475 - starts_accuracy: 0.6636 - stops_accuracy: 0.6891 - val_loss: 2.9819 - val_starts_loss: 1.5109 - val_stops_loss: 1.5047 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/1000\n",
      "20803/20803 [==============================] - 12s 595us/sample - loss: 2.0831 - starts_loss: 1.0555 - stops_loss: 1.0275 - starts_accuracy: 0.6628 - stops_accuracy: 0.6930 - val_loss: 2.9882 - val_starts_loss: 1.5123 - val_stops_loss: 1.5090 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6243\n",
      "Epoch 132/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0889 - starts_loss: 1.0553 - stops_loss: 1.0359 - starts_accuracy: 0.6662 - stops_accuracy: 0.6924 - val_loss: 2.9872 - val_starts_loss: 1.5126 - val_stops_loss: 1.5078 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6245\n",
      "Epoch 133/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0875 - starts_loss: 1.0429 - stops_loss: 1.0387 - starts_accuracy: 0.6657 - stops_accuracy: 0.6924 - val_loss: 2.9903 - val_starts_loss: 1.5123 - val_stops_loss: 1.5109 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6239\n",
      "Epoch 134/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0951 - starts_loss: 1.0523 - stops_loss: 1.0406 - starts_accuracy: 0.6651 - stops_accuracy: 0.6913 - val_loss: 2.9908 - val_starts_loss: 1.5128 - val_stops_loss: 1.5109 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6243\n",
      "Epoch 135/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0798 - starts_loss: 1.0537 - stops_loss: 1.0318 - starts_accuracy: 0.6643 - stops_accuracy: 0.6902 - val_loss: 2.9901 - val_starts_loss: 1.5125 - val_stops_loss: 1.5104 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6241\n",
      "Epoch 136/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0867 - starts_loss: 1.0541 - stops_loss: 1.0291 - starts_accuracy: 0.6640 - stops_accuracy: 0.6937 - val_loss: 2.9899 - val_starts_loss: 1.5120 - val_stops_loss: 1.5107 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6243\n",
      "Epoch 137/1000\n",
      "20803/20803 [==============================] - 12s 590us/sample - loss: 2.0873 - starts_loss: 1.0526 - stops_loss: 1.0307 - starts_accuracy: 0.6654 - stops_accuracy: 0.6922 - val_loss: 2.9927 - val_starts_loss: 1.5113 - val_stops_loss: 1.5137 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6235\n",
      "Epoch 138/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0843 - starts_loss: 1.0495 - stops_loss: 1.0331 - starts_accuracy: 0.6651 - stops_accuracy: 0.6917 - val_loss: 2.9938 - val_starts_loss: 1.5118 - val_stops_loss: 1.5144 - val_starts_accuracy: 0.6126 - val_stops_accuracy: 0.6231\n",
      "Epoch 139/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0818 - starts_loss: 1.0517 - stops_loss: 1.0346 - starts_accuracy: 0.6661 - stops_accuracy: 0.6923 - val_loss: 2.9902 - val_starts_loss: 1.5117 - val_stops_loss: 1.5116 - val_starts_accuracy: 0.6124 - val_stops_accuracy: 0.6241\n",
      "Epoch 140/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0968 - starts_loss: 1.0619 - stops_loss: 1.0327 - starts_accuracy: 0.6628 - stops_accuracy: 0.6926 - val_loss: 2.9964 - val_starts_loss: 1.5127 - val_stops_loss: 1.5162 - val_starts_accuracy: 0.6120 - val_stops_accuracy: 0.6233\n",
      "Epoch 141/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0779 - starts_loss: 1.0518 - stops_loss: 1.0249 - starts_accuracy: 0.6621 - stops_accuracy: 0.6936 - val_loss: 3.0020 - val_starts_loss: 1.5134 - val_stops_loss: 1.5200 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6230\n",
      "Epoch 142/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0882 - starts_loss: 1.0526 - stops_loss: 1.0343 - starts_accuracy: 0.6616 - stops_accuracy: 0.6898 - val_loss: 2.9946 - val_starts_loss: 1.5144 - val_stops_loss: 1.5129 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6249\n",
      "Epoch 143/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0765 - starts_loss: 1.0435 - stops_loss: 1.0330 - starts_accuracy: 0.6681 - stops_accuracy: 0.6940 - val_loss: 2.9935 - val_starts_loss: 1.5134 - val_stops_loss: 1.5126 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6241\n",
      "Epoch 144/1000\n",
      "20803/20803 [==============================] - 12s 595us/sample - loss: 2.0793 - starts_loss: 1.0510 - stops_loss: 1.0299 - starts_accuracy: 0.6650 - stops_accuracy: 0.6898 - val_loss: 2.9984 - val_starts_loss: 1.5121 - val_stops_loss: 1.5182 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6237\n",
      "Epoch 145/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0901 - starts_loss: 1.0559 - stops_loss: 1.0346 - starts_accuracy: 0.6643 - stops_accuracy: 0.6911 - val_loss: 3.0029 - val_starts_loss: 1.5150 - val_stops_loss: 1.5197 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6235\n",
      "Epoch 146/1000\n",
      "20803/20803 [==============================] - 12s 601us/sample - loss: 2.0792 - starts_loss: 1.0474 - stops_loss: 1.0335 - starts_accuracy: 0.6663 - stops_accuracy: 0.6912 - val_loss: 3.0040 - val_starts_loss: 1.5154 - val_stops_loss: 1.5204 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6239\n",
      "Epoch 147/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.0879 - starts_loss: 1.0537 - stops_loss: 1.0309 - starts_accuracy: 0.6661 - stops_accuracy: 0.6928 - val_loss: 2.9994 - val_starts_loss: 1.5155 - val_stops_loss: 1.5165 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6237\n",
      "Epoch 148/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0819 - starts_loss: 1.0522 - stops_loss: 1.0269 - starts_accuracy: 0.6617 - stops_accuracy: 0.6925 - val_loss: 2.9987 - val_starts_loss: 1.5154 - val_stops_loss: 1.5161 - val_starts_accuracy: 0.6126 - val_stops_accuracy: 0.6235\n",
      "Epoch 149/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0832 - starts_loss: 1.0473 - stops_loss: 1.0368 - starts_accuracy: 0.6624 - stops_accuracy: 0.6917 - val_loss: 3.0012 - val_starts_loss: 1.5146 - val_stops_loss: 1.5191 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6243\n",
      "Epoch 150/1000\n",
      "20803/20803 [==============================] - 12s 592us/sample - loss: 2.0785 - starts_loss: 1.0491 - stops_loss: 1.0309 - starts_accuracy: 0.6642 - stops_accuracy: 0.6944 - val_loss: 2.9964 - val_starts_loss: 1.5154 - val_stops_loss: 1.5143 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6241\n",
      "Epoch 151/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.0814 - starts_loss: 1.0528 - stops_loss: 1.0330 - starts_accuracy: 0.6642 - stops_accuracy: 0.6927 - val_loss: 2.9939 - val_starts_loss: 1.5152 - val_stops_loss: 1.5121 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6241\n",
      "Epoch 152/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0760 - starts_loss: 1.0472 - stops_loss: 1.0308 - starts_accuracy: 0.6661 - stops_accuracy: 0.6912 - val_loss: 2.9931 - val_starts_loss: 1.5148 - val_stops_loss: 1.5116 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6241\n",
      "Epoch 153/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0750 - starts_loss: 1.0451 - stops_loss: 1.0264 - starts_accuracy: 0.6646 - stops_accuracy: 0.6944 - val_loss: 2.9943 - val_starts_loss: 1.5149 - val_stops_loss: 1.5126 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6235\n",
      "Epoch 154/1000\n",
      "20803/20803 [==============================] - 13s 619us/sample - loss: 2.0706 - starts_loss: 1.0461 - stops_loss: 1.0179 - starts_accuracy: 0.6659 - stops_accuracy: 0.6941 - val_loss: 2.9967 - val_starts_loss: 1.5146 - val_stops_loss: 1.5150 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6239\n",
      "Epoch 155/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.0922 - starts_loss: 1.0491 - stops_loss: 1.0409 - starts_accuracy: 0.6616 - stops_accuracy: 0.6873 - val_loss: 2.9986 - val_starts_loss: 1.5147 - val_stops_loss: 1.5166 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6235\n",
      "Epoch 156/1000\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 2.0862 - starts_loss: 1.0487 - stops_loss: 1.0380 - starts_accuracy: 0.6648 - stops_accuracy: 0.6883 - val_loss: 2.9966 - val_starts_loss: 1.5151 - val_stops_loss: 1.5146 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/1000\n",
      "20803/20803 [==============================] - 12s 595us/sample - loss: 2.0844 - starts_loss: 1.0504 - stops_loss: 1.0308 - starts_accuracy: 0.6651 - stops_accuracy: 0.6934 - val_loss: 2.9948 - val_starts_loss: 1.5154 - val_stops_loss: 1.5129 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6237\n",
      "Epoch 158/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 2.0753 - starts_loss: 1.0481 - stops_loss: 1.0256 - starts_accuracy: 0.6652 - stops_accuracy: 0.6952 - val_loss: 2.9971 - val_starts_loss: 1.5146 - val_stops_loss: 1.5156 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6239\n",
      "Epoch 159/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0780 - starts_loss: 1.0467 - stops_loss: 1.0300 - starts_accuracy: 0.6629 - stops_accuracy: 0.6931 - val_loss: 2.9969 - val_starts_loss: 1.5144 - val_stops_loss: 1.5157 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6243\n",
      "Epoch 160/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0715 - starts_loss: 1.0467 - stops_loss: 1.0286 - starts_accuracy: 0.6651 - stops_accuracy: 0.6927 - val_loss: 2.9963 - val_starts_loss: 1.5146 - val_stops_loss: 1.5151 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6237\n",
      "Epoch 161/1000\n",
      "20803/20803 [==============================] - 12s 595us/sample - loss: 2.0832 - starts_loss: 1.0482 - stops_loss: 1.0332 - starts_accuracy: 0.6647 - stops_accuracy: 0.6932 - val_loss: 2.9981 - val_starts_loss: 1.5146 - val_stops_loss: 1.5165 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6239\n",
      "Epoch 162/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0709 - starts_loss: 1.0466 - stops_loss: 1.0222 - starts_accuracy: 0.6680 - stops_accuracy: 0.6958 - val_loss: 3.0016 - val_starts_loss: 1.5148 - val_stops_loss: 1.5194 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6243\n",
      "Epoch 163/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0725 - starts_loss: 1.0517 - stops_loss: 1.0158 - starts_accuracy: 0.6638 - stops_accuracy: 0.6975 - val_loss: 3.0047 - val_starts_loss: 1.5146 - val_stops_loss: 1.5221 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6243\n",
      "Epoch 164/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0754 - starts_loss: 1.0499 - stops_loss: 1.0208 - starts_accuracy: 0.6652 - stops_accuracy: 0.6914 - val_loss: 2.9967 - val_starts_loss: 1.5145 - val_stops_loss: 1.5152 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6243\n",
      "Epoch 165/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0652 - starts_loss: 1.0415 - stops_loss: 1.0256 - starts_accuracy: 0.6667 - stops_accuracy: 0.6963 - val_loss: 2.9960 - val_starts_loss: 1.5144 - val_stops_loss: 1.5149 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6239\n",
      "Epoch 166/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0656 - starts_loss: 1.0422 - stops_loss: 1.0196 - starts_accuracy: 0.6681 - stops_accuracy: 0.6925 - val_loss: 2.9973 - val_starts_loss: 1.5147 - val_stops_loss: 1.5157 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6243\n",
      "Epoch 167/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0939 - starts_loss: 1.0584 - stops_loss: 1.0356 - starts_accuracy: 0.6649 - stops_accuracy: 0.6899 - val_loss: 2.9982 - val_starts_loss: 1.5153 - val_stops_loss: 1.5159 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6237\n",
      "Epoch 168/1000\n",
      "20803/20803 [==============================] - 12s 595us/sample - loss: 2.0698 - starts_loss: 1.0466 - stops_loss: 1.0283 - starts_accuracy: 0.6626 - stops_accuracy: 0.6936 - val_loss: 3.0031 - val_starts_loss: 1.5153 - val_stops_loss: 1.5201 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6247\n",
      "Epoch 169/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0695 - starts_loss: 1.0415 - stops_loss: 1.0296 - starts_accuracy: 0.6694 - stops_accuracy: 0.6904 - val_loss: 3.0020 - val_starts_loss: 1.5159 - val_stops_loss: 1.5186 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6241\n",
      "Epoch 170/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0741 - starts_loss: 1.0513 - stops_loss: 1.0241 - starts_accuracy: 0.6642 - stops_accuracy: 0.6940 - val_loss: 3.0004 - val_starts_loss: 1.5160 - val_stops_loss: 1.5171 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6239\n",
      "Epoch 171/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0654 - starts_loss: 1.0492 - stops_loss: 1.0266 - starts_accuracy: 0.6667 - stops_accuracy: 0.6953 - val_loss: 3.0012 - val_starts_loss: 1.5163 - val_stops_loss: 1.5175 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6243\n",
      "Epoch 172/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0808 - starts_loss: 1.0488 - stops_loss: 1.0345 - starts_accuracy: 0.6653 - stops_accuracy: 0.6935 - val_loss: 3.0000 - val_starts_loss: 1.5161 - val_stops_loss: 1.5167 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6243\n",
      "Epoch 173/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.0723 - starts_loss: 1.0476 - stops_loss: 1.0287 - starts_accuracy: 0.6673 - stops_accuracy: 0.6969 - val_loss: 3.0019 - val_starts_loss: 1.5162 - val_stops_loss: 1.5184 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6241\n",
      "Epoch 174/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0911 - starts_loss: 1.0464 - stops_loss: 1.0344 - starts_accuracy: 0.6621 - stops_accuracy: 0.6910 - val_loss: 3.0031 - val_starts_loss: 1.5161 - val_stops_loss: 1.5195 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6243\n",
      "Epoch 175/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0749 - starts_loss: 1.0383 - stops_loss: 1.0315 - starts_accuracy: 0.6654 - stops_accuracy: 0.6931 - val_loss: 3.0027 - val_starts_loss: 1.5164 - val_stops_loss: 1.5190 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6241\n",
      "Epoch 176/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0669 - starts_loss: 1.0462 - stops_loss: 1.0258 - starts_accuracy: 0.6688 - stops_accuracy: 0.6954 - val_loss: 3.0003 - val_starts_loss: 1.5163 - val_stops_loss: 1.5168 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6241\n",
      "Epoch 177/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 2.0616 - starts_loss: 1.0419 - stops_loss: 1.0249 - starts_accuracy: 0.6683 - stops_accuracy: 0.6974 - val_loss: 3.0005 - val_starts_loss: 1.5164 - val_stops_loss: 1.5170 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6247\n",
      "Epoch 178/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0695 - starts_loss: 1.0557 - stops_loss: 1.0228 - starts_accuracy: 0.6653 - stops_accuracy: 0.6939 - val_loss: 3.0026 - val_starts_loss: 1.5171 - val_stops_loss: 1.5183 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6241\n",
      "Epoch 179/1000\n",
      "20803/20803 [==============================] - 13s 618us/sample - loss: 2.0822 - starts_loss: 1.0528 - stops_loss: 1.0340 - starts_accuracy: 0.6670 - stops_accuracy: 0.6903 - val_loss: 3.0026 - val_starts_loss: 1.5171 - val_stops_loss: 1.5181 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6243\n",
      "Epoch 180/1000\n",
      "20803/20803 [==============================] - 12s 591us/sample - loss: 2.0691 - starts_loss: 1.0462 - stops_loss: 1.0271 - starts_accuracy: 0.6638 - stops_accuracy: 0.6942 - val_loss: 3.0044 - val_starts_loss: 1.5168 - val_stops_loss: 1.5200 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6247\n",
      "Epoch 181/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0621 - starts_loss: 1.0406 - stops_loss: 1.0197 - starts_accuracy: 0.6663 - stops_accuracy: 0.6945 - val_loss: 3.0039 - val_starts_loss: 1.5168 - val_stops_loss: 1.5196 - val_starts_accuracy: 0.6124 - val_stops_accuracy: 0.6243\n",
      "Epoch 182/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.0789 - starts_loss: 1.0409 - stops_loss: 1.0380 - starts_accuracy: 0.6672 - stops_accuracy: 0.6887 - val_loss: 3.0029 - val_starts_loss: 1.5172 - val_stops_loss: 1.5184 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0781 - starts_loss: 1.0523 - stops_loss: 1.0264 - starts_accuracy: 0.6668 - stops_accuracy: 0.6918 - val_loss: 3.0062 - val_starts_loss: 1.5175 - val_stops_loss: 1.5213 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6247\n",
      "Epoch 184/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 2.0684 - starts_loss: 1.0430 - stops_loss: 1.0263 - starts_accuracy: 0.6663 - stops_accuracy: 0.6948 - val_loss: 3.0027 - val_starts_loss: 1.5171 - val_stops_loss: 1.5186 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6239\n",
      "Epoch 185/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0784 - starts_loss: 1.0427 - stops_loss: 1.0280 - starts_accuracy: 0.6645 - stops_accuracy: 0.6934 - val_loss: 3.0005 - val_starts_loss: 1.5169 - val_stops_loss: 1.5167 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6243\n",
      "Epoch 186/1000\n",
      "20803/20803 [==============================] - 13s 620us/sample - loss: 2.0810 - starts_loss: 1.0446 - stops_loss: 1.0347 - starts_accuracy: 0.6675 - stops_accuracy: 0.6957 - val_loss: 2.9995 - val_starts_loss: 1.5164 - val_stops_loss: 1.5162 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6249\n",
      "Epoch 187/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0788 - starts_loss: 1.0445 - stops_loss: 1.0259 - starts_accuracy: 0.6680 - stops_accuracy: 0.6904 - val_loss: 2.9997 - val_starts_loss: 1.5160 - val_stops_loss: 1.5168 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6241\n",
      "Epoch 188/1000\n",
      "20803/20803 [==============================] - 13s 621us/sample - loss: 2.0830 - starts_loss: 1.0485 - stops_loss: 1.0335 - starts_accuracy: 0.6661 - stops_accuracy: 0.6924 - val_loss: 3.0010 - val_starts_loss: 1.5160 - val_stops_loss: 1.5179 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6243\n",
      "Epoch 189/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0643 - starts_loss: 1.0494 - stops_loss: 1.0179 - starts_accuracy: 0.6677 - stops_accuracy: 0.6996 - val_loss: 3.0060 - val_starts_loss: 1.5163 - val_stops_loss: 1.5219 - val_starts_accuracy: 0.6126 - val_stops_accuracy: 0.6249\n",
      "Epoch 190/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0763 - starts_loss: 1.0524 - stops_loss: 1.0267 - starts_accuracy: 0.6671 - stops_accuracy: 0.6962 - val_loss: 3.0054 - val_starts_loss: 1.5165 - val_stops_loss: 1.5213 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6253\n",
      "Epoch 191/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0786 - starts_loss: 1.0434 - stops_loss: 1.0326 - starts_accuracy: 0.6660 - stops_accuracy: 0.6907 - val_loss: 3.0058 - val_starts_loss: 1.5169 - val_stops_loss: 1.5215 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6255\n",
      "Epoch 192/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0815 - starts_loss: 1.0490 - stops_loss: 1.0307 - starts_accuracy: 0.6650 - stops_accuracy: 0.6937 - val_loss: 3.0050 - val_starts_loss: 1.5167 - val_stops_loss: 1.5209 - val_starts_accuracy: 0.6126 - val_stops_accuracy: 0.6255\n",
      "Epoch 193/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0716 - starts_loss: 1.0498 - stops_loss: 1.0251 - starts_accuracy: 0.6667 - stops_accuracy: 0.6930 - val_loss: 3.0041 - val_starts_loss: 1.5168 - val_stops_loss: 1.5200 - val_starts_accuracy: 0.6126 - val_stops_accuracy: 0.6251\n",
      "Epoch 194/1000\n",
      "20803/20803 [==============================] - 12s 592us/sample - loss: 2.0586 - starts_loss: 1.0441 - stops_loss: 1.0184 - starts_accuracy: 0.6691 - stops_accuracy: 0.6953 - val_loss: 3.0032 - val_starts_loss: 1.5171 - val_stops_loss: 1.5191 - val_starts_accuracy: 0.6126 - val_stops_accuracy: 0.6243\n",
      "Epoch 195/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0744 - starts_loss: 1.0461 - stops_loss: 1.0399 - starts_accuracy: 0.6673 - stops_accuracy: 0.6939 - val_loss: 3.0041 - val_starts_loss: 1.5176 - val_stops_loss: 1.5195 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6245\n",
      "Epoch 196/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.0664 - starts_loss: 1.0440 - stops_loss: 1.0256 - starts_accuracy: 0.6691 - stops_accuracy: 0.6949 - val_loss: 3.0051 - val_starts_loss: 1.5177 - val_stops_loss: 1.5203 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6251\n",
      "Epoch 197/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0651 - starts_loss: 1.0416 - stops_loss: 1.0218 - starts_accuracy: 0.6675 - stops_accuracy: 0.6969 - val_loss: 3.0043 - val_starts_loss: 1.5171 - val_stops_loss: 1.5201 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6251\n",
      "Epoch 198/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0849 - starts_loss: 1.0537 - stops_loss: 1.0344 - starts_accuracy: 0.6655 - stops_accuracy: 0.6944 - val_loss: 3.0039 - val_starts_loss: 1.5174 - val_stops_loss: 1.5195 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6247\n",
      "Epoch 199/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.0639 - starts_loss: 1.0426 - stops_loss: 1.0189 - starts_accuracy: 0.6663 - stops_accuracy: 0.6949 - val_loss: 3.0079 - val_starts_loss: 1.5176 - val_stops_loss: 1.5229 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6253\n",
      "Epoch 200/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0733 - starts_loss: 1.0403 - stops_loss: 1.0279 - starts_accuracy: 0.6675 - stops_accuracy: 0.6953 - val_loss: 3.0059 - val_starts_loss: 1.5179 - val_stops_loss: 1.5210 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6251\n",
      "Epoch 201/1000\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 2.0690 - starts_loss: 1.0481 - stops_loss: 1.0298 - starts_accuracy: 0.6689 - stops_accuracy: 0.6924 - val_loss: 3.0046 - val_starts_loss: 1.5180 - val_stops_loss: 1.5198 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6243\n",
      "Epoch 202/1000\n",
      "20803/20803 [==============================] - 13s 619us/sample - loss: 2.0732 - starts_loss: 1.0384 - stops_loss: 1.0344 - starts_accuracy: 0.6676 - stops_accuracy: 0.6912 - val_loss: 3.0052 - val_starts_loss: 1.5179 - val_stops_loss: 1.5203 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6247\n",
      "Epoch 203/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0648 - starts_loss: 1.0362 - stops_loss: 1.0228 - starts_accuracy: 0.6666 - stops_accuracy: 0.6907 - val_loss: 3.0067 - val_starts_loss: 1.5178 - val_stops_loss: 1.5217 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6251\n",
      "Epoch 204/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0673 - starts_loss: 1.0463 - stops_loss: 1.0252 - starts_accuracy: 0.6680 - stops_accuracy: 0.6917 - val_loss: 3.0067 - val_starts_loss: 1.5179 - val_stops_loss: 1.5217 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6251\n",
      "Epoch 205/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0725 - starts_loss: 1.0502 - stops_loss: 1.0279 - starts_accuracy: 0.6678 - stops_accuracy: 0.6953 - val_loss: 3.0063 - val_starts_loss: 1.5178 - val_stops_loss: 1.5214 - val_starts_accuracy: 0.6126 - val_stops_accuracy: 0.6251\n",
      "Epoch 206/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0542 - starts_loss: 1.0401 - stops_loss: 1.0202 - starts_accuracy: 0.6687 - stops_accuracy: 0.6978 - val_loss: 3.0051 - val_starts_loss: 1.5178 - val_stops_loss: 1.5203 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6249\n",
      "Epoch 207/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 2.0635 - starts_loss: 1.0421 - stops_loss: 1.0205 - starts_accuracy: 0.6675 - stops_accuracy: 0.6965 - val_loss: 3.0041 - val_starts_loss: 1.5172 - val_stops_loss: 1.5200 - val_starts_accuracy: 0.6126 - val_stops_accuracy: 0.6251\n",
      "Epoch 208/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0687 - starts_loss: 1.0496 - stops_loss: 1.0196 - starts_accuracy: 0.6632 - stops_accuracy: 0.6942 - val_loss: 3.0046 - val_starts_loss: 1.5174 - val_stops_loss: 1.5204 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0549 - starts_loss: 1.0339 - stops_loss: 1.0212 - starts_accuracy: 0.6676 - stops_accuracy: 0.6960 - val_loss: 3.0054 - val_starts_loss: 1.5176 - val_stops_loss: 1.5209 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6247\n",
      "Epoch 210/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0502 - starts_loss: 1.0368 - stops_loss: 1.0116 - starts_accuracy: 0.6658 - stops_accuracy: 0.6966 - val_loss: 3.0053 - val_starts_loss: 1.5179 - val_stops_loss: 1.5207 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6247\n",
      "Epoch 211/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0686 - starts_loss: 1.0422 - stops_loss: 1.0275 - starts_accuracy: 0.6687 - stops_accuracy: 0.6944 - val_loss: 3.0055 - val_starts_loss: 1.5181 - val_stops_loss: 1.5207 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6251\n",
      "Epoch 212/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0507 - starts_loss: 1.0276 - stops_loss: 1.0255 - starts_accuracy: 0.6713 - stops_accuracy: 0.6942 - val_loss: 3.0052 - val_starts_loss: 1.5183 - val_stops_loss: 1.5203 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6247\n",
      "Epoch 213/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0696 - starts_loss: 1.0401 - stops_loss: 1.0308 - starts_accuracy: 0.6677 - stops_accuracy: 0.6938 - val_loss: 3.0031 - val_starts_loss: 1.5182 - val_stops_loss: 1.5185 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6247\n",
      "Epoch 214/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0728 - starts_loss: 1.0382 - stops_loss: 1.0331 - starts_accuracy: 0.6693 - stops_accuracy: 0.6920 - val_loss: 3.0032 - val_starts_loss: 1.5182 - val_stops_loss: 1.5185 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6245\n",
      "Epoch 215/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0623 - starts_loss: 1.0442 - stops_loss: 1.0167 - starts_accuracy: 0.6682 - stops_accuracy: 0.6960 - val_loss: 3.0045 - val_starts_loss: 1.5181 - val_stops_loss: 1.5198 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6247\n",
      "Epoch 216/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0695 - starts_loss: 1.0477 - stops_loss: 1.0244 - starts_accuracy: 0.6633 - stops_accuracy: 0.6946 - val_loss: 3.0057 - val_starts_loss: 1.5174 - val_stops_loss: 1.5214 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6245\n",
      "Epoch 217/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 2.0620 - starts_loss: 1.0426 - stops_loss: 1.0261 - starts_accuracy: 0.6658 - stops_accuracy: 0.6945 - val_loss: 3.0069 - val_starts_loss: 1.5171 - val_stops_loss: 1.5228 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6245\n",
      "Epoch 218/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0659 - starts_loss: 1.0412 - stops_loss: 1.0281 - starts_accuracy: 0.6691 - stops_accuracy: 0.6913 - val_loss: 3.0074 - val_starts_loss: 1.5175 - val_stops_loss: 1.5228 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6247\n",
      "Epoch 219/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.0485 - starts_loss: 1.0405 - stops_loss: 1.0046 - starts_accuracy: 0.6659 - stops_accuracy: 0.7002 - val_loss: 3.0066 - val_starts_loss: 1.5174 - val_stops_loss: 1.5224 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6245\n",
      "Epoch 220/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0512 - starts_loss: 1.0305 - stops_loss: 1.0199 - starts_accuracy: 0.6718 - stops_accuracy: 0.6980 - val_loss: 3.0049 - val_starts_loss: 1.5173 - val_stops_loss: 1.5210 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6243\n",
      "Epoch 221/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0780 - starts_loss: 1.0484 - stops_loss: 1.0269 - starts_accuracy: 0.6676 - stops_accuracy: 0.6968 - val_loss: 3.0049 - val_starts_loss: 1.5175 - val_stops_loss: 1.5208 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6249\n",
      "Epoch 222/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0725 - starts_loss: 1.0396 - stops_loss: 1.0279 - starts_accuracy: 0.6655 - stops_accuracy: 0.6950 - val_loss: 3.0061 - val_starts_loss: 1.5178 - val_stops_loss: 1.5216 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6247\n",
      "Epoch 223/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0582 - starts_loss: 1.0416 - stops_loss: 1.0107 - starts_accuracy: 0.6687 - stops_accuracy: 0.6982 - val_loss: 3.0069 - val_starts_loss: 1.5181 - val_stops_loss: 1.5221 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6245\n",
      "Epoch 224/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.0736 - starts_loss: 1.0528 - stops_loss: 1.0295 - starts_accuracy: 0.6643 - stops_accuracy: 0.6918 - val_loss: 3.0077 - val_starts_loss: 1.5184 - val_stops_loss: 1.5226 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6245\n",
      "Epoch 225/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 2.0648 - starts_loss: 1.0453 - stops_loss: 1.0306 - starts_accuracy: 0.6669 - stops_accuracy: 0.6949 - val_loss: 3.0060 - val_starts_loss: 1.5184 - val_stops_loss: 1.5211 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6243\n",
      "Epoch 226/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.0651 - starts_loss: 1.0394 - stops_loss: 1.0237 - starts_accuracy: 0.6693 - stops_accuracy: 0.6962 - val_loss: 3.0057 - val_starts_loss: 1.5184 - val_stops_loss: 1.5208 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6247\n",
      "Epoch 227/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0588 - starts_loss: 1.0394 - stops_loss: 1.0172 - starts_accuracy: 0.6667 - stops_accuracy: 0.6994 - val_loss: 3.0055 - val_starts_loss: 1.5184 - val_stops_loss: 1.5206 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6249\n",
      "Epoch 228/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0675 - starts_loss: 1.0492 - stops_loss: 1.0194 - starts_accuracy: 0.6638 - stops_accuracy: 0.6999 - val_loss: 3.0055 - val_starts_loss: 1.5185 - val_stops_loss: 1.5206 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6249\n",
      "Epoch 229/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0538 - starts_loss: 1.0339 - stops_loss: 1.0139 - starts_accuracy: 0.6727 - stops_accuracy: 0.6949 - val_loss: 3.0057 - val_starts_loss: 1.5185 - val_stops_loss: 1.5207 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6245\n",
      "Epoch 230/1000\n",
      "20803/20803 [==============================] - 12s 595us/sample - loss: 2.0590 - starts_loss: 1.0467 - stops_loss: 1.0184 - starts_accuracy: 0.6692 - stops_accuracy: 0.6944 - val_loss: 3.0058 - val_starts_loss: 1.5183 - val_stops_loss: 1.5210 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6245\n",
      "Epoch 231/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0492 - starts_loss: 1.0373 - stops_loss: 1.0163 - starts_accuracy: 0.6680 - stops_accuracy: 0.6963 - val_loss: 3.0061 - val_starts_loss: 1.5185 - val_stops_loss: 1.5210 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6247\n",
      "Epoch 232/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 2.0675 - starts_loss: 1.0361 - stops_loss: 1.0293 - starts_accuracy: 0.6695 - stops_accuracy: 0.6919 - val_loss: 3.0060 - val_starts_loss: 1.5187 - val_stops_loss: 1.5208 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6243\n",
      "Epoch 233/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0606 - starts_loss: 1.0459 - stops_loss: 1.0193 - starts_accuracy: 0.6686 - stops_accuracy: 0.6948 - val_loss: 3.0073 - val_starts_loss: 1.5189 - val_stops_loss: 1.5218 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6243\n",
      "Epoch 234/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0683 - starts_loss: 1.0505 - stops_loss: 1.0229 - starts_accuracy: 0.6664 - stops_accuracy: 0.6940 - val_loss: 3.0068 - val_starts_loss: 1.5188 - val_stops_loss: 1.5214 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/1000\n",
      "20803/20803 [==============================] - 12s 591us/sample - loss: 2.0580 - starts_loss: 1.0406 - stops_loss: 1.0162 - starts_accuracy: 0.6678 - stops_accuracy: 0.6936 - val_loss: 3.0058 - val_starts_loss: 1.5187 - val_stops_loss: 1.5206 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6245\n",
      "Epoch 236/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.0790 - starts_loss: 1.0489 - stops_loss: 1.0283 - starts_accuracy: 0.6638 - stops_accuracy: 0.6928 - val_loss: 3.0051 - val_starts_loss: 1.5188 - val_stops_loss: 1.5199 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6241\n",
      "Epoch 237/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0660 - starts_loss: 1.0496 - stops_loss: 1.0151 - starts_accuracy: 0.6636 - stops_accuracy: 0.6977 - val_loss: 3.0048 - val_starts_loss: 1.5185 - val_stops_loss: 1.5199 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6241\n",
      "Epoch 238/1000\n",
      "20803/20803 [==============================] - 12s 593us/sample - loss: 2.0579 - starts_loss: 1.0347 - stops_loss: 1.0143 - starts_accuracy: 0.6683 - stops_accuracy: 0.6940 - val_loss: 3.0062 - val_starts_loss: 1.5185 - val_stops_loss: 1.5211 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6245\n",
      "Epoch 239/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0547 - starts_loss: 1.0372 - stops_loss: 1.0116 - starts_accuracy: 0.6646 - stops_accuracy: 0.6960 - val_loss: 3.0075 - val_starts_loss: 1.5186 - val_stops_loss: 1.5221 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6243\n",
      "Epoch 240/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0734 - starts_loss: 1.0567 - stops_loss: 1.0196 - starts_accuracy: 0.6655 - stops_accuracy: 0.6946 - val_loss: 3.0078 - val_starts_loss: 1.5187 - val_stops_loss: 1.5222 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6243\n",
      "Epoch 241/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0583 - starts_loss: 1.0387 - stops_loss: 1.0200 - starts_accuracy: 0.6668 - stops_accuracy: 0.6952 - val_loss: 3.0079 - val_starts_loss: 1.5189 - val_stops_loss: 1.5221 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6245\n",
      "Epoch 242/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0657 - starts_loss: 1.0414 - stops_loss: 1.0272 - starts_accuracy: 0.6689 - stops_accuracy: 0.6951 - val_loss: 3.0088 - val_starts_loss: 1.5192 - val_stops_loss: 1.5227 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6243\n",
      "Epoch 243/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0535 - starts_loss: 1.0337 - stops_loss: 1.0171 - starts_accuracy: 0.6689 - stops_accuracy: 0.6944 - val_loss: 3.0112 - val_starts_loss: 1.5195 - val_stops_loss: 1.5246 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6245\n",
      "Epoch 244/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 2.0528 - starts_loss: 1.0404 - stops_loss: 1.0156 - starts_accuracy: 0.6701 - stops_accuracy: 0.6976 - val_loss: 3.0124 - val_starts_loss: 1.5197 - val_stops_loss: 1.5255 - val_starts_accuracy: 0.6122 - val_stops_accuracy: 0.6239\n",
      "Epoch 245/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0672 - starts_loss: 1.0337 - stops_loss: 1.0299 - starts_accuracy: 0.6668 - stops_accuracy: 0.6950 - val_loss: 3.0111 - val_starts_loss: 1.5197 - val_stops_loss: 1.5244 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6245\n",
      "Epoch 246/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0677 - starts_loss: 1.0442 - stops_loss: 1.0290 - starts_accuracy: 0.6666 - stops_accuracy: 0.6916 - val_loss: 3.0086 - val_starts_loss: 1.5199 - val_stops_loss: 1.5222 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6247\n",
      "Epoch 247/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0740 - starts_loss: 1.0498 - stops_loss: 1.0272 - starts_accuracy: 0.6652 - stops_accuracy: 0.6930 - val_loss: 3.0075 - val_starts_loss: 1.5200 - val_stops_loss: 1.5211 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6249\n",
      "Epoch 248/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 2.0622 - starts_loss: 1.0485 - stops_loss: 1.0153 - starts_accuracy: 0.6653 - stops_accuracy: 0.6949 - val_loss: 3.0072 - val_starts_loss: 1.5196 - val_stops_loss: 1.5213 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6249\n",
      "Epoch 249/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.0628 - starts_loss: 1.0357 - stops_loss: 1.0242 - starts_accuracy: 0.6712 - stops_accuracy: 0.6934 - val_loss: 3.0080 - val_starts_loss: 1.5195 - val_stops_loss: 1.5221 - val_starts_accuracy: 0.6126 - val_stops_accuracy: 0.6249\n",
      "Epoch 250/1000\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 2.0600 - starts_loss: 1.0464 - stops_loss: 1.0130 - starts_accuracy: 0.6652 - stops_accuracy: 0.6969 - val_loss: 3.0078 - val_starts_loss: 1.5199 - val_stops_loss: 1.5216 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6251\n",
      "Epoch 251/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0629 - starts_loss: 1.0394 - stops_loss: 1.0194 - starts_accuracy: 0.6670 - stops_accuracy: 0.6951 - val_loss: 3.0079 - val_starts_loss: 1.5200 - val_stops_loss: 1.5217 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6249\n",
      "Epoch 252/1000\n",
      "20803/20803 [==============================] - 14s 685us/sample - loss: 2.0546 - starts_loss: 1.0308 - stops_loss: 1.0154 - starts_accuracy: 0.6708 - stops_accuracy: 0.6986 - val_loss: 3.0068 - val_starts_loss: 1.5197 - val_stops_loss: 1.5210 - val_starts_accuracy: 0.6126 - val_stops_accuracy: 0.6253\n",
      "Epoch 253/1000\n",
      "20803/20803 [==============================] - 12s 601us/sample - loss: 2.0620 - starts_loss: 1.0434 - stops_loss: 1.0196 - starts_accuracy: 0.6658 - stops_accuracy: 0.6949 - val_loss: 3.0070 - val_starts_loss: 1.5194 - val_stops_loss: 1.5213 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6253\n",
      "Epoch 254/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0518 - starts_loss: 1.0336 - stops_loss: 1.0138 - starts_accuracy: 0.6700 - stops_accuracy: 0.6974 - val_loss: 3.0062 - val_starts_loss: 1.5194 - val_stops_loss: 1.5207 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6251\n",
      "Epoch 255/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0652 - starts_loss: 1.0367 - stops_loss: 1.0264 - starts_accuracy: 0.6679 - stops_accuracy: 0.6936 - val_loss: 3.0044 - val_starts_loss: 1.5191 - val_stops_loss: 1.5194 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6247\n",
      "Epoch 256/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 2.0638 - starts_loss: 1.0429 - stops_loss: 1.0197 - starts_accuracy: 0.6651 - stops_accuracy: 0.6960 - val_loss: 3.0049 - val_starts_loss: 1.5191 - val_stops_loss: 1.5198 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6249\n",
      "Epoch 257/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0574 - starts_loss: 1.0309 - stops_loss: 1.0247 - starts_accuracy: 0.6712 - stops_accuracy: 0.6926 - val_loss: 3.0071 - val_starts_loss: 1.5192 - val_stops_loss: 1.5216 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6253\n",
      "Epoch 258/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0629 - starts_loss: 1.0388 - stops_loss: 1.0207 - starts_accuracy: 0.6672 - stops_accuracy: 0.6962 - val_loss: 3.0084 - val_starts_loss: 1.5192 - val_stops_loss: 1.5226 - val_starts_accuracy: 0.6124 - val_stops_accuracy: 0.6251\n",
      "Epoch 259/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0702 - starts_loss: 1.0413 - stops_loss: 1.0334 - starts_accuracy: 0.6700 - stops_accuracy: 0.6931 - val_loss: 3.0088 - val_starts_loss: 1.5199 - val_stops_loss: 1.5226 - val_starts_accuracy: 0.6124 - val_stops_accuracy: 0.6249\n",
      "Epoch 260/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 2.0687 - starts_loss: 1.0452 - stops_loss: 1.0245 - starts_accuracy: 0.6674 - stops_accuracy: 0.6972 - val_loss: 3.0091 - val_starts_loss: 1.5200 - val_stops_loss: 1.5228 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 261/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0561 - starts_loss: 1.0395 - stops_loss: 1.0213 - starts_accuracy: 0.6693 - stops_accuracy: 0.6950 - val_loss: 3.0093 - val_starts_loss: 1.5202 - val_stops_loss: 1.5227 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6253\n",
      "Epoch 262/1000\n",
      "20803/20803 [==============================] - 12s 592us/sample - loss: 2.0566 - starts_loss: 1.0408 - stops_loss: 1.0156 - starts_accuracy: 0.6684 - stops_accuracy: 0.6968 - val_loss: 3.0091 - val_starts_loss: 1.5205 - val_stops_loss: 1.5223 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6251\n",
      "Epoch 263/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0559 - starts_loss: 1.0398 - stops_loss: 1.0168 - starts_accuracy: 0.6692 - stops_accuracy: 0.6961 - val_loss: 3.0070 - val_starts_loss: 1.5204 - val_stops_loss: 1.5206 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6249\n",
      "Epoch 264/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0527 - starts_loss: 1.0410 - stops_loss: 1.0103 - starts_accuracy: 0.6735 - stops_accuracy: 0.6980 - val_loss: 3.0084 - val_starts_loss: 1.5201 - val_stops_loss: 1.5220 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6251\n",
      "Epoch 265/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0592 - starts_loss: 1.0391 - stops_loss: 1.0241 - starts_accuracy: 0.6685 - stops_accuracy: 0.6970 - val_loss: 3.0093 - val_starts_loss: 1.5200 - val_stops_loss: 1.5228 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6251\n",
      "Epoch 266/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0550 - starts_loss: 1.0399 - stops_loss: 1.0182 - starts_accuracy: 0.6685 - stops_accuracy: 0.6944 - val_loss: 3.0091 - val_starts_loss: 1.5202 - val_stops_loss: 1.5226 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6253\n",
      "Epoch 267/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0642 - starts_loss: 1.0490 - stops_loss: 1.0205 - starts_accuracy: 0.6675 - stops_accuracy: 0.6969 - val_loss: 3.0098 - val_starts_loss: 1.5203 - val_stops_loss: 1.5230 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6253\n",
      "Epoch 268/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0631 - starts_loss: 1.0395 - stops_loss: 1.0216 - starts_accuracy: 0.6684 - stops_accuracy: 0.6920 - val_loss: 3.0095 - val_starts_loss: 1.5202 - val_stops_loss: 1.5229 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6251\n",
      "Epoch 269/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0576 - starts_loss: 1.0448 - stops_loss: 1.0150 - starts_accuracy: 0.6680 - stops_accuracy: 0.6976 - val_loss: 3.0094 - val_starts_loss: 1.5199 - val_stops_loss: 1.5230 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6253\n",
      "Epoch 270/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 2.0587 - starts_loss: 1.0381 - stops_loss: 1.0177 - starts_accuracy: 0.6702 - stops_accuracy: 0.6936 - val_loss: 3.0092 - val_starts_loss: 1.5200 - val_stops_loss: 1.5227 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6251\n",
      "Epoch 271/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 2.0666 - starts_loss: 1.0402 - stops_loss: 1.0234 - starts_accuracy: 0.6688 - stops_accuracy: 0.6922 - val_loss: 3.0103 - val_starts_loss: 1.5200 - val_stops_loss: 1.5237 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6249\n",
      "Epoch 272/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0585 - starts_loss: 1.0391 - stops_loss: 1.0151 - starts_accuracy: 0.6688 - stops_accuracy: 0.6951 - val_loss: 3.0103 - val_starts_loss: 1.5201 - val_stops_loss: 1.5237 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6251\n",
      "Epoch 273/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0458 - starts_loss: 1.0336 - stops_loss: 1.0098 - starts_accuracy: 0.6674 - stops_accuracy: 0.6936 - val_loss: 3.0101 - val_starts_loss: 1.5202 - val_stops_loss: 1.5235 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6251\n",
      "Epoch 274/1000\n",
      "20803/20803 [==============================] - 12s 591us/sample - loss: 2.0523 - starts_loss: 1.0350 - stops_loss: 1.0122 - starts_accuracy: 0.6657 - stops_accuracy: 0.6968 - val_loss: 3.0102 - val_starts_loss: 1.5204 - val_stops_loss: 1.5233 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6251\n",
      "Epoch 275/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0436 - starts_loss: 1.0420 - stops_loss: 1.0088 - starts_accuracy: 0.6693 - stops_accuracy: 0.6980 - val_loss: 3.0105 - val_starts_loss: 1.5206 - val_stops_loss: 1.5235 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6251\n",
      "Epoch 276/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0552 - starts_loss: 1.0349 - stops_loss: 1.0182 - starts_accuracy: 0.6698 - stops_accuracy: 0.6958 - val_loss: 3.0082 - val_starts_loss: 1.5202 - val_stops_loss: 1.5217 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6251\n",
      "Epoch 277/1000\n",
      "20803/20803 [==============================] - 12s 593us/sample - loss: 2.0585 - starts_loss: 1.0335 - stops_loss: 1.0201 - starts_accuracy: 0.6675 - stops_accuracy: 0.6988 - val_loss: 3.0077 - val_starts_loss: 1.5198 - val_stops_loss: 1.5216 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6247\n",
      "Epoch 278/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0498 - starts_loss: 1.0372 - stops_loss: 1.0104 - starts_accuracy: 0.6665 - stops_accuracy: 0.6973 - val_loss: 3.0086 - val_starts_loss: 1.5194 - val_stops_loss: 1.5227 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6249\n",
      "Epoch 279/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 2.0487 - starts_loss: 1.0306 - stops_loss: 1.0137 - starts_accuracy: 0.6681 - stops_accuracy: 0.6964 - val_loss: 3.0091 - val_starts_loss: 1.5194 - val_stops_loss: 1.5232 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6245\n",
      "Epoch 280/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 2.0665 - starts_loss: 1.0395 - stops_loss: 1.0339 - starts_accuracy: 0.6695 - stops_accuracy: 0.6947 - val_loss: 3.0091 - val_starts_loss: 1.5195 - val_stops_loss: 1.5230 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6249\n",
      "Epoch 281/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0582 - starts_loss: 1.0361 - stops_loss: 1.0175 - starts_accuracy: 0.6677 - stops_accuracy: 0.6982 - val_loss: 3.0101 - val_starts_loss: 1.5194 - val_stops_loss: 1.5239 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6245\n",
      "Epoch 282/1000\n",
      "20803/20803 [==============================] - 12s 590us/sample - loss: 2.0639 - starts_loss: 1.0486 - stops_loss: 1.0193 - starts_accuracy: 0.6670 - stops_accuracy: 0.6924 - val_loss: 3.0102 - val_starts_loss: 1.5194 - val_stops_loss: 1.5240 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6245\n",
      "Epoch 283/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0607 - starts_loss: 1.0371 - stops_loss: 1.0244 - starts_accuracy: 0.6708 - stops_accuracy: 0.6954 - val_loss: 3.0100 - val_starts_loss: 1.5196 - val_stops_loss: 1.5237 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6247\n",
      "Epoch 284/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.0526 - starts_loss: 1.0350 - stops_loss: 1.0127 - starts_accuracy: 0.6712 - stops_accuracy: 0.7010 - val_loss: 3.0105 - val_starts_loss: 1.5200 - val_stops_loss: 1.5239 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6251\n",
      "Epoch 285/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0643 - starts_loss: 1.0426 - stops_loss: 1.0301 - starts_accuracy: 0.6665 - stops_accuracy: 0.6950 - val_loss: 3.0097 - val_starts_loss: 1.5203 - val_stops_loss: 1.5229 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6256\n",
      "Epoch 286/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0693 - starts_loss: 1.0497 - stops_loss: 1.0245 - starts_accuracy: 0.6667 - stops_accuracy: 0.6933 - val_loss: 3.0085 - val_starts_loss: 1.5202 - val_stops_loss: 1.5221 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0471 - starts_loss: 1.0369 - stops_loss: 1.0130 - starts_accuracy: 0.6680 - stops_accuracy: 0.6982 - val_loss: 3.0098 - val_starts_loss: 1.5202 - val_stops_loss: 1.5232 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6256\n",
      "Epoch 288/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0439 - starts_loss: 1.0313 - stops_loss: 1.0054 - starts_accuracy: 0.6722 - stops_accuracy: 0.7006 - val_loss: 3.0108 - val_starts_loss: 1.5201 - val_stops_loss: 1.5241 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6251\n",
      "Epoch 289/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.0592 - starts_loss: 1.0352 - stops_loss: 1.0219 - starts_accuracy: 0.6687 - stops_accuracy: 0.6960 - val_loss: 3.0117 - val_starts_loss: 1.5202 - val_stops_loss: 1.5247 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6247\n",
      "Epoch 290/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.0566 - starts_loss: 1.0376 - stops_loss: 1.0187 - starts_accuracy: 0.6688 - stops_accuracy: 0.6946 - val_loss: 3.0102 - val_starts_loss: 1.5202 - val_stops_loss: 1.5235 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6249\n",
      "Epoch 291/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0701 - starts_loss: 1.0465 - stops_loss: 1.0262 - starts_accuracy: 0.6658 - stops_accuracy: 0.6933 - val_loss: 3.0086 - val_starts_loss: 1.5204 - val_stops_loss: 1.5220 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6256\n",
      "Epoch 292/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0530 - starts_loss: 1.0327 - stops_loss: 1.0152 - starts_accuracy: 0.6700 - stops_accuracy: 0.6956 - val_loss: 3.0091 - val_starts_loss: 1.5202 - val_stops_loss: 1.5226 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6251\n",
      "Epoch 293/1000\n",
      "20803/20803 [==============================] - 12s 601us/sample - loss: 2.0585 - starts_loss: 1.0428 - stops_loss: 1.0213 - starts_accuracy: 0.6684 - stops_accuracy: 0.6945 - val_loss: 3.0118 - val_starts_loss: 1.5201 - val_stops_loss: 1.5248 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6251\n",
      "Epoch 294/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0484 - starts_loss: 1.0341 - stops_loss: 1.0187 - starts_accuracy: 0.6707 - stops_accuracy: 0.6960 - val_loss: 3.0107 - val_starts_loss: 1.5200 - val_stops_loss: 1.5241 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6249\n",
      "Epoch 295/1000\n",
      "20803/20803 [==============================] - 13s 635us/sample - loss: 2.0602 - starts_loss: 1.0382 - stops_loss: 1.0210 - starts_accuracy: 0.6698 - stops_accuracy: 0.6939 - val_loss: 3.0102 - val_starts_loss: 1.5196 - val_stops_loss: 1.5239 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6249\n",
      "Epoch 296/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0590 - starts_loss: 1.0395 - stops_loss: 1.0218 - starts_accuracy: 0.6684 - stops_accuracy: 0.6963 - val_loss: 3.0119 - val_starts_loss: 1.5197 - val_stops_loss: 1.5253 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6249\n",
      "Epoch 297/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0605 - starts_loss: 1.0352 - stops_loss: 1.0286 - starts_accuracy: 0.6688 - stops_accuracy: 0.6959 - val_loss: 3.0143 - val_starts_loss: 1.5199 - val_stops_loss: 1.5272 - val_starts_accuracy: 0.6141 - val_stops_accuracy: 0.6235\n",
      "Epoch 298/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0562 - starts_loss: 1.0400 - stops_loss: 1.0169 - starts_accuracy: 0.6670 - stops_accuracy: 0.6951 - val_loss: 3.0149 - val_starts_loss: 1.5198 - val_stops_loss: 1.5278 - val_starts_accuracy: 0.6141 - val_stops_accuracy: 0.6233\n",
      "Epoch 299/1000\n",
      "20803/20803 [==============================] - 13s 619us/sample - loss: 2.0623 - starts_loss: 1.0397 - stops_loss: 1.0191 - starts_accuracy: 0.6682 - stops_accuracy: 0.6941 - val_loss: 3.0143 - val_starts_loss: 1.5201 - val_stops_loss: 1.5271 - val_starts_accuracy: 0.6141 - val_stops_accuracy: 0.6237\n",
      "Epoch 300/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0550 - starts_loss: 1.0329 - stops_loss: 1.0192 - starts_accuracy: 0.6698 - stops_accuracy: 0.6976 - val_loss: 3.0129 - val_starts_loss: 1.5200 - val_stops_loss: 1.5258 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6243\n",
      "Epoch 301/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0557 - starts_loss: 1.0366 - stops_loss: 1.0192 - starts_accuracy: 0.6665 - stops_accuracy: 0.6932 - val_loss: 3.0110 - val_starts_loss: 1.5199 - val_stops_loss: 1.5245 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6249\n",
      "Epoch 302/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0657 - starts_loss: 1.0401 - stops_loss: 1.0281 - starts_accuracy: 0.6708 - stops_accuracy: 0.6934 - val_loss: 3.0098 - val_starts_loss: 1.5196 - val_stops_loss: 1.5238 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6247\n",
      "Epoch 303/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0621 - starts_loss: 1.0356 - stops_loss: 1.0278 - starts_accuracy: 0.6699 - stops_accuracy: 0.6926 - val_loss: 3.0104 - val_starts_loss: 1.5197 - val_stops_loss: 1.5242 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6245\n",
      "Epoch 304/1000\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 2.0441 - starts_loss: 1.0288 - stops_loss: 1.0131 - starts_accuracy: 0.6704 - stops_accuracy: 0.6945 - val_loss: 3.0097 - val_starts_loss: 1.5200 - val_stops_loss: 1.5233 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6251\n",
      "Epoch 305/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0524 - starts_loss: 1.0405 - stops_loss: 1.0123 - starts_accuracy: 0.6691 - stops_accuracy: 0.6986 - val_loss: 3.0083 - val_starts_loss: 1.5199 - val_stops_loss: 1.5222 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6255\n",
      "Epoch 306/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0443 - starts_loss: 1.0319 - stops_loss: 1.0140 - starts_accuracy: 0.6684 - stops_accuracy: 0.6963 - val_loss: 3.0093 - val_starts_loss: 1.5201 - val_stops_loss: 1.5230 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6255\n",
      "Epoch 307/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0648 - starts_loss: 1.0436 - stops_loss: 1.0223 - starts_accuracy: 0.6664 - stops_accuracy: 0.6945 - val_loss: 3.0090 - val_starts_loss: 1.5200 - val_stops_loss: 1.5228 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6251\n",
      "Epoch 308/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0598 - starts_loss: 1.0393 - stops_loss: 1.0224 - starts_accuracy: 0.6695 - stops_accuracy: 0.6932 - val_loss: 3.0101 - val_starts_loss: 1.5203 - val_stops_loss: 1.5236 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6251\n",
      "Epoch 309/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0607 - starts_loss: 1.0464 - stops_loss: 1.0220 - starts_accuracy: 0.6666 - stops_accuracy: 0.6976 - val_loss: 3.0099 - val_starts_loss: 1.5204 - val_stops_loss: 1.5233 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6255\n",
      "Epoch 310/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.0361 - starts_loss: 1.0294 - stops_loss: 1.0130 - starts_accuracy: 0.6711 - stops_accuracy: 0.6957 - val_loss: 3.0108 - val_starts_loss: 1.5203 - val_stops_loss: 1.5242 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6249\n",
      "Epoch 311/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0447 - starts_loss: 1.0309 - stops_loss: 1.0153 - starts_accuracy: 0.6707 - stops_accuracy: 0.6985 - val_loss: 3.0125 - val_starts_loss: 1.5206 - val_stops_loss: 1.5252 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6247\n",
      "Epoch 312/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0710 - starts_loss: 1.0403 - stops_loss: 1.0268 - starts_accuracy: 0.6661 - stops_accuracy: 0.6938 - val_loss: 3.0115 - val_starts_loss: 1.5205 - val_stops_loss: 1.5245 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0628 - starts_loss: 1.0385 - stops_loss: 1.0244 - starts_accuracy: 0.6668 - stops_accuracy: 0.6910 - val_loss: 3.0115 - val_starts_loss: 1.5205 - val_stops_loss: 1.5245 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6251\n",
      "Epoch 314/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0521 - starts_loss: 1.0431 - stops_loss: 1.0090 - starts_accuracy: 0.6685 - stops_accuracy: 0.6945 - val_loss: 3.0095 - val_starts_loss: 1.5203 - val_stops_loss: 1.5229 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6253\n",
      "Epoch 315/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0529 - starts_loss: 1.0436 - stops_loss: 1.0134 - starts_accuracy: 0.6651 - stops_accuracy: 0.6993 - val_loss: 3.0086 - val_starts_loss: 1.5203 - val_stops_loss: 1.5222 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6251\n",
      "Epoch 316/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0484 - starts_loss: 1.0336 - stops_loss: 1.0120 - starts_accuracy: 0.6693 - stops_accuracy: 0.6955 - val_loss: 3.0087 - val_starts_loss: 1.5201 - val_stops_loss: 1.5225 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6253\n",
      "Epoch 317/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 2.0568 - starts_loss: 1.0386 - stops_loss: 1.0227 - starts_accuracy: 0.6671 - stops_accuracy: 0.6949 - val_loss: 3.0111 - val_starts_loss: 1.5201 - val_stops_loss: 1.5246 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6245\n",
      "Epoch 318/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0644 - starts_loss: 1.0380 - stops_loss: 1.0288 - starts_accuracy: 0.6674 - stops_accuracy: 0.6942 - val_loss: 3.0121 - val_starts_loss: 1.5204 - val_stops_loss: 1.5252 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6249\n",
      "Epoch 319/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0565 - starts_loss: 1.0407 - stops_loss: 1.0191 - starts_accuracy: 0.6684 - stops_accuracy: 0.6938 - val_loss: 3.0128 - val_starts_loss: 1.5204 - val_stops_loss: 1.5258 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6245\n",
      "Epoch 320/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0549 - starts_loss: 1.0402 - stops_loss: 1.0172 - starts_accuracy: 0.6665 - stops_accuracy: 0.6967 - val_loss: 3.0137 - val_starts_loss: 1.5205 - val_stops_loss: 1.5265 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6247\n",
      "Epoch 321/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0457 - starts_loss: 1.0273 - stops_loss: 1.0139 - starts_accuracy: 0.6679 - stops_accuracy: 0.6979 - val_loss: 3.0133 - val_starts_loss: 1.5205 - val_stops_loss: 1.5262 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6247\n",
      "Epoch 322/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0568 - starts_loss: 1.0336 - stops_loss: 1.0230 - starts_accuracy: 0.6704 - stops_accuracy: 0.6917 - val_loss: 3.0132 - val_starts_loss: 1.5207 - val_stops_loss: 1.5259 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6249\n",
      "Epoch 323/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.0471 - starts_loss: 1.0397 - stops_loss: 1.0066 - starts_accuracy: 0.6662 - stops_accuracy: 0.6963 - val_loss: 3.0131 - val_starts_loss: 1.5206 - val_stops_loss: 1.5260 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6247\n",
      "Epoch 324/1000\n",
      "20803/20803 [==============================] - 13s 617us/sample - loss: 2.0592 - starts_loss: 1.0391 - stops_loss: 1.0241 - starts_accuracy: 0.6685 - stops_accuracy: 0.6938 - val_loss: 3.0135 - val_starts_loss: 1.5208 - val_stops_loss: 1.5261 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6245\n",
      "Epoch 325/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0527 - starts_loss: 1.0350 - stops_loss: 1.0199 - starts_accuracy: 0.6711 - stops_accuracy: 0.6981 - val_loss: 3.0129 - val_starts_loss: 1.5208 - val_stops_loss: 1.5257 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6245\n",
      "Epoch 326/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0456 - starts_loss: 1.0394 - stops_loss: 1.0009 - starts_accuracy: 0.6652 - stops_accuracy: 0.7015 - val_loss: 3.0108 - val_starts_loss: 1.5210 - val_stops_loss: 1.5237 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6255\n",
      "Epoch 327/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0566 - starts_loss: 1.0310 - stops_loss: 1.0237 - starts_accuracy: 0.6690 - stops_accuracy: 0.6938 - val_loss: 3.0112 - val_starts_loss: 1.5211 - val_stops_loss: 1.5239 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6255\n",
      "Epoch 328/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0561 - starts_loss: 1.0388 - stops_loss: 1.0168 - starts_accuracy: 0.6679 - stops_accuracy: 0.6921 - val_loss: 3.0102 - val_starts_loss: 1.5211 - val_stops_loss: 1.5230 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6253\n",
      "Epoch 329/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0604 - starts_loss: 1.0414 - stops_loss: 1.0203 - starts_accuracy: 0.6683 - stops_accuracy: 0.6955 - val_loss: 3.0098 - val_starts_loss: 1.5212 - val_stops_loss: 1.5227 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6251\n",
      "Epoch 330/1000\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 2.0665 - starts_loss: 1.0370 - stops_loss: 1.0211 - starts_accuracy: 0.6689 - stops_accuracy: 0.6931 - val_loss: 3.0110 - val_starts_loss: 1.5211 - val_stops_loss: 1.5238 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6253\n",
      "Epoch 331/1000\n",
      "20803/20803 [==============================] - 12s 601us/sample - loss: 2.0524 - starts_loss: 1.0306 - stops_loss: 1.0207 - starts_accuracy: 0.6700 - stops_accuracy: 0.6939 - val_loss: 3.0121 - val_starts_loss: 1.5209 - val_stops_loss: 1.5248 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6251\n",
      "Epoch 332/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0421 - starts_loss: 1.0343 - stops_loss: 1.0085 - starts_accuracy: 0.6687 - stops_accuracy: 0.6988 - val_loss: 3.0123 - val_starts_loss: 1.5209 - val_stops_loss: 1.5248 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6249\n",
      "Epoch 333/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0539 - starts_loss: 1.0360 - stops_loss: 1.0130 - starts_accuracy: 0.6691 - stops_accuracy: 0.6959 - val_loss: 3.0116 - val_starts_loss: 1.5210 - val_stops_loss: 1.5243 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6255\n",
      "Epoch 334/1000\n",
      "20803/20803 [==============================] - 13s 619us/sample - loss: 2.0521 - starts_loss: 1.0312 - stops_loss: 1.0151 - starts_accuracy: 0.6692 - stops_accuracy: 0.6948 - val_loss: 3.0134 - val_starts_loss: 1.5211 - val_stops_loss: 1.5256 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6251\n",
      "Epoch 335/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0530 - starts_loss: 1.0357 - stops_loss: 1.0095 - starts_accuracy: 0.6666 - stops_accuracy: 0.6998 - val_loss: 3.0143 - val_starts_loss: 1.5213 - val_stops_loss: 1.5264 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6253\n",
      "Epoch 336/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0488 - starts_loss: 1.0357 - stops_loss: 1.0162 - starts_accuracy: 0.6699 - stops_accuracy: 0.6999 - val_loss: 3.0140 - val_starts_loss: 1.5215 - val_stops_loss: 1.5259 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6253\n",
      "Epoch 337/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0467 - starts_loss: 1.0360 - stops_loss: 1.0151 - starts_accuracy: 0.6703 - stops_accuracy: 0.6988 - val_loss: 3.0137 - val_starts_loss: 1.5215 - val_stops_loss: 1.5257 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6253\n",
      "Epoch 338/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0538 - starts_loss: 1.0314 - stops_loss: 1.0229 - starts_accuracy: 0.6681 - stops_accuracy: 0.6969 - val_loss: 3.0125 - val_starts_loss: 1.5212 - val_stops_loss: 1.5249 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0488 - starts_loss: 1.0301 - stops_loss: 1.0169 - starts_accuracy: 0.6710 - stops_accuracy: 0.6966 - val_loss: 3.0128 - val_starts_loss: 1.5210 - val_stops_loss: 1.5254 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6251\n",
      "Epoch 340/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0419 - starts_loss: 1.0441 - stops_loss: 1.0038 - starts_accuracy: 0.6669 - stops_accuracy: 0.6974 - val_loss: 3.0136 - val_starts_loss: 1.5207 - val_stops_loss: 1.5263 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6249\n",
      "Epoch 341/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0483 - starts_loss: 1.0383 - stops_loss: 1.0159 - starts_accuracy: 0.6691 - stops_accuracy: 0.7006 - val_loss: 3.0155 - val_starts_loss: 1.5212 - val_stops_loss: 1.5276 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6249\n",
      "Epoch 342/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0531 - starts_loss: 1.0381 - stops_loss: 1.0170 - starts_accuracy: 0.6694 - stops_accuracy: 0.6943 - val_loss: 3.0142 - val_starts_loss: 1.5213 - val_stops_loss: 1.5263 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6249\n",
      "Epoch 343/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0416 - starts_loss: 1.0352 - stops_loss: 1.0104 - starts_accuracy: 0.6690 - stops_accuracy: 0.6995 - val_loss: 3.0135 - val_starts_loss: 1.5213 - val_stops_loss: 1.5257 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6249\n",
      "Epoch 344/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0547 - starts_loss: 1.0426 - stops_loss: 1.0141 - starts_accuracy: 0.6694 - stops_accuracy: 0.6968 - val_loss: 3.0128 - val_starts_loss: 1.5211 - val_stops_loss: 1.5254 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6249\n",
      "Epoch 345/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0547 - starts_loss: 1.0364 - stops_loss: 1.0188 - starts_accuracy: 0.6671 - stops_accuracy: 0.6937 - val_loss: 3.0116 - val_starts_loss: 1.5208 - val_stops_loss: 1.5247 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6251\n",
      "Epoch 346/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0439 - starts_loss: 1.0350 - stops_loss: 1.0089 - starts_accuracy: 0.6688 - stops_accuracy: 0.6964 - val_loss: 3.0106 - val_starts_loss: 1.5204 - val_stops_loss: 1.5242 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6253\n",
      "Epoch 347/1000\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 2.0469 - starts_loss: 1.0358 - stops_loss: 1.0158 - starts_accuracy: 0.6680 - stops_accuracy: 0.7004 - val_loss: 3.0110 - val_starts_loss: 1.5206 - val_stops_loss: 1.5243 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6253\n",
      "Epoch 348/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0439 - starts_loss: 1.0389 - stops_loss: 1.0082 - starts_accuracy: 0.6681 - stops_accuracy: 0.6989 - val_loss: 3.0105 - val_starts_loss: 1.5201 - val_stops_loss: 1.5244 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6247\n",
      "Epoch 349/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0457 - starts_loss: 1.0356 - stops_loss: 1.0103 - starts_accuracy: 0.6700 - stops_accuracy: 0.7012 - val_loss: 3.0104 - val_starts_loss: 1.5201 - val_stops_loss: 1.5242 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6247\n",
      "Epoch 350/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0526 - starts_loss: 1.0375 - stops_loss: 1.0183 - starts_accuracy: 0.6686 - stops_accuracy: 0.6944 - val_loss: 3.0104 - val_starts_loss: 1.5201 - val_stops_loss: 1.5241 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6249\n",
      "Epoch 351/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0476 - starts_loss: 1.0367 - stops_loss: 1.0103 - starts_accuracy: 0.6674 - stops_accuracy: 0.6982 - val_loss: 3.0106 - val_starts_loss: 1.5203 - val_stops_loss: 1.5242 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6249\n",
      "Epoch 352/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0459 - starts_loss: 1.0375 - stops_loss: 1.0116 - starts_accuracy: 0.6678 - stops_accuracy: 0.6972 - val_loss: 3.0114 - val_starts_loss: 1.5209 - val_stops_loss: 1.5244 - val_starts_accuracy: 0.6128 - val_stops_accuracy: 0.6255\n",
      "Epoch 353/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0645 - starts_loss: 1.0389 - stops_loss: 1.0324 - starts_accuracy: 0.6697 - stops_accuracy: 0.6943 - val_loss: 3.0109 - val_starts_loss: 1.5211 - val_stops_loss: 1.5238 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6253\n",
      "Epoch 354/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0455 - starts_loss: 1.0333 - stops_loss: 1.0136 - starts_accuracy: 0.6690 - stops_accuracy: 0.6954 - val_loss: 3.0107 - val_starts_loss: 1.5209 - val_stops_loss: 1.5239 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6251\n",
      "Epoch 355/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0505 - starts_loss: 1.0311 - stops_loss: 1.0148 - starts_accuracy: 0.6694 - stops_accuracy: 0.6986 - val_loss: 3.0109 - val_starts_loss: 1.5208 - val_stops_loss: 1.5241 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6251\n",
      "Epoch 356/1000\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 2.0610 - starts_loss: 1.0383 - stops_loss: 1.0212 - starts_accuracy: 0.6684 - stops_accuracy: 0.6937 - val_loss: 3.0119 - val_starts_loss: 1.5209 - val_stops_loss: 1.5248 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6253\n",
      "Epoch 357/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0491 - starts_loss: 1.0281 - stops_loss: 1.0189 - starts_accuracy: 0.6677 - stops_accuracy: 0.6936 - val_loss: 3.0117 - val_starts_loss: 1.5210 - val_stops_loss: 1.5247 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6251\n",
      "Epoch 358/1000\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 2.0443 - starts_loss: 1.0253 - stops_loss: 1.0178 - starts_accuracy: 0.6679 - stops_accuracy: 0.6965 - val_loss: 3.0117 - val_starts_loss: 1.5212 - val_stops_loss: 1.5245 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6251\n",
      "Epoch 359/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0572 - starts_loss: 1.0413 - stops_loss: 1.0181 - starts_accuracy: 0.6704 - stops_accuracy: 0.6950 - val_loss: 3.0117 - val_starts_loss: 1.5213 - val_stops_loss: 1.5244 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6253\n",
      "Epoch 360/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0500 - starts_loss: 1.0342 - stops_loss: 1.0086 - starts_accuracy: 0.6690 - stops_accuracy: 0.6970 - val_loss: 3.0125 - val_starts_loss: 1.5214 - val_stops_loss: 1.5251 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6255\n",
      "Epoch 361/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0405 - starts_loss: 1.0365 - stops_loss: 1.0012 - starts_accuracy: 0.6700 - stops_accuracy: 0.6992 - val_loss: 3.0147 - val_starts_loss: 1.5216 - val_stops_loss: 1.5268 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6249\n",
      "Epoch 362/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0565 - starts_loss: 1.0395 - stops_loss: 1.0087 - starts_accuracy: 0.6683 - stops_accuracy: 0.6936 - val_loss: 3.0143 - val_starts_loss: 1.5215 - val_stops_loss: 1.5265 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6249\n",
      "Epoch 363/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 2.0562 - starts_loss: 1.0395 - stops_loss: 1.0167 - starts_accuracy: 0.6652 - stops_accuracy: 0.6984 - val_loss: 3.0140 - val_starts_loss: 1.5214 - val_stops_loss: 1.5263 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6249\n",
      "Epoch 364/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.0540 - starts_loss: 1.0456 - stops_loss: 1.0092 - starts_accuracy: 0.6690 - stops_accuracy: 0.7010 - val_loss: 3.0127 - val_starts_loss: 1.5213 - val_stops_loss: 1.5252 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365/1000\n",
      "20803/20803 [==============================] - 12s 593us/sample - loss: 2.0496 - starts_loss: 1.0337 - stops_loss: 1.0171 - starts_accuracy: 0.6677 - stops_accuracy: 0.6971 - val_loss: 3.0127 - val_starts_loss: 1.5211 - val_stops_loss: 1.5254 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6251\n",
      "Epoch 366/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0366 - starts_loss: 1.0316 - stops_loss: 1.0133 - starts_accuracy: 0.6689 - stops_accuracy: 0.6987 - val_loss: 3.0128 - val_starts_loss: 1.5210 - val_stops_loss: 1.5256 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6249\n",
      "Epoch 367/1000\n",
      "20803/20803 [==============================] - 12s 601us/sample - loss: 2.0476 - starts_loss: 1.0324 - stops_loss: 1.0150 - starts_accuracy: 0.6687 - stops_accuracy: 0.6950 - val_loss: 3.0116 - val_starts_loss: 1.5207 - val_stops_loss: 1.5250 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6249\n",
      "Epoch 368/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0449 - starts_loss: 1.0357 - stops_loss: 1.0111 - starts_accuracy: 0.6710 - stops_accuracy: 0.7010 - val_loss: 3.0133 - val_starts_loss: 1.5208 - val_stops_loss: 1.5263 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6247\n",
      "Epoch 369/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0565 - starts_loss: 1.0393 - stops_loss: 1.0145 - starts_accuracy: 0.6698 - stops_accuracy: 0.6931 - val_loss: 3.0122 - val_starts_loss: 1.5209 - val_stops_loss: 1.5253 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6251\n",
      "Epoch 370/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0451 - starts_loss: 1.0364 - stops_loss: 1.0124 - starts_accuracy: 0.6667 - stops_accuracy: 0.6949 - val_loss: 3.0104 - val_starts_loss: 1.5207 - val_stops_loss: 1.5238 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6255\n",
      "Epoch 371/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0383 - starts_loss: 1.0315 - stops_loss: 1.0021 - starts_accuracy: 0.6693 - stops_accuracy: 0.6994 - val_loss: 3.0113 - val_starts_loss: 1.5208 - val_stops_loss: 1.5246 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6251\n",
      "Epoch 372/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0426 - starts_loss: 1.0352 - stops_loss: 1.0120 - starts_accuracy: 0.6729 - stops_accuracy: 0.6981 - val_loss: 3.0132 - val_starts_loss: 1.5211 - val_stops_loss: 1.5259 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6251\n",
      "Epoch 373/1000\n",
      "20803/20803 [==============================] - 12s 586us/sample - loss: 2.0430 - starts_loss: 1.0308 - stops_loss: 1.0073 - starts_accuracy: 0.6678 - stops_accuracy: 0.6974 - val_loss: 3.0131 - val_starts_loss: 1.5211 - val_stops_loss: 1.5258 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6251\n",
      "Epoch 374/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0449 - starts_loss: 1.0300 - stops_loss: 1.0189 - starts_accuracy: 0.6707 - stops_accuracy: 0.6979 - val_loss: 3.0137 - val_starts_loss: 1.5216 - val_stops_loss: 1.5260 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6249\n",
      "Epoch 375/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 2.0481 - starts_loss: 1.0369 - stops_loss: 1.0117 - starts_accuracy: 0.6682 - stops_accuracy: 0.6971 - val_loss: 3.0129 - val_starts_loss: 1.5217 - val_stops_loss: 1.5252 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6253\n",
      "Epoch 376/1000\n",
      "20803/20803 [==============================] - 12s 586us/sample - loss: 2.0426 - starts_loss: 1.0246 - stops_loss: 1.0138 - starts_accuracy: 0.6705 - stops_accuracy: 0.6988 - val_loss: 3.0135 - val_starts_loss: 1.5216 - val_stops_loss: 1.5257 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6251\n",
      "Epoch 377/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0472 - starts_loss: 1.0363 - stops_loss: 1.0079 - starts_accuracy: 0.6700 - stops_accuracy: 0.6958 - val_loss: 3.0144 - val_starts_loss: 1.5215 - val_stops_loss: 1.5266 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6247\n",
      "Epoch 378/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0421 - starts_loss: 1.0259 - stops_loss: 1.0116 - starts_accuracy: 0.6711 - stops_accuracy: 0.6975 - val_loss: 3.0147 - val_starts_loss: 1.5218 - val_stops_loss: 1.5267 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6247\n",
      "Epoch 379/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0513 - starts_loss: 1.0378 - stops_loss: 1.0132 - starts_accuracy: 0.6705 - stops_accuracy: 0.6951 - val_loss: 3.0154 - val_starts_loss: 1.5220 - val_stops_loss: 1.5271 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6245\n",
      "Epoch 380/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0450 - starts_loss: 1.0334 - stops_loss: 1.0093 - starts_accuracy: 0.6689 - stops_accuracy: 0.6971 - val_loss: 3.0158 - val_starts_loss: 1.5221 - val_stops_loss: 1.5274 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6245\n",
      "Epoch 381/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0487 - starts_loss: 1.0353 - stops_loss: 1.0225 - starts_accuracy: 0.6706 - stops_accuracy: 0.6976 - val_loss: 3.0163 - val_starts_loss: 1.5223 - val_stops_loss: 1.5278 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6245\n",
      "Epoch 382/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.0393 - starts_loss: 1.0308 - stops_loss: 1.0113 - starts_accuracy: 0.6698 - stops_accuracy: 0.6967 - val_loss: 3.0151 - val_starts_loss: 1.5224 - val_stops_loss: 1.5266 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6249\n",
      "Epoch 383/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0507 - starts_loss: 1.0376 - stops_loss: 1.0110 - starts_accuracy: 0.6671 - stops_accuracy: 0.6995 - val_loss: 3.0146 - val_starts_loss: 1.5222 - val_stops_loss: 1.5264 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6247\n",
      "Epoch 384/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0362 - starts_loss: 1.0333 - stops_loss: 1.0063 - starts_accuracy: 0.6699 - stops_accuracy: 0.6983 - val_loss: 3.0127 - val_starts_loss: 1.5220 - val_stops_loss: 1.5249 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6251\n",
      "Epoch 385/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0488 - starts_loss: 1.0350 - stops_loss: 1.0107 - starts_accuracy: 0.6670 - stops_accuracy: 0.6980 - val_loss: 3.0121 - val_starts_loss: 1.5220 - val_stops_loss: 1.5244 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6255\n",
      "Epoch 386/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0421 - starts_loss: 1.0349 - stops_loss: 1.0104 - starts_accuracy: 0.6691 - stops_accuracy: 0.6964 - val_loss: 3.0122 - val_starts_loss: 1.5218 - val_stops_loss: 1.5246 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6251\n",
      "Epoch 387/1000\n",
      "20803/20803 [==============================] - 12s 595us/sample - loss: 2.0396 - starts_loss: 1.0344 - stops_loss: 1.0069 - starts_accuracy: 0.6719 - stops_accuracy: 0.6979 - val_loss: 3.0129 - val_starts_loss: 1.5214 - val_stops_loss: 1.5254 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6249\n",
      "Epoch 388/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0488 - starts_loss: 1.0328 - stops_loss: 1.0055 - starts_accuracy: 0.6680 - stops_accuracy: 0.6974 - val_loss: 3.0132 - val_starts_loss: 1.5214 - val_stops_loss: 1.5257 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6249\n",
      "Epoch 389/1000\n",
      "20803/20803 [==============================] - 13s 620us/sample - loss: 2.0474 - starts_loss: 1.0310 - stops_loss: 1.0160 - starts_accuracy: 0.6690 - stops_accuracy: 0.6971 - val_loss: 3.0138 - val_starts_loss: 1.5217 - val_stops_loss: 1.5260 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6247\n",
      "Epoch 390/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0457 - starts_loss: 1.0289 - stops_loss: 1.0162 - starts_accuracy: 0.6697 - stops_accuracy: 0.6966 - val_loss: 3.0137 - val_starts_loss: 1.5216 - val_stops_loss: 1.5260 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/1000\n",
      "20803/20803 [==============================] - 12s 595us/sample - loss: 2.0472 - starts_loss: 1.0253 - stops_loss: 1.0160 - starts_accuracy: 0.6714 - stops_accuracy: 0.6937 - val_loss: 3.0139 - val_starts_loss: 1.5216 - val_stops_loss: 1.5262 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6249\n",
      "Epoch 392/1000\n",
      "20803/20803 [==============================] - 12s 595us/sample - loss: 2.0543 - starts_loss: 1.0346 - stops_loss: 1.0207 - starts_accuracy: 0.6714 - stops_accuracy: 0.6978 - val_loss: 3.0124 - val_starts_loss: 1.5217 - val_stops_loss: 1.5247 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6253\n",
      "Epoch 393/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 2.0501 - starts_loss: 1.0387 - stops_loss: 1.0145 - starts_accuracy: 0.6661 - stops_accuracy: 0.6990 - val_loss: 3.0132 - val_starts_loss: 1.5215 - val_stops_loss: 1.5256 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6249\n",
      "Epoch 394/1000\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 2.0430 - starts_loss: 1.0293 - stops_loss: 1.0060 - starts_accuracy: 0.6690 - stops_accuracy: 0.6984 - val_loss: 3.0136 - val_starts_loss: 1.5214 - val_stops_loss: 1.5261 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6249\n",
      "Epoch 395/1000\n",
      "20803/20803 [==============================] - 15s 700us/sample - loss: 2.0552 - starts_loss: 1.0406 - stops_loss: 1.0131 - starts_accuracy: 0.6658 - stops_accuracy: 0.6974 - val_loss: 3.0159 - val_starts_loss: 1.5216 - val_stops_loss: 1.5279 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6249\n",
      "Epoch 396/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0387 - starts_loss: 1.0299 - stops_loss: 1.0100 - starts_accuracy: 0.6676 - stops_accuracy: 0.6964 - val_loss: 3.0165 - val_starts_loss: 1.5220 - val_stops_loss: 1.5283 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6249\n",
      "Epoch 397/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0466 - starts_loss: 1.0318 - stops_loss: 1.0123 - starts_accuracy: 0.6680 - stops_accuracy: 0.6973 - val_loss: 3.0159 - val_starts_loss: 1.5219 - val_stops_loss: 1.5278 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6247\n",
      "Epoch 398/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0377 - starts_loss: 1.0260 - stops_loss: 1.0081 - starts_accuracy: 0.6721 - stops_accuracy: 0.6956 - val_loss: 3.0140 - val_starts_loss: 1.5222 - val_stops_loss: 1.5261 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6251\n",
      "Epoch 399/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0469 - starts_loss: 1.0353 - stops_loss: 1.0066 - starts_accuracy: 0.6680 - stops_accuracy: 0.6982 - val_loss: 3.0132 - val_starts_loss: 1.5223 - val_stops_loss: 1.5253 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6249\n",
      "Epoch 400/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0482 - starts_loss: 1.0338 - stops_loss: 1.0146 - starts_accuracy: 0.6693 - stops_accuracy: 0.6975 - val_loss: 3.0124 - val_starts_loss: 1.5222 - val_stops_loss: 1.5247 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6251\n",
      "Epoch 401/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.0487 - starts_loss: 1.0331 - stops_loss: 1.0127 - starts_accuracy: 0.6695 - stops_accuracy: 0.6985 - val_loss: 3.0134 - val_starts_loss: 1.5221 - val_stops_loss: 1.5256 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6249\n",
      "Epoch 402/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0267 - starts_loss: 1.0236 - stops_loss: 0.9985 - starts_accuracy: 0.6693 - stops_accuracy: 0.7017 - val_loss: 3.0144 - val_starts_loss: 1.5219 - val_stops_loss: 1.5266 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6247\n",
      "Epoch 403/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0411 - starts_loss: 1.0386 - stops_loss: 1.0098 - starts_accuracy: 0.6691 - stops_accuracy: 0.7032 - val_loss: 3.0150 - val_starts_loss: 1.5219 - val_stops_loss: 1.5271 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6245\n",
      "Epoch 404/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0354 - starts_loss: 1.0283 - stops_loss: 0.9997 - starts_accuracy: 0.6710 - stops_accuracy: 0.6998 - val_loss: 3.0152 - val_starts_loss: 1.5219 - val_stops_loss: 1.5273 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6245\n",
      "Epoch 405/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0421 - starts_loss: 1.0378 - stops_loss: 1.0084 - starts_accuracy: 0.6661 - stops_accuracy: 0.7009 - val_loss: 3.0172 - val_starts_loss: 1.5226 - val_stops_loss: 1.5284 - val_starts_accuracy: 0.6130 - val_stops_accuracy: 0.6247\n",
      "Epoch 406/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0512 - starts_loss: 1.0378 - stops_loss: 1.0186 - starts_accuracy: 0.6732 - stops_accuracy: 0.6950 - val_loss: 3.0158 - val_starts_loss: 1.5225 - val_stops_loss: 1.5273 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6245\n",
      "Epoch 407/1000\n",
      "20803/20803 [==============================] - 13s 618us/sample - loss: 2.0526 - starts_loss: 1.0367 - stops_loss: 1.0151 - starts_accuracy: 0.6716 - stops_accuracy: 0.6945 - val_loss: 3.0150 - val_starts_loss: 1.5225 - val_stops_loss: 1.5266 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6247\n",
      "Epoch 408/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0451 - starts_loss: 1.0267 - stops_loss: 1.0156 - starts_accuracy: 0.6688 - stops_accuracy: 0.6961 - val_loss: 3.0151 - val_starts_loss: 1.5223 - val_stops_loss: 1.5269 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6247\n",
      "Epoch 409/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0420 - starts_loss: 1.0271 - stops_loss: 1.0159 - starts_accuracy: 0.6692 - stops_accuracy: 0.6950 - val_loss: 3.0157 - val_starts_loss: 1.5223 - val_stops_loss: 1.5275 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6249\n",
      "Epoch 410/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.0407 - starts_loss: 1.0301 - stops_loss: 1.0094 - starts_accuracy: 0.6692 - stops_accuracy: 0.6971 - val_loss: 3.0164 - val_starts_loss: 1.5223 - val_stops_loss: 1.5281 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6247\n",
      "Epoch 411/1000\n",
      "20803/20803 [==============================] - 13s 618us/sample - loss: 2.0397 - starts_loss: 1.0309 - stops_loss: 1.0073 - starts_accuracy: 0.6703 - stops_accuracy: 0.6970 - val_loss: 3.0160 - val_starts_loss: 1.5223 - val_stops_loss: 1.5277 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6245\n",
      "Epoch 412/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0415 - starts_loss: 1.0325 - stops_loss: 1.0102 - starts_accuracy: 0.6671 - stops_accuracy: 0.7004 - val_loss: 3.0142 - val_starts_loss: 1.5221 - val_stops_loss: 1.5263 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6247\n",
      "Epoch 413/1000\n",
      "20803/20803 [==============================] - 12s 601us/sample - loss: 2.0423 - starts_loss: 1.0343 - stops_loss: 1.0093 - starts_accuracy: 0.6680 - stops_accuracy: 0.7001 - val_loss: 3.0140 - val_starts_loss: 1.5219 - val_stops_loss: 1.5263 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6247\n",
      "Epoch 414/1000\n",
      "20803/20803 [==============================] - 13s 622us/sample - loss: 2.0615 - starts_loss: 1.0362 - stops_loss: 1.0243 - starts_accuracy: 0.6685 - stops_accuracy: 0.6948 - val_loss: 3.0142 - val_starts_loss: 1.5219 - val_stops_loss: 1.5265 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6247\n",
      "Epoch 415/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0347 - starts_loss: 1.0298 - stops_loss: 1.0045 - starts_accuracy: 0.6711 - stops_accuracy: 0.7005 - val_loss: 3.0153 - val_starts_loss: 1.5218 - val_stops_loss: 1.5274 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6251\n",
      "Epoch 416/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0392 - starts_loss: 1.0301 - stops_loss: 1.0065 - starts_accuracy: 0.6690 - stops_accuracy: 0.6986 - val_loss: 3.0151 - val_starts_loss: 1.5218 - val_stops_loss: 1.5272 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 417/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0377 - starts_loss: 1.0264 - stops_loss: 1.0040 - starts_accuracy: 0.6724 - stops_accuracy: 0.6962 - val_loss: 3.0146 - val_starts_loss: 1.5222 - val_stops_loss: 1.5266 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6247\n",
      "Epoch 418/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0474 - starts_loss: 1.0300 - stops_loss: 1.0156 - starts_accuracy: 0.6680 - stops_accuracy: 0.6980 - val_loss: 3.0156 - val_starts_loss: 1.5223 - val_stops_loss: 1.5273 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6247\n",
      "Epoch 419/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.0390 - starts_loss: 1.0234 - stops_loss: 1.0123 - starts_accuracy: 0.6723 - stops_accuracy: 0.6960 - val_loss: 3.0167 - val_starts_loss: 1.5222 - val_stops_loss: 1.5284 - val_starts_accuracy: 0.6141 - val_stops_accuracy: 0.6251\n",
      "Epoch 420/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.0473 - starts_loss: 1.0341 - stops_loss: 1.0191 - starts_accuracy: 0.6682 - stops_accuracy: 0.6960 - val_loss: 3.0160 - val_starts_loss: 1.5225 - val_stops_loss: 1.5276 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6247\n",
      "Epoch 421/1000\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 2.0468 - starts_loss: 1.0323 - stops_loss: 1.0200 - starts_accuracy: 0.6713 - stops_accuracy: 0.6961 - val_loss: 3.0158 - val_starts_loss: 1.5228 - val_stops_loss: 1.5272 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6245\n",
      "Epoch 422/1000\n",
      "20803/20803 [==============================] - 12s 592us/sample - loss: 2.0542 - starts_loss: 1.0326 - stops_loss: 1.0214 - starts_accuracy: 0.6715 - stops_accuracy: 0.6962 - val_loss: 3.0170 - val_starts_loss: 1.5230 - val_stops_loss: 1.5279 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6245\n",
      "Epoch 423/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0537 - starts_loss: 1.0403 - stops_loss: 1.0162 - starts_accuracy: 0.6681 - stops_accuracy: 0.6987 - val_loss: 3.0157 - val_starts_loss: 1.5230 - val_stops_loss: 1.5268 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6247\n",
      "Epoch 424/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0418 - starts_loss: 1.0380 - stops_loss: 1.0066 - starts_accuracy: 0.6686 - stops_accuracy: 0.6993 - val_loss: 3.0141 - val_starts_loss: 1.5226 - val_stops_loss: 1.5257 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6247\n",
      "Epoch 425/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0405 - starts_loss: 1.0274 - stops_loss: 1.0095 - starts_accuracy: 0.6729 - stops_accuracy: 0.6966 - val_loss: 3.0130 - val_starts_loss: 1.5225 - val_stops_loss: 1.5251 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6245\n",
      "Epoch 426/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0435 - starts_loss: 1.0316 - stops_loss: 1.0132 - starts_accuracy: 0.6680 - stops_accuracy: 0.6985 - val_loss: 3.0152 - val_starts_loss: 1.5229 - val_stops_loss: 1.5265 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6247\n",
      "Epoch 427/1000\n",
      "20803/20803 [==============================] - 12s 590us/sample - loss: 2.0316 - starts_loss: 1.0281 - stops_loss: 1.0022 - starts_accuracy: 0.6703 - stops_accuracy: 0.7006 - val_loss: 3.0155 - val_starts_loss: 1.5229 - val_stops_loss: 1.5269 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6245\n",
      "Epoch 428/1000\n",
      "20803/20803 [==============================] - 12s 590us/sample - loss: 2.0419 - starts_loss: 1.0357 - stops_loss: 1.0139 - starts_accuracy: 0.6701 - stops_accuracy: 0.6985 - val_loss: 3.0166 - val_starts_loss: 1.5231 - val_stops_loss: 1.5276 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6245\n",
      "Epoch 429/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.0481 - starts_loss: 1.0380 - stops_loss: 1.0047 - starts_accuracy: 0.6693 - stops_accuracy: 0.6996 - val_loss: 3.0171 - val_starts_loss: 1.5233 - val_stops_loss: 1.5279 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6247\n",
      "Epoch 430/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.0273 - starts_loss: 1.0365 - stops_loss: 1.0018 - starts_accuracy: 0.6694 - stops_accuracy: 0.6987 - val_loss: 3.0174 - val_starts_loss: 1.5233 - val_stops_loss: 1.5281 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6245\n",
      "Epoch 431/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0379 - starts_loss: 1.0302 - stops_loss: 1.0062 - starts_accuracy: 0.6692 - stops_accuracy: 0.6992 - val_loss: 3.0168 - val_starts_loss: 1.5231 - val_stops_loss: 1.5279 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6247\n",
      "Epoch 432/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0437 - starts_loss: 1.0270 - stops_loss: 1.0188 - starts_accuracy: 0.6682 - stops_accuracy: 0.6986 - val_loss: 3.0159 - val_starts_loss: 1.5225 - val_stops_loss: 1.5276 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6247\n",
      "Epoch 433/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0254 - starts_loss: 1.0303 - stops_loss: 0.9937 - starts_accuracy: 0.6707 - stops_accuracy: 0.7001 - val_loss: 3.0162 - val_starts_loss: 1.5226 - val_stops_loss: 1.5278 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6245\n",
      "Epoch 434/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0387 - starts_loss: 1.0270 - stops_loss: 1.0133 - starts_accuracy: 0.6713 - stops_accuracy: 0.6994 - val_loss: 3.0173 - val_starts_loss: 1.5226 - val_stops_loss: 1.5286 - val_starts_accuracy: 0.6141 - val_stops_accuracy: 0.6245\n",
      "Epoch 435/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0389 - starts_loss: 1.0336 - stops_loss: 1.0086 - starts_accuracy: 0.6718 - stops_accuracy: 0.6989 - val_loss: 3.0167 - val_starts_loss: 1.5227 - val_stops_loss: 1.5281 - val_starts_accuracy: 0.6141 - val_stops_accuracy: 0.6247\n",
      "Epoch 436/1000\n",
      "20803/20803 [==============================] - 13s 619us/sample - loss: 2.0375 - starts_loss: 1.0281 - stops_loss: 1.0117 - starts_accuracy: 0.6737 - stops_accuracy: 0.6985 - val_loss: 3.0164 - val_starts_loss: 1.5227 - val_stops_loss: 1.5278 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6245\n",
      "Epoch 437/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0259 - starts_loss: 1.0211 - stops_loss: 1.0062 - starts_accuracy: 0.6701 - stops_accuracy: 0.6999 - val_loss: 3.0165 - val_starts_loss: 1.5229 - val_stops_loss: 1.5277 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6247\n",
      "Epoch 438/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0320 - starts_loss: 1.0330 - stops_loss: 1.0055 - starts_accuracy: 0.6714 - stops_accuracy: 0.6986 - val_loss: 3.0173 - val_starts_loss: 1.5232 - val_stops_loss: 1.5281 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6247\n",
      "Epoch 439/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0432 - starts_loss: 1.0306 - stops_loss: 1.0139 - starts_accuracy: 0.6700 - stops_accuracy: 0.6982 - val_loss: 3.0179 - val_starts_loss: 1.5233 - val_stops_loss: 1.5285 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6245\n",
      "Epoch 440/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0500 - starts_loss: 1.0317 - stops_loss: 1.0140 - starts_accuracy: 0.6673 - stops_accuracy: 0.6987 - val_loss: 3.0189 - val_starts_loss: 1.5239 - val_stops_loss: 1.5288 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6247\n",
      "Epoch 441/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0387 - starts_loss: 1.0333 - stops_loss: 1.0098 - starts_accuracy: 0.6700 - stops_accuracy: 0.7007 - val_loss: 3.0188 - val_starts_loss: 1.5238 - val_stops_loss: 1.5288 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6245\n",
      "Epoch 442/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0338 - starts_loss: 1.0302 - stops_loss: 1.0031 - starts_accuracy: 0.6710 - stops_accuracy: 0.6993 - val_loss: 3.0178 - val_starts_loss: 1.5234 - val_stops_loss: 1.5283 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 443/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 2.0382 - starts_loss: 1.0293 - stops_loss: 1.0089 - starts_accuracy: 0.6696 - stops_accuracy: 0.6972 - val_loss: 3.0170 - val_starts_loss: 1.5236 - val_stops_loss: 1.5276 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6247\n",
      "Epoch 444/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0433 - starts_loss: 1.0336 - stops_loss: 1.0217 - starts_accuracy: 0.6691 - stops_accuracy: 0.6962 - val_loss: 3.0183 - val_starts_loss: 1.5238 - val_stops_loss: 1.5284 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6247\n",
      "Epoch 445/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0404 - starts_loss: 1.0318 - stops_loss: 1.0146 - starts_accuracy: 0.6692 - stops_accuracy: 0.6977 - val_loss: 3.0199 - val_starts_loss: 1.5238 - val_stops_loss: 1.5298 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6247\n",
      "Epoch 446/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0450 - starts_loss: 1.0337 - stops_loss: 1.0072 - starts_accuracy: 0.6693 - stops_accuracy: 0.6941 - val_loss: 3.0190 - val_starts_loss: 1.5236 - val_stops_loss: 1.5292 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6247\n",
      "Epoch 447/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0428 - starts_loss: 1.0394 - stops_loss: 1.0098 - starts_accuracy: 0.6656 - stops_accuracy: 0.6991 - val_loss: 3.0194 - val_starts_loss: 1.5237 - val_stops_loss: 1.5295 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6247\n",
      "Epoch 448/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0343 - starts_loss: 1.0325 - stops_loss: 1.0009 - starts_accuracy: 0.6681 - stops_accuracy: 0.6984 - val_loss: 3.0188 - val_starts_loss: 1.5236 - val_stops_loss: 1.5290 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6249\n",
      "Epoch 449/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0337 - starts_loss: 1.0294 - stops_loss: 1.0064 - starts_accuracy: 0.6715 - stops_accuracy: 0.6978 - val_loss: 3.0186 - val_starts_loss: 1.5237 - val_stops_loss: 1.5288 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6249\n",
      "Epoch 450/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0450 - starts_loss: 1.0350 - stops_loss: 1.0080 - starts_accuracy: 0.6692 - stops_accuracy: 0.6991 - val_loss: 3.0187 - val_starts_loss: 1.5241 - val_stops_loss: 1.5286 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6251\n",
      "Epoch 451/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0346 - starts_loss: 1.0304 - stops_loss: 1.0046 - starts_accuracy: 0.6703 - stops_accuracy: 0.6983 - val_loss: 3.0177 - val_starts_loss: 1.5241 - val_stops_loss: 1.5278 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6251\n",
      "Epoch 452/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0369 - starts_loss: 1.0322 - stops_loss: 1.0104 - starts_accuracy: 0.6698 - stops_accuracy: 0.7010 - val_loss: 3.0168 - val_starts_loss: 1.5240 - val_stops_loss: 1.5271 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6253\n",
      "Epoch 453/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0449 - starts_loss: 1.0375 - stops_loss: 1.0129 - starts_accuracy: 0.6695 - stops_accuracy: 0.6988 - val_loss: 3.0175 - val_starts_loss: 1.5239 - val_stops_loss: 1.5277 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6251\n",
      "Epoch 454/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.0289 - starts_loss: 1.0208 - stops_loss: 1.0070 - starts_accuracy: 0.6720 - stops_accuracy: 0.6982 - val_loss: 3.0178 - val_starts_loss: 1.5236 - val_stops_loss: 1.5282 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6249\n",
      "Epoch 455/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0405 - starts_loss: 1.0417 - stops_loss: 1.0104 - starts_accuracy: 0.6672 - stops_accuracy: 0.6989 - val_loss: 3.0191 - val_starts_loss: 1.5236 - val_stops_loss: 1.5293 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6245\n",
      "Epoch 456/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0325 - starts_loss: 1.0312 - stops_loss: 1.0037 - starts_accuracy: 0.6742 - stops_accuracy: 0.6970 - val_loss: 3.0180 - val_starts_loss: 1.5236 - val_stops_loss: 1.5285 - val_starts_accuracy: 0.6132 - val_stops_accuracy: 0.6245\n",
      "Epoch 457/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0453 - starts_loss: 1.0324 - stops_loss: 1.0140 - starts_accuracy: 0.6684 - stops_accuracy: 0.6971 - val_loss: 3.0172 - val_starts_loss: 1.5235 - val_stops_loss: 1.5278 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6247\n",
      "Epoch 458/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 2.0366 - starts_loss: 1.0320 - stops_loss: 1.0021 - starts_accuracy: 0.6684 - stops_accuracy: 0.6976 - val_loss: 3.0172 - val_starts_loss: 1.5234 - val_stops_loss: 1.5281 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6245\n",
      "Epoch 459/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0404 - starts_loss: 1.0284 - stops_loss: 1.0081 - starts_accuracy: 0.6696 - stops_accuracy: 0.6994 - val_loss: 3.0162 - val_starts_loss: 1.5230 - val_stops_loss: 1.5275 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6247\n",
      "Epoch 460/1000\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 2.0336 - starts_loss: 1.0344 - stops_loss: 0.9979 - starts_accuracy: 0.6663 - stops_accuracy: 0.6986 - val_loss: 3.0174 - val_starts_loss: 1.5230 - val_stops_loss: 1.5286 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6249\n",
      "Epoch 461/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 2.0307 - starts_loss: 1.0369 - stops_loss: 1.0010 - starts_accuracy: 0.6695 - stops_accuracy: 0.6992 - val_loss: 3.0190 - val_starts_loss: 1.5232 - val_stops_loss: 1.5297 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6251\n",
      "Epoch 462/1000\n",
      "20803/20803 [==============================] - 12s 591us/sample - loss: 2.0442 - starts_loss: 1.0310 - stops_loss: 1.0109 - starts_accuracy: 0.6666 - stops_accuracy: 0.6969 - val_loss: 3.0190 - val_starts_loss: 1.5232 - val_stops_loss: 1.5297 - val_starts_accuracy: 0.6143 - val_stops_accuracy: 0.6247\n",
      "Epoch 463/1000\n",
      "20803/20803 [==============================] - 12s 601us/sample - loss: 2.0521 - starts_loss: 1.0408 - stops_loss: 1.0136 - starts_accuracy: 0.6696 - stops_accuracy: 0.6974 - val_loss: 3.0175 - val_starts_loss: 1.5230 - val_stops_loss: 1.5285 - val_starts_accuracy: 0.6133 - val_stops_accuracy: 0.6247\n",
      "Epoch 464/1000\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 2.0302 - starts_loss: 1.0274 - stops_loss: 0.9990 - starts_accuracy: 0.6674 - stops_accuracy: 0.7011 - val_loss: 3.0171 - val_starts_loss: 1.5229 - val_stops_loss: 1.5282 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6247\n",
      "Epoch 465/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0369 - starts_loss: 1.0278 - stops_loss: 1.0041 - starts_accuracy: 0.6713 - stops_accuracy: 0.7020 - val_loss: 3.0174 - val_starts_loss: 1.5231 - val_stops_loss: 1.5285 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6251\n",
      "Epoch 466/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.0490 - starts_loss: 1.0343 - stops_loss: 1.0099 - starts_accuracy: 0.6687 - stops_accuracy: 0.6968 - val_loss: 3.0171 - val_starts_loss: 1.5236 - val_stops_loss: 1.5278 - val_starts_accuracy: 0.6143 - val_stops_accuracy: 0.6253\n",
      "Epoch 467/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0196 - starts_loss: 1.0280 - stops_loss: 0.9932 - starts_accuracy: 0.6717 - stops_accuracy: 0.7031 - val_loss: 3.0174 - val_starts_loss: 1.5239 - val_stops_loss: 1.5278 - val_starts_accuracy: 0.6141 - val_stops_accuracy: 0.6253\n",
      "Epoch 468/1000\n",
      "20803/20803 [==============================] - 12s 593us/sample - loss: 2.0466 - starts_loss: 1.0345 - stops_loss: 1.0081 - starts_accuracy: 0.6703 - stops_accuracy: 0.6969 - val_loss: 3.0186 - val_starts_loss: 1.5240 - val_stops_loss: 1.5287 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0340 - starts_loss: 1.0288 - stops_loss: 1.0054 - starts_accuracy: 0.6677 - stops_accuracy: 0.7034 - val_loss: 3.0182 - val_starts_loss: 1.5240 - val_stops_loss: 1.5284 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6251\n",
      "Epoch 470/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0402 - starts_loss: 1.0296 - stops_loss: 1.0114 - starts_accuracy: 0.6704 - stops_accuracy: 0.7014 - val_loss: 3.0189 - val_starts_loss: 1.5242 - val_stops_loss: 1.5289 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6247\n",
      "Epoch 471/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0244 - starts_loss: 1.0255 - stops_loss: 0.9984 - starts_accuracy: 0.6708 - stops_accuracy: 0.7021 - val_loss: 3.0187 - val_starts_loss: 1.5242 - val_stops_loss: 1.5288 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6251\n",
      "Epoch 472/1000\n",
      "20803/20803 [==============================] - 13s 618us/sample - loss: 2.0336 - starts_loss: 1.0283 - stops_loss: 1.0123 - starts_accuracy: 0.6740 - stops_accuracy: 0.6976 - val_loss: 3.0198 - val_starts_loss: 1.5242 - val_stops_loss: 1.5298 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6253\n",
      "Epoch 473/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0303 - starts_loss: 1.0277 - stops_loss: 1.0031 - starts_accuracy: 0.6719 - stops_accuracy: 0.6954 - val_loss: 3.0184 - val_starts_loss: 1.5239 - val_stops_loss: 1.5288 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6253\n",
      "Epoch 474/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.0428 - starts_loss: 1.0308 - stops_loss: 1.0074 - starts_accuracy: 0.6658 - stops_accuracy: 0.6976 - val_loss: 3.0193 - val_starts_loss: 1.5241 - val_stops_loss: 1.5295 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6251\n",
      "Epoch 475/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 2.0287 - starts_loss: 1.0187 - stops_loss: 1.0045 - starts_accuracy: 0.6726 - stops_accuracy: 0.6961 - val_loss: 3.0204 - val_starts_loss: 1.5241 - val_stops_loss: 1.5303 - val_starts_accuracy: 0.6143 - val_stops_accuracy: 0.6251\n",
      "Epoch 476/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0446 - starts_loss: 1.0386 - stops_loss: 1.0057 - starts_accuracy: 0.6666 - stops_accuracy: 0.6986 - val_loss: 3.0209 - val_starts_loss: 1.5244 - val_stops_loss: 1.5306 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6249\n",
      "Epoch 477/1000\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 2.0471 - starts_loss: 1.0304 - stops_loss: 1.0146 - starts_accuracy: 0.6679 - stops_accuracy: 0.6967 - val_loss: 3.0207 - val_starts_loss: 1.5247 - val_stops_loss: 1.5302 - val_starts_accuracy: 0.6143 - val_stops_accuracy: 0.6251\n",
      "Epoch 478/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0286 - starts_loss: 1.0315 - stops_loss: 1.0000 - starts_accuracy: 0.6700 - stops_accuracy: 0.7018 - val_loss: 3.0210 - val_starts_loss: 1.5251 - val_stops_loss: 1.5301 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6247\n",
      "Epoch 479/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0369 - starts_loss: 1.0348 - stops_loss: 1.0061 - starts_accuracy: 0.6696 - stops_accuracy: 0.7029 - val_loss: 3.0209 - val_starts_loss: 1.5250 - val_stops_loss: 1.5302 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6253\n",
      "Epoch 480/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0347 - starts_loss: 1.0318 - stops_loss: 1.0058 - starts_accuracy: 0.6685 - stops_accuracy: 0.6986 - val_loss: 3.0197 - val_starts_loss: 1.5245 - val_stops_loss: 1.5295 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6253\n",
      "Epoch 481/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0411 - starts_loss: 1.0321 - stops_loss: 1.0055 - starts_accuracy: 0.6712 - stops_accuracy: 0.6980 - val_loss: 3.0210 - val_starts_loss: 1.5246 - val_stops_loss: 1.5304 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6253\n",
      "Epoch 482/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0367 - starts_loss: 1.0286 - stops_loss: 1.0129 - starts_accuracy: 0.6699 - stops_accuracy: 0.6975 - val_loss: 3.0203 - val_starts_loss: 1.5243 - val_stops_loss: 1.5301 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6249\n",
      "Epoch 483/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0409 - starts_loss: 1.0331 - stops_loss: 1.0079 - starts_accuracy: 0.6688 - stops_accuracy: 0.6989 - val_loss: 3.0200 - val_starts_loss: 1.5243 - val_stops_loss: 1.5297 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6247\n",
      "Epoch 484/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0568 - starts_loss: 1.0402 - stops_loss: 1.0200 - starts_accuracy: 0.6691 - stops_accuracy: 0.6997 - val_loss: 3.0195 - val_starts_loss: 1.5241 - val_stops_loss: 1.5295 - val_starts_accuracy: 0.6135 - val_stops_accuracy: 0.6245\n",
      "Epoch 485/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0375 - starts_loss: 1.0277 - stops_loss: 1.0097 - starts_accuracy: 0.6733 - stops_accuracy: 0.6977 - val_loss: 3.0187 - val_starts_loss: 1.5240 - val_stops_loss: 1.5289 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6247\n",
      "Epoch 486/1000\n",
      "20803/20803 [==============================] - 12s 595us/sample - loss: 2.0259 - starts_loss: 1.0218 - stops_loss: 1.0022 - starts_accuracy: 0.6737 - stops_accuracy: 0.6977 - val_loss: 3.0200 - val_starts_loss: 1.5239 - val_stops_loss: 1.5301 - val_starts_accuracy: 0.6141 - val_stops_accuracy: 0.6249\n",
      "Epoch 487/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0291 - starts_loss: 1.0281 - stops_loss: 1.0019 - starts_accuracy: 0.6710 - stops_accuracy: 0.7020 - val_loss: 3.0196 - val_starts_loss: 1.5240 - val_stops_loss: 1.5298 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6249\n",
      "Epoch 488/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0350 - starts_loss: 1.0340 - stops_loss: 1.0031 - starts_accuracy: 0.6696 - stops_accuracy: 0.6991 - val_loss: 3.0206 - val_starts_loss: 1.5240 - val_stops_loss: 1.5306 - val_starts_accuracy: 0.6143 - val_stops_accuracy: 0.6251\n",
      "Epoch 489/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0213 - starts_loss: 1.0262 - stops_loss: 0.9975 - starts_accuracy: 0.6730 - stops_accuracy: 0.6991 - val_loss: 3.0208 - val_starts_loss: 1.5242 - val_stops_loss: 1.5306 - val_starts_accuracy: 0.6141 - val_stops_accuracy: 0.6251\n",
      "Epoch 490/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0359 - starts_loss: 1.0247 - stops_loss: 1.0057 - starts_accuracy: 0.6691 - stops_accuracy: 0.6999 - val_loss: 3.0211 - val_starts_loss: 1.5242 - val_stops_loss: 1.5309 - val_starts_accuracy: 0.6141 - val_stops_accuracy: 0.6247\n",
      "Epoch 491/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0353 - starts_loss: 1.0281 - stops_loss: 1.0058 - starts_accuracy: 0.6727 - stops_accuracy: 0.6969 - val_loss: 3.0207 - val_starts_loss: 1.5243 - val_stops_loss: 1.5304 - val_starts_accuracy: 0.6141 - val_stops_accuracy: 0.6247\n",
      "Epoch 492/1000\n",
      "20803/20803 [==============================] - 12s 595us/sample - loss: 2.0377 - starts_loss: 1.0234 - stops_loss: 1.0078 - starts_accuracy: 0.6730 - stops_accuracy: 0.6937 - val_loss: 3.0199 - val_starts_loss: 1.5245 - val_stops_loss: 1.5297 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6251\n",
      "Epoch 493/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0299 - starts_loss: 1.0349 - stops_loss: 1.0011 - starts_accuracy: 0.6710 - stops_accuracy: 0.7024 - val_loss: 3.0192 - val_starts_loss: 1.5248 - val_stops_loss: 1.5289 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6255\n",
      "Epoch 494/1000\n",
      "20803/20803 [==============================] - 12s 587us/sample - loss: 2.0337 - starts_loss: 1.0314 - stops_loss: 1.0063 - starts_accuracy: 0.6722 - stops_accuracy: 0.6985 - val_loss: 3.0191 - val_starts_loss: 1.5246 - val_stops_loss: 1.5289 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0427 - starts_loss: 1.0316 - stops_loss: 1.0106 - starts_accuracy: 0.6702 - stops_accuracy: 0.6971 - val_loss: 3.0201 - val_starts_loss: 1.5247 - val_stops_loss: 1.5299 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6247\n",
      "Epoch 496/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0438 - starts_loss: 1.0304 - stops_loss: 1.0153 - starts_accuracy: 0.6726 - stops_accuracy: 0.6973 - val_loss: 3.0191 - val_starts_loss: 1.5246 - val_stops_loss: 1.5292 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6251\n",
      "Epoch 497/1000\n",
      "20803/20803 [==============================] - 12s 601us/sample - loss: 2.0274 - starts_loss: 1.0332 - stops_loss: 1.0002 - starts_accuracy: 0.6692 - stops_accuracy: 0.7041 - val_loss: 3.0204 - val_starts_loss: 1.5245 - val_stops_loss: 1.5303 - val_starts_accuracy: 0.6143 - val_stops_accuracy: 0.6247\n",
      "Epoch 498/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0413 - starts_loss: 1.0277 - stops_loss: 1.0100 - starts_accuracy: 0.6704 - stops_accuracy: 0.6993 - val_loss: 3.0204 - val_starts_loss: 1.5244 - val_stops_loss: 1.5304 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6245\n",
      "Epoch 499/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0403 - starts_loss: 1.0336 - stops_loss: 1.0062 - starts_accuracy: 0.6702 - stops_accuracy: 0.6991 - val_loss: 3.0217 - val_starts_loss: 1.5244 - val_stops_loss: 1.5314 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6247\n",
      "Epoch 500/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.0315 - starts_loss: 1.0280 - stops_loss: 1.0007 - starts_accuracy: 0.6710 - stops_accuracy: 0.7014 - val_loss: 3.0222 - val_starts_loss: 1.5249 - val_stops_loss: 1.5315 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6243\n",
      "Epoch 501/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0380 - starts_loss: 1.0282 - stops_loss: 1.0095 - starts_accuracy: 0.6719 - stops_accuracy: 0.6969 - val_loss: 3.0217 - val_starts_loss: 1.5247 - val_stops_loss: 1.5313 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6247\n",
      "Epoch 502/1000\n",
      "20803/20803 [==============================] - 13s 617us/sample - loss: 2.0231 - starts_loss: 1.0287 - stops_loss: 0.9990 - starts_accuracy: 0.6721 - stops_accuracy: 0.7023 - val_loss: 3.0225 - val_starts_loss: 1.5250 - val_stops_loss: 1.5317 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6247\n",
      "Epoch 503/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0309 - starts_loss: 1.0252 - stops_loss: 1.0056 - starts_accuracy: 0.6732 - stops_accuracy: 0.6977 - val_loss: 3.0213 - val_starts_loss: 1.5250 - val_stops_loss: 1.5307 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6247\n",
      "Epoch 504/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.0305 - starts_loss: 1.0329 - stops_loss: 1.0058 - starts_accuracy: 0.6727 - stops_accuracy: 0.6976 - val_loss: 3.0180 - val_starts_loss: 1.5245 - val_stops_loss: 1.5283 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6251\n",
      "Epoch 505/1000\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 2.0264 - starts_loss: 1.0215 - stops_loss: 1.0052 - starts_accuracy: 0.6704 - stops_accuracy: 0.7013 - val_loss: 3.0189 - val_starts_loss: 1.5249 - val_stops_loss: 1.5289 - val_starts_accuracy: 0.6137 - val_stops_accuracy: 0.6249\n",
      "Epoch 506/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0365 - starts_loss: 1.0286 - stops_loss: 1.0142 - starts_accuracy: 0.6699 - stops_accuracy: 0.6975 - val_loss: 3.0191 - val_starts_loss: 1.5249 - val_stops_loss: 1.5289 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6249\n",
      "Epoch 507/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0438 - starts_loss: 1.0323 - stops_loss: 1.0086 - starts_accuracy: 0.6700 - stops_accuracy: 0.6960 - val_loss: 3.0195 - val_starts_loss: 1.5247 - val_stops_loss: 1.5294 - val_starts_accuracy: 0.6141 - val_stops_accuracy: 0.6243\n",
      "Epoch 508/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.0401 - starts_loss: 1.0291 - stops_loss: 1.0059 - starts_accuracy: 0.6712 - stops_accuracy: 0.6979 - val_loss: 3.0193 - val_starts_loss: 1.5248 - val_stops_loss: 1.5294 - val_starts_accuracy: 0.6141 - val_stops_accuracy: 0.6243\n",
      "Epoch 509/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.0358 - starts_loss: 1.0300 - stops_loss: 1.0063 - starts_accuracy: 0.6703 - stops_accuracy: 0.6996 - val_loss: 3.0190 - val_starts_loss: 1.5248 - val_stops_loss: 1.5290 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6249\n",
      "Epoch 510/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0363 - starts_loss: 1.0298 - stops_loss: 1.0093 - starts_accuracy: 0.6713 - stops_accuracy: 0.6975 - val_loss: 3.0200 - val_starts_loss: 1.5251 - val_stops_loss: 1.5296 - val_starts_accuracy: 0.6139 - val_stops_accuracy: 0.6245\n",
      "Epoch 511/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0254 - starts_loss: 1.0248 - stops_loss: 0.9960 - starts_accuracy: 0.6718 - stops_accuracy: 0.7010 - val_loss: 3.0206 - val_starts_loss: 1.5252 - val_stops_loss: 1.5301 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6247\n",
      "Epoch 512/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0318 - starts_loss: 1.0250 - stops_loss: 1.0066 - starts_accuracy: 0.6712 - stops_accuracy: 0.6989 - val_loss: 3.0205 - val_starts_loss: 1.5251 - val_stops_loss: 1.5300 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6247\n",
      "Epoch 513/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0292 - starts_loss: 1.0252 - stops_loss: 1.0027 - starts_accuracy: 0.6713 - stops_accuracy: 0.7000 - val_loss: 3.0212 - val_starts_loss: 1.5253 - val_stops_loss: 1.5305 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6247\n",
      "Epoch 514/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0342 - starts_loss: 1.0251 - stops_loss: 1.0055 - starts_accuracy: 0.6730 - stops_accuracy: 0.6998 - val_loss: 3.0211 - val_starts_loss: 1.5251 - val_stops_loss: 1.5305 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6249\n",
      "Epoch 515/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0298 - starts_loss: 1.0226 - stops_loss: 1.0028 - starts_accuracy: 0.6697 - stops_accuracy: 0.7015 - val_loss: 3.0205 - val_starts_loss: 1.5253 - val_stops_loss: 1.5299 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6245\n",
      "Epoch 516/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 2.0309 - starts_loss: 1.0277 - stops_loss: 1.0053 - starts_accuracy: 0.6702 - stops_accuracy: 0.7024 - val_loss: 3.0219 - val_starts_loss: 1.5255 - val_stops_loss: 1.5308 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6243\n",
      "Epoch 517/1000\n",
      "20803/20803 [==============================] - 12s 591us/sample - loss: 2.0412 - starts_loss: 1.0308 - stops_loss: 1.0073 - starts_accuracy: 0.6689 - stops_accuracy: 0.6991 - val_loss: 3.0215 - val_starts_loss: 1.5255 - val_stops_loss: 1.5305 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6245\n",
      "Epoch 518/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0266 - starts_loss: 1.0278 - stops_loss: 1.0039 - starts_accuracy: 0.6703 - stops_accuracy: 0.7024 - val_loss: 3.0220 - val_starts_loss: 1.5257 - val_stops_loss: 1.5306 - val_starts_accuracy: 0.6143 - val_stops_accuracy: 0.6243\n",
      "Epoch 519/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0297 - starts_loss: 1.0298 - stops_loss: 1.0052 - starts_accuracy: 0.6696 - stops_accuracy: 0.6996 - val_loss: 3.0221 - val_starts_loss: 1.5257 - val_stops_loss: 1.5308 - val_starts_accuracy: 0.6141 - val_stops_accuracy: 0.6243\n",
      "Epoch 520/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0399 - starts_loss: 1.0311 - stops_loss: 1.0118 - starts_accuracy: 0.6692 - stops_accuracy: 0.6949 - val_loss: 3.0216 - val_starts_loss: 1.5260 - val_stops_loss: 1.5301 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 521/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0304 - starts_loss: 1.0207 - stops_loss: 1.0105 - starts_accuracy: 0.6734 - stops_accuracy: 0.6974 - val_loss: 3.0226 - val_starts_loss: 1.5253 - val_stops_loss: 1.5314 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6241\n",
      "Epoch 522/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 2.0290 - starts_loss: 1.0245 - stops_loss: 1.0008 - starts_accuracy: 0.6724 - stops_accuracy: 0.7000 - val_loss: 3.0248 - val_starts_loss: 1.5256 - val_stops_loss: 1.5331 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6245\n",
      "Epoch 523/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0448 - starts_loss: 1.0311 - stops_loss: 1.0139 - starts_accuracy: 0.6682 - stops_accuracy: 0.6947 - val_loss: 3.0235 - val_starts_loss: 1.5256 - val_stops_loss: 1.5321 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6243\n",
      "Epoch 524/1000\n",
      "20803/20803 [==============================] - 12s 592us/sample - loss: 2.0236 - starts_loss: 1.0289 - stops_loss: 0.9965 - starts_accuracy: 0.6690 - stops_accuracy: 0.6999 - val_loss: 3.0226 - val_starts_loss: 1.5258 - val_stops_loss: 1.5314 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6245\n",
      "Epoch 525/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0379 - starts_loss: 1.0288 - stops_loss: 1.0124 - starts_accuracy: 0.6718 - stops_accuracy: 0.6979 - val_loss: 3.0213 - val_starts_loss: 1.5257 - val_stops_loss: 1.5303 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6247\n",
      "Epoch 526/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.0226 - starts_loss: 1.0288 - stops_loss: 0.9928 - starts_accuracy: 0.6712 - stops_accuracy: 0.7044 - val_loss: 3.0218 - val_starts_loss: 1.5259 - val_stops_loss: 1.5307 - val_starts_accuracy: 0.6143 - val_stops_accuracy: 0.6249\n",
      "Epoch 527/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0225 - starts_loss: 1.0260 - stops_loss: 1.0020 - starts_accuracy: 0.6709 - stops_accuracy: 0.6988 - val_loss: 3.0219 - val_starts_loss: 1.5259 - val_stops_loss: 1.5307 - val_starts_accuracy: 0.6143 - val_stops_accuracy: 0.6247\n",
      "Epoch 528/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 2.0243 - starts_loss: 1.0207 - stops_loss: 1.0043 - starts_accuracy: 0.6747 - stops_accuracy: 0.7004 - val_loss: 3.0232 - val_starts_loss: 1.5261 - val_stops_loss: 1.5317 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6241\n",
      "Epoch 529/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0241 - starts_loss: 1.0212 - stops_loss: 1.0065 - starts_accuracy: 0.6731 - stops_accuracy: 0.7024 - val_loss: 3.0228 - val_starts_loss: 1.5261 - val_stops_loss: 1.5314 - val_starts_accuracy: 0.6143 - val_stops_accuracy: 0.6247\n",
      "Epoch 530/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0336 - starts_loss: 1.0305 - stops_loss: 1.0098 - starts_accuracy: 0.6737 - stops_accuracy: 0.7003 - val_loss: 3.0229 - val_starts_loss: 1.5261 - val_stops_loss: 1.5316 - val_starts_accuracy: 0.6143 - val_stops_accuracy: 0.6243\n",
      "Epoch 531/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0243 - starts_loss: 1.0297 - stops_loss: 1.0017 - starts_accuracy: 0.6674 - stops_accuracy: 0.7005 - val_loss: 3.0221 - val_starts_loss: 1.5257 - val_stops_loss: 1.5312 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6249\n",
      "Epoch 532/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0283 - starts_loss: 1.0256 - stops_loss: 1.0099 - starts_accuracy: 0.6724 - stops_accuracy: 0.7002 - val_loss: 3.0228 - val_starts_loss: 1.5260 - val_stops_loss: 1.5315 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6245\n",
      "Epoch 533/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0260 - starts_loss: 1.0192 - stops_loss: 1.0051 - starts_accuracy: 0.6747 - stops_accuracy: 0.6993 - val_loss: 3.0223 - val_starts_loss: 1.5259 - val_stops_loss: 1.5312 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6249\n",
      "Epoch 534/1000\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 2.0352 - starts_loss: 1.0329 - stops_loss: 1.0064 - starts_accuracy: 0.6706 - stops_accuracy: 0.7011 - val_loss: 3.0218 - val_starts_loss: 1.5258 - val_stops_loss: 1.5308 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6245\n",
      "Epoch 535/1000\n",
      "20803/20803 [==============================] - 12s 601us/sample - loss: 2.0266 - starts_loss: 1.0257 - stops_loss: 1.0025 - starts_accuracy: 0.6740 - stops_accuracy: 0.6996 - val_loss: 3.0224 - val_starts_loss: 1.5260 - val_stops_loss: 1.5311 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6245\n",
      "Epoch 536/1000\n",
      "20803/20803 [==============================] - 12s 595us/sample - loss: 2.0372 - starts_loss: 1.0298 - stops_loss: 1.0092 - starts_accuracy: 0.6700 - stops_accuracy: 0.6961 - val_loss: 3.0214 - val_starts_loss: 1.5257 - val_stops_loss: 1.5305 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6245\n",
      "Epoch 537/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0246 - starts_loss: 1.0211 - stops_loss: 0.9987 - starts_accuracy: 0.6715 - stops_accuracy: 0.7031 - val_loss: 3.0221 - val_starts_loss: 1.5256 - val_stops_loss: 1.5311 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6247\n",
      "Epoch 538/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0432 - starts_loss: 1.0299 - stops_loss: 1.0157 - starts_accuracy: 0.6712 - stops_accuracy: 0.6971 - val_loss: 3.0232 - val_starts_loss: 1.5255 - val_stops_loss: 1.5321 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6253\n",
      "Epoch 539/1000\n",
      "20803/20803 [==============================] - 15s 700us/sample - loss: 2.0256 - starts_loss: 1.0285 - stops_loss: 1.0008 - starts_accuracy: 0.6732 - stops_accuracy: 0.7017 - val_loss: 3.0240 - val_starts_loss: 1.5258 - val_stops_loss: 1.5325 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6249\n",
      "Epoch 540/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0229 - starts_loss: 1.0230 - stops_loss: 0.9989 - starts_accuracy: 0.6734 - stops_accuracy: 0.7019 - val_loss: 3.0239 - val_starts_loss: 1.5257 - val_stops_loss: 1.5326 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6249\n",
      "Epoch 541/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0381 - starts_loss: 1.0296 - stops_loss: 1.0192 - starts_accuracy: 0.6709 - stops_accuracy: 0.6978 - val_loss: 3.0248 - val_starts_loss: 1.5262 - val_stops_loss: 1.5329 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6247\n",
      "Epoch 542/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0171 - starts_loss: 1.0326 - stops_loss: 0.9844 - starts_accuracy: 0.6705 - stops_accuracy: 0.7026 - val_loss: 3.0260 - val_starts_loss: 1.5269 - val_stops_loss: 1.5335 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6245\n",
      "Epoch 543/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0332 - starts_loss: 1.0288 - stops_loss: 1.0012 - starts_accuracy: 0.6699 - stops_accuracy: 0.6990 - val_loss: 3.0254 - val_starts_loss: 1.5271 - val_stops_loss: 1.5328 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6245\n",
      "Epoch 544/1000\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 2.0316 - starts_loss: 1.0296 - stops_loss: 1.0051 - starts_accuracy: 0.6694 - stops_accuracy: 0.6968 - val_loss: 3.0218 - val_starts_loss: 1.5269 - val_stops_loss: 1.5300 - val_starts_accuracy: 0.6143 - val_stops_accuracy: 0.6251\n",
      "Epoch 545/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0294 - starts_loss: 1.0263 - stops_loss: 1.0019 - starts_accuracy: 0.6681 - stops_accuracy: 0.7000 - val_loss: 3.0193 - val_starts_loss: 1.5265 - val_stops_loss: 1.5281 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6249\n",
      "Epoch 546/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0204 - starts_loss: 1.0162 - stops_loss: 1.0009 - starts_accuracy: 0.6740 - stops_accuracy: 0.7010 - val_loss: 3.0196 - val_starts_loss: 1.5265 - val_stops_loss: 1.5284 - val_starts_accuracy: 0.6143 - val_stops_accuracy: 0.6253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 547/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0298 - starts_loss: 1.0224 - stops_loss: 1.0047 - starts_accuracy: 0.6728 - stops_accuracy: 0.6995 - val_loss: 3.0210 - val_starts_loss: 1.5261 - val_stops_loss: 1.5299 - val_starts_accuracy: 0.6143 - val_stops_accuracy: 0.6251\n",
      "Epoch 548/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0354 - starts_loss: 1.0222 - stops_loss: 1.0143 - starts_accuracy: 0.6724 - stops_accuracy: 0.7003 - val_loss: 3.0211 - val_starts_loss: 1.5260 - val_stops_loss: 1.5300 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6251\n",
      "Epoch 549/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0353 - starts_loss: 1.0279 - stops_loss: 1.0073 - starts_accuracy: 0.6712 - stops_accuracy: 0.6974 - val_loss: 3.0209 - val_starts_loss: 1.5257 - val_stops_loss: 1.5300 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6253\n",
      "Epoch 550/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0333 - starts_loss: 1.0296 - stops_loss: 1.0066 - starts_accuracy: 0.6693 - stops_accuracy: 0.7011 - val_loss: 3.0224 - val_starts_loss: 1.5259 - val_stops_loss: 1.5311 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6255\n",
      "Epoch 551/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0222 - starts_loss: 1.0300 - stops_loss: 0.9930 - starts_accuracy: 0.6705 - stops_accuracy: 0.6995 - val_loss: 3.0226 - val_starts_loss: 1.5259 - val_stops_loss: 1.5314 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6251\n",
      "Epoch 552/1000\n",
      "20803/20803 [==============================] - 12s 601us/sample - loss: 2.0267 - starts_loss: 1.0256 - stops_loss: 1.0055 - starts_accuracy: 0.6721 - stops_accuracy: 0.7002 - val_loss: 3.0222 - val_starts_loss: 1.5259 - val_stops_loss: 1.5310 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6253\n",
      "Epoch 553/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0316 - starts_loss: 1.0360 - stops_loss: 1.0008 - starts_accuracy: 0.6686 - stops_accuracy: 0.7006 - val_loss: 3.0214 - val_starts_loss: 1.5259 - val_stops_loss: 1.5304 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6253\n",
      "Epoch 554/1000\n",
      "20803/20803 [==============================] - 12s 590us/sample - loss: 2.0327 - starts_loss: 1.0231 - stops_loss: 1.0032 - starts_accuracy: 0.6723 - stops_accuracy: 0.6988 - val_loss: 3.0212 - val_starts_loss: 1.5259 - val_stops_loss: 1.5303 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6249\n",
      "Epoch 555/1000\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 2.0351 - starts_loss: 1.0289 - stops_loss: 1.0049 - starts_accuracy: 0.6725 - stops_accuracy: 0.6985 - val_loss: 3.0226 - val_starts_loss: 1.5259 - val_stops_loss: 1.5314 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6249\n",
      "Epoch 556/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0328 - starts_loss: 1.0247 - stops_loss: 1.0066 - starts_accuracy: 0.6730 - stops_accuracy: 0.6999 - val_loss: 3.0252 - val_starts_loss: 1.5262 - val_stops_loss: 1.5334 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6241\n",
      "Epoch 557/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0267 - starts_loss: 1.0257 - stops_loss: 1.0011 - starts_accuracy: 0.6739 - stops_accuracy: 0.7013 - val_loss: 3.0253 - val_starts_loss: 1.5259 - val_stops_loss: 1.5336 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6243\n",
      "Epoch 558/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0152 - starts_loss: 1.0202 - stops_loss: 0.9932 - starts_accuracy: 0.6716 - stops_accuracy: 0.7029 - val_loss: 3.0261 - val_starts_loss: 1.5262 - val_stops_loss: 1.5342 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6245\n",
      "Epoch 559/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0330 - starts_loss: 1.0331 - stops_loss: 1.0016 - starts_accuracy: 0.6694 - stops_accuracy: 0.6970 - val_loss: 3.0260 - val_starts_loss: 1.5266 - val_stops_loss: 1.5339 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6241\n",
      "Epoch 560/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 2.0143 - starts_loss: 1.0199 - stops_loss: 0.9932 - starts_accuracy: 0.6708 - stops_accuracy: 0.7012 - val_loss: 3.0245 - val_starts_loss: 1.5267 - val_stops_loss: 1.5326 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6243\n",
      "Epoch 561/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0222 - starts_loss: 1.0242 - stops_loss: 1.0020 - starts_accuracy: 0.6716 - stops_accuracy: 0.7011 - val_loss: 3.0240 - val_starts_loss: 1.5268 - val_stops_loss: 1.5320 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6247\n",
      "Epoch 562/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0397 - starts_loss: 1.0306 - stops_loss: 1.0090 - starts_accuracy: 0.6708 - stops_accuracy: 0.6986 - val_loss: 3.0225 - val_starts_loss: 1.5266 - val_stops_loss: 1.5310 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6249\n",
      "Epoch 563/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0333 - starts_loss: 1.0225 - stops_loss: 1.0045 - starts_accuracy: 0.6730 - stops_accuracy: 0.6992 - val_loss: 3.0239 - val_starts_loss: 1.5269 - val_stops_loss: 1.5318 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6249\n",
      "Epoch 564/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0275 - starts_loss: 1.0248 - stops_loss: 1.0060 - starts_accuracy: 0.6725 - stops_accuracy: 0.7001 - val_loss: 3.0240 - val_starts_loss: 1.5266 - val_stops_loss: 1.5320 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6245\n",
      "Epoch 565/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0325 - starts_loss: 1.0306 - stops_loss: 1.0014 - starts_accuracy: 0.6697 - stops_accuracy: 0.7011 - val_loss: 3.0247 - val_starts_loss: 1.5266 - val_stops_loss: 1.5326 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6245\n",
      "Epoch 566/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0137 - starts_loss: 1.0174 - stops_loss: 0.9922 - starts_accuracy: 0.6707 - stops_accuracy: 0.7018 - val_loss: 3.0250 - val_starts_loss: 1.5263 - val_stops_loss: 1.5332 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6243\n",
      "Epoch 567/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 2.0210 - starts_loss: 1.0176 - stops_loss: 0.9998 - starts_accuracy: 0.6727 - stops_accuracy: 0.7004 - val_loss: 3.0251 - val_starts_loss: 1.5264 - val_stops_loss: 1.5333 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6243\n",
      "Epoch 568/1000\n",
      "20803/20803 [==============================] - 12s 601us/sample - loss: 2.0302 - starts_loss: 1.0236 - stops_loss: 1.0055 - starts_accuracy: 0.6724 - stops_accuracy: 0.7011 - val_loss: 3.0240 - val_starts_loss: 1.5267 - val_stops_loss: 1.5322 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6247\n",
      "Epoch 569/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0190 - starts_loss: 1.0241 - stops_loss: 0.9936 - starts_accuracy: 0.6702 - stops_accuracy: 0.7027 - val_loss: 3.0242 - val_starts_loss: 1.5269 - val_stops_loss: 1.5322 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6249\n",
      "Epoch 570/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0216 - starts_loss: 1.0266 - stops_loss: 0.9970 - starts_accuracy: 0.6699 - stops_accuracy: 0.7049 - val_loss: 3.0237 - val_starts_loss: 1.5266 - val_stops_loss: 1.5320 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6253\n",
      "Epoch 571/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 2.0155 - starts_loss: 1.0253 - stops_loss: 0.9942 - starts_accuracy: 0.6718 - stops_accuracy: 0.7048 - val_loss: 3.0256 - val_starts_loss: 1.5267 - val_stops_loss: 1.5335 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6245\n",
      "Epoch 572/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0159 - starts_loss: 1.0245 - stops_loss: 0.9846 - starts_accuracy: 0.6686 - stops_accuracy: 0.7048 - val_loss: 3.0272 - val_starts_loss: 1.5270 - val_stops_loss: 1.5347 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 573/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0227 - starts_loss: 1.0262 - stops_loss: 0.9958 - starts_accuracy: 0.6720 - stops_accuracy: 0.7047 - val_loss: 3.0268 - val_starts_loss: 1.5271 - val_stops_loss: 1.5343 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6245\n",
      "Epoch 574/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.0287 - starts_loss: 1.0194 - stops_loss: 0.9997 - starts_accuracy: 0.6732 - stops_accuracy: 0.6982 - val_loss: 3.0251 - val_starts_loss: 1.5267 - val_stops_loss: 1.5331 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6243\n",
      "Epoch 575/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0342 - starts_loss: 1.0272 - stops_loss: 1.0065 - starts_accuracy: 0.6728 - stops_accuracy: 0.7006 - val_loss: 3.0250 - val_starts_loss: 1.5266 - val_stops_loss: 1.5331 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6245\n",
      "Epoch 576/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0207 - starts_loss: 1.0252 - stops_loss: 0.9995 - starts_accuracy: 0.6735 - stops_accuracy: 0.6978 - val_loss: 3.0255 - val_starts_loss: 1.5270 - val_stops_loss: 1.5332 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6243\n",
      "Epoch 577/1000\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 2.0180 - starts_loss: 1.0233 - stops_loss: 0.9897 - starts_accuracy: 0.6712 - stops_accuracy: 0.7035 - val_loss: 3.0260 - val_starts_loss: 1.5269 - val_stops_loss: 1.5338 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6241\n",
      "Epoch 578/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0301 - starts_loss: 1.0281 - stops_loss: 1.0092 - starts_accuracy: 0.6680 - stops_accuracy: 0.6986 - val_loss: 3.0269 - val_starts_loss: 1.5272 - val_stops_loss: 1.5344 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6247\n",
      "Epoch 579/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 2.0191 - starts_loss: 1.0303 - stops_loss: 0.9886 - starts_accuracy: 0.6750 - stops_accuracy: 0.7049 - val_loss: 3.0261 - val_starts_loss: 1.5272 - val_stops_loss: 1.5337 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6249\n",
      "Epoch 580/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0209 - starts_loss: 1.0246 - stops_loss: 1.0043 - starts_accuracy: 0.6749 - stops_accuracy: 0.6999 - val_loss: 3.0265 - val_starts_loss: 1.5273 - val_stops_loss: 1.5340 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6251\n",
      "Epoch 581/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.0278 - starts_loss: 1.0273 - stops_loss: 1.0004 - starts_accuracy: 0.6700 - stops_accuracy: 0.7006 - val_loss: 3.0268 - val_starts_loss: 1.5273 - val_stops_loss: 1.5342 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6251\n",
      "Epoch 582/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 2.0291 - starts_loss: 1.0260 - stops_loss: 0.9952 - starts_accuracy: 0.6710 - stops_accuracy: 0.6995 - val_loss: 3.0265 - val_starts_loss: 1.5272 - val_stops_loss: 1.5341 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6247\n",
      "Epoch 583/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0349 - starts_loss: 1.0199 - stops_loss: 1.0161 - starts_accuracy: 0.6700 - stops_accuracy: 0.6969 - val_loss: 3.0259 - val_starts_loss: 1.5272 - val_stops_loss: 1.5335 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6245\n",
      "Epoch 584/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0207 - starts_loss: 1.0257 - stops_loss: 0.9935 - starts_accuracy: 0.6717 - stops_accuracy: 0.7005 - val_loss: 3.0239 - val_starts_loss: 1.5275 - val_stops_loss: 1.5315 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6253\n",
      "Epoch 585/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 2.0252 - starts_loss: 1.0225 - stops_loss: 1.0016 - starts_accuracy: 0.6756 - stops_accuracy: 0.6986 - val_loss: 3.0242 - val_starts_loss: 1.5277 - val_stops_loss: 1.5316 - val_starts_accuracy: 0.6143 - val_stops_accuracy: 0.6251\n",
      "Epoch 586/1000\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 2.0098 - starts_loss: 1.0157 - stops_loss: 0.9989 - starts_accuracy: 0.6716 - stops_accuracy: 0.7011 - val_loss: 3.0246 - val_starts_loss: 1.5273 - val_stops_loss: 1.5323 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6247\n",
      "Epoch 587/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0212 - starts_loss: 1.0269 - stops_loss: 0.9979 - starts_accuracy: 0.6746 - stops_accuracy: 0.7021 - val_loss: 3.0239 - val_starts_loss: 1.5272 - val_stops_loss: 1.5318 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6247\n",
      "Epoch 588/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.0234 - starts_loss: 1.0210 - stops_loss: 1.0059 - starts_accuracy: 0.6724 - stops_accuracy: 0.7025 - val_loss: 3.0253 - val_starts_loss: 1.5271 - val_stops_loss: 1.5330 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6245\n",
      "Epoch 589/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0244 - starts_loss: 1.0305 - stops_loss: 0.9997 - starts_accuracy: 0.6710 - stops_accuracy: 0.7002 - val_loss: 3.0272 - val_starts_loss: 1.5276 - val_stops_loss: 1.5342 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6241\n",
      "Epoch 590/1000\n",
      "20803/20803 [==============================] - 12s 601us/sample - loss: 2.0231 - starts_loss: 1.0246 - stops_loss: 0.9985 - starts_accuracy: 0.6708 - stops_accuracy: 0.7009 - val_loss: 3.0273 - val_starts_loss: 1.5275 - val_stops_loss: 1.5343 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6239\n",
      "Epoch 591/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0296 - starts_loss: 1.0199 - stops_loss: 0.9982 - starts_accuracy: 0.6722 - stops_accuracy: 0.6984 - val_loss: 3.0280 - val_starts_loss: 1.5273 - val_stops_loss: 1.5352 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6245\n",
      "Epoch 592/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0238 - starts_loss: 1.0215 - stops_loss: 1.0074 - starts_accuracy: 0.6700 - stops_accuracy: 0.7022 - val_loss: 3.0279 - val_starts_loss: 1.5272 - val_stops_loss: 1.5352 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6249\n",
      "Epoch 593/1000\n",
      "20803/20803 [==============================] - 12s 601us/sample - loss: 2.0101 - starts_loss: 1.0184 - stops_loss: 0.9935 - starts_accuracy: 0.6750 - stops_accuracy: 0.7033 - val_loss: 3.0282 - val_starts_loss: 1.5274 - val_stops_loss: 1.5354 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6249\n",
      "Epoch 594/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 2.0244 - starts_loss: 1.0293 - stops_loss: 0.9973 - starts_accuracy: 0.6743 - stops_accuracy: 0.7018 - val_loss: 3.0290 - val_starts_loss: 1.5276 - val_stops_loss: 1.5359 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6253\n",
      "Epoch 595/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0291 - starts_loss: 1.0258 - stops_loss: 1.0065 - starts_accuracy: 0.6727 - stops_accuracy: 0.6995 - val_loss: 3.0284 - val_starts_loss: 1.5276 - val_stops_loss: 1.5354 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6251\n",
      "Epoch 596/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0314 - starts_loss: 1.0267 - stops_loss: 1.0059 - starts_accuracy: 0.6721 - stops_accuracy: 0.7011 - val_loss: 3.0269 - val_starts_loss: 1.5281 - val_stops_loss: 1.5338 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6245\n",
      "Epoch 597/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 2.0278 - starts_loss: 1.0275 - stops_loss: 0.9997 - starts_accuracy: 0.6701 - stops_accuracy: 0.6993 - val_loss: 3.0281 - val_starts_loss: 1.5281 - val_stops_loss: 1.5349 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6247\n",
      "Epoch 598/1000\n",
      "20803/20803 [==============================] - 13s 620us/sample - loss: 2.0240 - starts_loss: 1.0285 - stops_loss: 0.9943 - starts_accuracy: 0.6713 - stops_accuracy: 0.7016 - val_loss: 3.0265 - val_starts_loss: 1.5281 - val_stops_loss: 1.5335 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 599/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0302 - starts_loss: 1.0300 - stops_loss: 1.0015 - starts_accuracy: 0.6719 - stops_accuracy: 0.6998 - val_loss: 3.0259 - val_starts_loss: 1.5280 - val_stops_loss: 1.5330 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6249\n",
      "Epoch 600/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0171 - starts_loss: 1.0221 - stops_loss: 0.9977 - starts_accuracy: 0.6714 - stops_accuracy: 0.7015 - val_loss: 3.0255 - val_starts_loss: 1.5279 - val_stops_loss: 1.5328 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6249\n",
      "Epoch 601/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0191 - starts_loss: 1.0215 - stops_loss: 0.9930 - starts_accuracy: 0.6700 - stops_accuracy: 0.7054 - val_loss: 3.0261 - val_starts_loss: 1.5283 - val_stops_loss: 1.5330 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6249\n",
      "Epoch 602/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0213 - starts_loss: 1.0266 - stops_loss: 0.9936 - starts_accuracy: 0.6750 - stops_accuracy: 0.7039 - val_loss: 3.0259 - val_starts_loss: 1.5279 - val_stops_loss: 1.5331 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6245\n",
      "Epoch 603/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0218 - starts_loss: 1.0236 - stops_loss: 1.0068 - starts_accuracy: 0.6734 - stops_accuracy: 0.7021 - val_loss: 3.0264 - val_starts_loss: 1.5279 - val_stops_loss: 1.5337 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6249\n",
      "Epoch 604/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0205 - starts_loss: 1.0225 - stops_loss: 0.9970 - starts_accuracy: 0.6716 - stops_accuracy: 0.6988 - val_loss: 3.0257 - val_starts_loss: 1.5281 - val_stops_loss: 1.5330 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6247\n",
      "Epoch 605/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0228 - starts_loss: 1.0200 - stops_loss: 0.9973 - starts_accuracy: 0.6721 - stops_accuracy: 0.7008 - val_loss: 3.0242 - val_starts_loss: 1.5279 - val_stops_loss: 1.5319 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6249\n",
      "Epoch 606/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0167 - starts_loss: 1.0168 - stops_loss: 0.9936 - starts_accuracy: 0.6717 - stops_accuracy: 0.7032 - val_loss: 3.0229 - val_starts_loss: 1.5280 - val_stops_loss: 1.5307 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6247\n",
      "Epoch 607/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.0206 - starts_loss: 1.0222 - stops_loss: 0.9980 - starts_accuracy: 0.6749 - stops_accuracy: 0.7014 - val_loss: 3.0234 - val_starts_loss: 1.5281 - val_stops_loss: 1.5311 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6247\n",
      "Epoch 608/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0297 - starts_loss: 1.0297 - stops_loss: 1.0030 - starts_accuracy: 0.6716 - stops_accuracy: 0.6971 - val_loss: 3.0233 - val_starts_loss: 1.5280 - val_stops_loss: 1.5309 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6247\n",
      "Epoch 609/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0247 - starts_loss: 1.0279 - stops_loss: 0.9967 - starts_accuracy: 0.6719 - stops_accuracy: 0.7005 - val_loss: 3.0258 - val_starts_loss: 1.5281 - val_stops_loss: 1.5330 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6251\n",
      "Epoch 610/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0268 - starts_loss: 1.0230 - stops_loss: 1.0123 - starts_accuracy: 0.6731 - stops_accuracy: 0.6975 - val_loss: 3.0284 - val_starts_loss: 1.5284 - val_stops_loss: 1.5350 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6249\n",
      "Epoch 611/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.0341 - starts_loss: 1.0253 - stops_loss: 1.0021 - starts_accuracy: 0.6694 - stops_accuracy: 0.6972 - val_loss: 3.0277 - val_starts_loss: 1.5286 - val_stops_loss: 1.5344 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6251\n",
      "Epoch 612/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.0363 - starts_loss: 1.0330 - stops_loss: 1.0069 - starts_accuracy: 0.6712 - stops_accuracy: 0.7002 - val_loss: 3.0284 - val_starts_loss: 1.5287 - val_stops_loss: 1.5350 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6247\n",
      "Epoch 613/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 2.0249 - starts_loss: 1.0249 - stops_loss: 0.9979 - starts_accuracy: 0.6714 - stops_accuracy: 0.7049 - val_loss: 3.0264 - val_starts_loss: 1.5286 - val_stops_loss: 1.5335 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6251\n",
      "Epoch 614/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0222 - starts_loss: 1.0202 - stops_loss: 0.9974 - starts_accuracy: 0.6732 - stops_accuracy: 0.6988 - val_loss: 3.0273 - val_starts_loss: 1.5285 - val_stops_loss: 1.5343 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6251\n",
      "Epoch 615/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 2.0149 - starts_loss: 1.0260 - stops_loss: 0.9893 - starts_accuracy: 0.6731 - stops_accuracy: 0.7026 - val_loss: 3.0268 - val_starts_loss: 1.5286 - val_stops_loss: 1.5338 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6249\n",
      "Epoch 616/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0105 - starts_loss: 1.0243 - stops_loss: 0.9923 - starts_accuracy: 0.6709 - stops_accuracy: 0.6977 - val_loss: 3.0267 - val_starts_loss: 1.5284 - val_stops_loss: 1.5338 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6251\n",
      "Epoch 617/1000\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 2.0230 - starts_loss: 1.0272 - stops_loss: 0.9994 - starts_accuracy: 0.6714 - stops_accuracy: 0.7034 - val_loss: 3.0296 - val_starts_loss: 1.5286 - val_stops_loss: 1.5361 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6247\n",
      "Epoch 618/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0171 - starts_loss: 1.0214 - stops_loss: 0.9940 - starts_accuracy: 0.6735 - stops_accuracy: 0.7024 - val_loss: 3.0312 - val_starts_loss: 1.5288 - val_stops_loss: 1.5373 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6245\n",
      "Epoch 619/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0334 - starts_loss: 1.0246 - stops_loss: 1.0066 - starts_accuracy: 0.6744 - stops_accuracy: 0.6976 - val_loss: 3.0297 - val_starts_loss: 1.5291 - val_stops_loss: 1.5357 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6241\n",
      "Epoch 620/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 2.0146 - starts_loss: 1.0269 - stops_loss: 0.9915 - starts_accuracy: 0.6700 - stops_accuracy: 0.7026 - val_loss: 3.0274 - val_starts_loss: 1.5288 - val_stops_loss: 1.5339 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6249\n",
      "Epoch 621/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0232 - starts_loss: 1.0190 - stops_loss: 0.9990 - starts_accuracy: 0.6711 - stops_accuracy: 0.7018 - val_loss: 3.0255 - val_starts_loss: 1.5284 - val_stops_loss: 1.5325 - val_starts_accuracy: 0.6143 - val_stops_accuracy: 0.6253\n",
      "Epoch 622/1000\n",
      "20803/20803 [==============================] - 12s 601us/sample - loss: 2.0194 - starts_loss: 1.0263 - stops_loss: 0.9966 - starts_accuracy: 0.6724 - stops_accuracy: 0.7025 - val_loss: 3.0256 - val_starts_loss: 1.5284 - val_stops_loss: 1.5327 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6249\n",
      "Epoch 623/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0244 - starts_loss: 1.0250 - stops_loss: 1.0000 - starts_accuracy: 0.6713 - stops_accuracy: 0.7011 - val_loss: 3.0256 - val_starts_loss: 1.5285 - val_stops_loss: 1.5326 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6245\n",
      "Epoch 624/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0243 - starts_loss: 1.0190 - stops_loss: 1.0012 - starts_accuracy: 0.6743 - stops_accuracy: 0.7010 - val_loss: 3.0244 - val_starts_loss: 1.5285 - val_stops_loss: 1.5315 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 625/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0252 - starts_loss: 1.0277 - stops_loss: 0.9973 - starts_accuracy: 0.6693 - stops_accuracy: 0.7062 - val_loss: 3.0247 - val_starts_loss: 1.5283 - val_stops_loss: 1.5318 - val_starts_accuracy: 0.6143 - val_stops_accuracy: 0.6247\n",
      "Epoch 626/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0274 - starts_loss: 1.0237 - stops_loss: 0.9991 - starts_accuracy: 0.6711 - stops_accuracy: 0.6999 - val_loss: 3.0252 - val_starts_loss: 1.5286 - val_stops_loss: 1.5321 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6249\n",
      "Epoch 627/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0278 - starts_loss: 1.0283 - stops_loss: 1.0016 - starts_accuracy: 0.6709 - stops_accuracy: 0.6999 - val_loss: 3.0270 - val_starts_loss: 1.5285 - val_stops_loss: 1.5338 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6243\n",
      "Epoch 628/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0185 - starts_loss: 1.0222 - stops_loss: 0.9984 - starts_accuracy: 0.6723 - stops_accuracy: 0.7040 - val_loss: 3.0271 - val_starts_loss: 1.5281 - val_stops_loss: 1.5342 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6245\n",
      "Epoch 629/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0024 - starts_loss: 1.0169 - stops_loss: 0.9838 - starts_accuracy: 0.6744 - stops_accuracy: 0.7033 - val_loss: 3.0296 - val_starts_loss: 1.5281 - val_stops_loss: 1.5364 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6247\n",
      "Epoch 630/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0275 - starts_loss: 1.0300 - stops_loss: 0.9997 - starts_accuracy: 0.6700 - stops_accuracy: 0.7003 - val_loss: 3.0293 - val_starts_loss: 1.5284 - val_stops_loss: 1.5360 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6247\n",
      "Epoch 631/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0235 - starts_loss: 1.0349 - stops_loss: 0.9942 - starts_accuracy: 0.6727 - stops_accuracy: 0.7046 - val_loss: 3.0271 - val_starts_loss: 1.5280 - val_stops_loss: 1.5344 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6249\n",
      "Epoch 632/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0240 - starts_loss: 1.0280 - stops_loss: 1.0039 - starts_accuracy: 0.6729 - stops_accuracy: 0.7006 - val_loss: 3.0265 - val_starts_loss: 1.5279 - val_stops_loss: 1.5340 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6249\n",
      "Epoch 633/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0245 - starts_loss: 1.0221 - stops_loss: 0.9992 - starts_accuracy: 0.6720 - stops_accuracy: 0.7000 - val_loss: 3.0280 - val_starts_loss: 1.5280 - val_stops_loss: 1.5350 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6251\n",
      "Epoch 634/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0187 - starts_loss: 1.0287 - stops_loss: 0.9907 - starts_accuracy: 0.6715 - stops_accuracy: 0.7016 - val_loss: 3.0300 - val_starts_loss: 1.5283 - val_stops_loss: 1.5366 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6243\n",
      "Epoch 635/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0186 - starts_loss: 1.0257 - stops_loss: 0.9923 - starts_accuracy: 0.6695 - stops_accuracy: 0.7008 - val_loss: 3.0300 - val_starts_loss: 1.5283 - val_stops_loss: 1.5365 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6241\n",
      "Epoch 636/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0185 - starts_loss: 1.0194 - stops_loss: 0.9922 - starts_accuracy: 0.6737 - stops_accuracy: 0.6981 - val_loss: 3.0272 - val_starts_loss: 1.5282 - val_stops_loss: 1.5343 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6243\n",
      "Epoch 637/1000\n",
      "20803/20803 [==============================] - 12s 593us/sample - loss: 2.0225 - starts_loss: 1.0226 - stops_loss: 0.9977 - starts_accuracy: 0.6723 - stops_accuracy: 0.7019 - val_loss: 3.0273 - val_starts_loss: 1.5282 - val_stops_loss: 1.5343 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6249\n",
      "Epoch 638/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0184 - starts_loss: 1.0233 - stops_loss: 0.9961 - starts_accuracy: 0.6717 - stops_accuracy: 0.7023 - val_loss: 3.0276 - val_starts_loss: 1.5285 - val_stops_loss: 1.5343 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6247\n",
      "Epoch 639/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.0233 - starts_loss: 1.0294 - stops_loss: 0.9973 - starts_accuracy: 0.6727 - stops_accuracy: 0.7025 - val_loss: 3.0276 - val_starts_loss: 1.5284 - val_stops_loss: 1.5344 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6253\n",
      "Epoch 640/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.0249 - starts_loss: 1.0210 - stops_loss: 1.0008 - starts_accuracy: 0.6723 - stops_accuracy: 0.6992 - val_loss: 3.0287 - val_starts_loss: 1.5289 - val_stops_loss: 1.5350 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6249\n",
      "Epoch 641/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 2.0252 - starts_loss: 1.0255 - stops_loss: 1.0002 - starts_accuracy: 0.6729 - stops_accuracy: 0.6987 - val_loss: 3.0286 - val_starts_loss: 1.5288 - val_stops_loss: 1.5351 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6253\n",
      "Epoch 642/1000\n",
      "20803/20803 [==============================] - 12s 601us/sample - loss: 2.0300 - starts_loss: 1.0292 - stops_loss: 0.9989 - starts_accuracy: 0.6721 - stops_accuracy: 0.7012 - val_loss: 3.0284 - val_starts_loss: 1.5286 - val_stops_loss: 1.5350 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6249\n",
      "Epoch 643/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0215 - starts_loss: 1.0253 - stops_loss: 1.0009 - starts_accuracy: 0.6737 - stops_accuracy: 0.6991 - val_loss: 3.0274 - val_starts_loss: 1.5285 - val_stops_loss: 1.5343 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6249\n",
      "Epoch 644/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0222 - starts_loss: 1.0218 - stops_loss: 0.9987 - starts_accuracy: 0.6733 - stops_accuracy: 0.7017 - val_loss: 3.0271 - val_starts_loss: 1.5287 - val_stops_loss: 1.5338 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6249\n",
      "Epoch 645/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0148 - starts_loss: 1.0200 - stops_loss: 1.0006 - starts_accuracy: 0.6753 - stops_accuracy: 0.7008 - val_loss: 3.0285 - val_starts_loss: 1.5290 - val_stops_loss: 1.5348 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6251\n",
      "Epoch 646/1000\n",
      "20803/20803 [==============================] - 13s 627us/sample - loss: 2.0161 - starts_loss: 1.0245 - stops_loss: 0.9940 - starts_accuracy: 0.6722 - stops_accuracy: 0.7038 - val_loss: 3.0276 - val_starts_loss: 1.5287 - val_stops_loss: 1.5342 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6249\n",
      "Epoch 647/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0293 - starts_loss: 1.0221 - stops_loss: 1.0093 - starts_accuracy: 0.6743 - stops_accuracy: 0.6973 - val_loss: 3.0278 - val_starts_loss: 1.5288 - val_stops_loss: 1.5344 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6251\n",
      "Epoch 648/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 2.0188 - starts_loss: 1.0248 - stops_loss: 0.9951 - starts_accuracy: 0.6727 - stops_accuracy: 0.7008 - val_loss: 3.0285 - val_starts_loss: 1.5285 - val_stops_loss: 1.5352 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6249\n",
      "Epoch 649/1000\n",
      "20803/20803 [==============================] - 13s 617us/sample - loss: 2.0151 - starts_loss: 1.0208 - stops_loss: 0.9968 - starts_accuracy: 0.6724 - stops_accuracy: 0.7019 - val_loss: 3.0294 - val_starts_loss: 1.5285 - val_stops_loss: 1.5360 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6253\n",
      "Epoch 650/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0107 - starts_loss: 1.0163 - stops_loss: 0.9893 - starts_accuracy: 0.6738 - stops_accuracy: 0.7036 - val_loss: 3.0289 - val_starts_loss: 1.5286 - val_stops_loss: 1.5356 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 651/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 2.0178 - starts_loss: 1.0215 - stops_loss: 1.0000 - starts_accuracy: 0.6734 - stops_accuracy: 0.7038 - val_loss: 3.0285 - val_starts_loss: 1.5286 - val_stops_loss: 1.5352 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6253\n",
      "Epoch 652/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0059 - starts_loss: 1.0125 - stops_loss: 0.9919 - starts_accuracy: 0.6735 - stops_accuracy: 0.7043 - val_loss: 3.0285 - val_starts_loss: 1.5286 - val_stops_loss: 1.5352 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6253\n",
      "Epoch 653/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 2.0223 - starts_loss: 1.0265 - stops_loss: 0.9987 - starts_accuracy: 0.6719 - stops_accuracy: 0.6990 - val_loss: 3.0281 - val_starts_loss: 1.5288 - val_stops_loss: 1.5347 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6249\n",
      "Epoch 654/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0188 - starts_loss: 1.0182 - stops_loss: 0.9973 - starts_accuracy: 0.6722 - stops_accuracy: 0.7006 - val_loss: 3.0277 - val_starts_loss: 1.5286 - val_stops_loss: 1.5345 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6245\n",
      "Epoch 655/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0196 - starts_loss: 1.0245 - stops_loss: 0.9922 - starts_accuracy: 0.6709 - stops_accuracy: 0.7048 - val_loss: 3.0272 - val_starts_loss: 1.5286 - val_stops_loss: 1.5342 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6251\n",
      "Epoch 656/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0129 - starts_loss: 1.0219 - stops_loss: 0.9909 - starts_accuracy: 0.6723 - stops_accuracy: 0.7059 - val_loss: 3.0270 - val_starts_loss: 1.5284 - val_stops_loss: 1.5342 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6251\n",
      "Epoch 657/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0204 - starts_loss: 1.0245 - stops_loss: 1.0021 - starts_accuracy: 0.6710 - stops_accuracy: 0.7051 - val_loss: 3.0268 - val_starts_loss: 1.5287 - val_stops_loss: 1.5339 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6251\n",
      "Epoch 658/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0190 - starts_loss: 1.0219 - stops_loss: 1.0034 - starts_accuracy: 0.6705 - stops_accuracy: 0.6996 - val_loss: 3.0263 - val_starts_loss: 1.5284 - val_stops_loss: 1.5338 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6253\n",
      "Epoch 659/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0093 - starts_loss: 1.0226 - stops_loss: 0.9845 - starts_accuracy: 0.6698 - stops_accuracy: 0.7036 - val_loss: 3.0271 - val_starts_loss: 1.5286 - val_stops_loss: 1.5343 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6251\n",
      "Epoch 660/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0211 - starts_loss: 1.0219 - stops_loss: 0.9990 - starts_accuracy: 0.6712 - stops_accuracy: 0.7016 - val_loss: 3.0264 - val_starts_loss: 1.5285 - val_stops_loss: 1.5335 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6253\n",
      "Epoch 661/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0155 - starts_loss: 1.0181 - stops_loss: 1.0001 - starts_accuracy: 0.6727 - stops_accuracy: 0.7045 - val_loss: 3.0271 - val_starts_loss: 1.5286 - val_stops_loss: 1.5341 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6251\n",
      "Epoch 662/1000\n",
      "20803/20803 [==============================] - 13s 617us/sample - loss: 2.0107 - starts_loss: 1.0210 - stops_loss: 0.9955 - starts_accuracy: 0.6763 - stops_accuracy: 0.7026 - val_loss: 3.0277 - val_starts_loss: 1.5291 - val_stops_loss: 1.5343 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6253\n",
      "Epoch 663/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0193 - starts_loss: 1.0244 - stops_loss: 1.0015 - starts_accuracy: 0.6725 - stops_accuracy: 0.7028 - val_loss: 3.0265 - val_starts_loss: 1.5291 - val_stops_loss: 1.5333 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6253\n",
      "Epoch 664/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0343 - starts_loss: 1.0317 - stops_loss: 1.0054 - starts_accuracy: 0.6748 - stops_accuracy: 0.7002 - val_loss: 3.0274 - val_starts_loss: 1.5292 - val_stops_loss: 1.5339 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6253\n",
      "Epoch 665/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0150 - starts_loss: 1.0167 - stops_loss: 1.0012 - starts_accuracy: 0.6717 - stops_accuracy: 0.7012 - val_loss: 3.0290 - val_starts_loss: 1.5294 - val_stops_loss: 1.5351 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6253\n",
      "Epoch 666/1000\n",
      "20803/20803 [==============================] - 13s 620us/sample - loss: 2.0108 - starts_loss: 1.0223 - stops_loss: 0.9898 - starts_accuracy: 0.6709 - stops_accuracy: 0.7059 - val_loss: 3.0283 - val_starts_loss: 1.5292 - val_stops_loss: 1.5348 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6253\n",
      "Epoch 667/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0295 - starts_loss: 1.0281 - stops_loss: 1.0014 - starts_accuracy: 0.6737 - stops_accuracy: 0.7016 - val_loss: 3.0301 - val_starts_loss: 1.5292 - val_stops_loss: 1.5364 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6249\n",
      "Epoch 668/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0101 - starts_loss: 1.0197 - stops_loss: 0.9885 - starts_accuracy: 0.6715 - stops_accuracy: 0.7005 - val_loss: 3.0294 - val_starts_loss: 1.5292 - val_stops_loss: 1.5357 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6253\n",
      "Epoch 669/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0170 - starts_loss: 1.0208 - stops_loss: 0.9958 - starts_accuracy: 0.6720 - stops_accuracy: 0.7008 - val_loss: 3.0294 - val_starts_loss: 1.5290 - val_stops_loss: 1.5357 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6251\n",
      "Epoch 670/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0173 - starts_loss: 1.0147 - stops_loss: 0.9970 - starts_accuracy: 0.6709 - stops_accuracy: 0.7001 - val_loss: 3.0314 - val_starts_loss: 1.5288 - val_stops_loss: 1.5375 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6247\n",
      "Epoch 671/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 2.0108 - starts_loss: 1.0244 - stops_loss: 0.9919 - starts_accuracy: 0.6705 - stops_accuracy: 0.7050 - val_loss: 3.0324 - val_starts_loss: 1.5289 - val_stops_loss: 1.5383 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6243\n",
      "Epoch 672/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 2.0207 - starts_loss: 1.0257 - stops_loss: 1.0046 - starts_accuracy: 0.6751 - stops_accuracy: 0.7012 - val_loss: 3.0327 - val_starts_loss: 1.5289 - val_stops_loss: 1.5385 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6243\n",
      "Epoch 673/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0124 - starts_loss: 1.0242 - stops_loss: 0.9868 - starts_accuracy: 0.6708 - stops_accuracy: 0.7056 - val_loss: 3.0322 - val_starts_loss: 1.5291 - val_stops_loss: 1.5381 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6247\n",
      "Epoch 674/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0203 - starts_loss: 1.0244 - stops_loss: 0.9954 - starts_accuracy: 0.6695 - stops_accuracy: 0.7008 - val_loss: 3.0329 - val_starts_loss: 1.5295 - val_stops_loss: 1.5384 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6241\n",
      "Epoch 675/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0276 - starts_loss: 1.0223 - stops_loss: 1.0109 - starts_accuracy: 0.6711 - stops_accuracy: 0.7004 - val_loss: 3.0307 - val_starts_loss: 1.5294 - val_stops_loss: 1.5367 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6251\n",
      "Epoch 676/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.9979 - starts_loss: 1.0131 - stops_loss: 0.9862 - starts_accuracy: 0.6743 - stops_accuracy: 0.7027 - val_loss: 3.0297 - val_starts_loss: 1.5297 - val_stops_loss: 1.5356 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 677/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0004 - starts_loss: 1.0149 - stops_loss: 0.9850 - starts_accuracy: 0.6749 - stops_accuracy: 0.7053 - val_loss: 3.0319 - val_starts_loss: 1.5300 - val_stops_loss: 1.5375 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6251\n",
      "Epoch 678/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0248 - starts_loss: 1.0253 - stops_loss: 1.0001 - starts_accuracy: 0.6706 - stops_accuracy: 0.7043 - val_loss: 3.0319 - val_starts_loss: 1.5303 - val_stops_loss: 1.5373 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6251\n",
      "Epoch 679/1000\n",
      "20803/20803 [==============================] - 13s 621us/sample - loss: 2.0026 - starts_loss: 1.0165 - stops_loss: 0.9813 - starts_accuracy: 0.6749 - stops_accuracy: 0.7047 - val_loss: 3.0319 - val_starts_loss: 1.5301 - val_stops_loss: 1.5375 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6247\n",
      "Epoch 680/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0216 - starts_loss: 1.0195 - stops_loss: 0.9990 - starts_accuracy: 0.6730 - stops_accuracy: 0.7037 - val_loss: 3.0330 - val_starts_loss: 1.5301 - val_stops_loss: 1.5385 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6247\n",
      "Epoch 681/1000\n",
      "20803/20803 [==============================] - 13s 621us/sample - loss: 2.0150 - starts_loss: 1.0162 - stops_loss: 0.9995 - starts_accuracy: 0.6709 - stops_accuracy: 0.6990 - val_loss: 3.0321 - val_starts_loss: 1.5302 - val_stops_loss: 1.5376 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6251\n",
      "Epoch 682/1000\n",
      "20803/20803 [==============================] - 15s 699us/sample - loss: 2.0055 - starts_loss: 1.0140 - stops_loss: 0.9890 - starts_accuracy: 0.6771 - stops_accuracy: 0.7032 - val_loss: 3.0309 - val_starts_loss: 1.5301 - val_stops_loss: 1.5366 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6249\n",
      "Epoch 683/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0090 - starts_loss: 1.0243 - stops_loss: 0.9925 - starts_accuracy: 0.6724 - stops_accuracy: 0.7034 - val_loss: 3.0311 - val_starts_loss: 1.5299 - val_stops_loss: 1.5370 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6253\n",
      "Epoch 684/1000\n",
      "20803/20803 [==============================] - 13s 617us/sample - loss: 2.0030 - starts_loss: 1.0141 - stops_loss: 0.9881 - starts_accuracy: 0.6749 - stops_accuracy: 0.7030 - val_loss: 3.0313 - val_starts_loss: 1.5300 - val_stops_loss: 1.5370 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6249\n",
      "Epoch 685/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0048 - starts_loss: 1.0089 - stops_loss: 0.9886 - starts_accuracy: 0.6747 - stops_accuracy: 0.6992 - val_loss: 3.0315 - val_starts_loss: 1.5302 - val_stops_loss: 1.5370 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6251\n",
      "Epoch 686/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0079 - starts_loss: 1.0187 - stops_loss: 0.9909 - starts_accuracy: 0.6726 - stops_accuracy: 0.7028 - val_loss: 3.0299 - val_starts_loss: 1.5300 - val_stops_loss: 1.5357 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6253\n",
      "Epoch 687/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0110 - starts_loss: 1.0111 - stops_loss: 0.9976 - starts_accuracy: 0.6712 - stops_accuracy: 0.7031 - val_loss: 3.0289 - val_starts_loss: 1.5297 - val_stops_loss: 1.5352 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6253\n",
      "Epoch 688/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.0196 - starts_loss: 1.0231 - stops_loss: 0.9976 - starts_accuracy: 0.6756 - stops_accuracy: 0.6989 - val_loss: 3.0301 - val_starts_loss: 1.5300 - val_stops_loss: 1.5359 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6253\n",
      "Epoch 689/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0064 - starts_loss: 1.0236 - stops_loss: 0.9817 - starts_accuracy: 0.6703 - stops_accuracy: 0.7026 - val_loss: 3.0308 - val_starts_loss: 1.5301 - val_stops_loss: 1.5365 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6251\n",
      "Epoch 690/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0152 - starts_loss: 1.0212 - stops_loss: 0.9903 - starts_accuracy: 0.6735 - stops_accuracy: 0.7021 - val_loss: 3.0317 - val_starts_loss: 1.5298 - val_stops_loss: 1.5376 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6249\n",
      "Epoch 691/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0204 - starts_loss: 1.0242 - stops_loss: 0.9950 - starts_accuracy: 0.6712 - stops_accuracy: 0.7052 - val_loss: 3.0302 - val_starts_loss: 1.5295 - val_stops_loss: 1.5365 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6253\n",
      "Epoch 692/1000\n",
      "20803/20803 [==============================] - 12s 601us/sample - loss: 2.0171 - starts_loss: 1.0269 - stops_loss: 0.9939 - starts_accuracy: 0.6710 - stops_accuracy: 0.7026 - val_loss: 3.0324 - val_starts_loss: 1.5299 - val_stops_loss: 1.5380 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6251\n",
      "Epoch 693/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0102 - starts_loss: 1.0187 - stops_loss: 0.9964 - starts_accuracy: 0.6740 - stops_accuracy: 0.7043 - val_loss: 3.0330 - val_starts_loss: 1.5299 - val_stops_loss: 1.5384 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6247\n",
      "Epoch 694/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 2.0164 - starts_loss: 1.0145 - stops_loss: 0.9978 - starts_accuracy: 0.6709 - stops_accuracy: 0.7019 - val_loss: 3.0322 - val_starts_loss: 1.5299 - val_stops_loss: 1.5378 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6249\n",
      "Epoch 695/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0162 - starts_loss: 1.0253 - stops_loss: 0.9852 - starts_accuracy: 0.6698 - stops_accuracy: 0.7060 - val_loss: 3.0327 - val_starts_loss: 1.5300 - val_stops_loss: 1.5382 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6249\n",
      "Epoch 696/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0179 - starts_loss: 1.0191 - stops_loss: 0.9963 - starts_accuracy: 0.6722 - stops_accuracy: 0.6996 - val_loss: 3.0324 - val_starts_loss: 1.5303 - val_stops_loss: 1.5378 - val_starts_accuracy: 0.6162 - val_stops_accuracy: 0.6249\n",
      "Epoch 697/1000\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 2.0213 - starts_loss: 1.0273 - stops_loss: 0.9909 - starts_accuracy: 0.6700 - stops_accuracy: 0.7037 - val_loss: 3.0305 - val_starts_loss: 1.5302 - val_stops_loss: 1.5363 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6251\n",
      "Epoch 698/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 1.9996 - starts_loss: 1.0160 - stops_loss: 0.9849 - starts_accuracy: 0.6727 - stops_accuracy: 0.7059 - val_loss: 3.0309 - val_starts_loss: 1.5301 - val_stops_loss: 1.5366 - val_starts_accuracy: 0.6162 - val_stops_accuracy: 0.6251\n",
      "Epoch 699/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0213 - starts_loss: 1.0164 - stops_loss: 1.0007 - starts_accuracy: 0.6722 - stops_accuracy: 0.6990 - val_loss: 3.0313 - val_starts_loss: 1.5300 - val_stops_loss: 1.5371 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6251\n",
      "Epoch 700/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0134 - starts_loss: 1.0157 - stops_loss: 0.9934 - starts_accuracy: 0.6716 - stops_accuracy: 0.7032 - val_loss: 3.0308 - val_starts_loss: 1.5299 - val_stops_loss: 1.5367 - val_starts_accuracy: 0.6162 - val_stops_accuracy: 0.6249\n",
      "Epoch 701/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0225 - starts_loss: 1.0301 - stops_loss: 0.9998 - starts_accuracy: 0.6705 - stops_accuracy: 0.7016 - val_loss: 3.0308 - val_starts_loss: 1.5302 - val_stops_loss: 1.5365 - val_starts_accuracy: 0.6162 - val_stops_accuracy: 0.6249\n",
      "Epoch 702/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0242 - starts_loss: 1.0245 - stops_loss: 0.9994 - starts_accuracy: 0.6725 - stops_accuracy: 0.7022 - val_loss: 3.0306 - val_starts_loss: 1.5305 - val_stops_loss: 1.5362 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 703/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.0062 - starts_loss: 1.0132 - stops_loss: 0.9869 - starts_accuracy: 0.6732 - stops_accuracy: 0.7036 - val_loss: 3.0316 - val_starts_loss: 1.5303 - val_stops_loss: 1.5371 - val_starts_accuracy: 0.6164 - val_stops_accuracy: 0.6249\n",
      "Epoch 704/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0066 - starts_loss: 1.0179 - stops_loss: 0.9887 - starts_accuracy: 0.6715 - stops_accuracy: 0.7038 - val_loss: 3.0308 - val_starts_loss: 1.5301 - val_stops_loss: 1.5366 - val_starts_accuracy: 0.6162 - val_stops_accuracy: 0.6247\n",
      "Epoch 705/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0083 - starts_loss: 1.0147 - stops_loss: 0.9974 - starts_accuracy: 0.6759 - stops_accuracy: 0.7040 - val_loss: 3.0306 - val_starts_loss: 1.5299 - val_stops_loss: 1.5365 - val_starts_accuracy: 0.6162 - val_stops_accuracy: 0.6249\n",
      "Epoch 706/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 2.0147 - starts_loss: 1.0259 - stops_loss: 0.9910 - starts_accuracy: 0.6688 - stops_accuracy: 0.7023 - val_loss: 3.0316 - val_starts_loss: 1.5299 - val_stops_loss: 1.5376 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6255\n",
      "Epoch 707/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.0008 - starts_loss: 1.0101 - stops_loss: 0.9858 - starts_accuracy: 0.6740 - stops_accuracy: 0.7024 - val_loss: 3.0314 - val_starts_loss: 1.5303 - val_stops_loss: 1.5370 - val_starts_accuracy: 0.6162 - val_stops_accuracy: 0.6249\n",
      "Epoch 708/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0090 - starts_loss: 1.0196 - stops_loss: 0.9907 - starts_accuracy: 0.6734 - stops_accuracy: 0.7040 - val_loss: 3.0314 - val_starts_loss: 1.5303 - val_stops_loss: 1.5370 - val_starts_accuracy: 0.6162 - val_stops_accuracy: 0.6249\n",
      "Epoch 709/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 2.0070 - starts_loss: 1.0232 - stops_loss: 0.9823 - starts_accuracy: 0.6711 - stops_accuracy: 0.7043 - val_loss: 3.0324 - val_starts_loss: 1.5304 - val_stops_loss: 1.5378 - val_starts_accuracy: 0.6162 - val_stops_accuracy: 0.6251\n",
      "Epoch 710/1000\n",
      "20803/20803 [==============================] - 13s 618us/sample - loss: 2.0022 - starts_loss: 1.0174 - stops_loss: 0.9866 - starts_accuracy: 0.6767 - stops_accuracy: 0.7047 - val_loss: 3.0329 - val_starts_loss: 1.5310 - val_stops_loss: 1.5378 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6249\n",
      "Epoch 711/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0045 - starts_loss: 1.0159 - stops_loss: 0.9849 - starts_accuracy: 0.6727 - stops_accuracy: 0.7048 - val_loss: 3.0302 - val_starts_loss: 1.5310 - val_stops_loss: 1.5355 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6251\n",
      "Epoch 712/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0157 - starts_loss: 1.0175 - stops_loss: 0.9957 - starts_accuracy: 0.6734 - stops_accuracy: 0.7014 - val_loss: 3.0284 - val_starts_loss: 1.5307 - val_stops_loss: 1.5342 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6249\n",
      "Epoch 713/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0144 - starts_loss: 1.0154 - stops_loss: 0.9972 - starts_accuracy: 0.6733 - stops_accuracy: 0.6994 - val_loss: 3.0288 - val_starts_loss: 1.5305 - val_stops_loss: 1.5347 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6247\n",
      "Epoch 714/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0199 - starts_loss: 1.0252 - stops_loss: 0.9942 - starts_accuracy: 0.6735 - stops_accuracy: 0.7024 - val_loss: 3.0289 - val_starts_loss: 1.5300 - val_stops_loss: 1.5351 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6247\n",
      "Epoch 715/1000\n",
      "20803/20803 [==============================] - 12s 590us/sample - loss: 2.0167 - starts_loss: 1.0204 - stops_loss: 0.9937 - starts_accuracy: 0.6737 - stops_accuracy: 0.7035 - val_loss: 3.0285 - val_starts_loss: 1.5300 - val_stops_loss: 1.5347 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6245\n",
      "Epoch 716/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0247 - starts_loss: 1.0234 - stops_loss: 1.0066 - starts_accuracy: 0.6760 - stops_accuracy: 0.6991 - val_loss: 3.0296 - val_starts_loss: 1.5301 - val_stops_loss: 1.5356 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6253\n",
      "Epoch 717/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0044 - starts_loss: 1.0177 - stops_loss: 0.9883 - starts_accuracy: 0.6733 - stops_accuracy: 0.7057 - val_loss: 3.0305 - val_starts_loss: 1.5296 - val_stops_loss: 1.5367 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6251\n",
      "Epoch 718/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0097 - starts_loss: 1.0151 - stops_loss: 0.9961 - starts_accuracy: 0.6730 - stops_accuracy: 0.7004 - val_loss: 3.0315 - val_starts_loss: 1.5299 - val_stops_loss: 1.5375 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6251\n",
      "Epoch 719/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0071 - starts_loss: 1.0260 - stops_loss: 0.9863 - starts_accuracy: 0.6704 - stops_accuracy: 0.7057 - val_loss: 3.0305 - val_starts_loss: 1.5298 - val_stops_loss: 1.5367 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6255\n",
      "Epoch 720/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 2.0157 - starts_loss: 1.0193 - stops_loss: 0.9973 - starts_accuracy: 0.6744 - stops_accuracy: 0.7042 - val_loss: 3.0301 - val_starts_loss: 1.5302 - val_stops_loss: 1.5362 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6251\n",
      "Epoch 721/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0109 - starts_loss: 1.0156 - stops_loss: 0.9929 - starts_accuracy: 0.6734 - stops_accuracy: 0.6991 - val_loss: 3.0292 - val_starts_loss: 1.5302 - val_stops_loss: 1.5353 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6253\n",
      "Epoch 722/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0187 - starts_loss: 1.0263 - stops_loss: 0.9906 - starts_accuracy: 0.6710 - stops_accuracy: 0.7051 - val_loss: 3.0310 - val_starts_loss: 1.5304 - val_stops_loss: 1.5366 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6253\n",
      "Epoch 723/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0112 - starts_loss: 1.0158 - stops_loss: 0.9975 - starts_accuracy: 0.6728 - stops_accuracy: 0.7002 - val_loss: 3.0310 - val_starts_loss: 1.5305 - val_stops_loss: 1.5364 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6251\n",
      "Epoch 724/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 1.9962 - starts_loss: 1.0126 - stops_loss: 0.9800 - starts_accuracy: 0.6749 - stops_accuracy: 0.7065 - val_loss: 3.0320 - val_starts_loss: 1.5305 - val_stops_loss: 1.5374 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6255\n",
      "Epoch 725/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.0050 - starts_loss: 1.0222 - stops_loss: 0.9879 - starts_accuracy: 0.6728 - stops_accuracy: 0.7049 - val_loss: 3.0326 - val_starts_loss: 1.5308 - val_stops_loss: 1.5378 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6253\n",
      "Epoch 726/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0059 - starts_loss: 1.0151 - stops_loss: 0.9895 - starts_accuracy: 0.6746 - stops_accuracy: 0.7016 - val_loss: 3.0316 - val_starts_loss: 1.5309 - val_stops_loss: 1.5368 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6253\n",
      "Epoch 727/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0034 - starts_loss: 1.0179 - stops_loss: 0.9858 - starts_accuracy: 0.6725 - stops_accuracy: 0.7048 - val_loss: 3.0300 - val_starts_loss: 1.5307 - val_stops_loss: 1.5357 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6253\n",
      "Epoch 728/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0128 - starts_loss: 1.0162 - stops_loss: 0.9878 - starts_accuracy: 0.6745 - stops_accuracy: 0.7013 - val_loss: 3.0280 - val_starts_loss: 1.5306 - val_stops_loss: 1.5340 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0116 - starts_loss: 1.0205 - stops_loss: 0.9904 - starts_accuracy: 0.6725 - stops_accuracy: 0.7031 - val_loss: 3.0298 - val_starts_loss: 1.5306 - val_stops_loss: 1.5356 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6255\n",
      "Epoch 730/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.0041 - starts_loss: 1.0155 - stops_loss: 0.9873 - starts_accuracy: 0.6746 - stops_accuracy: 0.7055 - val_loss: 3.0323 - val_starts_loss: 1.5308 - val_stops_loss: 1.5374 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6253\n",
      "Epoch 731/1000\n",
      "20803/20803 [==============================] - 13s 621us/sample - loss: 2.0127 - starts_loss: 1.0171 - stops_loss: 0.9956 - starts_accuracy: 0.6727 - stops_accuracy: 0.7037 - val_loss: 3.0351 - val_starts_loss: 1.5311 - val_stops_loss: 1.5396 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6245\n",
      "Epoch 732/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0136 - starts_loss: 1.0185 - stops_loss: 0.9961 - starts_accuracy: 0.6732 - stops_accuracy: 0.7021 - val_loss: 3.0358 - val_starts_loss: 1.5316 - val_stops_loss: 1.5398 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6245\n",
      "Epoch 733/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0145 - starts_loss: 1.0200 - stops_loss: 0.9950 - starts_accuracy: 0.6721 - stops_accuracy: 0.7036 - val_loss: 3.0346 - val_starts_loss: 1.5312 - val_stops_loss: 1.5391 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6249\n",
      "Epoch 734/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0031 - starts_loss: 1.0120 - stops_loss: 0.9939 - starts_accuracy: 0.6764 - stops_accuracy: 0.7036 - val_loss: 3.0326 - val_starts_loss: 1.5311 - val_stops_loss: 1.5376 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6255\n",
      "Epoch 735/1000\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 2.0033 - starts_loss: 1.0180 - stops_loss: 0.9909 - starts_accuracy: 0.6751 - stops_accuracy: 0.7034 - val_loss: 3.0337 - val_starts_loss: 1.5313 - val_stops_loss: 1.5384 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6253\n",
      "Epoch 736/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0167 - starts_loss: 1.0220 - stops_loss: 0.9979 - starts_accuracy: 0.6741 - stops_accuracy: 0.7000 - val_loss: 3.0331 - val_starts_loss: 1.5317 - val_stops_loss: 1.5377 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6253\n",
      "Epoch 737/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0076 - starts_loss: 1.0140 - stops_loss: 0.9908 - starts_accuracy: 0.6739 - stops_accuracy: 0.7009 - val_loss: 3.0320 - val_starts_loss: 1.5316 - val_stops_loss: 1.5369 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6255\n",
      "Epoch 738/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 1.9993 - starts_loss: 1.0188 - stops_loss: 0.9823 - starts_accuracy: 0.6762 - stops_accuracy: 0.7047 - val_loss: 3.0317 - val_starts_loss: 1.5312 - val_stops_loss: 1.5369 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6256\n",
      "Epoch 739/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0034 - starts_loss: 1.0175 - stops_loss: 0.9874 - starts_accuracy: 0.6695 - stops_accuracy: 0.7040 - val_loss: 3.0334 - val_starts_loss: 1.5311 - val_stops_loss: 1.5383 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6255\n",
      "Epoch 740/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0100 - starts_loss: 1.0225 - stops_loss: 0.9914 - starts_accuracy: 0.6714 - stops_accuracy: 0.7024 - val_loss: 3.0335 - val_starts_loss: 1.5311 - val_stops_loss: 1.5384 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6251\n",
      "Epoch 741/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0044 - starts_loss: 1.0130 - stops_loss: 0.9879 - starts_accuracy: 0.6739 - stops_accuracy: 0.7048 - val_loss: 3.0341 - val_starts_loss: 1.5313 - val_stops_loss: 1.5386 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6251\n",
      "Epoch 742/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0219 - starts_loss: 1.0187 - stops_loss: 0.9993 - starts_accuracy: 0.6736 - stops_accuracy: 0.6996 - val_loss: 3.0338 - val_starts_loss: 1.5316 - val_stops_loss: 1.5381 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6249\n",
      "Epoch 743/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0149 - starts_loss: 1.0246 - stops_loss: 0.9903 - starts_accuracy: 0.6731 - stops_accuracy: 0.7036 - val_loss: 3.0334 - val_starts_loss: 1.5318 - val_stops_loss: 1.5374 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6249\n",
      "Epoch 744/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 2.0122 - starts_loss: 1.0142 - stops_loss: 0.9915 - starts_accuracy: 0.6738 - stops_accuracy: 0.7020 - val_loss: 3.0344 - val_starts_loss: 1.5318 - val_stops_loss: 1.5384 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6251\n",
      "Epoch 745/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0144 - starts_loss: 1.0165 - stops_loss: 0.9950 - starts_accuracy: 0.6738 - stops_accuracy: 0.7038 - val_loss: 3.0334 - val_starts_loss: 1.5316 - val_stops_loss: 1.5377 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6251\n",
      "Epoch 746/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0054 - starts_loss: 1.0234 - stops_loss: 0.9839 - starts_accuracy: 0.6735 - stops_accuracy: 0.7056 - val_loss: 3.0338 - val_starts_loss: 1.5312 - val_stops_loss: 1.5383 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6253\n",
      "Epoch 747/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.0026 - starts_loss: 1.0231 - stops_loss: 0.9803 - starts_accuracy: 0.6743 - stops_accuracy: 0.7074 - val_loss: 3.0342 - val_starts_loss: 1.5310 - val_stops_loss: 1.5389 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6256\n",
      "Epoch 748/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.0019 - starts_loss: 1.0118 - stops_loss: 0.9919 - starts_accuracy: 0.6755 - stops_accuracy: 0.7039 - val_loss: 3.0348 - val_starts_loss: 1.5307 - val_stops_loss: 1.5397 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6256\n",
      "Epoch 749/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0196 - starts_loss: 1.0197 - stops_loss: 1.0001 - starts_accuracy: 0.6700 - stops_accuracy: 0.7021 - val_loss: 3.0339 - val_starts_loss: 1.5305 - val_stops_loss: 1.5391 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6255\n",
      "Epoch 750/1000\n",
      "20803/20803 [==============================] - 12s 601us/sample - loss: 2.0137 - starts_loss: 1.0171 - stops_loss: 0.9925 - starts_accuracy: 0.6738 - stops_accuracy: 0.6996 - val_loss: 3.0346 - val_starts_loss: 1.5305 - val_stops_loss: 1.5398 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6251\n",
      "Epoch 751/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0074 - starts_loss: 1.0172 - stops_loss: 0.9870 - starts_accuracy: 0.6735 - stops_accuracy: 0.7043 - val_loss: 3.0339 - val_starts_loss: 1.5307 - val_stops_loss: 1.5391 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6255\n",
      "Epoch 752/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0139 - starts_loss: 1.0188 - stops_loss: 0.9968 - starts_accuracy: 0.6749 - stops_accuracy: 0.7031 - val_loss: 3.0356 - val_starts_loss: 1.5311 - val_stops_loss: 1.5403 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6251\n",
      "Epoch 753/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0062 - starts_loss: 1.0144 - stops_loss: 0.9847 - starts_accuracy: 0.6737 - stops_accuracy: 0.7010 - val_loss: 3.0360 - val_starts_loss: 1.5316 - val_stops_loss: 1.5403 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6251\n",
      "Epoch 754/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0135 - starts_loss: 1.0196 - stops_loss: 0.9917 - starts_accuracy: 0.6724 - stops_accuracy: 0.7016 - val_loss: 3.0356 - val_starts_loss: 1.5317 - val_stops_loss: 1.5398 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 755/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0060 - starts_loss: 1.0121 - stops_loss: 0.9937 - starts_accuracy: 0.6745 - stops_accuracy: 0.7033 - val_loss: 3.0359 - val_starts_loss: 1.5319 - val_stops_loss: 1.5399 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6255\n",
      "Epoch 756/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0184 - starts_loss: 1.0232 - stops_loss: 0.9979 - starts_accuracy: 0.6714 - stops_accuracy: 0.7030 - val_loss: 3.0359 - val_starts_loss: 1.5322 - val_stops_loss: 1.5398 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6253\n",
      "Epoch 757/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0068 - starts_loss: 1.0146 - stops_loss: 0.9930 - starts_accuracy: 0.6748 - stops_accuracy: 0.7008 - val_loss: 3.0343 - val_starts_loss: 1.5320 - val_stops_loss: 1.5387 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6256\n",
      "Epoch 758/1000\n",
      "20803/20803 [==============================] - 13s 619us/sample - loss: 2.0098 - starts_loss: 1.0150 - stops_loss: 0.9917 - starts_accuracy: 0.6752 - stops_accuracy: 0.7047 - val_loss: 3.0333 - val_starts_loss: 1.5317 - val_stops_loss: 1.5380 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6256\n",
      "Epoch 759/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0086 - starts_loss: 1.0177 - stops_loss: 0.9873 - starts_accuracy: 0.6753 - stops_accuracy: 0.7041 - val_loss: 3.0320 - val_starts_loss: 1.5320 - val_stops_loss: 1.5365 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6253\n",
      "Epoch 760/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0076 - starts_loss: 1.0214 - stops_loss: 0.9891 - starts_accuracy: 0.6727 - stops_accuracy: 0.7008 - val_loss: 3.0322 - val_starts_loss: 1.5315 - val_stops_loss: 1.5371 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6253\n",
      "Epoch 761/1000\n",
      "20803/20803 [==============================] - 13s 625us/sample - loss: 2.0022 - starts_loss: 1.0124 - stops_loss: 0.9940 - starts_accuracy: 0.6751 - stops_accuracy: 0.7021 - val_loss: 3.0354 - val_starts_loss: 1.5316 - val_stops_loss: 1.5398 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6253\n",
      "Epoch 762/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 1.9974 - starts_loss: 1.0153 - stops_loss: 0.9819 - starts_accuracy: 0.6711 - stops_accuracy: 0.7061 - val_loss: 3.0348 - val_starts_loss: 1.5317 - val_stops_loss: 1.5391 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6249\n",
      "Epoch 763/1000\n",
      "20803/20803 [==============================] - 13s 617us/sample - loss: 2.0028 - starts_loss: 1.0157 - stops_loss: 0.9904 - starts_accuracy: 0.6769 - stops_accuracy: 0.7040 - val_loss: 3.0343 - val_starts_loss: 1.5316 - val_stops_loss: 1.5386 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6253\n",
      "Epoch 764/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0020 - starts_loss: 1.0105 - stops_loss: 0.9811 - starts_accuracy: 0.6720 - stops_accuracy: 0.7054 - val_loss: 3.0330 - val_starts_loss: 1.5313 - val_stops_loss: 1.5377 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6249\n",
      "Epoch 765/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0017 - starts_loss: 1.0106 - stops_loss: 0.9917 - starts_accuracy: 0.6768 - stops_accuracy: 0.7031 - val_loss: 3.0322 - val_starts_loss: 1.5309 - val_stops_loss: 1.5373 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6249\n",
      "Epoch 766/1000\n",
      "20803/20803 [==============================] - 13s 620us/sample - loss: 2.0031 - starts_loss: 1.0182 - stops_loss: 0.9861 - starts_accuracy: 0.6718 - stops_accuracy: 0.7032 - val_loss: 3.0328 - val_starts_loss: 1.5311 - val_stops_loss: 1.5376 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6253\n",
      "Epoch 767/1000\n",
      "20803/20803 [==============================] - 13s 620us/sample - loss: 1.9983 - starts_loss: 1.0140 - stops_loss: 0.9848 - starts_accuracy: 0.6757 - stops_accuracy: 0.7047 - val_loss: 3.0316 - val_starts_loss: 1.5312 - val_stops_loss: 1.5367 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6251\n",
      "Epoch 768/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 2.0034 - starts_loss: 1.0211 - stops_loss: 0.9872 - starts_accuracy: 0.6724 - stops_accuracy: 0.7067 - val_loss: 3.0316 - val_starts_loss: 1.5313 - val_stops_loss: 1.5367 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6253\n",
      "Epoch 769/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0117 - starts_loss: 1.0249 - stops_loss: 0.9904 - starts_accuracy: 0.6736 - stops_accuracy: 0.7036 - val_loss: 3.0337 - val_starts_loss: 1.5311 - val_stops_loss: 1.5386 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6256\n",
      "Epoch 770/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0102 - starts_loss: 1.0203 - stops_loss: 0.9827 - starts_accuracy: 0.6741 - stops_accuracy: 0.7035 - val_loss: 3.0349 - val_starts_loss: 1.5315 - val_stops_loss: 1.5394 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6255\n",
      "Epoch 771/1000\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 2.0120 - starts_loss: 1.0124 - stops_loss: 0.9951 - starts_accuracy: 0.6736 - stops_accuracy: 0.7007 - val_loss: 3.0354 - val_starts_loss: 1.5313 - val_stops_loss: 1.5401 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6253\n",
      "Epoch 772/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0090 - starts_loss: 1.0167 - stops_loss: 0.9897 - starts_accuracy: 0.6717 - stops_accuracy: 0.7036 - val_loss: 3.0370 - val_starts_loss: 1.5317 - val_stops_loss: 1.5413 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6247\n",
      "Epoch 773/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0078 - starts_loss: 1.0148 - stops_loss: 0.9923 - starts_accuracy: 0.6724 - stops_accuracy: 0.7029 - val_loss: 3.0359 - val_starts_loss: 1.5318 - val_stops_loss: 1.5403 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6253\n",
      "Epoch 774/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0081 - starts_loss: 1.0220 - stops_loss: 0.9865 - starts_accuracy: 0.6741 - stops_accuracy: 0.7045 - val_loss: 3.0356 - val_starts_loss: 1.5318 - val_stops_loss: 1.5400 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6253\n",
      "Epoch 775/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 1.9862 - starts_loss: 1.0107 - stops_loss: 0.9754 - starts_accuracy: 0.6755 - stops_accuracy: 0.7085 - val_loss: 3.0359 - val_starts_loss: 1.5319 - val_stops_loss: 1.5401 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6255\n",
      "Epoch 776/1000\n",
      "20803/20803 [==============================] - 12s 591us/sample - loss: 2.0098 - starts_loss: 1.0156 - stops_loss: 0.9929 - starts_accuracy: 0.6742 - stops_accuracy: 0.7045 - val_loss: 3.0348 - val_starts_loss: 1.5314 - val_stops_loss: 1.5396 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6255\n",
      "Epoch 777/1000\n",
      "20803/20803 [==============================] - 13s 618us/sample - loss: 2.0070 - starts_loss: 1.0088 - stops_loss: 0.9945 - starts_accuracy: 0.6748 - stops_accuracy: 0.7011 - val_loss: 3.0379 - val_starts_loss: 1.5318 - val_stops_loss: 1.5419 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6249\n",
      "Epoch 778/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0044 - starts_loss: 1.0216 - stops_loss: 0.9846 - starts_accuracy: 0.6711 - stops_accuracy: 0.7048 - val_loss: 3.0377 - val_starts_loss: 1.5324 - val_stops_loss: 1.5413 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6253\n",
      "Epoch 779/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.0042 - starts_loss: 1.0102 - stops_loss: 0.9936 - starts_accuracy: 0.6762 - stops_accuracy: 0.7020 - val_loss: 3.0369 - val_starts_loss: 1.5324 - val_stops_loss: 1.5405 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6256\n",
      "Epoch 780/1000\n",
      "20803/20803 [==============================] - 13s 618us/sample - loss: 1.9961 - starts_loss: 1.0162 - stops_loss: 0.9807 - starts_accuracy: 0.6759 - stops_accuracy: 0.7065 - val_loss: 3.0347 - val_starts_loss: 1.5323 - val_stops_loss: 1.5387 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 781/1000\n",
      "20803/20803 [==============================] - 13s 624us/sample - loss: 2.0056 - starts_loss: 1.0139 - stops_loss: 0.9883 - starts_accuracy: 0.6707 - stops_accuracy: 0.7050 - val_loss: 3.0356 - val_starts_loss: 1.5322 - val_stops_loss: 1.5396 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6255\n",
      "Epoch 782/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 1.9971 - starts_loss: 1.0119 - stops_loss: 0.9826 - starts_accuracy: 0.6745 - stops_accuracy: 0.7058 - val_loss: 3.0388 - val_starts_loss: 1.5326 - val_stops_loss: 1.5420 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6251\n",
      "Epoch 783/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.0042 - starts_loss: 1.0107 - stops_loss: 0.9900 - starts_accuracy: 0.6754 - stops_accuracy: 0.7024 - val_loss: 3.0379 - val_starts_loss: 1.5327 - val_stops_loss: 1.5412 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6251\n",
      "Epoch 784/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 1.9990 - starts_loss: 1.0059 - stops_loss: 0.9887 - starts_accuracy: 0.6733 - stops_accuracy: 0.7042 - val_loss: 3.0392 - val_starts_loss: 1.5331 - val_stops_loss: 1.5420 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6253\n",
      "Epoch 785/1000\n",
      "20803/20803 [==============================] - 13s 620us/sample - loss: 2.0050 - starts_loss: 1.0162 - stops_loss: 0.9929 - starts_accuracy: 0.6728 - stops_accuracy: 0.7004 - val_loss: 3.0400 - val_starts_loss: 1.5334 - val_stops_loss: 1.5424 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6251\n",
      "Epoch 786/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0060 - starts_loss: 1.0189 - stops_loss: 0.9841 - starts_accuracy: 0.6725 - stops_accuracy: 0.7033 - val_loss: 3.0399 - val_starts_loss: 1.5335 - val_stops_loss: 1.5424 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6249\n",
      "Epoch 787/1000\n",
      "20803/20803 [==============================] - 12s 595us/sample - loss: 2.0007 - starts_loss: 1.0087 - stops_loss: 0.9875 - starts_accuracy: 0.6751 - stops_accuracy: 0.7048 - val_loss: 3.0409 - val_starts_loss: 1.5340 - val_stops_loss: 1.5430 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6249\n",
      "Epoch 788/1000\n",
      "20803/20803 [==============================] - 13s 620us/sample - loss: 2.0083 - starts_loss: 1.0218 - stops_loss: 0.9886 - starts_accuracy: 0.6740 - stops_accuracy: 0.7036 - val_loss: 3.0409 - val_starts_loss: 1.5344 - val_stops_loss: 1.5428 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6247\n",
      "Epoch 789/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 1.9892 - starts_loss: 1.0027 - stops_loss: 0.9819 - starts_accuracy: 0.6744 - stops_accuracy: 0.7044 - val_loss: 3.0382 - val_starts_loss: 1.5340 - val_stops_loss: 1.5408 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6253\n",
      "Epoch 790/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0056 - starts_loss: 1.0177 - stops_loss: 0.9885 - starts_accuracy: 0.6739 - stops_accuracy: 0.7006 - val_loss: 3.0372 - val_starts_loss: 1.5338 - val_stops_loss: 1.5402 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6253\n",
      "Epoch 791/1000\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 1.9928 - starts_loss: 1.0072 - stops_loss: 0.9818 - starts_accuracy: 0.6750 - stops_accuracy: 0.7017 - val_loss: 3.0360 - val_starts_loss: 1.5338 - val_stops_loss: 1.5390 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6251\n",
      "Epoch 792/1000\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 2.0079 - starts_loss: 1.0213 - stops_loss: 0.9933 - starts_accuracy: 0.6691 - stops_accuracy: 0.7020 - val_loss: 3.0370 - val_starts_loss: 1.5339 - val_stops_loss: 1.5398 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6251\n",
      "Epoch 793/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0053 - starts_loss: 1.0172 - stops_loss: 0.9923 - starts_accuracy: 0.6757 - stops_accuracy: 0.7058 - val_loss: 3.0384 - val_starts_loss: 1.5337 - val_stops_loss: 1.5411 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6251\n",
      "Epoch 794/1000\n",
      "20803/20803 [==============================] - 12s 601us/sample - loss: 2.0140 - starts_loss: 1.0182 - stops_loss: 1.0012 - starts_accuracy: 0.6755 - stops_accuracy: 0.7023 - val_loss: 3.0384 - val_starts_loss: 1.5338 - val_stops_loss: 1.5409 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6253\n",
      "Epoch 795/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0040 - starts_loss: 1.0137 - stops_loss: 0.9843 - starts_accuracy: 0.6734 - stops_accuracy: 0.7010 - val_loss: 3.0378 - val_starts_loss: 1.5337 - val_stops_loss: 1.5404 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6253\n",
      "Epoch 796/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 2.0114 - starts_loss: 1.0185 - stops_loss: 0.9943 - starts_accuracy: 0.6728 - stops_accuracy: 0.7038 - val_loss: 3.0390 - val_starts_loss: 1.5337 - val_stops_loss: 1.5414 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6256\n",
      "Epoch 797/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 2.0045 - starts_loss: 1.0148 - stops_loss: 0.9923 - starts_accuracy: 0.6760 - stops_accuracy: 0.7049 - val_loss: 3.0369 - val_starts_loss: 1.5336 - val_stops_loss: 1.5398 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6253\n",
      "Epoch 798/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0070 - starts_loss: 1.0226 - stops_loss: 0.9900 - starts_accuracy: 0.6718 - stops_accuracy: 0.7055 - val_loss: 3.0363 - val_starts_loss: 1.5335 - val_stops_loss: 1.5394 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6253\n",
      "Epoch 799/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0052 - starts_loss: 1.0210 - stops_loss: 0.9933 - starts_accuracy: 0.6756 - stops_accuracy: 0.7042 - val_loss: 3.0368 - val_starts_loss: 1.5333 - val_stops_loss: 1.5399 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6253\n",
      "Epoch 800/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 1.9937 - starts_loss: 1.0090 - stops_loss: 0.9866 - starts_accuracy: 0.6767 - stops_accuracy: 0.7036 - val_loss: 3.0369 - val_starts_loss: 1.5334 - val_stops_loss: 1.5399 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6253\n",
      "Epoch 801/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.0005 - starts_loss: 1.0168 - stops_loss: 0.9942 - starts_accuracy: 0.6737 - stops_accuracy: 0.7058 - val_loss: 3.0383 - val_starts_loss: 1.5333 - val_stops_loss: 1.5411 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6255\n",
      "Epoch 802/1000\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 2.0043 - starts_loss: 1.0155 - stops_loss: 0.9888 - starts_accuracy: 0.6746 - stops_accuracy: 0.7037 - val_loss: 3.0387 - val_starts_loss: 1.5334 - val_stops_loss: 1.5414 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6255\n",
      "Epoch 803/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 2.0129 - starts_loss: 1.0208 - stops_loss: 0.9905 - starts_accuracy: 0.6739 - stops_accuracy: 0.6998 - val_loss: 3.0387 - val_starts_loss: 1.5332 - val_stops_loss: 1.5415 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6253\n",
      "Epoch 804/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0006 - starts_loss: 1.0154 - stops_loss: 0.9818 - starts_accuracy: 0.6742 - stops_accuracy: 0.7042 - val_loss: 3.0401 - val_starts_loss: 1.5334 - val_stops_loss: 1.5426 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6255\n",
      "Epoch 805/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 1.9948 - starts_loss: 1.0164 - stops_loss: 0.9852 - starts_accuracy: 0.6749 - stops_accuracy: 0.7036 - val_loss: 3.0394 - val_starts_loss: 1.5334 - val_stops_loss: 1.5419 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6255\n",
      "Epoch 806/1000\n",
      "20803/20803 [==============================] - 13s 617us/sample - loss: 2.0011 - starts_loss: 1.0109 - stops_loss: 0.9906 - starts_accuracy: 0.6755 - stops_accuracy: 0.7062 - val_loss: 3.0383 - val_starts_loss: 1.5335 - val_stops_loss: 1.5409 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 807/1000\n",
      "20803/20803 [==============================] - 12s 601us/sample - loss: 2.0041 - starts_loss: 1.0088 - stops_loss: 0.9965 - starts_accuracy: 0.6741 - stops_accuracy: 0.7027 - val_loss: 3.0371 - val_starts_loss: 1.5332 - val_stops_loss: 1.5402 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6255\n",
      "Epoch 808/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 1.9867 - starts_loss: 1.0075 - stops_loss: 0.9806 - starts_accuracy: 0.6760 - stops_accuracy: 0.7044 - val_loss: 3.0365 - val_starts_loss: 1.5330 - val_stops_loss: 1.5397 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6253\n",
      "Epoch 809/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 1.9930 - starts_loss: 1.0110 - stops_loss: 0.9791 - starts_accuracy: 0.6731 - stops_accuracy: 0.7057 - val_loss: 3.0371 - val_starts_loss: 1.5327 - val_stops_loss: 1.5405 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6253\n",
      "Epoch 810/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0157 - starts_loss: 1.0186 - stops_loss: 0.9980 - starts_accuracy: 0.6737 - stops_accuracy: 0.7021 - val_loss: 3.0383 - val_starts_loss: 1.5326 - val_stops_loss: 1.5416 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6251\n",
      "Epoch 811/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 1.9893 - starts_loss: 1.0144 - stops_loss: 0.9793 - starts_accuracy: 0.6732 - stops_accuracy: 0.7081 - val_loss: 3.0404 - val_starts_loss: 1.5327 - val_stops_loss: 1.5433 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6251\n",
      "Epoch 812/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 1.9989 - starts_loss: 1.0140 - stops_loss: 0.9789 - starts_accuracy: 0.6712 - stops_accuracy: 0.7066 - val_loss: 3.0428 - val_starts_loss: 1.5328 - val_stops_loss: 1.5453 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6253\n",
      "Epoch 813/1000\n",
      "20803/20803 [==============================] - 13s 617us/sample - loss: 2.0019 - starts_loss: 1.0135 - stops_loss: 0.9848 - starts_accuracy: 0.6721 - stops_accuracy: 0.7036 - val_loss: 3.0415 - val_starts_loss: 1.5331 - val_stops_loss: 1.5441 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6247\n",
      "Epoch 814/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0137 - starts_loss: 1.0182 - stops_loss: 0.9928 - starts_accuracy: 0.6697 - stops_accuracy: 0.7024 - val_loss: 3.0401 - val_starts_loss: 1.5332 - val_stops_loss: 1.5429 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6247\n",
      "Epoch 815/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 2.0041 - starts_loss: 1.0159 - stops_loss: 0.9819 - starts_accuracy: 0.6711 - stops_accuracy: 0.6996 - val_loss: 3.0394 - val_starts_loss: 1.5333 - val_stops_loss: 1.5423 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6251\n",
      "Epoch 816/1000\n",
      "20803/20803 [==============================] - 13s 624us/sample - loss: 2.0031 - starts_loss: 1.0185 - stops_loss: 0.9871 - starts_accuracy: 0.6774 - stops_accuracy: 0.7040 - val_loss: 3.0376 - val_starts_loss: 1.5333 - val_stops_loss: 1.5408 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6253\n",
      "Epoch 817/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 1.9957 - starts_loss: 1.0156 - stops_loss: 0.9808 - starts_accuracy: 0.6760 - stops_accuracy: 0.7054 - val_loss: 3.0345 - val_starts_loss: 1.5329 - val_stops_loss: 1.5385 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6249\n",
      "Epoch 818/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 2.0072 - starts_loss: 1.0182 - stops_loss: 0.9874 - starts_accuracy: 0.6742 - stops_accuracy: 0.7050 - val_loss: 3.0365 - val_starts_loss: 1.5329 - val_stops_loss: 1.5401 - val_starts_accuracy: 0.6162 - val_stops_accuracy: 0.6253\n",
      "Epoch 819/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 1.9900 - starts_loss: 1.0079 - stops_loss: 0.9874 - starts_accuracy: 0.6768 - stops_accuracy: 0.7060 - val_loss: 3.0361 - val_starts_loss: 1.5328 - val_stops_loss: 1.5399 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6253\n",
      "Epoch 820/1000\n",
      "20803/20803 [==============================] - 13s 622us/sample - loss: 2.0097 - starts_loss: 1.0196 - stops_loss: 0.9879 - starts_accuracy: 0.6715 - stops_accuracy: 0.7040 - val_loss: 3.0372 - val_starts_loss: 1.5331 - val_stops_loss: 1.5406 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6255\n",
      "Epoch 821/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0020 - starts_loss: 1.0078 - stops_loss: 0.9915 - starts_accuracy: 0.6761 - stops_accuracy: 0.7040 - val_loss: 3.0371 - val_starts_loss: 1.5334 - val_stops_loss: 1.5402 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6255\n",
      "Epoch 822/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 1.9998 - starts_loss: 1.0126 - stops_loss: 0.9896 - starts_accuracy: 0.6742 - stops_accuracy: 0.7021 - val_loss: 3.0374 - val_starts_loss: 1.5337 - val_stops_loss: 1.5402 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6255\n",
      "Epoch 823/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0086 - starts_loss: 1.0171 - stops_loss: 0.9895 - starts_accuracy: 0.6713 - stops_accuracy: 0.7032 - val_loss: 3.0377 - val_starts_loss: 1.5339 - val_stops_loss: 1.5403 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6253\n",
      "Epoch 824/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 1.9917 - starts_loss: 1.0074 - stops_loss: 0.9883 - starts_accuracy: 0.6757 - stops_accuracy: 0.7061 - val_loss: 3.0385 - val_starts_loss: 1.5340 - val_stops_loss: 1.5408 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6255\n",
      "Epoch 825/1000\n",
      "20803/20803 [==============================] - 15s 702us/sample - loss: 1.9981 - starts_loss: 1.0110 - stops_loss: 0.9861 - starts_accuracy: 0.6769 - stops_accuracy: 0.7061 - val_loss: 3.0382 - val_starts_loss: 1.5337 - val_stops_loss: 1.5409 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6253\n",
      "Epoch 826/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 1.9990 - starts_loss: 1.0132 - stops_loss: 0.9844 - starts_accuracy: 0.6752 - stops_accuracy: 0.7047 - val_loss: 3.0387 - val_starts_loss: 1.5338 - val_stops_loss: 1.5412 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6258\n",
      "Epoch 827/1000\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 1.9860 - starts_loss: 1.0121 - stops_loss: 0.9760 - starts_accuracy: 0.6760 - stops_accuracy: 0.7087 - val_loss: 3.0375 - val_starts_loss: 1.5339 - val_stops_loss: 1.5403 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6255\n",
      "Epoch 828/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 1.9972 - starts_loss: 1.0114 - stops_loss: 0.9859 - starts_accuracy: 0.6761 - stops_accuracy: 0.7048 - val_loss: 3.0360 - val_starts_loss: 1.5337 - val_stops_loss: 1.5391 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6253\n",
      "Epoch 829/1000\n",
      "20803/20803 [==============================] - 13s 622us/sample - loss: 1.9992 - starts_loss: 1.0143 - stops_loss: 0.9892 - starts_accuracy: 0.6745 - stops_accuracy: 0.7062 - val_loss: 3.0362 - val_starts_loss: 1.5336 - val_stops_loss: 1.5393 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6251\n",
      "Epoch 830/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 2.0018 - starts_loss: 1.0110 - stops_loss: 0.9878 - starts_accuracy: 0.6761 - stops_accuracy: 0.7018 - val_loss: 3.0365 - val_starts_loss: 1.5333 - val_stops_loss: 1.5398 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6253\n",
      "Epoch 831/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 1.9976 - starts_loss: 1.0123 - stops_loss: 0.9844 - starts_accuracy: 0.6740 - stops_accuracy: 0.7053 - val_loss: 3.0367 - val_starts_loss: 1.5333 - val_stops_loss: 1.5399 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6253\n",
      "Epoch 832/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 1.9840 - starts_loss: 1.0061 - stops_loss: 0.9780 - starts_accuracy: 0.6752 - stops_accuracy: 0.7074 - val_loss: 3.0372 - val_starts_loss: 1.5332 - val_stops_loss: 1.5405 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 833/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 1.9994 - starts_loss: 1.0148 - stops_loss: 0.9853 - starts_accuracy: 0.6746 - stops_accuracy: 0.7061 - val_loss: 3.0385 - val_starts_loss: 1.5336 - val_stops_loss: 1.5412 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6256\n",
      "Epoch 834/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 1.9962 - starts_loss: 1.0130 - stops_loss: 0.9882 - starts_accuracy: 0.6759 - stops_accuracy: 0.7019 - val_loss: 3.0390 - val_starts_loss: 1.5335 - val_stops_loss: 1.5417 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6256\n",
      "Epoch 835/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 1.9948 - starts_loss: 1.0124 - stops_loss: 0.9893 - starts_accuracy: 0.6763 - stops_accuracy: 0.7027 - val_loss: 3.0406 - val_starts_loss: 1.5337 - val_stops_loss: 1.5431 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6251\n",
      "Epoch 836/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 1.9978 - starts_loss: 1.0109 - stops_loss: 0.9859 - starts_accuracy: 0.6766 - stops_accuracy: 0.7039 - val_loss: 3.0395 - val_starts_loss: 1.5335 - val_stops_loss: 1.5424 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6253\n",
      "Epoch 837/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0050 - starts_loss: 1.0158 - stops_loss: 0.9863 - starts_accuracy: 0.6732 - stops_accuracy: 0.7050 - val_loss: 3.0390 - val_starts_loss: 1.5335 - val_stops_loss: 1.5418 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6255\n",
      "Epoch 838/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 1.9933 - starts_loss: 1.0096 - stops_loss: 0.9815 - starts_accuracy: 0.6750 - stops_accuracy: 0.7060 - val_loss: 3.0377 - val_starts_loss: 1.5330 - val_stops_loss: 1.5413 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6251\n",
      "Epoch 839/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 2.0074 - starts_loss: 1.0213 - stops_loss: 0.9909 - starts_accuracy: 0.6728 - stops_accuracy: 0.7027 - val_loss: 3.0381 - val_starts_loss: 1.5332 - val_stops_loss: 1.5414 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6251\n",
      "Epoch 840/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0055 - starts_loss: 1.0242 - stops_loss: 0.9815 - starts_accuracy: 0.6769 - stops_accuracy: 0.7073 - val_loss: 3.0379 - val_starts_loss: 1.5336 - val_stops_loss: 1.5410 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6249\n",
      "Epoch 841/1000\n",
      "20803/20803 [==============================] - 12s 595us/sample - loss: 2.0039 - starts_loss: 1.0127 - stops_loss: 0.9908 - starts_accuracy: 0.6711 - stops_accuracy: 0.7020 - val_loss: 3.0383 - val_starts_loss: 1.5338 - val_stops_loss: 1.5411 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6245\n",
      "Epoch 842/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 1.9986 - starts_loss: 1.0189 - stops_loss: 0.9820 - starts_accuracy: 0.6745 - stops_accuracy: 0.7039 - val_loss: 3.0383 - val_starts_loss: 1.5334 - val_stops_loss: 1.5415 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6253\n",
      "Epoch 843/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 1.9941 - starts_loss: 1.0191 - stops_loss: 0.9810 - starts_accuracy: 0.6769 - stops_accuracy: 0.7049 - val_loss: 3.0381 - val_starts_loss: 1.5333 - val_stops_loss: 1.5414 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6255\n",
      "Epoch 844/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 1.9992 - starts_loss: 1.0161 - stops_loss: 0.9784 - starts_accuracy: 0.6741 - stops_accuracy: 0.7061 - val_loss: 3.0372 - val_starts_loss: 1.5333 - val_stops_loss: 1.5407 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6251\n",
      "Epoch 845/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0035 - starts_loss: 1.0128 - stops_loss: 0.9863 - starts_accuracy: 0.6718 - stops_accuracy: 0.7021 - val_loss: 3.0366 - val_starts_loss: 1.5334 - val_stops_loss: 1.5401 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6249\n",
      "Epoch 846/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 2.0025 - starts_loss: 1.0138 - stops_loss: 0.9822 - starts_accuracy: 0.6754 - stops_accuracy: 0.7019 - val_loss: 3.0366 - val_starts_loss: 1.5333 - val_stops_loss: 1.5401 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6251\n",
      "Epoch 847/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 1.9963 - starts_loss: 1.0116 - stops_loss: 0.9793 - starts_accuracy: 0.6711 - stops_accuracy: 0.7049 - val_loss: 3.0382 - val_starts_loss: 1.5335 - val_stops_loss: 1.5413 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6251\n",
      "Epoch 848/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 2.0015 - starts_loss: 1.0110 - stops_loss: 0.9949 - starts_accuracy: 0.6769 - stops_accuracy: 0.6998 - val_loss: 3.0402 - val_starts_loss: 1.5337 - val_stops_loss: 1.5429 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6251\n",
      "Epoch 849/1000\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 2.0027 - starts_loss: 1.0173 - stops_loss: 0.9886 - starts_accuracy: 0.6719 - stops_accuracy: 0.7058 - val_loss: 3.0408 - val_starts_loss: 1.5343 - val_stops_loss: 1.5430 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6247\n",
      "Epoch 850/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 1.9948 - starts_loss: 1.0165 - stops_loss: 0.9821 - starts_accuracy: 0.6739 - stops_accuracy: 0.7074 - val_loss: 3.0397 - val_starts_loss: 1.5342 - val_stops_loss: 1.5422 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6249\n",
      "Epoch 851/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 1.9959 - starts_loss: 1.0089 - stops_loss: 0.9805 - starts_accuracy: 0.6712 - stops_accuracy: 0.7067 - val_loss: 3.0392 - val_starts_loss: 1.5342 - val_stops_loss: 1.5417 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6249\n",
      "Epoch 852/1000\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 2.0023 - starts_loss: 1.0066 - stops_loss: 0.9944 - starts_accuracy: 0.6757 - stops_accuracy: 0.7059 - val_loss: 3.0406 - val_starts_loss: 1.5345 - val_stops_loss: 1.5427 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6253\n",
      "Epoch 853/1000\n",
      "20803/20803 [==============================] - 13s 620us/sample - loss: 1.9976 - starts_loss: 1.0159 - stops_loss: 0.9821 - starts_accuracy: 0.6734 - stops_accuracy: 0.7060 - val_loss: 3.0422 - val_starts_loss: 1.5349 - val_stops_loss: 1.5437 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6253\n",
      "Epoch 854/1000\n",
      "20803/20803 [==============================] - 13s 618us/sample - loss: 2.0028 - starts_loss: 1.0163 - stops_loss: 0.9879 - starts_accuracy: 0.6752 - stops_accuracy: 0.7042 - val_loss: 3.0400 - val_starts_loss: 1.5349 - val_stops_loss: 1.5418 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6256\n",
      "Epoch 855/1000\n",
      "20803/20803 [==============================] - 13s 631us/sample - loss: 2.0015 - starts_loss: 1.0154 - stops_loss: 0.9849 - starts_accuracy: 0.6731 - stops_accuracy: 0.7024 - val_loss: 3.0400 - val_starts_loss: 1.5351 - val_stops_loss: 1.5417 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6255\n",
      "Epoch 856/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 1.9932 - starts_loss: 1.0113 - stops_loss: 0.9828 - starts_accuracy: 0.6752 - stops_accuracy: 0.7040 - val_loss: 3.0418 - val_starts_loss: 1.5351 - val_stops_loss: 1.5432 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6256\n",
      "Epoch 857/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 1.9954 - starts_loss: 1.0147 - stops_loss: 0.9849 - starts_accuracy: 0.6723 - stops_accuracy: 0.7031 - val_loss: 3.0393 - val_starts_loss: 1.5351 - val_stops_loss: 1.5411 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6253\n",
      "Epoch 858/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0006 - starts_loss: 1.0135 - stops_loss: 0.9845 - starts_accuracy: 0.6747 - stops_accuracy: 0.7071 - val_loss: 3.0387 - val_starts_loss: 1.5348 - val_stops_loss: 1.5409 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 859/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 1.9981 - starts_loss: 1.0151 - stops_loss: 0.9859 - starts_accuracy: 0.6737 - stops_accuracy: 0.7046 - val_loss: 3.0388 - val_starts_loss: 1.5346 - val_stops_loss: 1.5412 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6255\n",
      "Epoch 860/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 1.9847 - starts_loss: 1.0075 - stops_loss: 0.9700 - starts_accuracy: 0.6772 - stops_accuracy: 0.7075 - val_loss: 3.0389 - val_starts_loss: 1.5341 - val_stops_loss: 1.5418 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6253\n",
      "Epoch 861/1000\n",
      "20803/20803 [==============================] - 13s 618us/sample - loss: 1.9914 - starts_loss: 1.0109 - stops_loss: 0.9813 - starts_accuracy: 0.6740 - stops_accuracy: 0.7055 - val_loss: 3.0377 - val_starts_loss: 1.5340 - val_stops_loss: 1.5408 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6253\n",
      "Epoch 862/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0046 - starts_loss: 1.0136 - stops_loss: 0.9873 - starts_accuracy: 0.6755 - stops_accuracy: 0.7032 - val_loss: 3.0394 - val_starts_loss: 1.5342 - val_stops_loss: 1.5421 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6253\n",
      "Epoch 863/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 1.9868 - starts_loss: 1.0052 - stops_loss: 0.9821 - starts_accuracy: 0.6753 - stops_accuracy: 0.7075 - val_loss: 3.0435 - val_starts_loss: 1.5347 - val_stops_loss: 1.5451 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6253\n",
      "Epoch 864/1000\n",
      "20803/20803 [==============================] - 12s 594us/sample - loss: 2.0012 - starts_loss: 1.0200 - stops_loss: 0.9885 - starts_accuracy: 0.6736 - stops_accuracy: 0.7038 - val_loss: 3.0429 - val_starts_loss: 1.5347 - val_stops_loss: 1.5447 - val_starts_accuracy: 0.6143 - val_stops_accuracy: 0.6255\n",
      "Epoch 865/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 1.9986 - starts_loss: 1.0086 - stops_loss: 0.9854 - starts_accuracy: 0.6770 - stops_accuracy: 0.7043 - val_loss: 3.0418 - val_starts_loss: 1.5350 - val_stops_loss: 1.5435 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6253\n",
      "Epoch 866/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0040 - starts_loss: 1.0096 - stops_loss: 0.9917 - starts_accuracy: 0.6763 - stops_accuracy: 0.7011 - val_loss: 3.0407 - val_starts_loss: 1.5352 - val_stops_loss: 1.5425 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6255\n",
      "Epoch 867/1000\n",
      "20803/20803 [==============================] - 13s 619us/sample - loss: 1.9977 - starts_loss: 1.0125 - stops_loss: 0.9841 - starts_accuracy: 0.6735 - stops_accuracy: 0.7038 - val_loss: 3.0392 - val_starts_loss: 1.5351 - val_stops_loss: 1.5413 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6255\n",
      "Epoch 868/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 1.9922 - starts_loss: 1.0147 - stops_loss: 0.9837 - starts_accuracy: 0.6750 - stops_accuracy: 0.7089 - val_loss: 3.0405 - val_starts_loss: 1.5355 - val_stops_loss: 1.5422 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6256\n",
      "Epoch 869/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0074 - starts_loss: 1.0191 - stops_loss: 0.9902 - starts_accuracy: 0.6749 - stops_accuracy: 0.7071 - val_loss: 3.0409 - val_starts_loss: 1.5355 - val_stops_loss: 1.5425 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6262\n",
      "Epoch 870/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 1.9905 - starts_loss: 1.0101 - stops_loss: 0.9825 - starts_accuracy: 0.6741 - stops_accuracy: 0.7040 - val_loss: 3.0383 - val_starts_loss: 1.5351 - val_stops_loss: 1.5405 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6253\n",
      "Epoch 871/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 1.9981 - starts_loss: 1.0113 - stops_loss: 0.9907 - starts_accuracy: 0.6759 - stops_accuracy: 0.7023 - val_loss: 3.0399 - val_starts_loss: 1.5345 - val_stops_loss: 1.5425 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6258\n",
      "Epoch 872/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 1.9953 - starts_loss: 1.0077 - stops_loss: 0.9862 - starts_accuracy: 0.6775 - stops_accuracy: 0.7057 - val_loss: 3.0423 - val_starts_loss: 1.5349 - val_stops_loss: 1.5442 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6249\n",
      "Epoch 873/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 2.0040 - starts_loss: 1.0159 - stops_loss: 0.9848 - starts_accuracy: 0.6745 - stops_accuracy: 0.7015 - val_loss: 3.0417 - val_starts_loss: 1.5346 - val_stops_loss: 1.5439 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6251\n",
      "Epoch 874/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 1.9866 - starts_loss: 1.0122 - stops_loss: 0.9723 - starts_accuracy: 0.6764 - stops_accuracy: 0.7060 - val_loss: 3.0388 - val_starts_loss: 1.5342 - val_stops_loss: 1.5417 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6255\n",
      "Epoch 875/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 1.9836 - starts_loss: 1.0055 - stops_loss: 0.9790 - starts_accuracy: 0.6750 - stops_accuracy: 0.7063 - val_loss: 3.0395 - val_starts_loss: 1.5341 - val_stops_loss: 1.5424 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6249\n",
      "Epoch 876/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 2.0003 - starts_loss: 1.0212 - stops_loss: 0.9830 - starts_accuracy: 0.6754 - stops_accuracy: 0.7038 - val_loss: 3.0387 - val_starts_loss: 1.5342 - val_stops_loss: 1.5416 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6256\n",
      "Epoch 877/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 1.9885 - starts_loss: 1.0062 - stops_loss: 0.9800 - starts_accuracy: 0.6778 - stops_accuracy: 0.7054 - val_loss: 3.0388 - val_starts_loss: 1.5344 - val_stops_loss: 1.5416 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6253\n",
      "Epoch 878/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 2.0104 - starts_loss: 1.0186 - stops_loss: 0.9911 - starts_accuracy: 0.6738 - stops_accuracy: 0.7019 - val_loss: 3.0392 - val_starts_loss: 1.5345 - val_stops_loss: 1.5417 - val_starts_accuracy: 0.6162 - val_stops_accuracy: 0.6258\n",
      "Epoch 879/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 1.9855 - starts_loss: 1.0090 - stops_loss: 0.9740 - starts_accuracy: 0.6758 - stops_accuracy: 0.7068 - val_loss: 3.0389 - val_starts_loss: 1.5345 - val_stops_loss: 1.5415 - val_starts_accuracy: 0.6162 - val_stops_accuracy: 0.6251\n",
      "Epoch 880/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 1.9900 - starts_loss: 1.0069 - stops_loss: 0.9863 - starts_accuracy: 0.6783 - stops_accuracy: 0.7056 - val_loss: 3.0402 - val_starts_loss: 1.5346 - val_stops_loss: 1.5425 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6251\n",
      "Epoch 881/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 2.0000 - starts_loss: 1.0165 - stops_loss: 0.9818 - starts_accuracy: 0.6747 - stops_accuracy: 0.7098 - val_loss: 3.0386 - val_starts_loss: 1.5344 - val_stops_loss: 1.5414 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6247\n",
      "Epoch 882/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 1.9874 - starts_loss: 1.0148 - stops_loss: 0.9803 - starts_accuracy: 0.6752 - stops_accuracy: 0.7059 - val_loss: 3.0383 - val_starts_loss: 1.5343 - val_stops_loss: 1.5411 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6249\n",
      "Epoch 883/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.9876 - starts_loss: 1.0052 - stops_loss: 0.9795 - starts_accuracy: 0.6750 - stops_accuracy: 0.7083 - val_loss: 3.0398 - val_starts_loss: 1.5346 - val_stops_loss: 1.5422 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6247\n",
      "Epoch 884/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 2.0028 - starts_loss: 1.0201 - stops_loss: 0.9835 - starts_accuracy: 0.6738 - stops_accuracy: 0.7070 - val_loss: 3.0405 - val_starts_loss: 1.5349 - val_stops_loss: 1.5426 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 885/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 1.9858 - starts_loss: 1.0065 - stops_loss: 0.9795 - starts_accuracy: 0.6765 - stops_accuracy: 0.7098 - val_loss: 3.0410 - val_starts_loss: 1.5348 - val_stops_loss: 1.5431 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6251\n",
      "Epoch 886/1000\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 1.9794 - starts_loss: 1.0096 - stops_loss: 0.9776 - starts_accuracy: 0.6784 - stops_accuracy: 0.7080 - val_loss: 3.0410 - val_starts_loss: 1.5348 - val_stops_loss: 1.5433 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6249\n",
      "Epoch 887/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 2.0008 - starts_loss: 1.0100 - stops_loss: 0.9858 - starts_accuracy: 0.6769 - stops_accuracy: 0.7035 - val_loss: 3.0418 - val_starts_loss: 1.5352 - val_stops_loss: 1.5436 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6249\n",
      "Epoch 888/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 1.9868 - starts_loss: 1.0086 - stops_loss: 0.9784 - starts_accuracy: 0.6738 - stops_accuracy: 0.7080 - val_loss: 3.0407 - val_starts_loss: 1.5355 - val_stops_loss: 1.5424 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6251\n",
      "Epoch 889/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 1.9960 - starts_loss: 1.0177 - stops_loss: 0.9866 - starts_accuracy: 0.6732 - stops_accuracy: 0.7055 - val_loss: 3.0406 - val_starts_loss: 1.5356 - val_stops_loss: 1.5423 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6253\n",
      "Epoch 890/1000\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 1.9828 - starts_loss: 1.0105 - stops_loss: 0.9760 - starts_accuracy: 0.6753 - stops_accuracy: 0.7070 - val_loss: 3.0407 - val_starts_loss: 1.5355 - val_stops_loss: 1.5425 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6255\n",
      "Epoch 891/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 1.9975 - starts_loss: 1.0147 - stops_loss: 0.9868 - starts_accuracy: 0.6729 - stops_accuracy: 0.7021 - val_loss: 3.0417 - val_starts_loss: 1.5353 - val_stops_loss: 1.5435 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6251\n",
      "Epoch 892/1000\n",
      "20803/20803 [==============================] - 13s 614us/sample - loss: 1.9930 - starts_loss: 1.0166 - stops_loss: 0.9833 - starts_accuracy: 0.6742 - stops_accuracy: 0.7060 - val_loss: 3.0414 - val_starts_loss: 1.5354 - val_stops_loss: 1.5432 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6253\n",
      "Epoch 893/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 1.9851 - starts_loss: 1.0104 - stops_loss: 0.9807 - starts_accuracy: 0.6750 - stops_accuracy: 0.7044 - val_loss: 3.0422 - val_starts_loss: 1.5356 - val_stops_loss: 1.5437 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6253\n",
      "Epoch 894/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 1.9938 - starts_loss: 1.0071 - stops_loss: 0.9868 - starts_accuracy: 0.6768 - stops_accuracy: 0.7057 - val_loss: 3.0434 - val_starts_loss: 1.5358 - val_stops_loss: 1.5447 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6249\n",
      "Epoch 895/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 1.9896 - starts_loss: 1.0157 - stops_loss: 0.9756 - starts_accuracy: 0.6718 - stops_accuracy: 0.7076 - val_loss: 3.0420 - val_starts_loss: 1.5357 - val_stops_loss: 1.5434 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6255\n",
      "Epoch 896/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 1.9995 - starts_loss: 1.0150 - stops_loss: 0.9877 - starts_accuracy: 0.6750 - stops_accuracy: 0.7028 - val_loss: 3.0408 - val_starts_loss: 1.5354 - val_stops_loss: 1.5426 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6258\n",
      "Epoch 897/1000\n",
      "20803/20803 [==============================] - 13s 615us/sample - loss: 1.9926 - starts_loss: 1.0116 - stops_loss: 0.9792 - starts_accuracy: 0.6740 - stops_accuracy: 0.7046 - val_loss: 3.0421 - val_starts_loss: 1.5355 - val_stops_loss: 1.5438 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6253\n",
      "Epoch 898/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 1.9947 - starts_loss: 1.0117 - stops_loss: 0.9866 - starts_accuracy: 0.6757 - stops_accuracy: 0.7021 - val_loss: 3.0429 - val_starts_loss: 1.5353 - val_stops_loss: 1.5446 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6251\n",
      "Epoch 899/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 1.9876 - starts_loss: 1.0047 - stops_loss: 0.9829 - starts_accuracy: 0.6778 - stops_accuracy: 0.7030 - val_loss: 3.0415 - val_starts_loss: 1.5351 - val_stops_loss: 1.5435 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6251\n",
      "Epoch 900/1000\n",
      "20803/20803 [==============================] - 13s 642us/sample - loss: 1.9905 - starts_loss: 1.0077 - stops_loss: 0.9842 - starts_accuracy: 0.6725 - stops_accuracy: 0.7039 - val_loss: 3.0413 - val_starts_loss: 1.5349 - val_stops_loss: 1.5435 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6249\n",
      "Epoch 901/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.9915 - starts_loss: 1.0207 - stops_loss: 0.9781 - starts_accuracy: 0.6744 - stops_accuracy: 0.7078 - val_loss: 3.0423 - val_starts_loss: 1.5356 - val_stops_loss: 1.5438 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6253\n",
      "Epoch 902/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 1.9833 - starts_loss: 1.0027 - stops_loss: 0.9843 - starts_accuracy: 0.6763 - stops_accuracy: 0.7030 - val_loss: 3.0415 - val_starts_loss: 1.5355 - val_stops_loss: 1.5433 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6255\n",
      "Epoch 903/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.9922 - starts_loss: 1.0170 - stops_loss: 0.9793 - starts_accuracy: 0.6741 - stops_accuracy: 0.7026 - val_loss: 3.0413 - val_starts_loss: 1.5356 - val_stops_loss: 1.5429 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6255\n",
      "Epoch 904/1000\n",
      "20803/20803 [==============================] - 13s 618us/sample - loss: 1.9860 - starts_loss: 1.0036 - stops_loss: 0.9772 - starts_accuracy: 0.6757 - stops_accuracy: 0.7082 - val_loss: 3.0404 - val_starts_loss: 1.5354 - val_stops_loss: 1.5423 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6255\n",
      "Epoch 905/1000\n",
      "20803/20803 [==============================] - 13s 625us/sample - loss: 1.9903 - starts_loss: 1.0122 - stops_loss: 0.9828 - starts_accuracy: 0.6751 - stops_accuracy: 0.7032 - val_loss: 3.0424 - val_starts_loss: 1.5352 - val_stops_loss: 1.5443 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6251\n",
      "Epoch 906/1000\n",
      "20803/20803 [==============================] - 13s 630us/sample - loss: 1.9973 - starts_loss: 1.0079 - stops_loss: 0.9882 - starts_accuracy: 0.6781 - stops_accuracy: 0.7048 - val_loss: 3.0424 - val_starts_loss: 1.5353 - val_stops_loss: 1.5442 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6251\n",
      "Epoch 907/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 1.9950 - starts_loss: 1.0095 - stops_loss: 0.9886 - starts_accuracy: 0.6771 - stops_accuracy: 0.7039 - val_loss: 3.0426 - val_starts_loss: 1.5355 - val_stops_loss: 1.5442 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6251\n",
      "Epoch 908/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 1.9784 - starts_loss: 1.0086 - stops_loss: 0.9688 - starts_accuracy: 0.6759 - stops_accuracy: 0.7095 - val_loss: 3.0442 - val_starts_loss: 1.5359 - val_stops_loss: 1.5453 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6251\n",
      "Epoch 909/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 1.9963 - starts_loss: 1.0140 - stops_loss: 0.9835 - starts_accuracy: 0.6756 - stops_accuracy: 0.7037 - val_loss: 3.0422 - val_starts_loss: 1.5357 - val_stops_loss: 1.5437 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6251\n",
      "Epoch 910/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 1.9859 - starts_loss: 1.0074 - stops_loss: 0.9742 - starts_accuracy: 0.6721 - stops_accuracy: 0.7060 - val_loss: 3.0429 - val_starts_loss: 1.5360 - val_stops_loss: 1.5439 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 911/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 1.9906 - starts_loss: 1.0094 - stops_loss: 0.9824 - starts_accuracy: 0.6784 - stops_accuracy: 0.7056 - val_loss: 3.0423 - val_starts_loss: 1.5358 - val_stops_loss: 1.5435 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6253\n",
      "Epoch 912/1000\n",
      "20803/20803 [==============================] - 13s 617us/sample - loss: 1.9809 - starts_loss: 1.0006 - stops_loss: 0.9802 - starts_accuracy: 0.6769 - stops_accuracy: 0.7061 - val_loss: 3.0443 - val_starts_loss: 1.5360 - val_stops_loss: 1.5449 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6255\n",
      "Epoch 913/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 1.9969 - starts_loss: 1.0135 - stops_loss: 0.9814 - starts_accuracy: 0.6756 - stops_accuracy: 0.7055 - val_loss: 3.0444 - val_starts_loss: 1.5361 - val_stops_loss: 1.5451 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6247\n",
      "Epoch 914/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 1.9933 - starts_loss: 1.0153 - stops_loss: 0.9761 - starts_accuracy: 0.6730 - stops_accuracy: 0.7049 - val_loss: 3.0435 - val_starts_loss: 1.5361 - val_stops_loss: 1.5444 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6255\n",
      "Epoch 915/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 1.9921 - starts_loss: 1.0058 - stops_loss: 0.9891 - starts_accuracy: 0.6775 - stops_accuracy: 0.7040 - val_loss: 3.0437 - val_starts_loss: 1.5358 - val_stops_loss: 1.5447 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6247\n",
      "Epoch 916/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 1.9944 - starts_loss: 1.0172 - stops_loss: 0.9885 - starts_accuracy: 0.6771 - stops_accuracy: 0.7058 - val_loss: 3.0451 - val_starts_loss: 1.5360 - val_stops_loss: 1.5458 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6247\n",
      "Epoch 917/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 1.9897 - starts_loss: 1.0085 - stops_loss: 0.9832 - starts_accuracy: 0.6763 - stops_accuracy: 0.7039 - val_loss: 3.0460 - val_starts_loss: 1.5363 - val_stops_loss: 1.5463 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6251\n",
      "Epoch 918/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 1.9906 - starts_loss: 1.0053 - stops_loss: 0.9784 - starts_accuracy: 0.6792 - stops_accuracy: 0.7087 - val_loss: 3.0457 - val_starts_loss: 1.5366 - val_stops_loss: 1.5459 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6247\n",
      "Epoch 919/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 1.9854 - starts_loss: 1.0134 - stops_loss: 0.9744 - starts_accuracy: 0.6734 - stops_accuracy: 0.7084 - val_loss: 3.0447 - val_starts_loss: 1.5363 - val_stops_loss: 1.5453 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6247\n",
      "Epoch 920/1000\n",
      "20803/20803 [==============================] - 13s 617us/sample - loss: 1.9775 - starts_loss: 1.0117 - stops_loss: 0.9693 - starts_accuracy: 0.6766 - stops_accuracy: 0.7105 - val_loss: 3.0442 - val_starts_loss: 1.5363 - val_stops_loss: 1.5449 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6249\n",
      "Epoch 921/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 2.0005 - starts_loss: 1.0083 - stops_loss: 0.9934 - starts_accuracy: 0.6753 - stops_accuracy: 0.7010 - val_loss: 3.0429 - val_starts_loss: 1.5361 - val_stops_loss: 1.5439 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6249\n",
      "Epoch 922/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 1.9891 - starts_loss: 1.0157 - stops_loss: 0.9694 - starts_accuracy: 0.6754 - stops_accuracy: 0.7070 - val_loss: 3.0421 - val_starts_loss: 1.5360 - val_stops_loss: 1.5433 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6249\n",
      "Epoch 923/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 1.9785 - starts_loss: 1.0031 - stops_loss: 0.9698 - starts_accuracy: 0.6792 - stops_accuracy: 0.7074 - val_loss: 3.0434 - val_starts_loss: 1.5359 - val_stops_loss: 1.5446 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6249\n",
      "Epoch 924/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 1.9793 - starts_loss: 1.0077 - stops_loss: 0.9744 - starts_accuracy: 0.6770 - stops_accuracy: 0.7068 - val_loss: 3.0426 - val_starts_loss: 1.5359 - val_stops_loss: 1.5439 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6249\n",
      "Epoch 925/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 1.9860 - starts_loss: 1.0066 - stops_loss: 0.9743 - starts_accuracy: 0.6738 - stops_accuracy: 0.7077 - val_loss: 3.0426 - val_starts_loss: 1.5362 - val_stops_loss: 1.5438 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6251\n",
      "Epoch 926/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 1.9840 - starts_loss: 1.0006 - stops_loss: 0.9811 - starts_accuracy: 0.6741 - stops_accuracy: 0.7070 - val_loss: 3.0438 - val_starts_loss: 1.5364 - val_stops_loss: 1.5446 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6255\n",
      "Epoch 927/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 1.9833 - starts_loss: 1.0093 - stops_loss: 0.9730 - starts_accuracy: 0.6754 - stops_accuracy: 0.7070 - val_loss: 3.0446 - val_starts_loss: 1.5364 - val_stops_loss: 1.5453 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6251\n",
      "Epoch 928/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.9859 - starts_loss: 1.0066 - stops_loss: 0.9830 - starts_accuracy: 0.6762 - stops_accuracy: 0.7077 - val_loss: 3.0460 - val_starts_loss: 1.5366 - val_stops_loss: 1.5463 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6253\n",
      "Epoch 929/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 1.9760 - starts_loss: 0.9932 - stops_loss: 0.9788 - starts_accuracy: 0.6787 - stops_accuracy: 0.7065 - val_loss: 3.0458 - val_starts_loss: 1.5365 - val_stops_loss: 1.5463 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6251\n",
      "Epoch 930/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 1.9993 - starts_loss: 1.0124 - stops_loss: 0.9894 - starts_accuracy: 0.6781 - stops_accuracy: 0.7037 - val_loss: 3.0450 - val_starts_loss: 1.5367 - val_stops_loss: 1.5455 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6251\n",
      "Epoch 931/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 1.9949 - starts_loss: 1.0137 - stops_loss: 0.9848 - starts_accuracy: 0.6763 - stops_accuracy: 0.7031 - val_loss: 3.0436 - val_starts_loss: 1.5366 - val_stops_loss: 1.5443 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6256\n",
      "Epoch 932/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.9708 - starts_loss: 1.0023 - stops_loss: 0.9625 - starts_accuracy: 0.6759 - stops_accuracy: 0.7129 - val_loss: 3.0450 - val_starts_loss: 1.5367 - val_stops_loss: 1.5457 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6251\n",
      "Epoch 933/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.9792 - starts_loss: 1.0032 - stops_loss: 0.9777 - starts_accuracy: 0.6763 - stops_accuracy: 0.7090 - val_loss: 3.0459 - val_starts_loss: 1.5369 - val_stops_loss: 1.5464 - val_starts_accuracy: 0.6141 - val_stops_accuracy: 0.6251\n",
      "Epoch 934/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 1.9995 - starts_loss: 1.0112 - stops_loss: 0.9845 - starts_accuracy: 0.6732 - stops_accuracy: 0.7023 - val_loss: 3.0445 - val_starts_loss: 1.5367 - val_stops_loss: 1.5452 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6253\n",
      "Epoch 935/1000\n",
      "20803/20803 [==============================] - 13s 621us/sample - loss: 1.9892 - starts_loss: 1.0085 - stops_loss: 0.9807 - starts_accuracy: 0.6763 - stops_accuracy: 0.7055 - val_loss: 3.0430 - val_starts_loss: 1.5368 - val_stops_loss: 1.5438 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6255\n",
      "Epoch 936/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 1.9890 - starts_loss: 1.0133 - stops_loss: 0.9777 - starts_accuracy: 0.6765 - stops_accuracy: 0.7084 - val_loss: 3.0426 - val_starts_loss: 1.5368 - val_stops_loss: 1.5433 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 937/1000\n",
      "20803/20803 [==============================] - 13s 613us/sample - loss: 1.9890 - starts_loss: 1.0058 - stops_loss: 0.9791 - starts_accuracy: 0.6794 - stops_accuracy: 0.7033 - val_loss: 3.0420 - val_starts_loss: 1.5365 - val_stops_loss: 1.5431 - val_starts_accuracy: 0.6160 - val_stops_accuracy: 0.6255\n",
      "Epoch 938/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 1.9890 - starts_loss: 1.0092 - stops_loss: 0.9731 - starts_accuracy: 0.6774 - stops_accuracy: 0.7048 - val_loss: 3.0416 - val_starts_loss: 1.5368 - val_stops_loss: 1.5424 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6251\n",
      "Epoch 939/1000\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 1.9893 - starts_loss: 1.0084 - stops_loss: 0.9809 - starts_accuracy: 0.6764 - stops_accuracy: 0.7102 - val_loss: 3.0414 - val_starts_loss: 1.5365 - val_stops_loss: 1.5425 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6253\n",
      "Epoch 940/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 1.9898 - starts_loss: 1.0103 - stops_loss: 0.9753 - starts_accuracy: 0.6768 - stops_accuracy: 0.7056 - val_loss: 3.0421 - val_starts_loss: 1.5367 - val_stops_loss: 1.5430 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6253\n",
      "Epoch 941/1000\n",
      "20803/20803 [==============================] - 12s 592us/sample - loss: 1.9919 - starts_loss: 1.0096 - stops_loss: 0.9801 - starts_accuracy: 0.6772 - stops_accuracy: 0.7051 - val_loss: 3.0431 - val_starts_loss: 1.5366 - val_stops_loss: 1.5440 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6251\n",
      "Epoch 942/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 1.9840 - starts_loss: 1.0069 - stops_loss: 0.9775 - starts_accuracy: 0.6772 - stops_accuracy: 0.7093 - val_loss: 3.0450 - val_starts_loss: 1.5368 - val_stops_loss: 1.5455 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6256\n",
      "Epoch 943/1000\n",
      "20803/20803 [==============================] - 13s 617us/sample - loss: 1.9943 - starts_loss: 1.0089 - stops_loss: 0.9849 - starts_accuracy: 0.6753 - stops_accuracy: 0.7064 - val_loss: 3.0465 - val_starts_loss: 1.5371 - val_stops_loss: 1.5465 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6251\n",
      "Epoch 944/1000\n",
      "20803/20803 [==============================] - 12s 591us/sample - loss: 1.9910 - starts_loss: 1.0113 - stops_loss: 0.9827 - starts_accuracy: 0.6751 - stops_accuracy: 0.7075 - val_loss: 3.0468 - val_starts_loss: 1.5372 - val_stops_loss: 1.5466 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6256\n",
      "Epoch 945/1000\n",
      "20803/20803 [==============================] - 12s 600us/sample - loss: 1.9867 - starts_loss: 1.0121 - stops_loss: 0.9797 - starts_accuracy: 0.6765 - stops_accuracy: 0.7057 - val_loss: 3.0448 - val_starts_loss: 1.5374 - val_stops_loss: 1.5448 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6253\n",
      "Epoch 946/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 1.9844 - starts_loss: 1.0009 - stops_loss: 0.9870 - starts_accuracy: 0.6757 - stops_accuracy: 0.7050 - val_loss: 3.0442 - val_starts_loss: 1.5372 - val_stops_loss: 1.5443 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6253\n",
      "Epoch 947/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 1.9764 - starts_loss: 0.9983 - stops_loss: 0.9742 - starts_accuracy: 0.6772 - stops_accuracy: 0.7055 - val_loss: 3.0447 - val_starts_loss: 1.5373 - val_stops_loss: 1.5447 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6253\n",
      "Epoch 948/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 1.9914 - starts_loss: 1.0076 - stops_loss: 0.9791 - starts_accuracy: 0.6770 - stops_accuracy: 0.7038 - val_loss: 3.0438 - val_starts_loss: 1.5369 - val_stops_loss: 1.5444 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6253\n",
      "Epoch 949/1000\n",
      "20803/20803 [==============================] - 13s 612us/sample - loss: 1.9740 - starts_loss: 1.0071 - stops_loss: 0.9684 - starts_accuracy: 0.6753 - stops_accuracy: 0.7112 - val_loss: 3.0452 - val_starts_loss: 1.5368 - val_stops_loss: 1.5456 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6251\n",
      "Epoch 950/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 1.9869 - starts_loss: 1.0072 - stops_loss: 0.9735 - starts_accuracy: 0.6767 - stops_accuracy: 0.7082 - val_loss: 3.0471 - val_starts_loss: 1.5371 - val_stops_loss: 1.5472 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6251\n",
      "Epoch 951/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 1.9782 - starts_loss: 1.0136 - stops_loss: 0.9677 - starts_accuracy: 0.6769 - stops_accuracy: 0.7124 - val_loss: 3.0468 - val_starts_loss: 1.5373 - val_stops_loss: 1.5468 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6251\n",
      "Epoch 952/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 1.9798 - starts_loss: 1.0126 - stops_loss: 0.9663 - starts_accuracy: 0.6737 - stops_accuracy: 0.7116 - val_loss: 3.0474 - val_starts_loss: 1.5370 - val_stops_loss: 1.5476 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6253\n",
      "Epoch 953/1000\n",
      "20803/20803 [==============================] - 12s 593us/sample - loss: 1.9861 - starts_loss: 1.0114 - stops_loss: 0.9777 - starts_accuracy: 0.6780 - stops_accuracy: 0.7050 - val_loss: 3.0477 - val_starts_loss: 1.5371 - val_stops_loss: 1.5478 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6253\n",
      "Epoch 954/1000\n",
      "20803/20803 [==============================] - 13s 611us/sample - loss: 1.9837 - starts_loss: 1.0092 - stops_loss: 0.9760 - starts_accuracy: 0.6752 - stops_accuracy: 0.7084 - val_loss: 3.0454 - val_starts_loss: 1.5372 - val_stops_loss: 1.5457 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6255\n",
      "Epoch 955/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.9830 - starts_loss: 1.0117 - stops_loss: 0.9749 - starts_accuracy: 0.6756 - stops_accuracy: 0.7061 - val_loss: 3.0457 - val_starts_loss: 1.5371 - val_stops_loss: 1.5462 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6251\n",
      "Epoch 956/1000\n",
      "20803/20803 [==============================] - 12s 599us/sample - loss: 1.9862 - starts_loss: 1.0041 - stops_loss: 0.9772 - starts_accuracy: 0.6776 - stops_accuracy: 0.7057 - val_loss: 3.0466 - val_starts_loss: 1.5371 - val_stops_loss: 1.5469 - val_starts_accuracy: 0.6143 - val_stops_accuracy: 0.6253\n",
      "Epoch 957/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 1.9804 - starts_loss: 1.0039 - stops_loss: 0.9781 - starts_accuracy: 0.6790 - stops_accuracy: 0.7081 - val_loss: 3.0474 - val_starts_loss: 1.5371 - val_stops_loss: 1.5476 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6251\n",
      "Epoch 958/1000\n",
      "20803/20803 [==============================] - 12s 590us/sample - loss: 2.0023 - starts_loss: 1.0079 - stops_loss: 0.9923 - starts_accuracy: 0.6763 - stops_accuracy: 0.7029 - val_loss: 3.0450 - val_starts_loss: 1.5370 - val_stops_loss: 1.5456 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6253\n",
      "Epoch 959/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 1.9918 - starts_loss: 1.0050 - stops_loss: 0.9913 - starts_accuracy: 0.6767 - stops_accuracy: 0.7061 - val_loss: 3.0440 - val_starts_loss: 1.5372 - val_stops_loss: 1.5445 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6258\n",
      "Epoch 960/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 1.9854 - starts_loss: 1.0149 - stops_loss: 0.9672 - starts_accuracy: 0.6762 - stops_accuracy: 0.7112 - val_loss: 3.0440 - val_starts_loss: 1.5373 - val_stops_loss: 1.5443 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6256\n",
      "Epoch 961/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 1.9922 - starts_loss: 1.0053 - stops_loss: 0.9822 - starts_accuracy: 0.6761 - stops_accuracy: 0.7055 - val_loss: 3.0445 - val_starts_loss: 1.5373 - val_stops_loss: 1.5447 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6256\n",
      "Epoch 962/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 1.9835 - starts_loss: 1.0054 - stops_loss: 0.9738 - starts_accuracy: 0.6782 - stops_accuracy: 0.7088 - val_loss: 3.0450 - val_starts_loss: 1.5369 - val_stops_loss: 1.5456 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 963/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.9826 - starts_loss: 1.0047 - stops_loss: 0.9732 - starts_accuracy: 0.6750 - stops_accuracy: 0.7077 - val_loss: 3.0477 - val_starts_loss: 1.5371 - val_stops_loss: 1.5478 - val_starts_accuracy: 0.6143 - val_stops_accuracy: 0.6253\n",
      "Epoch 964/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 1.9797 - starts_loss: 1.0068 - stops_loss: 0.9785 - starts_accuracy: 0.6795 - stops_accuracy: 0.7095 - val_loss: 3.0471 - val_starts_loss: 1.5371 - val_stops_loss: 1.5472 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6255\n",
      "Epoch 965/1000\n",
      "20803/20803 [==============================] - 13s 605us/sample - loss: 1.9805 - starts_loss: 1.0096 - stops_loss: 0.9745 - starts_accuracy: 0.6793 - stops_accuracy: 0.7100 - val_loss: 3.0473 - val_starts_loss: 1.5374 - val_stops_loss: 1.5470 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6255\n",
      "Epoch 966/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 1.9808 - starts_loss: 1.0118 - stops_loss: 0.9805 - starts_accuracy: 0.6767 - stops_accuracy: 0.7069 - val_loss: 3.0436 - val_starts_loss: 1.5370 - val_stops_loss: 1.5440 - val_starts_accuracy: 0.6158 - val_stops_accuracy: 0.6258\n",
      "Epoch 967/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 1.9890 - starts_loss: 1.0159 - stops_loss: 0.9792 - starts_accuracy: 0.6758 - stops_accuracy: 0.7052 - val_loss: 3.0449 - val_starts_loss: 1.5374 - val_stops_loss: 1.5448 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6258\n",
      "Epoch 968/1000\n",
      "20803/20803 [==============================] - 15s 707us/sample - loss: 1.9883 - starts_loss: 1.0018 - stops_loss: 0.9809 - starts_accuracy: 0.6776 - stops_accuracy: 0.7075 - val_loss: 3.0433 - val_starts_loss: 1.5369 - val_stops_loss: 1.5438 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6258\n",
      "Epoch 969/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.9889 - starts_loss: 1.0104 - stops_loss: 0.9782 - starts_accuracy: 0.6747 - stops_accuracy: 0.7089 - val_loss: 3.0439 - val_starts_loss: 1.5368 - val_stops_loss: 1.5445 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6262\n",
      "Epoch 970/1000\n",
      "20803/20803 [==============================] - 13s 619us/sample - loss: 1.9897 - starts_loss: 1.0093 - stops_loss: 0.9836 - starts_accuracy: 0.6740 - stops_accuracy: 0.7071 - val_loss: 3.0457 - val_starts_loss: 1.5372 - val_stops_loss: 1.5457 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6262\n",
      "Epoch 971/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 1.9905 - starts_loss: 1.0125 - stops_loss: 0.9788 - starts_accuracy: 0.6763 - stops_accuracy: 0.7055 - val_loss: 3.0470 - val_starts_loss: 1.5371 - val_stops_loss: 1.5469 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6255\n",
      "Epoch 972/1000\n",
      "20803/20803 [==============================] - 13s 620us/sample - loss: 1.9811 - starts_loss: 1.0146 - stops_loss: 0.9644 - starts_accuracy: 0.6753 - stops_accuracy: 0.7109 - val_loss: 3.0451 - val_starts_loss: 1.5370 - val_stops_loss: 1.5453 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6262\n",
      "Epoch 973/1000\n",
      "20803/20803 [==============================] - 12s 596us/sample - loss: 1.9864 - starts_loss: 1.0060 - stops_loss: 0.9786 - starts_accuracy: 0.6769 - stops_accuracy: 0.7056 - val_loss: 3.0431 - val_starts_loss: 1.5367 - val_stops_loss: 1.5438 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6262\n",
      "Epoch 974/1000\n",
      "20803/20803 [==============================] - 13s 606us/sample - loss: 1.9889 - starts_loss: 1.0083 - stops_loss: 0.9805 - starts_accuracy: 0.6736 - stops_accuracy: 0.7072 - val_loss: 3.0421 - val_starts_loss: 1.5368 - val_stops_loss: 1.5428 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6258\n",
      "Epoch 975/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 1.9918 - starts_loss: 1.0091 - stops_loss: 0.9811 - starts_accuracy: 0.6752 - stops_accuracy: 0.7058 - val_loss: 3.0418 - val_starts_loss: 1.5369 - val_stops_loss: 1.5425 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6258\n",
      "Epoch 976/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 1.9821 - starts_loss: 1.0057 - stops_loss: 0.9699 - starts_accuracy: 0.6768 - stops_accuracy: 0.7096 - val_loss: 3.0413 - val_starts_loss: 1.5368 - val_stops_loss: 1.5421 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6262\n",
      "Epoch 977/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 1.9784 - starts_loss: 1.0057 - stops_loss: 0.9742 - starts_accuracy: 0.6750 - stops_accuracy: 0.7069 - val_loss: 3.0438 - val_starts_loss: 1.5370 - val_stops_loss: 1.5442 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6262\n",
      "Epoch 978/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 1.9782 - starts_loss: 1.0034 - stops_loss: 0.9780 - starts_accuracy: 0.6790 - stops_accuracy: 0.7070 - val_loss: 3.0460 - val_starts_loss: 1.5368 - val_stops_loss: 1.5463 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6256\n",
      "Epoch 979/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 1.9855 - starts_loss: 1.0081 - stops_loss: 0.9761 - starts_accuracy: 0.6757 - stops_accuracy: 0.7040 - val_loss: 3.0451 - val_starts_loss: 1.5368 - val_stops_loss: 1.5456 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6258\n",
      "Epoch 980/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.9720 - starts_loss: 1.0017 - stops_loss: 0.9682 - starts_accuracy: 0.6789 - stops_accuracy: 0.7054 - val_loss: 3.0454 - val_starts_loss: 1.5371 - val_stops_loss: 1.5457 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6258\n",
      "Epoch 981/1000\n",
      "20803/20803 [==============================] - 13s 601us/sample - loss: 1.9822 - starts_loss: 1.0042 - stops_loss: 0.9763 - starts_accuracy: 0.6759 - stops_accuracy: 0.7043 - val_loss: 3.0442 - val_starts_loss: 1.5373 - val_stops_loss: 1.5444 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6264\n",
      "Epoch 982/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 1.9833 - starts_loss: 1.0093 - stops_loss: 0.9786 - starts_accuracy: 0.6727 - stops_accuracy: 0.7073 - val_loss: 3.0452 - val_starts_loss: 1.5372 - val_stops_loss: 1.5454 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6262\n",
      "Epoch 983/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 1.9739 - starts_loss: 1.0045 - stops_loss: 0.9677 - starts_accuracy: 0.6792 - stops_accuracy: 0.7102 - val_loss: 3.0463 - val_starts_loss: 1.5372 - val_stops_loss: 1.5464 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6258\n",
      "Epoch 984/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.9854 - starts_loss: 1.0147 - stops_loss: 0.9742 - starts_accuracy: 0.6747 - stops_accuracy: 0.7052 - val_loss: 3.0455 - val_starts_loss: 1.5370 - val_stops_loss: 1.5459 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6260\n",
      "Epoch 985/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 1.9926 - starts_loss: 1.0049 - stops_loss: 0.9870 - starts_accuracy: 0.6783 - stops_accuracy: 0.7061 - val_loss: 3.0470 - val_starts_loss: 1.5373 - val_stops_loss: 1.5470 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6260\n",
      "Epoch 986/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 1.9864 - starts_loss: 1.0023 - stops_loss: 0.9824 - starts_accuracy: 0.6769 - stops_accuracy: 0.7060 - val_loss: 3.0478 - val_starts_loss: 1.5373 - val_stops_loss: 1.5476 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6256\n",
      "Epoch 987/1000\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 1.9740 - starts_loss: 1.0049 - stops_loss: 0.9700 - starts_accuracy: 0.6776 - stops_accuracy: 0.7066 - val_loss: 3.0470 - val_starts_loss: 1.5371 - val_stops_loss: 1.5473 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6256\n",
      "Epoch 988/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.9765 - starts_loss: 1.0008 - stops_loss: 0.9752 - starts_accuracy: 0.6745 - stops_accuracy: 0.7073 - val_loss: 3.0475 - val_starts_loss: 1.5371 - val_stops_loss: 1.5476 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989/1000\n",
      "20803/20803 [==============================] - 13s 602us/sample - loss: 1.9740 - starts_loss: 1.0046 - stops_loss: 0.9727 - starts_accuracy: 0.6768 - stops_accuracy: 0.7086 - val_loss: 3.0481 - val_starts_loss: 1.5374 - val_stops_loss: 1.5479 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6253\n",
      "Epoch 990/1000\n",
      "20803/20803 [==============================] - 13s 616us/sample - loss: 1.9816 - starts_loss: 1.0062 - stops_loss: 0.9743 - starts_accuracy: 0.6758 - stops_accuracy: 0.7073 - val_loss: 3.0462 - val_starts_loss: 1.5370 - val_stops_loss: 1.5466 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6253\n",
      "Epoch 991/1000\n",
      "20803/20803 [==============================] - 12s 598us/sample - loss: 1.9768 - starts_loss: 1.0041 - stops_loss: 0.9624 - starts_accuracy: 0.6743 - stops_accuracy: 0.7078 - val_loss: 3.0442 - val_starts_loss: 1.5368 - val_stops_loss: 1.5451 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6256\n",
      "Epoch 992/1000\n",
      "20803/20803 [==============================] - 13s 607us/sample - loss: 1.9826 - starts_loss: 0.9979 - stops_loss: 0.9819 - starts_accuracy: 0.6798 - stops_accuracy: 0.7047 - val_loss: 3.0456 - val_starts_loss: 1.5372 - val_stops_loss: 1.5460 - val_starts_accuracy: 0.6153 - val_stops_accuracy: 0.6256\n",
      "Epoch 993/1000\n",
      "20803/20803 [==============================] - 13s 609us/sample - loss: 1.9835 - starts_loss: 0.9988 - stops_loss: 0.9841 - starts_accuracy: 0.6769 - stops_accuracy: 0.7051 - val_loss: 3.0468 - val_starts_loss: 1.5375 - val_stops_loss: 1.5467 - val_starts_accuracy: 0.6149 - val_stops_accuracy: 0.6255\n",
      "Epoch 994/1000\n",
      "20803/20803 [==============================] - 13s 604us/sample - loss: 1.9846 - starts_loss: 1.0061 - stops_loss: 0.9843 - starts_accuracy: 0.6781 - stops_accuracy: 0.7073 - val_loss: 3.0475 - val_starts_loss: 1.5376 - val_stops_loss: 1.5473 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6256\n",
      "Epoch 995/1000\n",
      "20803/20803 [==============================] - 12s 601us/sample - loss: 1.9817 - starts_loss: 1.0042 - stops_loss: 0.9801 - starts_accuracy: 0.6762 - stops_accuracy: 0.7081 - val_loss: 3.0462 - val_starts_loss: 1.5377 - val_stops_loss: 1.5461 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6258\n",
      "Epoch 996/1000\n",
      "20803/20803 [==============================] - 12s 597us/sample - loss: 1.9804 - starts_loss: 1.0091 - stops_loss: 0.9714 - starts_accuracy: 0.6743 - stops_accuracy: 0.7095 - val_loss: 3.0472 - val_starts_loss: 1.5380 - val_stops_loss: 1.5466 - val_starts_accuracy: 0.6157 - val_stops_accuracy: 0.6258\n",
      "Epoch 997/1000\n",
      "20803/20803 [==============================] - 13s 610us/sample - loss: 1.9764 - starts_loss: 0.9992 - stops_loss: 0.9700 - starts_accuracy: 0.6768 - stops_accuracy: 0.7057 - val_loss: 3.0476 - val_starts_loss: 1.5380 - val_stops_loss: 1.5469 - val_starts_accuracy: 0.6155 - val_stops_accuracy: 0.6256\n",
      "Epoch 998/1000\n",
      "20803/20803 [==============================] - 13s 608us/sample - loss: 1.9798 - starts_loss: 1.0095 - stops_loss: 0.9713 - starts_accuracy: 0.6745 - stops_accuracy: 0.7095 - val_loss: 3.0481 - val_starts_loss: 1.5381 - val_stops_loss: 1.5474 - val_starts_accuracy: 0.6151 - val_stops_accuracy: 0.6256\n",
      "Epoch 999/1000\n",
      "20803/20803 [==============================] - 13s 631us/sample - loss: 1.9649 - starts_loss: 0.9956 - stops_loss: 0.9698 - starts_accuracy: 0.6798 - stops_accuracy: 0.7070 - val_loss: 3.0493 - val_starts_loss: 1.5382 - val_stops_loss: 1.5485 - val_starts_accuracy: 0.6145 - val_stops_accuracy: 0.6258\n",
      "Epoch 1000/1000\n",
      "20803/20803 [==============================] - 13s 603us/sample - loss: 1.9848 - starts_loss: 1.0057 - stops_loss: 0.9776 - starts_accuracy: 0.6768 - stops_accuracy: 0.7058 - val_loss: 3.0499 - val_starts_loss: 1.5384 - val_stops_loss: 1.5489 - val_starts_accuracy: 0.6147 - val_stops_accuracy: 0.6260\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x={\"att_flags\":X_att_train,\n",
    "                       \"words\":X_train},\n",
    "                    y={\"starts\":Y_starts_train.argmax(axis=1),\n",
    "                       \"stops\":Y_stops_train.argmax(axis=1)},\n",
    "                    shuffle=True,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    validation_data=({\"att_flags\":X_att_val, \"words\":X_val},\n",
    "                                     {\"starts\":Y_starts_val.argmax(axis=1), \"stops\":Y_stops_val.argmax(axis=1)}),\n",
    "                    verbose=1,\n",
    "                    callbacks=[clr, mcp]) #es, rlrop, tb, mcp,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#metric_names = ['loss' ,'accuracy']\n",
    "metric_names = [\"loss\", \"starts_loss\", \"stops_loss\", \"accuracy\", \"starts_accuracy\", \"stops_accuracy\"]\n",
    "\n",
    "for i, j in zip(metric_names, ['val_'+i for i in metric_names]):\n",
    "    plt.plot(history.history[i])\n",
    "    plt.plot(history.history[j])\n",
    "    plt.title('Model '+i)\n",
    "    plt.ylabel(i.upper())\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = tf.keras.models.load_model(\n",
    "    filepath=\"../results/\"+MODEL_PREFIX+\"Checkpoint.h5\",\n",
    "    compile=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5201/5201 [==============================] - 1s 244us/sample - loss: 2.8970 - starts_loss: 1.4497 - stops_loss: 1.4370 - starts_accuracy: 0.6055 - stops_accuracy: 0.6135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.896954140647561, 1.4496785, 1.4369935, 0.60546046, 0.6135359]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x = {\"att_flags\":X_att_val, \"words\":X_val},\n",
    "               y={\"starts\":Y_starts_val.argmax(axis=1), \"stops\":Y_stops_val.argmax(axis=1)},\n",
    "               batch_size=PREDICT_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(x = {\"att_flags\":X_att_train, \"words\":X_train},\n",
    "                           batch_size=PREDICT_BATCH_SIZE)\n",
    "pred_val = model.predict(x = {\"att_flags\":X_att_val, \"words\":X_val},\n",
    "                         batch_size=PREDICT_BATCH_SIZE)\n",
    "pred_test = model.predict(x = {\"att_flags\":X_att_test, \"words\":X_test},\n",
    "                          batch_size=PREDICT_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_starts_train, pred_stops_train = pred_train[0], pred_train[1]\n",
    "pred_starts_val, pred_stops_val = pred_val[0], pred_val[1]\n",
    "pred_starts_test, pred_stops_test = pred_test[0], pred_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20803, 110) (20803, 110)\n",
      "(5201, 110) (5201, 110)\n",
      "(3534, 110) (3534, 110)\n"
     ]
    }
   ],
   "source": [
    "print(pred_starts_train.shape, pred_stops_train.shape)\n",
    "print(pred_starts_val.shape, pred_stops_val.shape)\n",
    "print(pred_starts_test.shape, pred_stops_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = {\n",
    "    \"train\":{\n",
    "        \"starts\":{\n",
    "            \"y_true\":Y_starts_train.argmax(axis=1),\n",
    "            \"y_pred\":pred_starts_train.argmax(axis=1)\n",
    "        },\n",
    "        \"stops\":{\n",
    "            \"y_true\":Y_stops_train.argmax(axis=1),\n",
    "            \"y_pred\":pred_stops_train.argmax(axis=1)\n",
    "        }\n",
    "    },\n",
    "    \"valid\":{\n",
    "        \"starts\":{\n",
    "            \"y_true\":Y_starts_val.argmax(axis=1),\n",
    "            \"y_pred\":pred_starts_val.argmax(axis=1)\n",
    "        },\n",
    "        \"stops\":{\n",
    "            \"y_true\":Y_stops_train.argmax(axis=1),\n",
    "            \"y_pred\":pred_stops_train.argmax(axis=1)\n",
    "        }        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.60 \t|| train \t|| starts \t|| accuracy_score\n",
      "72.09 \t|| train \t|| stops \t|| accuracy_score\n",
      "60.55 \t|| valid \t|| starts \t|| accuracy_score\n",
      "72.09 \t|| valid \t|| stops \t|| accuracy_score\n",
      "================================================================\n",
      "19.13 \t|| train \t|| starts \t|| f1_score\n",
      "73.16 \t|| train \t|| stops \t|| f1_score\n",
      "5.88 \t|| valid \t|| starts \t|| f1_score\n",
      "73.16 \t|| valid \t|| stops \t|| f1_score\n",
      "================================================================\n",
      "35.40 \t|| train \t|| starts \t|| precision_score\n",
      "71.68 \t|| train \t|| stops \t|| precision_score\n",
      "14.90 \t|| valid \t|| starts \t|| precision_score\n",
      "71.68 \t|| valid \t|| stops \t|| precision_score\n",
      "================================================================\n",
      "16.21 \t|| train \t|| starts \t|| recall_score\n",
      "75.91 \t|| train \t|| stops \t|| recall_score\n",
      "5.31 \t|| valid \t|| starts \t|| recall_score\n",
      "75.91 \t|| valid \t|| stops \t|| recall_score\n",
      "================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\deepak\\miniconda3\\envs\\dev\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t|| train \t|| starts \t|| confusion_matrix \t|| ../results/ConfusionMatrix_V10_train_starts.csv\n",
      "\t|| train \t|| stops \t|| confusion_matrix \t|| ../results/ConfusionMatrix_V10_train_stops.csv\n",
      "\t|| valid \t|| starts \t|| confusion_matrix \t|| ../results/ConfusionMatrix_V10_valid_starts.csv\n",
      "\t|| valid \t|| stops \t|| confusion_matrix \t|| ../results/ConfusionMatrix_V10_valid_stops.csv\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "def print_metrics():\n",
    "    funcs = [accuracy_score, f1_score, precision_score, recall_score, confusion_matrix]\n",
    "    for f in funcs:\n",
    "        for data_set in [\"train\",\"valid\"]:\n",
    "            for var in [\"starts\", \"stops\"]:\n",
    "                if f in [accuracy_score]:\n",
    "                    res = f(**preds[data_set][var])\n",
    "                    print(\"{:.2f}\".format(100 * res), \"\\t||\", data_set, \"\\t||\", var, \"\\t||\", f.__name__)\n",
    "                elif f in [confusion_matrix]:\n",
    "                    res = f(**preds[data_set][var], labels = np.arange(max_len))\n",
    "                    np.savetxt(X=res, fmt='%i', delimiter=\",\",\n",
    "                               fname=\"../results/ConfusionMatrix_\"+MODEL_PREFIX+\"_\"+data_set+\"_\"+var+\".csv\")\n",
    "                    print(\"\\t||\", data_set, \"\\t||\", var, \"\\t||\", f.__name__, \"\\t||\", \n",
    "                          \"../results/ConfusionMatrix_\"+MODEL_PREFIX+\"_\"+data_set+\"_\"+var+\".csv\")\n",
    "                else:\n",
    "                    res = f(**preds[data_set][var], average=\"macro\")\n",
    "                    print(\"{:.2f}\".format(100 * res), \"\\t||\", data_set, \"\\t||\", var, \"\\t||\", f.__name__)\n",
    "        print(\"================================================================\")\n",
    "\n",
    "print_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_words_train = [[vocab_itos[j] for j in i if j!=0] for num,i in enumerate(Y_train)]\n",
    "Y_words_val = [[vocab_itos[j] for j in i if j!=0] for num,i in enumerate(Y_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19157\n",
      "4900\n",
      "3359\n"
     ]
    }
   ],
   "source": [
    "print(sum([s<e for s,e in zip(pred_starts_train.argmax(axis=1), pred_stops_train.argmax(axis=1))]))\n",
    "print(sum([s<e for s,e in zip(pred_starts_val.argmax(axis=1), pred_stops_val.argmax(axis=1))]))\n",
    "print(sum([s<e for s,e in zip(pred_starts_test.argmax(axis=1), pred_stops_test.argmax(axis=1))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_words_train = [t[s:e] if s<e else t[e:-3] for t,s,e in zip([[vocab_itos[j] for j in i  if j!=0] for i in X_train], pred_starts_train.argmax(axis=1), pred_stops_train.argmax(axis=1))]\n",
    "pred_words_val = [t[s:e] if s<e else t[e:-3] for t,s,e in zip([[vocab_itos[j] for j in i  if j!=0] for i in X_val], pred_starts_val.argmax(axis=1), pred_stops_val.argmax(axis=1))]\n",
    "pred_words_test = [t[s:e] if s<e else t[e:-3] for t,s,e in zip([[vocab_itos[j] for j in i  if j!=0] for i in X_test], pred_starts_test.argmax(axis=1), pred_stops_test.argmax(axis=1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(str1, str2):\n",
    "    a = set(str1)\n",
    "    b = set(str2)\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Jaccard Score 0.5985801697789666\n",
      "Validation Jaccard Score 0.5542312685005739\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Jaccard Score\", np.mean([jaccard(str1=i, str2=j) for i,j in zip(Y_words_train, pred_words_train)]))\n",
    "print(\"Validation Jaccard Score\", np.mean([jaccard(str1=i, str2=j) for i,j in zip(Y_words_val, pred_words_val)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_labels = {i:j for i,j in enumerate(df.sentiment_code.cat.categories)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spot Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spot_check(index_to_check, mode):\n",
    "    print(\"================== Sample #\", index_to_check, \"==================\")\n",
    "    if mode == \"train\":\n",
    "        print(\"Selected_text:\")\n",
    "        print('\\t', Y_words[train_idx[index_to_check]])\n",
    "        print(\"Predicted_text:\")\n",
    "        print('\\t', pred_words_train[index_to_check])\n",
    "        print(\"Predictions:\")\n",
    "        print('\\t',*[[\"%.2f\"%j, \n",
    "                      \"%.2f\"%k,\n",
    "                      i,\n",
    "                      X_words[train_idx[index_to_check]][num]] for num, (i,j,k) in enumerate(zip(X_train[index_to_check].tolist(),\n",
    "                                                                                               pred_starts_train[index_to_check].tolist(),\n",
    "                                                                                               pred_stops_train[index_to_check].tolist())) if i!=0], sep=\"\\n\\t\")\n",
    "        \n",
    "    elif mode == \"validation\":\n",
    "        print(\"Selected_text:\")\n",
    "        print('\\t', Y_words[val_idx[index_to_check]])\n",
    "        print(\"Predicted_text:\")\n",
    "        print('\\t', pred_words_val[index_to_check])\n",
    "        print(\"Predictions:\")\n",
    "        print('\\t',*[[\"%.2f\"%j, \n",
    "                      \"%.2f\"%k,\n",
    "                      i,\n",
    "                      X_words[val_idx[index_to_check]][num]] for num, (i,j,k) in enumerate(zip(X_val[index_to_check].tolist(),\n",
    "                                                                                               pred_starts_val[index_to_check].tolist(),\n",
    "                                                                                               pred_stops_val[index_to_check].tolist())) if i!=0], sep=\"\\n\\t\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Selected_text:\")\n",
    "        print('\\t', \"Not Available\")\n",
    "        print(\"Predicted_text:\")\n",
    "        print('\\t', pred_words_test[index_to_check])\n",
    "        print(\"Predictions:\")\n",
    "        print('\\t',*[[\"%.2f\"%j, \n",
    "                      \"%.2f\"%k,\n",
    "                      i,\n",
    "                      X_words_test[index_to_check][num]] for num, (i,j,k) in enumerate(zip(X_test[index_to_check].tolist(),\n",
    "                                                                                               pred_starts_test[index_to_check].tolist(),\n",
    "                                                                                               pred_stops_test[index_to_check].tolist())) if i!=0], sep=\"\\n\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Sample # 10 ==================\n",
      "Selected_text:\n",
      "\t ['says', 'good', '(', 'or', 'should', 'i', 'say', 'bad', '?', ')', 'afternoon', '!']\n",
      "Predicted_text:\n",
      "\t ['says', 'good', '(', 'or', 'should', 'i', 'say', 'bad', '?', ')', 'afternoon', '!']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.76', '0.06', 1103, 'says']\n",
      "\t['0.05', '0.12', 448, 'good']\n",
      "\t['0.07', '0.11', 81, '(']\n",
      "\t['0.02', '0.15', 758, 'or']\n",
      "\t['0.01', '0.02', 350, 'should']\n",
      "\t['0.01', '0.08', 7, 'i']\n",
      "\t['0.02', '0.03', 460, 'say']\n",
      "\t['0.01', '0.04', 318, 'bad']\n",
      "\t['0.01', '0.02', 74, '?']\n",
      "\t['0.01', '0.06', 84, ')']\n",
      "\t['0.02', '0.01', 1434, 'afternoon']\n",
      "\t['0.01', '0.06', 22, '!']\n",
      "\t['0.01', '0.16', 47, 'http']\n",
      "\t['0.00', '0.01', 48, ':']\n",
      "\t['0.00', '0.02', 49, '/']\n",
      "\t['0.00', '0.00', 49, '/']\n",
      "\t['0.00', '0.02', 376, 'plurk']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.00', '0.00', 51, 'com']\n",
      "\t['0.00', '0.00', 49, '/']\n",
      "\t['0.00', '0.00', 95, 'p']\n",
      "\t['0.00', '0.01', 49, '/']\n",
      "\t['0.00', '0.02', 1, 'wxpdj']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 11 ==================\n",
      "Selected_text:\n",
      "\t ['goodnight']\n",
      "Predicted_text:\n",
      "\t ['goodnight', 'all', 'in', 'the', 'twitterverse']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['1.00', '0.90', 2223, 'goodnight']\n",
      "\t['0.00', '0.05', 66, 'all']\n",
      "\t['0.00', '0.02', 19, 'in']\n",
      "\t['0.00', '0.01', 42, 'the']\n",
      "\t['0.00', '0.02', 2113, 'twitterverse']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 12 ==================\n",
      "Selected_text:\n",
      "\t ['is', 'resting', '.', 'ahhhhh', '.', 'i', 'feel', 'good']\n",
      "Predicted_text:\n",
      "\t ['is', 'resting', '.', 'ahhhhh', '.', 'i', 'feel']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.56', '0.01', 26, 'is']\n",
      "\t['0.04', '0.02', 6136, 'resting']\n",
      "\t['0.07', '0.02', 28, '.']\n",
      "\t['0.04', '0.01', 3328, 'ahhhhh']\n",
      "\t['0.05', '0.00', 28, '.']\n",
      "\t['0.05', '0.01', 7, 'i']\n",
      "\t['0.12', '0.01', 338, 'feel']\n",
      "\t['0.07', '0.91', 448, 'good']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.01', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 13 ==================\n",
      "Selected_text:\n",
      "\t ['awww', ',', 'that`s', 'nice', '.']\n",
      "Predicted_text:\n",
      "\t ['awww', ',', 'that`s']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.21', '0.06', 2124, 'awww']\n",
      "\t['0.09', '0.08', 5, ',']\n",
      "\t['0.12', '0.10', 240, 'that`s']\n",
      "\t['0.12', '0.11', 397, 'nice']\n",
      "\t['0.08', '0.10', 28, '.']\n",
      "\t['0.07', '0.10', 17, 'you']\n",
      "\t['0.07', '0.10', 72, 'both']\n",
      "\t['0.05', '0.05', 237, 'make']\n",
      "\t['0.05', '0.04', 142, 'a']\n",
      "\t['0.04', '0.06', 102, 'really']\n",
      "\t['0.03', '0.03', 2048, 'beautiful']\n",
      "\t['0.02', '0.03', 912, 'couple']\n",
      "\t['0.02', '0.05', 5, ',']\n",
      "\t['0.01', '0.02', 17, 'you']\n",
      "\t['0.01', '0.01', 8708, 'balance']\n",
      "\t['0.01', '0.02', 1127, 'each']\n",
      "\t['0.00', '0.02', 353, 'other']\n",
      "\t['0.00', '0.01', 28, '.']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 14 ==================\n",
      "Selected_text:\n",
      "\t ['disappointed']\n",
      "Predicted_text:\n",
      "\t ['disappointed', 'she', 'didn`t', 'win', 'teh', 'xxxUNK', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.99', '0.48', 924, 'disappointed']\n",
      "\t['0.00', '0.05', 447, 'she']\n",
      "\t['0.00', '0.41', 475, 'didn`t']\n",
      "\t['0.00', '0.01', 738, 'win']\n",
      "\t['0.00', '0.01', 6019, 'teh']\n",
      "\t['0.00', '0.00', 1, 'glassez']\n",
      "\t['0.00', '0.05', 28, '.']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 23, 'negative']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 15 ==================\n",
      "Selected_text:\n",
      "\t ['back', 'here', ',', 'i', 'was', 'busy', 'xd', 'wirting', 'stars', 'loves', ',', 'almos', '400', 'pages', 'xd', 'and', 'listenint', 'afh', 'and', 'tv']\n",
      "Predicted_text:\n",
      "\t ['back', 'here', ',', 'i', 'was', 'busy', 'xd', 'xxxUNK', 'stars', 'loves', ',', 'xxxUNK', '400', 'pages', 'xd', 'and', 'xxxUNK', 'xxxUNK', 'and']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['1.00', '0.00', 224, 'back']\n",
      "\t['0.00', '0.00', 18, 'here']\n",
      "\t['0.00', '0.00', 5, ',']\n",
      "\t['0.00', '0.00', 7, 'i']\n",
      "\t['0.00', '0.00', 183, 'was']\n",
      "\t['0.00', '0.00', 275, 'busy']\n",
      "\t['0.00', '0.00', 2529, 'xd']\n",
      "\t['0.00', '0.00', 1, 'wirting']\n",
      "\t['0.00', '0.00', 2240, 'stars']\n",
      "\t['0.00', '0.00', 1482, 'loves']\n",
      "\t['0.00', '0.00', 5, ',']\n",
      "\t['0.00', '0.00', 1, 'almos']\n",
      "\t['0.00', '0.00', 5941, '400']\n",
      "\t['0.00', '0.00', 3439, 'pages']\n",
      "\t['0.00', '0.00', 2529, 'xd']\n",
      "\t['0.00', '0.00', 68, 'and']\n",
      "\t['0.00', '0.00', 1, 'listenint']\n",
      "\t['0.00', '0.00', 1, 'afh']\n",
      "\t['0.00', '0.00', 68, 'and']\n",
      "\t['0.00', '1.00', 1216, 'tv']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 16 ==================\n",
      "Selected_text:\n",
      "\t ['my', 'kind', 'of', 'night']\n",
      "Predicted_text:\n",
      "\t ['we', 'got', 'xxxUNK', 'in', 'for', 'free', 'and', 'free', 'drinks', 'for', 'mom', '!', 'my', 'kind', 'of']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.37', '0.06', 44, 'we']\n",
      "\t['0.06', '0.06', 406, 'got']\n",
      "\t['0.10', '0.05', 1, 'jojo']\n",
      "\t['0.06', '0.06', 19, 'in']\n",
      "\t['0.04', '0.04', 55, 'for']\n",
      "\t['0.05', '0.04', 197, 'free']\n",
      "\t['0.05', '0.06', 68, 'and']\n",
      "\t['0.04', '0.05', 197, 'free']\n",
      "\t['0.04', '0.04', 2813, 'drinks']\n",
      "\t['0.03', '0.03', 55, 'for']\n",
      "\t['0.04', '0.04', 932, 'mom']\n",
      "\t['0.03', '0.02', 22, '!']\n",
      "\t['0.03', '0.03', 24, 'my']\n",
      "\t['0.03', '0.06', 1543, 'kind']\n",
      "\t['0.02', '0.05', 34, 'of']\n",
      "\t['0.01', '0.28', 559, 'night']\n",
      "\t['0.00', '0.03', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.01', 69, 'positive']\n",
      "\t['0.00', '0.01', 12, 'xxxEND']\n",
      "================== Sample # 17 ==================\n",
      "Selected_text:\n",
      "\t ['just', 'got', 'home', 'from', 'the', 'last', 'day', 'of', 'school', '.', 'graduation', 'tomorrow', '.']\n",
      "Predicted_text:\n",
      "\t ['just', 'got', 'home', 'from', 'the', 'last', 'day', 'of', 'school', '.', 'graduation', 'tomorrow']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['1.00', '0.00', 77, 'just']\n",
      "\t['0.00', '0.00', 406, 'got']\n",
      "\t['0.00', '0.00', 228, 'home']\n",
      "\t['0.00', '0.00', 120, 'from']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.00', '0.00', 285, 'last']\n",
      "\t['0.00', '0.00', 286, 'day']\n",
      "\t['0.00', '0.00', 34, 'of']\n",
      "\t['0.00', '0.00', 288, 'school']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.00', '0.00', 541, 'graduation']\n",
      "\t['0.00', '0.00', 251, 'tomorrow']\n",
      "\t['0.00', '1.00', 28, '.']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 18 ==================\n",
      "Selected_text:\n",
      "\t ['*', '*', '*', '*']\n",
      "Predicted_text:\n",
      "\t ['in', 'a', 'drill', 'xxxUNK', 'voice', ':', 'everybody', 'wake', 'the', '*', '*', '*']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.20', '0.04', 19, 'in']\n",
      "\t['0.05', '0.03', 142, 'a']\n",
      "\t['0.07', '0.03', 9548, 'drill']\n",
      "\t['0.05', '0.03', 1, 'sergeant`s']\n",
      "\t['0.04', '0.03', 118, 'voice']\n",
      "\t['0.03', '0.02', 48, ':']\n",
      "\t['0.03', '0.03', 1856, 'everybody']\n",
      "\t['0.03', '0.03', 1271, 'wake']\n",
      "\t['0.04', '0.03', 42, 'the']\n",
      "\t['0.04', '0.02', 35, '*']\n",
      "\t['0.05', '0.02', 35, '*']\n",
      "\t['0.03', '0.02', 35, '*']\n",
      "\t['0.03', '0.06', 35, '*']\n",
      "\t['0.03', '0.05', 225, 'up']\n",
      "\t['0.02', '0.04', 22, '!']\n",
      "\t['0.03', '0.03', 22, '!']\n",
      "\t['0.02', '0.02', 22, '!']\n",
      "\t['0.02', '0.03', 35, '*']\n",
      "\t['0.02', '0.02', 9838, 'flicks']\n",
      "\t['0.01', '0.02', 41, 'on']\n",
      "\t['0.02', '0.03', 3301, 'everyone`s']\n",
      "\t['0.01', '0.01', 8221, 'lights']\n",
      "\t['0.01', '0.01', 35, '*']\n",
      "\t['0.01', '0.02', 192, 'it`s']\n",
      "\t['0.01', '0.02', 5001, '500']\n",
      "\t['0.02', '0.03', 9839, 'est']\n",
      "\t['0.01', '0.03', 4080, 'rise']\n",
      "\t['0.01', '0.02', 68, 'and']\n",
      "\t['0.01', '0.03', 2998, 'shine']\n",
      "\t['0.01', '0.04', 1, 'beetches']\n",
      "\t['0.01', '0.03', 22, '!']\n",
      "\t['0.00', '0.02', 22, '!']\n",
      "\t['0.00', '0.02', 426, 'lol']\n",
      "\t['0.00', '0.03', 3953, 'jk']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.01', 23, 'negative']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 19 ==================\n",
      "Selected_text:\n",
      "\t ['really', 'good', 'job', '!']\n",
      "Predicted_text:\n",
      "\t ['really', 'good', 'job']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.00', '0.00', 1997, 'gave']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.00', '0.00', 3155, 'bikes']\n",
      "\t['0.00', '0.00', 142, 'a']\n",
      "\t['0.00', '0.00', 1, 'thorough']\n",
      "\t['0.00', '0.00', 2140, 'wash']\n",
      "\t['0.00', '0.00', 5, ',']\n",
      "\t['0.00', '0.00', 1, 'degrease']\n",
      "\t['0.00', '0.00', 144, 'it']\n",
      "\t['0.00', '0.00', 68, 'and']\n",
      "\t['0.01', '0.00', 3315, 'grease']\n",
      "\t['0.01', '0.00', 144, 'it']\n",
      "\t['0.01', '0.00', 28, '.']\n",
      "\t['0.05', '0.00', 425, 'think']\n",
      "\t['0.08', '0.00', 7, 'i']\n",
      "\t['0.11', '0.00', 765, 'did']\n",
      "\t['0.13', '0.00', 142, 'a']\n",
      "\t['0.24', '0.01', 102, 'really']\n",
      "\t['0.12', '0.21', 448, 'good']\n",
      "\t['0.09', '0.03', 167, 'job']\n",
      "\t['0.09', '0.73', 22, '!']\n",
      "\t['0.01', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.02', '0.00', 69, 'positive']\n",
      "\t['0.01', '0.00', 12, 'xxxEND']\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,20):\n",
    "    spot_check(i, mode=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Sample # 200 ==================\n",
      "Selected_text:\n",
      "\t ['bad', 'day', 'the', 'day', 'you', 'realize', 'what', 'mess', 'you`ve', 'put', 'me', 'through', 'will', 'be', 'one', 'of', 'the', 'happiest', 'days', 'of', 'my', 'life', '.', '.', '.']\n",
      "Predicted_text:\n",
      "\t ['bad', 'day', 'the', 'day', 'you', 'realize', 'what', 'mess', 'you`ve', 'put', 'me', 'through', 'will', 'be', 'one', 'of', 'the', 'happiest', 'days', 'of', 'my', 'life', '.', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['1.00', '0.00', 318, 'bad']\n",
      "\t['0.00', '0.00', 286, 'day']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.00', '0.00', 286, 'day']\n",
      "\t['0.00', '0.00', 17, 'you']\n",
      "\t['0.00', '0.00', 972, 'realize']\n",
      "\t['0.00', '0.00', 29, 'what']\n",
      "\t['0.00', '0.00', 345, 'mess']\n",
      "\t['0.00', '0.00', 973, 'you`ve']\n",
      "\t['0.00', '0.00', 39, 'put']\n",
      "\t['0.00', '0.00', 27, 'me']\n",
      "\t['0.00', '0.00', 247, 'through']\n",
      "\t['0.00', '0.00', 15, 'will']\n",
      "\t['0.00', '0.00', 89, 'be']\n",
      "\t['0.00', '0.00', 310, 'one']\n",
      "\t['0.00', '0.00', 34, 'of']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.00', '0.00', 974, 'happiest']\n",
      "\t['0.00', '0.00', 136, 'days']\n",
      "\t['0.00', '0.00', 34, 'of']\n",
      "\t['0.00', '0.00', 24, 'my']\n",
      "\t['0.00', '0.00', 868, 'life']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.00', '1.00', 28, '.']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 201 ==================\n",
      "Selected_text:\n",
      "\t ['visiting', 'family', 'in', 'hospital', '=', 'not', 'fun']\n",
      "Predicted_text:\n",
      "\t ['visiting', 'family', 'in', 'hospital', '=', 'not']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.38', '0.02', 346, 'visiting']\n",
      "\t['0.05', '0.03', 173, 'family']\n",
      "\t['0.08', '0.01', 19, 'in']\n",
      "\t['0.08', '0.01', 455, 'hospital']\n",
      "\t['0.09', '0.02', 94, '=']\n",
      "\t['0.16', '0.02', 149, 'not']\n",
      "\t['0.14', '0.86', 63, 'fun']\n",
      "\t['0.02', '0.02', 10, 'xxxSENTIMENT']\n",
      "\t['0.01', '0.01', 23, 'negative']\n",
      "\t['0.00', '0.01', 12, 'xxxEND']\n",
      "================== Sample # 202 ==================\n",
      "Selected_text:\n",
      "\t ['wish', 'me', 'luck']\n",
      "Predicted_text:\n",
      "\t ['going', 'to', 'take', 'my', 'last', 'final', '.', '.', '.', 'wish', 'me', 'luck', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.21', '0.03', 9, 'going']\n",
      "\t['0.05', '0.02', 88, 'to']\n",
      "\t['0.07', '0.03', 433, 'take']\n",
      "\t['0.05', '0.03', 24, 'my']\n",
      "\t['0.06', '0.02', 285, 'last']\n",
      "\t['0.06', '0.03', 1897, 'final']\n",
      "\t['0.07', '0.03', 28, '.']\n",
      "\t['0.08', '0.06', 28, '.']\n",
      "\t['0.10', '0.05', 28, '.']\n",
      "\t['0.09', '0.06', 520, 'wish']\n",
      "\t['0.06', '0.06', 27, 'me']\n",
      "\t['0.04', '0.04', 2010, 'luck']\n",
      "\t['0.04', '0.09', 28, '.']\n",
      "\t['0.01', '0.42', 28, '.']\n",
      "\t['0.00', '0.02', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 203 ==================\n",
      "Selected_text:\n",
      "\t ['lol']\n",
      "Predicted_text:\n",
      "\t ['lol', 'simpsons', 'xxxUNK', ':', \"'\", 'first', 'day', 'at', 'your', 'new', 'school', ',', 'so', 'lisa', ':', 'have', 'fun', '!', 'and', 'bart', ':', 'don`t', '!']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.38', '0.07', 426, 'lol']\n",
      "\t['0.06', '0.06', 1967, 'simpsons']\n",
      "\t['0.07', '0.06', 1, 's20e19']\n",
      "\t['0.04', '0.05', 48, ':']\n",
      "\t['0.03', '0.03', 332, \"'\"]\n",
      "\t['0.03', '0.03', 813, 'first']\n",
      "\t['0.05', '0.03', 286, 'day']\n",
      "\t['0.03', '0.03', 358, 'at']\n",
      "\t['0.02', '0.02', 305, 'your']\n",
      "\t['0.03', '0.03', 163, 'new']\n",
      "\t['0.02', '0.02', 288, 'school']\n",
      "\t['0.02', '0.03', 5, ',']\n",
      "\t['0.02', '0.02', 151, 'so']\n",
      "\t['0.02', '0.01', 3838, 'lisa']\n",
      "\t['0.02', '0.02', 48, ':']\n",
      "\t['0.03', '0.02', 4, 'have']\n",
      "\t['0.03', '0.05', 63, 'fun']\n",
      "\t['0.02', '0.04', 22, '!']\n",
      "\t['0.01', '0.04', 68, 'and']\n",
      "\t['0.01', '0.04', 8516, 'bart']\n",
      "\t['0.01', '0.03', 48, ':']\n",
      "\t['0.01', '0.06', 424, 'don`t']\n",
      "\t['0.00', '0.03', 22, '!']\n",
      "\t['0.01', '0.11', 332, \"'\"]\n",
      "\t['0.00', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.01', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 204 ==================\n",
      "Selected_text:\n",
      "\t ['hahaha', 'sa', 'una', 'lang', 'yan', '!', 'i', 'started', 'with', '40', 'minutes', 'ng', '5k', '.', 'that', 'was', 'a', 'year', 'ago', '.']\n",
      "Predicted_text:\n",
      "\t ['hahaha', 'sa', 'una', 'lang', 'yan', '!', 'i', 'started', 'with', '40', 'minutes', 'ng', '5k', '.', 'that', 'was', 'a', 'year', 'ago']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['1.00', '0.00', 939, 'hahaha']\n",
      "\t['0.00', '0.00', 4426, 'sa']\n",
      "\t['0.00', '0.00', 8599, 'una']\n",
      "\t['0.00', '0.00', 2847, 'lang']\n",
      "\t['0.00', '0.00', 8600, 'yan']\n",
      "\t['0.00', '0.00', 22, '!']\n",
      "\t['0.00', '0.00', 7, 'i']\n",
      "\t['0.00', '0.00', 1877, 'started']\n",
      "\t['0.00', '0.00', 278, 'with']\n",
      "\t['0.00', '0.00', 2965, '40']\n",
      "\t['0.00', '0.00', 713, 'minutes']\n",
      "\t['0.00', '0.00', 2844, 'ng']\n",
      "\t['0.00', '0.00', 6604, '5k']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.00', '0.00', 82, 'that']\n",
      "\t['0.00', '0.00', 183, 'was']\n",
      "\t['0.00', '0.00', 142, 'a']\n",
      "\t['0.00', '0.00', 882, 'year']\n",
      "\t['0.00', '0.00', 913, 'ago']\n",
      "\t['0.00', '1.00', 28, '.']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 205 ==================\n",
      "Selected_text:\n",
      "\t ['_', 'devil1', 'big', 'brother', 'quiz', '?', 'what', '?', '!', 'i`m', 'too', 'busy', 'rocking', 'out', 'on', 'guitar', 'hero', ',', 'i', 'didn`t', 'notice', 'any', 'such', 'thing']\n",
      "Predicted_text:\n",
      "\t ['_', 'xxxUNK', 'big', 'brother', 'quiz', '?', 'what', '?', '!', 'i`m', 'too', 'busy', 'rocking', 'out', 'on', 'guitar', 'hero', ',', 'i', 'didn`t', 'notice', 'any', 'such']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.88', '0.01', 405, '_']\n",
      "\t['0.01', '0.01', 1, 'devil1']\n",
      "\t['0.03', '0.01', 292, 'big']\n",
      "\t['0.01', '0.01', 1087, 'brother']\n",
      "\t['0.01', '0.00', 3851, 'quiz']\n",
      "\t['0.01', '0.00', 74, '?']\n",
      "\t['0.01', '0.00', 29, 'what']\n",
      "\t['0.00', '0.00', 74, '?']\n",
      "\t['0.00', '0.00', 22, '!']\n",
      "\t['0.01', '0.00', 96, 'i`m']\n",
      "\t['0.01', '0.00', 227, 'too']\n",
      "\t['0.00', '0.00', 275, 'busy']\n",
      "\t['0.00', '0.00', 994, 'rocking']\n",
      "\t['0.00', '0.00', 215, 'out']\n",
      "\t['0.00', '0.00', 41, 'on']\n",
      "\t['0.00', '0.01', 2389, 'guitar']\n",
      "\t['0.01', '0.00', 261, 'hero']\n",
      "\t['0.00', '0.00', 5, ',']\n",
      "\t['0.00', '0.01', 7, 'i']\n",
      "\t['0.00', '0.01', 475, 'didn`t']\n",
      "\t['0.00', '0.00', 2396, 'notice']\n",
      "\t['0.00', '0.01', 853, 'any']\n",
      "\t['0.00', '0.03', 416, 'such']\n",
      "\t['0.00', '0.87', 311, 'thing']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 206 ==================\n",
      "Selected_text:\n",
      "\t ['actually', ',', 'by', 'the', 'time', 'i', 'get', 'there', ',', 'the', 'train', 'would', 'have', 'arrived', '.', '.', '.']\n",
      "Predicted_text:\n",
      "\t ['actually', ',', 'by', 'the', 'time', 'i', 'get', 'there', ',', 'the', 'train', 'would', 'have', 'arrived', '.', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.99', '0.00', 732, 'actually']\n",
      "\t['0.00', '0.00', 5, ',']\n",
      "\t['0.00', '0.00', 106, 'by']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.00', '0.00', 504, 'time']\n",
      "\t['0.00', '0.00', 7, 'i']\n",
      "\t['0.00', '0.00', 99, 'get']\n",
      "\t['0.00', '0.00', 216, 'there']\n",
      "\t['0.00', '0.00', 5, ',']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.00', '0.00', 1752, 'train']\n",
      "\t['0.00', '0.00', 145, 'would']\n",
      "\t['0.00', '0.00', 4, 'have']\n",
      "\t['0.00', '0.00', 3306, 'arrived']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.00', '1.00', 28, '.']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 207 ==================\n",
      "Selected_text:\n",
      "\t ['sounds', 'good', ',', 'the', 'one', 'i', 'was', 'too', 'was', 'also', 'fun']\n",
      "Predicted_text:\n",
      "\t ['sounds', 'good', ',', 'the', 'one', 'i', 'was', 'too', 'was', 'also']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.28', '0.05', 423, 'sounds']\n",
      "\t['0.06', '0.03', 448, 'good']\n",
      "\t['0.09', '0.04', 5, ',']\n",
      "\t['0.08', '0.05', 42, 'the']\n",
      "\t['0.09', '0.03', 310, 'one']\n",
      "\t['0.04', '0.04', 7, 'i']\n",
      "\t['0.08', '0.03', 183, 'was']\n",
      "\t['0.13', '0.05', 227, 'too']\n",
      "\t['0.09', '0.05', 183, 'was']\n",
      "\t['0.04', '0.04', 356, 'also']\n",
      "\t['0.02', '0.55', 63, 'fun']\n",
      "\t['0.00', '0.03', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 208 ==================\n",
      "Selected_text:\n",
      "\t ['decreasing']\n",
      "Predicted_text:\n",
      "\t ['showed', 'my', 'fluids', 'decreasing', 'slightly', '.', 'so', 'doesn`t', 'look', 'like', 'she`s', 'letting', 'me', 'out', 'of', 'this', 'bed', 'anytime', 'soon', 'i', 'have', 'a', 'follow', 'up', 'u', '/', 's', 'next', 'week']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.50', '0.09', 1112, 'showed']\n",
      "\t['0.06', '0.09', 24, 'my']\n",
      "\t['0.09', '0.06', 3935, 'fluids']\n",
      "\t['0.05', '0.08', 9167, 'decreasing']\n",
      "\t['0.04', '0.04', 1567, 'slightly']\n",
      "\t['0.03', '0.08', 28, '.']\n",
      "\t['0.03', '0.05', 151, 'so']\n",
      "\t['0.02', '0.03', 1279, 'doesn`t']\n",
      "\t['0.03', '0.02', 146, 'look']\n",
      "\t['0.03', '0.04', 103, 'like']\n",
      "\t['0.03', '0.05', 547, 'she`s']\n",
      "\t['0.02', '0.03', 4986, 'letting']\n",
      "\t['0.02', '0.03', 27, 'me']\n",
      "\t['0.01', '0.02', 215, 'out']\n",
      "\t['0.01', '0.01', 34, 'of']\n",
      "\t['0.02', '0.02', 276, 'this']\n",
      "\t['0.01', '0.02', 557, 'bed']\n",
      "\t['0.01', '0.04', 2022, 'anytime']\n",
      "\t['0.00', '0.04', 156, 'soon']\n",
      "\t['0.00', '0.02', 7, 'i']\n",
      "\t['0.01', '0.02', 4, 'have']\n",
      "\t['0.00', '0.04', 142, 'a']\n",
      "\t['0.00', '0.02', 1240, 'follow']\n",
      "\t['0.00', '0.02', 225, 'up']\n",
      "\t['0.00', '0.01', 76, 'u']\n",
      "\t['0.00', '0.00', 49, '/']\n",
      "\t['0.00', '0.00', 2148, 's']\n",
      "\t['0.00', '0.00', 574, 'next']\n",
      "\t['0.00', '0.02', 570, 'week']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 23, 'negative']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 209 ==================\n",
      "Selected_text:\n",
      "\t ['jealous', '*']\n",
      "Predicted_text:\n",
      "\t ['_', 'r', 'drive', '-', 'in', '!', '?', 'srsly', '!', '?', '*', 'jealous', '*', 'i', 'have', 'never', 'ever', 'been', 'to', 'one', '.', 'there', 'is', 'one', 'down', 'the', 'rd', ',', 'but', 'it`s', 'no', 'longer', 'operational', ':']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.16', '0.01', 405, '_']\n",
      "\t['0.02', '0.01', 706, 'r']\n",
      "\t['0.04', '0.01', 731, 'drive']\n",
      "\t['0.02', '0.02', 52, '-']\n",
      "\t['0.02', '0.01', 19, 'in']\n",
      "\t['0.02', '0.02', 22, '!']\n",
      "\t['0.02', '0.01', 74, '?']\n",
      "\t['0.02', '0.01', 2036, 'srsly']\n",
      "\t['0.02', '0.01', 22, '!']\n",
      "\t['0.03', '0.01', 74, '?']\n",
      "\t['0.03', '0.01', 35, '*']\n",
      "\t['0.02', '0.01', 408, 'jealous']\n",
      "\t['0.02', '0.01', 35, '*']\n",
      "\t['0.03', '0.02', 7, 'i']\n",
      "\t['0.03', '0.01', 4, 'have']\n",
      "\t['0.03', '0.05', 97, 'never']\n",
      "\t['0.04', '0.02', 817, 'ever']\n",
      "\t['0.02', '0.01', 132, 'been']\n",
      "\t['0.02', '0.02', 88, 'to']\n",
      "\t['0.02', '0.01', 310, 'one']\n",
      "\t['0.03', '0.02', 28, '.']\n",
      "\t['0.02', '0.02', 216, 'there']\n",
      "\t['0.02', '0.02', 26, 'is']\n",
      "\t['0.03', '0.02', 310, 'one']\n",
      "\t['0.02', '0.03', 585, 'down']\n",
      "\t['0.03', '0.02', 42, 'the']\n",
      "\t['0.02', '0.02', 1675, 'rd']\n",
      "\t['0.03', '0.03', 5, ',']\n",
      "\t['0.02', '0.04', 116, 'but']\n",
      "\t['0.02', '0.02', 192, 'it`s']\n",
      "\t['0.02', '0.04', 204, 'no']\n",
      "\t['0.01', '0.04', 727, 'longer']\n",
      "\t['0.01', '0.05', 4367, 'operational']\n",
      "\t['0.01', '0.03', 48, ':']\n",
      "\t['0.01', '0.12', 2428, '|']\n",
      "\t['0.01', '0.02', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.04', 23, 'negative']\n",
      "\t['0.00', '0.01', 12, 'xxxEND']\n"
     ]
    }
   ],
   "source": [
    "for i in range(200,210):\n",
    "    spot_check(i, mode=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Sample # 10 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['have', 'known', 'that', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.12', '0.04', 24, 'my']\n",
      "\t['0.04', '0.04', 977, 'bike']\n",
      "\t['0.05', '0.04', 183, 'was']\n",
      "\t['0.04', '0.05', 39, 'put']\n",
      "\t['0.03', '0.04', 41, 'on']\n",
      "\t['0.04', '0.03', 3270, 'hold']\n",
      "\t['0.03', '0.05', 28, '.']\n",
      "\t['0.03', '0.03', 28, '.']\n",
      "\t['0.04', '0.03', 28, '.']\n",
      "\t['0.07', '0.02', 350, 'should']\n",
      "\t['0.12', '0.06', 4, 'have']\n",
      "\t['0.09', '0.06', 2467, 'known']\n",
      "\t['0.07', '0.06', 82, 'that']\n",
      "\t['0.05', '0.04', 28, '.']\n",
      "\t['0.06', '0.13', 28, '.']\n",
      "\t['0.03', '0.08', 28, '.']\n",
      "\t['0.03', '0.04', 28, '.']\n",
      "\t['0.02', '0.01', 1286, 'argh']\n",
      "\t['0.02', '0.02', 1291, 'total']\n",
      "\t['0.01', '0.08', 5242, 'bummer']\n",
      "\t['0.01', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.01', 23, 'negative']\n",
      "\t['0.00', '0.01', 12, 'xxxEND']\n",
      "================== Sample # 11 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['i', 'checked', '.', 'we', 'didn`t']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.98', '0.00', 7, 'i']\n",
      "\t['0.00', '0.00', 2486, 'checked']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.00', '0.00', 44, 'we']\n",
      "\t['0.00', '0.00', 475, 'didn`t']\n",
      "\t['0.00', '0.99', 738, 'win']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 12 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['.', '.', 'and', 'you`re', 'on', 'twitter', '!', 'did', 'the', 'xxxUNK', 'xxxUNK', 'you', 'that', 'much']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.99', '0.00', 28, '.']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.00', '0.00', 68, 'and']\n",
      "\t['0.00', '0.00', 956, 'you`re']\n",
      "\t['0.00', '0.00', 41, 'on']\n",
      "\t['0.00', '0.00', 231, 'twitter']\n",
      "\t['0.00', '0.00', 22, '!']\n",
      "\t['0.00', '0.00', 765, 'did']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.00', '0.00', 1, 'tavern']\n",
      "\t['0.00', '0.00', 1, 'bore']\n",
      "\t['0.00', '0.00', 17, 'you']\n",
      "\t['0.00', '0.00', 82, 'that']\n",
      "\t['0.00', '0.00', 86, 'much']\n",
      "\t['0.00', '1.00', 74, '?']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 13 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['me', 'kinda', 'sad', ',', 'he', 'is', 'getting', 'so', 'big', ',']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.00', '0.00', 96, 'i`m']\n",
      "\t['0.00', '0.00', 19, 'in']\n",
      "\t['0.00', '0.00', 6180, 'va']\n",
      "\t['0.00', '0.00', 55, 'for']\n",
      "\t['0.00', '0.00', 42, 'the']\n",
      "\t['0.00', '0.00', 1231, 'weekend']\n",
      "\t['0.00', '0.00', 5, ',']\n",
      "\t['0.00', '0.00', 24, 'my']\n",
      "\t['0.00', '0.00', 1, 'youngest']\n",
      "\t['0.00', '0.00', 945, 'son']\n",
      "\t['0.00', '0.00', 1040, 'turns']\n",
      "\t['0.00', '0.00', 694, '2']\n",
      "\t['0.00', '0.00', 251, 'tomorrow']\n",
      "\t['0.01', '0.00', 28, '.']\n",
      "\t['0.02', '0.00', 28, '.']\n",
      "\t['0.01', '0.00', 28, '.']\n",
      "\t['0.03', '0.00', 28, '.']\n",
      "\t['0.04', '0.00', 28, '.']\n",
      "\t['0.02', '0.00', 28, '.']\n",
      "\t['0.09', '0.01', 144, 'it']\n",
      "\t['0.06', '0.01', 1151, 'makes']\n",
      "\t['0.20', '0.05', 27, 'me']\n",
      "\t['0.03', '0.01', 1814, 'kinda']\n",
      "\t['0.08', '0.08', 14, 'sad']\n",
      "\t['0.02', '0.03', 5, ',']\n",
      "\t['0.05', '0.01', 65, 'he']\n",
      "\t['0.05', '0.00', 26, 'is']\n",
      "\t['0.07', '0.00', 540, 'getting']\n",
      "\t['0.05', '0.02', 151, 'so']\n",
      "\t['0.10', '0.01', 292, 'big']\n",
      "\t['0.05', '0.03', 5, ',']\n",
      "\t['0.00', '0.49', 351, 'check']\n",
      "\t['0.00', '0.10', 215, 'out']\n",
      "\t['0.00', '0.00', 24, 'my']\n",
      "\t['0.00', '0.11', 1, 'twipics']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.02', 23, 'negative']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 14 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['its', 'coming', 'out', 'the', 'xxxUNK', 'i', 'feel', 'like', 'my', 'phones', 'hole', 'is', 'not', 'a', 'virgin', '.', 'that`s', 'how', 'loose', 'it', 'is', '.', '.', '.', ':', '`']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.32', '0.03', 213, 'its']\n",
      "\t['0.03', '0.02', 277, 'coming']\n",
      "\t['0.05', '0.02', 215, 'out']\n",
      "\t['0.03', '0.02', 42, 'the']\n",
      "\t['0.02', '0.02', 1, 'socket']\n",
      "\t['0.02', '0.01', 7, 'i']\n",
      "\t['0.03', '0.02', 338, 'feel']\n",
      "\t['0.02', '0.01', 103, 'like']\n",
      "\t['0.03', '0.01', 24, 'my']\n",
      "\t['0.05', '0.03', 1682, 'phones']\n",
      "\t['0.04', '0.02', 5511, 'hole']\n",
      "\t['0.02', '0.02', 26, 'is']\n",
      "\t['0.01', '0.01', 149, 'not']\n",
      "\t['0.03', '0.02', 142, 'a']\n",
      "\t['0.02', '0.01', 10085, 'virgin']\n",
      "\t['0.02', '0.02', 28, '.']\n",
      "\t['0.02', '0.01', 240, 'that`s']\n",
      "\t['0.02', '0.01', 335, 'how']\n",
      "\t['0.02', '0.01', 4396, 'loose']\n",
      "\t['0.02', '0.01', 144, 'it']\n",
      "\t['0.04', '0.02', 26, 'is']\n",
      "\t['0.02', '0.02', 28, '.']\n",
      "\t['0.01', '0.04', 28, '.']\n",
      "\t['0.02', '0.06', 28, '.']\n",
      "\t['0.02', '0.04', 48, ':']\n",
      "\t['0.01', '0.07', 3541, '`']\n",
      "\t['0.01', '0.34', 81, '(']\n",
      "\t['0.00', '0.01', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.02', 23, 'negative']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 15 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['so', 'hot', 'today', '=', '_', '=', 'don`t', 'like', 'it', 'and', 'i', 'hate', 'my', 'new', 'xxxUNK', ',', 'having', 'such', 'a', 'bad']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.20', '0.02', 151, 'so']\n",
      "\t['0.03', '0.02', 1662, 'hot']\n",
      "\t['0.04', '0.02', 177, 'today']\n",
      "\t['0.02', '0.01', 94, '=']\n",
      "\t['0.02', '0.01', 405, '_']\n",
      "\t['0.02', '0.01', 94, '=']\n",
      "\t['0.02', '0.01', 424, 'don`t']\n",
      "\t['0.03', '0.01', 103, 'like']\n",
      "\t['0.03', '0.01', 144, 'it']\n",
      "\t['0.05', '0.02', 68, 'and']\n",
      "\t['0.06', '0.05', 7, 'i']\n",
      "\t['0.05', '0.03', 355, 'hate']\n",
      "\t['0.04', '0.02', 24, 'my']\n",
      "\t['0.05', '0.03', 163, 'new']\n",
      "\t['0.06', '0.03', 1, 'timetable']\n",
      "\t['0.06', '0.04', 5, ',']\n",
      "\t['0.06', '0.03', 830, 'having']\n",
      "\t['0.04', '0.04', 416, 'such']\n",
      "\t['0.04', '0.06', 142, 'a']\n",
      "\t['0.03', '0.09', 318, 'bad']\n",
      "\t['0.03', '0.35', 570, 'week']\n",
      "\t['0.01', '0.03', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.01', 23, 'negative']\n",
      "\t['0.00', '0.01', 12, 'xxxEND']\n",
      "================== Sample # 16 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['miss', 'you']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['1.00', '0.62', 16, 'miss']\n",
      "\t['0.00', '0.38', 17, 'you']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 23, 'negative']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 17 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['cramps', '.', '.']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.56', '0.06', 1896, 'cramps']\n",
      "\t['0.12', '0.12', 28, '.']\n",
      "\t['0.18', '0.09', 28, '.']\n",
      "\t['0.11', '0.67', 28, '.']\n",
      "\t['0.02', '0.03', 10, 'xxxSENTIMENT']\n",
      "\t['0.01', '0.02', 23, 'negative']\n",
      "\t['0.01', '0.01', 12, 'xxxEND']\n",
      "================== Sample # 18 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['you', 'guys', 'didn`t', 'say', 'hi', 'or', 'answer', 'my', 'questions', 'yesterday', 'but', 'nice', 'songs']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['0.16', '0.04', 17, 'you']\n",
      "\t['0.05', '0.03', 493, 'guys']\n",
      "\t['0.06', '0.05', 475, 'didn`t']\n",
      "\t['0.05', '0.05', 460, 'say']\n",
      "\t['0.05', '0.03', 461, 'hi']\n",
      "\t['0.05', '0.03', 758, 'or']\n",
      "\t['0.07', '0.04', 1677, 'answer']\n",
      "\t['0.08', '0.07', 24, 'my']\n",
      "\t['0.10', '0.04', 2614, 'questions']\n",
      "\t['0.10', '0.05', 453, 'yesterday']\n",
      "\t['0.09', '0.06', 116, 'but']\n",
      "\t['0.06', '0.09', 397, 'nice']\n",
      "\t['0.05', '0.08', 645, 'songs']\n",
      "\t['0.02', '0.31', 28, '.']\n",
      "\t['0.01', '0.02', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 69, 'positive']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n",
      "================== Sample # 19 ==================\n",
      "Selected_text:\n",
      "\t Not Available\n",
      "Predicted_text:\n",
      "\t ['i`m', 'going', 'into', 'a', 'xxxUNK', 'xxxUNK', ',', 'its', 'xxxUNK', 'my', 'ego', '!', '.', 'i', 'now', 'realise', ',', 'i`m', 'not', 'all', 'that', 'great', '.', 'and', 'i`m', 'ok', 'with', 'that']\n",
      "Predictions:\n",
      "\t\n",
      "\t['0.00', '0.00', 2, 'xxxSTART']\n",
      "\t['1.00', '0.00', 96, 'i`m']\n",
      "\t['0.00', '0.00', 9, 'going']\n",
      "\t['0.00', '0.00', 150, 'into']\n",
      "\t['0.00', '0.00', 142, 'a']\n",
      "\t['0.00', '0.00', 1, 'spiritual']\n",
      "\t['0.00', '0.00', 1, 'stagnentation']\n",
      "\t['0.00', '0.00', 5, ',']\n",
      "\t['0.00', '0.00', 213, 'its']\n",
      "\t['0.00', '0.00', 1, 'exploding']\n",
      "\t['0.00', '0.00', 24, 'my']\n",
      "\t['0.00', '0.00', 5906, 'ego']\n",
      "\t['0.00', '0.00', 22, '!']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.00', '0.00', 7, 'i']\n",
      "\t['0.00', '0.00', 229, 'now']\n",
      "\t['0.00', '0.00', 2825, 'realise']\n",
      "\t['0.00', '0.00', 5, ',']\n",
      "\t['0.00', '0.00', 96, 'i`m']\n",
      "\t['0.00', '0.00', 149, 'not']\n",
      "\t['0.00', '0.00', 66, 'all']\n",
      "\t['0.00', '0.00', 82, 'that']\n",
      "\t['0.00', '0.00', 812, 'great']\n",
      "\t['0.00', '0.00', 28, '.']\n",
      "\t['0.00', '0.00', 68, 'and']\n",
      "\t['0.00', '0.00', 96, 'i`m']\n",
      "\t['0.00', '0.00', 458, 'ok']\n",
      "\t['0.00', '0.00', 278, 'with']\n",
      "\t['0.00', '0.01', 82, 'that']\n",
      "\t['0.00', '0.99', 28, '.']\n",
      "\t['0.00', '0.00', 10, 'xxxSENTIMENT']\n",
      "\t['0.00', '0.00', 11, 'neutral']\n",
      "\t['0.00', '0.00', 12, 'xxxEND']\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,20):\n",
    "    spot_check(i, mode=\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
