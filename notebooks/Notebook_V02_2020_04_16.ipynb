{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTROLS\n",
    "MODEL_PREFIX = \"V02\"\n",
    "MODEL_NUMBER = MODEL_PREFIX[-2:]\n",
    "TRAIN_SPLIT_RATIO = 0.8\n",
    "\n",
    "DROPOUT = 0.1\n",
    "MIN_LR = 1e-5\n",
    "MAX_LR = 1e-3\n",
    "BATCH_SIZE = 128\n",
    "PREDICT_BATCH_SIZE = 2048\n",
    "STEP_SIZE = 20\n",
    "CLR_METHOD = \"triangular2\" # exp_range, triangular, triangular2\n",
    "NUM_EPOCHS = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import pickle, os, sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, LSTM, Embedding, Dense, concatenate, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout, Flatten, Reshape, Activation, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def signaltonoise(a, axis=0, ddof=0):\n",
    "    a = np.asanyarray(a)\n",
    "    m = a.mean(axis)\n",
    "    sd = a.std(axis=axis, ddof=ddof)\n",
    "    return np.where(sd == 0, 0, m/sd)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import *\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "class CyclicLR(Callback):\n",
    "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
    "    The method cycles the learning rate between two boundaries with\n",
    "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
    "    The amplitude of the cycle can be scaled on a per-iteration or \n",
    "    per-cycle basis.\n",
    "    This class has three built-in policies, as put forth in the paper.\n",
    "    \"triangular\":\n",
    "        A basic triangular cycle w/ no amplitude scaling.\n",
    "    \"triangular2\":\n",
    "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
    "    \"exp_range\":\n",
    "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n",
    "        cycle iteration.\n",
    "    For more detail, please see paper.\n",
    "    \n",
    "    # Example\n",
    "        ```python\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```\n",
    "    \n",
    "    Class also supports custom scaling functions:\n",
    "        ```python\n",
    "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., scale_fn=clr_fn,\n",
    "                                scale_mode='cycle')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```    \n",
    "    # Arguments\n",
    "        base_lr: initial learning rate which is the\n",
    "            lower boundary in the cycle.\n",
    "        max_lr: upper boundary in the cycle. Functionally,\n",
    "            it defines the cycle amplitude (max_lr - base_lr).\n",
    "            The lr at any cycle is the sum of base_lr\n",
    "            and some scaling of the amplitude; therefore \n",
    "            max_lr may not actually be reached depending on\n",
    "            scaling function.\n",
    "        step_size: number of training iterations per\n",
    "            half cycle. Authors suggest setting step_size\n",
    "            2-8 x training iterations in epoch.\n",
    "        mode: one of {triangular, triangular2, exp_range}.\n",
    "            Default 'triangular'.\n",
    "            Values correspond to policies detailed above.\n",
    "            If scale_fn is not None, this argument is ignored.\n",
    "        gamma: constant in 'exp_range' scaling function:\n",
    "            gamma**(cycle iterations)\n",
    "        scale_fn: Custom scaling policy defined by a single\n",
    "            argument lambda function, where \n",
    "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
    "            mode paramater is ignored \n",
    "        scale_mode: {'cycle', 'iterations'}.\n",
    "            Defines whether scale_fn is evaluated on \n",
    "            cycle number or cycle iterations (training\n",
    "            iterations since start of cycle). Default is 'cycle'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma**(x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        \"\"\"Resets cycle iterations.\n",
    "        Optional boundary/step size adjustment.\n",
    "        \"\"\"\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "        \n",
    "    def clr(self):\n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
    "            \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0  1\n",
      "textID         object  0\n",
      "text           object  1\n",
      "selected_text  object  1\n",
      "sentiment      object  0\n",
      "(27481, 4)\n",
      "{'textID': 27481, 'text': 27480, 'selected_text': 22463, 'sentiment': 3}\n",
      "            textID                                               text  \\\n",
      "count        27481                                              27480   \n",
      "unique       27481                                              27480   \n",
      "top     f9d3b11eae   - Hey, Lenny, we are waiting you in Bulgaria ...   \n",
      "freq             1                                                  1   \n",
      "\n",
      "       selected_text sentiment  \n",
      "count          27480     27481  \n",
      "unique         22463         3  \n",
      "top             good   neutral  \n",
      "freq             199     11118  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\", dtype={\"time\":np.float64,\"signal\":np.float64,\"open_channels\":np.int16})\n",
    "print(pd.concat((df.dtypes, df.isna().sum()), axis=1))\n",
    "print(df.shape)\n",
    "\n",
    "# Counts of various columns\n",
    "print({i:df[i].nunique() for i in df.columns})\n",
    "print(df.describe()) #.astype(int)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0  1\n",
      "textID     object  0\n",
      "text       object  0\n",
      "sentiment  object  0\n",
      "(3534, 3)\n",
      "{'textID': 3534, 'text': 3534, 'sentiment': 3}\n",
      "            textID                                               text  \\\n",
      "count         3534                                               3534   \n",
      "unique        3534                                               3534   \n",
      "top     69d6b5d93e  Going to clean my room but thats not hard. i k...   \n",
      "freq             1                                                  1   \n",
      "\n",
      "       sentiment  \n",
      "count       3534  \n",
      "unique         3  \n",
      "top      neutral  \n",
      "freq        1430  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f87dea47db</td>\n",
       "      <td>Last session of the day  http://twitpic.com/67ezh</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96d74cb729</td>\n",
       "      <td>Shanghai is also really exciting (precisely -...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eee518ae67</td>\n",
       "      <td>Recession hit Veronique Branquinho, she has to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01082688c6</td>\n",
       "      <td>happy bday!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33987a8ee5</td>\n",
       "      <td>http://twitpic.com/4w75p - I like it!!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text sentiment\n",
       "0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral\n",
       "1  96d74cb729   Shanghai is also really exciting (precisely -...  positive\n",
       "2  eee518ae67  Recession hit Veronique Branquinho, she has to...  negative\n",
       "3  01082688c6                                        happy bday!  positive\n",
       "4  33987a8ee5             http://twitpic.com/4w75p - I like it!!  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"../data/test.csv\", dtype={\"time\":np.float64,\"signal\":np.float64})\n",
    "print(pd.concat((test_df.dtypes, test_df.isna().sum()), axis=1))\n",
    "print(test_df.shape)\n",
    "\n",
    "# Counts of various columns\n",
    "print({i:test_df[i].nunique() for i in test_df.columns})\n",
    "print(test_df.describe())\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"original_index\"] = df.index\n",
    "test_df[\"original_index\"] = test_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment count in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>7781</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>11117</td>\n",
       "      <td>1430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>8582</td>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text  text\n",
       "sentiment             \n",
       "negative    7781  1001\n",
       "neutral    11117  1430\n",
       "positive    8582  1103"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df.groupby(\"sentiment\")[[\"text\"]].count(), test_df.groupby(\"sentiment\")[[\"text\"]].count()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentiment_code\"] = df[\"sentiment\"].astype(\"category\")\n",
    "X_sentiments = df[\"sentiment_code\"].cat.codes.values\n",
    "\n",
    "test_df[\"sentiment_code\"] = test_df[\"sentiment\"].astype(\"category\")\n",
    "X_sentiments_test = test_df[\"sentiment_code\"].cat.codes.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "df[\"selected_text\"] = df[\"selected_text\"].astype(str)\n",
    "test_df[\"text\"] = test_df[\"text\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(i.split(\" \")) for i in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tkn = Tokenizer() # num_words=\n",
    "Tkn.fit_on_texts(texts)\n",
    "X = Tkn.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_texts = df[\"selected_text\"].tolist()\n",
    "Y = Tkn.texts_to_sequences(selected_texts)\n",
    "Y2 = [[1 if j in y else 0 for j in X[i]] for i,y in enumerate(Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = test_df[\"text\"].tolist()\n",
    "X_test = Tkn.texts_to_sequences(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_y = max([len(i) for i in Y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 35\n"
     ]
    }
   ],
   "source": [
    "print(max_len, max_len_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27481 21985 5496 27481\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "idx = [i for i in np.arange(len(Y))]\n",
    "np.random.shuffle(idx)\n",
    "train_idx, val_idx = idx[:round(TRAIN_SPLIT_RATIO*len(Y))], idx[round(TRAIN_SPLIT_RATIO*len(Y)):]\n",
    "\n",
    "print(len(idx), len(train_idx), len(val_idx), len(train_idx) + len(val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21985, 5496, 21985, 5496, 21985, 5496, 21985, 5496]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val = [X[i] for i in train_idx], [X[i] for i in val_idx]\n",
    "X_sentiments_train, X_sentiments_val = [X_sentiments[i] for i in train_idx], [X_sentiments[i] for i in val_idx]\n",
    "X_sentiments_train, X_sentiments_val = np.array(X_sentiments_train, dtype=np.int32), np.array(X_sentiments_val, dtype=np.int32)\n",
    "Y_train, Y_val = [Y[i] for i in train_idx], [Y[i] for i in val_idx]\n",
    "Y2_train, Y2_val = [Y2[i] for i in train_idx], [Y2[i] for i in val_idx]\n",
    "\n",
    "[len(i) for i in [X_train, X_val, X_sentiments_train, X_sentiments_val, Y_train, Y_val, Y2_train, Y2_val]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=max_len + 1, padding=\"post\")\n",
    "Y_train = pad_sequences(Y_train, maxlen=max_len + 1, padding=\"post\")\n",
    "Y2_train = pad_sequences(Y2_train, maxlen=max_len + 1, padding=\"post\")\n",
    "\n",
    "X_val = pad_sequences(X_val, maxlen=max_len + 1, padding=\"post\")\n",
    "Y_val = pad_sequences(Y_val, maxlen=max_len + 1, padding=\"post\")\n",
    "Y2_val = pad_sequences(Y2_val, maxlen=max_len + 1, padding=\"post\")\n",
    "\n",
    "X_test = pad_sequences(X_test, maxlen=max_len + 1, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21985, 102) (21985,) (5496, 102) (5496,) (3534, 102)\n",
      "(21985, 102) (21985, 102) (5496, 102) (5496, 102)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_sentiments_train.shape, X_val.shape, X_sentiments_val.shape, X_test.shape)\n",
    "print(Y_train.shape, Y2_train.shape, Y_val.shape, Y2_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = max(Tkn.index_word.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking for zero input vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_x_train = X_train.sum(axis=1) > 0\n",
    "X_train, Y_train = X_train[keep_x_train], Y_train[keep_x_train]\n",
    "X_sentiments_train, Y2_train = X_sentiments_train[keep_x_train], Y2_train[keep_x_train]\n",
    "\n",
    "keep_x_val = X_val.sum(axis=1) > 0\n",
    "X_val, Y_val = X_val[keep_x_val], Y_val[keep_x_val]\n",
    "X_sentiments_val, Y2_val = X_sentiments_val[keep_x_val], Y2_val[keep_x_val]\n",
    "\n",
    "keep_x_test = X_test.sum(axis=1) > 0\n",
    "test_df[\"kept\"] = keep_x_test\n",
    "X_test, X_sentiments_test = X_test[keep_x_test], X_sentiments_test[keep_x_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6\n",
      "0 37\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax([X_train.sum(axis=1)==0]), np.min([X_train.sum(axis=1)]))\n",
    "print(np.argmax([X_val.sum(axis=1)==0]), np.min([X_val.sum(axis=1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentiment = Input((1))\n",
    "input_sequences = Input((max_len+1))\n",
    "\n",
    "emb_sequences = Embedding(input_dim=VOCAB_SIZE+1, input_length=max_len+1, output_dim=32, mask_zero=True)(input_sequences)\n",
    "\n",
    "seq = Bidirectional(LSTM(32, return_sequences=True))(emb_sequences)\n",
    "seq = BatchNormalization()(seq)\n",
    "seq = Dropout(DROPOUT)(seq)\n",
    "\n",
    "seq = Bidirectional(LSTM(32, return_sequences=True))(seq)\n",
    "seq = BatchNormalization()(seq)\n",
    "seq = Dropout(DROPOUT)(seq)\n",
    "\n",
    "seq = TimeDistributed(Dense(64, activation=\"relu\"))(seq)\n",
    "seq = BatchNormalization()(seq)\n",
    "seq = Dropout(DROPOUT)(seq)\n",
    "\n",
    "seq = Flatten()(seq)\n",
    "\n",
    "emb_sentiment = Embedding(input_dim=3, input_length=1, output_dim=5)(input_sentiment)\n",
    "senti = Dense(8, activation=\"relu\")(emb_sentiment)\n",
    "senti = BatchNormalization()(senti)\n",
    "senti = Dropout(DROPOUT)(senti)\n",
    "senti = Flatten()(senti)\n",
    "\n",
    "concat_layer = concatenate([senti, seq])\n",
    "output = Dense(max_len+1, activation=\"sigmoid\")(concat_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 102)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 102, 32)      851168      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 102, 64)      16640       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 102, 64)      256         bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 102, 64)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 102, 64)      24832       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 102, 64)      256         bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 5)         15          input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 102, 64)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1, 8)         48          embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 102, 64)      4160        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1, 8)         32          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 102, 64)      256         time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 1, 8)         0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 102, 64)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 8)            0           dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 6528)         0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 6536)         0           flatten_5[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 102)          666774      concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,564,437\n",
      "Trainable params: 1,564,037\n",
      "Non-trainable params: 400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([input_sentiment, input_sequences], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=MIN_LR)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "#model.compile(loss='sparse_categorical_crossentropy',\n",
    "#              optimizer=adam) #, metrics=['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks\n",
    "mcp = ModelCheckpoint(filepath=\"../results/\"+MODEL_PREFIX+\"Checkpoint.h5\",\n",
    "                      monitor='val_loss',\n",
    "                      mode=\"auto\",\n",
    "                      save_weights_only=False,\n",
    "                      save_best_only=True)\n",
    "\n",
    "clr = CyclicLR(mode=CLR_METHOD,\n",
    "               base_lr=MIN_LR,\n",
    "               max_lr=MAX_LR,\n",
    "               step_size= STEP_SIZE * (X_train.shape[0] // BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21984 samples, validate on 5495 samples\n",
      "Epoch 1/200\n",
      "21984/21984 [==============================] - 22s 1ms/sample - loss: 0.3406 - accuracy: 0.8510 - val_loss: 0.2444 - val_accuracy: 0.9329\n",
      "Epoch 2/200\n",
      "21984/21984 [==============================] - 7s 320us/sample - loss: 0.1210 - accuracy: 0.9372 - val_loss: 0.1916 - val_accuracy: 0.9318\n",
      "Epoch 3/200\n",
      "21984/21984 [==============================] - 7s 314us/sample - loss: 0.1004 - accuracy: 0.9442 - val_loss: 0.1561 - val_accuracy: 0.9340\n",
      "Epoch 4/200\n",
      "21984/21984 [==============================] - 7s 313us/sample - loss: 0.0863 - accuracy: 0.9541 - val_loss: 0.0893 - val_accuracy: 0.9502\n",
      "Epoch 5/200\n",
      "21984/21984 [==============================] - 7s 312us/sample - loss: 0.0727 - accuracy: 0.9644 - val_loss: 0.0719 - val_accuracy: 0.9685\n",
      "Epoch 6/200\n",
      "21984/21984 [==============================] - 7s 340us/sample - loss: 0.0611 - accuracy: 0.9719 - val_loss: 0.0659 - val_accuracy: 0.9702\n",
      "Epoch 7/200\n",
      "21984/21984 [==============================] - 8s 346us/sample - loss: 0.0498 - accuracy: 0.9783 - val_loss: 0.0679 - val_accuracy: 0.9681\n",
      "Epoch 8/200\n",
      "21984/21984 [==============================] - 7s 328us/sample - loss: 0.0416 - accuracy: 0.9824 - val_loss: 0.0734 - val_accuracy: 0.9673\n",
      "Epoch 9/200\n",
      "21984/21984 [==============================] - 8s 347us/sample - loss: 0.0362 - accuracy: 0.9850 - val_loss: 0.0774 - val_accuracy: 0.9661\n",
      "Epoch 10/200\n",
      "21984/21984 [==============================] - 7s 325us/sample - loss: 0.0321 - accuracy: 0.9868 - val_loss: 0.0796 - val_accuracy: 0.9664\n",
      "Epoch 11/200\n",
      "21984/21984 [==============================] - 8s 344us/sample - loss: 0.0280 - accuracy: 0.9887 - val_loss: 0.0892 - val_accuracy: 0.9653\n",
      "Epoch 12/200\n",
      "21984/21984 [==============================] - 8s 347us/sample - loss: 0.0255 - accuracy: 0.9898 - val_loss: 0.0893 - val_accuracy: 0.9657\n",
      "Epoch 13/200\n",
      "21984/21984 [==============================] - 8s 346us/sample - loss: 0.0225 - accuracy: 0.9912 - val_loss: 0.0994 - val_accuracy: 0.9647\n",
      "Epoch 14/200\n",
      "21984/21984 [==============================] - 7s 326us/sample - loss: 0.0210 - accuracy: 0.9918 - val_loss: 0.0972 - val_accuracy: 0.9654\n",
      "Epoch 15/200\n",
      "21984/21984 [==============================] - 7s 314us/sample - loss: 0.0200 - accuracy: 0.9922 - val_loss: 0.0994 - val_accuracy: 0.9654\n",
      "Epoch 16/200\n",
      "21984/21984 [==============================] - 8s 348us/sample - loss: 0.0184 - accuracy: 0.9929 - val_loss: 0.0954 - val_accuracy: 0.9664\n",
      "Epoch 17/200\n",
      "21984/21984 [==============================] - 7s 320us/sample - loss: 0.0172 - accuracy: 0.9933 - val_loss: 0.1075 - val_accuracy: 0.9653\n",
      "Epoch 18/200\n",
      "21984/21984 [==============================] - 7s 339us/sample - loss: 0.0159 - accuracy: 0.9939 - val_loss: 0.1069 - val_accuracy: 0.9655\n",
      "Epoch 19/200\n",
      "21984/21984 [==============================] - 7s 335us/sample - loss: 0.0147 - accuracy: 0.9944 - val_loss: 0.1222 - val_accuracy: 0.9644\n",
      "Epoch 20/200\n",
      "21984/21984 [==============================] - 7s 337us/sample - loss: 0.0141 - accuracy: 0.9946 - val_loss: 0.1260 - val_accuracy: 0.9643\n",
      "Epoch 21/200\n",
      "21984/21984 [==============================] - 8s 341us/sample - loss: 0.0138 - accuracy: 0.9948 - val_loss: 0.1216 - val_accuracy: 0.9654\n",
      "Epoch 22/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 0.0118 - accuracy: 0.9956 - val_loss: 0.1218 - val_accuracy: 0.9656\n",
      "Epoch 23/200\n",
      "21984/21984 [==============================] - 7s 314us/sample - loss: 0.0101 - accuracy: 0.9962 - val_loss: 0.1282 - val_accuracy: 0.9645\n",
      "Epoch 24/200\n",
      "21984/21984 [==============================] - 7s 330us/sample - loss: 0.0091 - accuracy: 0.9966 - val_loss: 0.1339 - val_accuracy: 0.9644\n",
      "Epoch 25/200\n",
      "21984/21984 [==============================] - 8s 350us/sample - loss: 0.0081 - accuracy: 0.9969 - val_loss: 0.1443 - val_accuracy: 0.9638\n",
      "Epoch 26/200\n",
      "21984/21984 [==============================] - 7s 314us/sample - loss: 0.0072 - accuracy: 0.9973 - val_loss: 0.1453 - val_accuracy: 0.9634\n",
      "Epoch 27/200\n",
      "21984/21984 [==============================] - 7s 314us/sample - loss: 0.0064 - accuracy: 0.9976 - val_loss: 0.1467 - val_accuracy: 0.9635\n",
      "Epoch 28/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.1636 - val_accuracy: 0.9626\n",
      "Epoch 29/200\n",
      "21984/21984 [==============================] - 7s 314us/sample - loss: 0.0053 - accuracy: 0.9981 - val_loss: 0.1744 - val_accuracy: 0.9618\n",
      "Epoch 30/200\n",
      "21984/21984 [==============================] - 8s 341us/sample - loss: 0.0049 - accuracy: 0.9982 - val_loss: 0.1657 - val_accuracy: 0.9623\n",
      "Epoch 31/200\n",
      "21984/21984 [==============================] - 7s 313us/sample - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.1810 - val_accuracy: 0.9618\n",
      "Epoch 32/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 0.0041 - accuracy: 0.9985 - val_loss: 0.1774 - val_accuracy: 0.9619\n",
      "Epoch 33/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 0.0037 - accuracy: 0.9986 - val_loss: 0.1861 - val_accuracy: 0.9614\n",
      "Epoch 34/200\n",
      "21984/21984 [==============================] - 7s 339us/sample - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.1891 - val_accuracy: 0.9613\n",
      "Epoch 35/200\n",
      "21984/21984 [==============================] - 8s 359us/sample - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.1903 - val_accuracy: 0.9612\n",
      "Epoch 36/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.2007 - val_accuracy: 0.9608\n",
      "Epoch 37/200\n",
      "21984/21984 [==============================] - 7s 323us/sample - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.2114 - val_accuracy: 0.9603\n",
      "Epoch 38/200\n",
      "21984/21984 [==============================] - 7s 323us/sample - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.2081 - val_accuracy: 0.9604\n",
      "Epoch 39/200\n",
      "21984/21984 [==============================] - 7s 314us/sample - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.2102 - val_accuracy: 0.9603\n",
      "Epoch 40/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.2110 - val_accuracy: 0.9603\n",
      "Epoch 41/200\n",
      "21984/21984 [==============================] - 7s 314us/sample - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.2140 - val_accuracy: 0.9601\n",
      "Epoch 42/200\n",
      "21984/21984 [==============================] - 7s 326us/sample - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.2159 - val_accuracy: 0.9600\n",
      "Epoch 43/200\n",
      "21984/21984 [==============================] - 7s 314us/sample - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.2178 - val_accuracy: 0.9600\n",
      "Epoch 44/200\n",
      "21984/21984 [==============================] - 7s 330us/sample - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.2151 - val_accuracy: 0.9603\n",
      "Epoch 45/200\n",
      "21984/21984 [==============================] - 8s 346us/sample - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.2261 - val_accuracy: 0.9596\n",
      "Epoch 46/200\n",
      "21984/21984 [==============================] - 7s 318us/sample - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.2315 - val_accuracy: 0.9595\n",
      "Epoch 47/200\n",
      "21984/21984 [==============================] - 7s 313us/sample - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.2289 - val_accuracy: 0.9596\n",
      "Epoch 48/200\n",
      "21984/21984 [==============================] - 7s 330us/sample - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.2262 - val_accuracy: 0.9600\n",
      "Epoch 49/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.2354 - val_accuracy: 0.9597\n",
      "Epoch 50/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.2400 - val_accuracy: 0.9596\n",
      "Epoch 51/200\n",
      "21984/21984 [==============================] - 7s 314us/sample - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.2375 - val_accuracy: 0.9593\n",
      "Epoch 52/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 0.0026 - accuracy: 0.9990 - val_loss: 0.2427 - val_accuracy: 0.9590\n",
      "Epoch 53/200\n",
      "21984/21984 [==============================] - 7s 327us/sample - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.2458 - val_accuracy: 0.9596\n",
      "Epoch 54/200\n",
      "21984/21984 [==============================] - 7s 330us/sample - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.2431 - val_accuracy: 0.9596\n",
      "Epoch 55/200\n",
      "21984/21984 [==============================] - 7s 336us/sample - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.2479 - val_accuracy: 0.9595\n",
      "Epoch 56/200\n",
      "21984/21984 [==============================] - 7s 337us/sample - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.2415 - val_accuracy: 0.9600\n",
      "Epoch 57/200\n",
      "21984/21984 [==============================] - 7s 327us/sample - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.2429 - val_accuracy: 0.9600\n",
      "Epoch 58/200\n",
      "21984/21984 [==============================] - 7s 312us/sample - loss: 0.0030 - accuracy: 0.9989 - val_loss: 0.2486 - val_accuracy: 0.9598\n",
      "Epoch 59/200\n",
      "21984/21984 [==============================] - 7s 325us/sample - loss: 0.0031 - accuracy: 0.9989 - val_loss: 0.2516 - val_accuracy: 0.9606\n",
      "Epoch 60/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 0.0035 - accuracy: 0.9987 - val_loss: 0.2629 - val_accuracy: 0.9595\n",
      "Epoch 61/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.2682 - val_accuracy: 0.9600\n",
      "Epoch 62/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.2565 - val_accuracy: 0.9601\n",
      "Epoch 63/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.2580 - val_accuracy: 0.9601\n",
      "Epoch 64/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.2668 - val_accuracy: 0.9598\n",
      "Epoch 65/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.2622 - val_accuracy: 0.9597\n",
      "Epoch 66/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.2734 - val_accuracy: 0.9593\n",
      "Epoch 67/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.2838 - val_accuracy: 0.9593\n",
      "Epoch 68/200\n",
      "21984/21984 [==============================] - 7s 341us/sample - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.2803 - val_accuracy: 0.9593\n",
      "Epoch 69/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.2885 - val_accuracy: 0.9588\n",
      "Epoch 70/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.2871 - val_accuracy: 0.9590\n",
      "Epoch 71/200\n",
      "21984/21984 [==============================] - 7s 314us/sample - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.2917 - val_accuracy: 0.9590\n",
      "Epoch 72/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.2959 - val_accuracy: 0.9587\n",
      "Epoch 73/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.2924 - val_accuracy: 0.9589\n",
      "Epoch 74/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.2907 - val_accuracy: 0.9589\n",
      "Epoch 75/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 9.5697e-04 - accuracy: 0.9997 - val_loss: 0.3022 - val_accuracy: 0.9587\n",
      "Epoch 76/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 9.2016e-04 - accuracy: 0.9997 - val_loss: 0.3042 - val_accuracy: 0.9587\n",
      "Epoch 77/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 8.6789e-04 - accuracy: 0.9997 - val_loss: 0.3032 - val_accuracy: 0.9586\n",
      "Epoch 78/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 8.3050e-04 - accuracy: 0.9997 - val_loss: 0.3096 - val_accuracy: 0.9585\n",
      "Epoch 79/200\n",
      "21984/21984 [==============================] - 7s 314us/sample - loss: 7.9865e-04 - accuracy: 0.9997 - val_loss: 0.3089 - val_accuracy: 0.9585\n",
      "Epoch 80/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 7.8412e-04 - accuracy: 0.9997 - val_loss: 0.3095 - val_accuracy: 0.9585\n",
      "Epoch 81/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 7.7794e-04 - accuracy: 0.9997 - val_loss: 0.3105 - val_accuracy: 0.9585\n",
      "Epoch 82/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 7.9064e-04 - accuracy: 0.9997 - val_loss: 0.3109 - val_accuracy: 0.9585\n",
      "Epoch 83/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 7.5657e-04 - accuracy: 0.9997 - val_loss: 0.3139 - val_accuracy: 0.9584\n",
      "Epoch 84/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 7.7454e-04 - accuracy: 0.9997 - val_loss: 0.3124 - val_accuracy: 0.9585\n",
      "Epoch 85/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 8.0397e-04 - accuracy: 0.9997 - val_loss: 0.3121 - val_accuracy: 0.9584\n",
      "Epoch 86/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 7.5340e-04 - accuracy: 0.9997 - val_loss: 0.3161 - val_accuracy: 0.9583\n",
      "Epoch 87/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 7.9096e-04 - accuracy: 0.9997 - val_loss: 0.3262 - val_accuracy: 0.9581\n",
      "Epoch 88/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 7.9021e-04 - accuracy: 0.9997 - val_loss: 0.3180 - val_accuracy: 0.9581\n",
      "Epoch 89/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 8.0065e-04 - accuracy: 0.9997 - val_loss: 0.3186 - val_accuracy: 0.9582\n",
      "Epoch 90/200\n",
      "21984/21984 [==============================] - 7s 314us/sample - loss: 8.0186e-04 - accuracy: 0.9997 - val_loss: 0.3202 - val_accuracy: 0.9582\n",
      "Epoch 91/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 8.7912e-04 - accuracy: 0.9997 - val_loss: 0.3327 - val_accuracy: 0.9580\n",
      "Epoch 92/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 9.0754e-04 - accuracy: 0.9997 - val_loss: 0.3303 - val_accuracy: 0.9579\n",
      "Epoch 93/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.3341 - val_accuracy: 0.9582\n",
      "Epoch 94/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 9.7565e-04 - accuracy: 0.9996 - val_loss: 0.3434 - val_accuracy: 0.9576\n",
      "Epoch 95/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 9.9678e-04 - accuracy: 0.9997 - val_loss: 0.3260 - val_accuracy: 0.9580\n",
      "Epoch 96/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 9.8718e-04 - accuracy: 0.9997 - val_loss: 0.3405 - val_accuracy: 0.9579\n",
      "Epoch 97/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.3507 - val_accuracy: 0.9571\n",
      "Epoch 98/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.3391 - val_accuracy: 0.9580\n",
      "Epoch 99/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.3274 - val_accuracy: 0.9583\n",
      "Epoch 100/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.3434 - val_accuracy: 0.9578\n",
      "Epoch 101/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.3367 - val_accuracy: 0.9577\n",
      "Epoch 102/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.3456 - val_accuracy: 0.9576\n",
      "Epoch 103/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 9.2535e-04 - accuracy: 0.9997 - val_loss: 0.3421 - val_accuracy: 0.9578\n",
      "Epoch 104/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 9.5188e-04 - accuracy: 0.9997 - val_loss: 0.3491 - val_accuracy: 0.9577\n",
      "Epoch 105/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 8.4554e-04 - accuracy: 0.9997 - val_loss: 0.3506 - val_accuracy: 0.9577\n",
      "Epoch 106/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 8.3591e-04 - accuracy: 0.9997 - val_loss: 0.3497 - val_accuracy: 0.9579\n",
      "Epoch 107/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21984/21984 [==============================] - 7s 315us/sample - loss: 7.9495e-04 - accuracy: 0.9997 - val_loss: 0.3636 - val_accuracy: 0.9573\n",
      "Epoch 108/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 7.4390e-04 - accuracy: 0.9997 - val_loss: 0.3631 - val_accuracy: 0.9576\n",
      "Epoch 109/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 7.3391e-04 - accuracy: 0.9997 - val_loss: 0.3580 - val_accuracy: 0.9577\n",
      "Epoch 110/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 7.0347e-04 - accuracy: 0.9998 - val_loss: 0.3616 - val_accuracy: 0.9574\n",
      "Epoch 111/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 6.6851e-04 - accuracy: 0.9998 - val_loss: 0.3654 - val_accuracy: 0.9573\n",
      "Epoch 112/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 6.3074e-04 - accuracy: 0.9998 - val_loss: 0.3741 - val_accuracy: 0.9571\n",
      "Epoch 113/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 6.4236e-04 - accuracy: 0.9998 - val_loss: 0.3657 - val_accuracy: 0.9575\n",
      "Epoch 114/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 5.7722e-04 - accuracy: 0.9998 - val_loss: 0.3714 - val_accuracy: 0.9573\n",
      "Epoch 115/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 5.4335e-04 - accuracy: 0.9998 - val_loss: 0.3697 - val_accuracy: 0.9574\n",
      "Epoch 116/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 5.5789e-04 - accuracy: 0.9998 - val_loss: 0.3684 - val_accuracy: 0.9574\n",
      "Epoch 117/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 5.1990e-04 - accuracy: 0.9998 - val_loss: 0.3663 - val_accuracy: 0.9575\n",
      "Epoch 118/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 5.1969e-04 - accuracy: 0.9998 - val_loss: 0.3755 - val_accuracy: 0.9573\n",
      "Epoch 119/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 4.8962e-04 - accuracy: 0.9998 - val_loss: 0.3722 - val_accuracy: 0.9573\n",
      "Epoch 120/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 4.9249e-04 - accuracy: 0.9998 - val_loss: 0.3726 - val_accuracy: 0.9572\n",
      "Epoch 121/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 5.0719e-04 - accuracy: 0.9998 - val_loss: 0.3722 - val_accuracy: 0.9572\n",
      "Epoch 122/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 4.9799e-04 - accuracy: 0.9998 - val_loss: 0.3749 - val_accuracy: 0.9572\n",
      "Epoch 123/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 5.0789e-04 - accuracy: 0.9998 - val_loss: 0.3729 - val_accuracy: 0.9572\n",
      "Epoch 124/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 4.8064e-04 - accuracy: 0.9998 - val_loss: 0.3779 - val_accuracy: 0.9571\n",
      "Epoch 125/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 4.8218e-04 - accuracy: 0.9998 - val_loss: 0.3781 - val_accuracy: 0.9572\n",
      "Epoch 126/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 5.2773e-04 - accuracy: 0.9998 - val_loss: 0.3793 - val_accuracy: 0.9571\n",
      "Epoch 127/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 5.1959e-04 - accuracy: 0.9998 - val_loss: 0.3825 - val_accuracy: 0.9571\n",
      "Epoch 128/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 5.3232e-04 - accuracy: 0.9998 - val_loss: 0.3806 - val_accuracy: 0.9573\n",
      "Epoch 129/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 5.1746e-04 - accuracy: 0.9998 - val_loss: 0.3760 - val_accuracy: 0.9571\n",
      "Epoch 130/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 5.0165e-04 - accuracy: 0.9998 - val_loss: 0.3885 - val_accuracy: 0.9569\n",
      "Epoch 131/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 5.4482e-04 - accuracy: 0.9998 - val_loss: 0.3738 - val_accuracy: 0.9573\n",
      "Epoch 132/200\n",
      "21984/21984 [==============================] - 7s 325us/sample - loss: 5.2094e-04 - accuracy: 0.9998 - val_loss: 0.3830 - val_accuracy: 0.9572\n",
      "Epoch 133/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 5.5938e-04 - accuracy: 0.9998 - val_loss: 0.3852 - val_accuracy: 0.9569\n",
      "Epoch 134/200\n",
      "21984/21984 [==============================] - 7s 315us/sample - loss: 5.6434e-04 - accuracy: 0.9998 - val_loss: 0.3892 - val_accuracy: 0.9569\n",
      "Epoch 135/200\n",
      "21984/21984 [==============================] - 7s 318us/sample - loss: 5.6817e-04 - accuracy: 0.9998 - val_loss: 0.3816 - val_accuracy: 0.9568\n",
      "Epoch 136/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 5.6717e-04 - accuracy: 0.9998 - val_loss: 0.3909 - val_accuracy: 0.9569\n",
      "Epoch 137/200\n",
      "21984/21984 [==============================] - 7s 320us/sample - loss: 5.2564e-04 - accuracy: 0.9998 - val_loss: 0.3892 - val_accuracy: 0.9569\n",
      "Epoch 138/200\n",
      "21984/21984 [==============================] - 7s 323us/sample - loss: 5.4560e-04 - accuracy: 0.9998 - val_loss: 0.3982 - val_accuracy: 0.9568\n",
      "Epoch 139/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 5.7528e-04 - accuracy: 0.9998 - val_loss: 0.3863 - val_accuracy: 0.9570\n",
      "Epoch 140/200\n",
      "21984/21984 [==============================] - 7s 320us/sample - loss: 5.8708e-04 - accuracy: 0.9998 - val_loss: 0.4001 - val_accuracy: 0.9566\n",
      "Epoch 141/200\n",
      "21984/21984 [==============================] - 7s 319us/sample - loss: 6.0466e-04 - accuracy: 0.9998 - val_loss: 0.3937 - val_accuracy: 0.9568\n",
      "Epoch 142/200\n",
      "21984/21984 [==============================] - 7s 319us/sample - loss: 5.6139e-04 - accuracy: 0.9998 - val_loss: 0.3894 - val_accuracy: 0.9569\n",
      "Epoch 143/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 5.4307e-04 - accuracy: 0.9998 - val_loss: 0.4002 - val_accuracy: 0.9568\n",
      "Epoch 144/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 5.4257e-04 - accuracy: 0.9998 - val_loss: 0.4067 - val_accuracy: 0.9566\n",
      "Epoch 145/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 5.2692e-04 - accuracy: 0.9998 - val_loss: 0.4106 - val_accuracy: 0.9564\n",
      "Epoch 146/200\n",
      "21984/21984 [==============================] - 7s 318us/sample - loss: 5.1095e-04 - accuracy: 0.9998 - val_loss: 0.3982 - val_accuracy: 0.9567\n",
      "Epoch 147/200\n",
      "21984/21984 [==============================] - 7s 318us/sample - loss: 5.0675e-04 - accuracy: 0.9998 - val_loss: 0.4039 - val_accuracy: 0.9566\n",
      "Epoch 148/200\n",
      "21984/21984 [==============================] - 7s 319us/sample - loss: 5.0326e-04 - accuracy: 0.9998 - val_loss: 0.4099 - val_accuracy: 0.9566\n",
      "Epoch 149/200\n",
      "21984/21984 [==============================] - 7s 318us/sample - loss: 4.5045e-04 - accuracy: 0.9998 - val_loss: 0.4134 - val_accuracy: 0.9565\n",
      "Epoch 150/200\n",
      "21984/21984 [==============================] - 7s 318us/sample - loss: 4.5318e-04 - accuracy: 0.9999 - val_loss: 0.4050 - val_accuracy: 0.9567\n",
      "Epoch 151/200\n",
      "21984/21984 [==============================] - 7s 318us/sample - loss: 4.4778e-04 - accuracy: 0.9998 - val_loss: 0.4066 - val_accuracy: 0.9568\n",
      "Epoch 152/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 4.4588e-04 - accuracy: 0.9998 - val_loss: 0.4049 - val_accuracy: 0.9568\n",
      "Epoch 153/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 4.6778e-04 - accuracy: 0.9998 - val_loss: 0.4124 - val_accuracy: 0.9567\n",
      "Epoch 154/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 4.0727e-04 - accuracy: 0.9999 - val_loss: 0.4085 - val_accuracy: 0.9567\n",
      "Epoch 155/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 4.1199e-04 - accuracy: 0.9999 - val_loss: 0.4071 - val_accuracy: 0.9567\n",
      "Epoch 156/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 4.2387e-04 - accuracy: 0.9999 - val_loss: 0.4119 - val_accuracy: 0.9566\n",
      "Epoch 157/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 3.8991e-04 - accuracy: 0.9999 - val_loss: 0.4074 - val_accuracy: 0.9567\n",
      "Epoch 158/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 4.0508e-04 - accuracy: 0.9998 - val_loss: 0.4106 - val_accuracy: 0.9567\n",
      "Epoch 159/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 3.9872e-04 - accuracy: 0.9998 - val_loss: 0.4113 - val_accuracy: 0.9566\n",
      "Epoch 160/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 4.2414e-04 - accuracy: 0.9998 - val_loss: 0.4107 - val_accuracy: 0.9566\n",
      "Epoch 161/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 3.7118e-04 - accuracy: 0.9999 - val_loss: 0.4122 - val_accuracy: 0.9566\n",
      "Epoch 162/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 4.0039e-04 - accuracy: 0.9999 - val_loss: 0.4109 - val_accuracy: 0.9566\n",
      "Epoch 163/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 3.8632e-04 - accuracy: 0.9999 - val_loss: 0.4134 - val_accuracy: 0.9565\n",
      "Epoch 164/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 3.7739e-04 - accuracy: 0.9999 - val_loss: 0.4133 - val_accuracy: 0.9565\n",
      "Epoch 165/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 3.7665e-04 - accuracy: 0.9999 - val_loss: 0.4130 - val_accuracy: 0.9566\n",
      "Epoch 166/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 3.9068e-04 - accuracy: 0.9999 - val_loss: 0.4188 - val_accuracy: 0.9564\n",
      "Epoch 167/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 3.5956e-04 - accuracy: 0.9999 - val_loss: 0.4107 - val_accuracy: 0.9567\n",
      "Epoch 168/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 3.8508e-04 - accuracy: 0.9999 - val_loss: 0.4169 - val_accuracy: 0.9565\n",
      "Epoch 169/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 3.9113e-04 - accuracy: 0.9999 - val_loss: 0.4225 - val_accuracy: 0.9563\n",
      "Epoch 170/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 3.9701e-04 - accuracy: 0.9999 - val_loss: 0.4180 - val_accuracy: 0.9565\n",
      "Epoch 171/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 4.4745e-04 - accuracy: 0.9998 - val_loss: 0.4120 - val_accuracy: 0.9566\n",
      "Epoch 172/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 4.1413e-04 - accuracy: 0.9998 - val_loss: 0.4160 - val_accuracy: 0.9565\n",
      "Epoch 173/200\n",
      "21984/21984 [==============================] - 7s 317us/sample - loss: 4.2778e-04 - accuracy: 0.9998 - val_loss: 0.4172 - val_accuracy: 0.9566\n",
      "Epoch 174/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 3.9011e-04 - accuracy: 0.9999 - val_loss: 0.4221 - val_accuracy: 0.9563\n",
      "Epoch 175/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 4.2010e-04 - accuracy: 0.9998 - val_loss: 0.4246 - val_accuracy: 0.9562\n",
      "Epoch 176/200\n",
      "21984/21984 [==============================] - 7s 327us/sample - loss: 3.9704e-04 - accuracy: 0.9999 - val_loss: 0.4088 - val_accuracy: 0.9566\n",
      "Epoch 177/200\n",
      "21984/21984 [==============================] - 7s 316us/sample - loss: 4.1972e-04 - accuracy: 0.9999 - val_loss: 0.4206 - val_accuracy: 0.9564\n",
      "Epoch 178/200\n",
      "21984/21984 [==============================] - 7s 337us/sample - loss: 4.2425e-04 - accuracy: 0.9998 - val_loss: 0.4133 - val_accuracy: 0.9566\n",
      "Epoch 179/200\n",
      "21984/21984 [==============================] - 8s 346us/sample - loss: 3.9502e-04 - accuracy: 0.9999 - val_loss: 0.4308 - val_accuracy: 0.9562\n",
      "Epoch 180/200\n",
      "21984/21984 [==============================] - 7s 327us/sample - loss: 4.0276e-04 - accuracy: 0.9999 - val_loss: 0.4181 - val_accuracy: 0.9564\n",
      "Epoch 181/200\n",
      "21984/21984 [==============================] - 7s 337us/sample - loss: 4.0385e-04 - accuracy: 0.9999 - val_loss: 0.4160 - val_accuracy: 0.9565\n",
      "Epoch 182/200\n",
      "21984/21984 [==============================] - 7s 324us/sample - loss: 3.8948e-04 - accuracy: 0.9999 - val_loss: 0.4224 - val_accuracy: 0.9564\n",
      "Epoch 183/200\n",
      "21984/21984 [==============================] - 7s 322us/sample - loss: 3.9644e-04 - accuracy: 0.9999 - val_loss: 0.4310 - val_accuracy: 0.9562\n",
      "Epoch 184/200\n",
      "21984/21984 [==============================] - 7s 333us/sample - loss: 4.0477e-04 - accuracy: 0.9998 - val_loss: 0.4111 - val_accuracy: 0.9567\n",
      "Epoch 185/200\n",
      "21984/21984 [==============================] - 7s 319us/sample - loss: 3.7759e-04 - accuracy: 0.9999 - val_loss: 0.4251 - val_accuracy: 0.9564\n",
      "Epoch 186/200\n",
      "21984/21984 [==============================] - 7s 327us/sample - loss: 4.0320e-04 - accuracy: 0.9999 - val_loss: 0.4296 - val_accuracy: 0.9564\n",
      "Epoch 187/200\n",
      "21984/21984 [==============================] - 7s 318us/sample - loss: 3.8265e-04 - accuracy: 0.9999 - val_loss: 0.4265 - val_accuracy: 0.9563\n",
      "Epoch 188/200\n",
      "21984/21984 [==============================] - 7s 324us/sample - loss: 3.8395e-04 - accuracy: 0.9999 - val_loss: 0.4287 - val_accuracy: 0.9563\n",
      "Epoch 189/200\n",
      "21984/21984 [==============================] - 7s 318us/sample - loss: 3.6438e-04 - accuracy: 0.9999 - val_loss: 0.4242 - val_accuracy: 0.9563\n",
      "Epoch 190/200\n",
      "21984/21984 [==============================] - 7s 321us/sample - loss: 3.6525e-04 - accuracy: 0.9999 - val_loss: 0.4331 - val_accuracy: 0.9562\n",
      "Epoch 191/200\n",
      "21984/21984 [==============================] - 7s 331us/sample - loss: 3.6275e-04 - accuracy: 0.9999 - val_loss: 0.4368 - val_accuracy: 0.9563\n",
      "Epoch 192/200\n",
      "21984/21984 [==============================] - 7s 331us/sample - loss: 3.5840e-04 - accuracy: 0.9999 - val_loss: 0.4333 - val_accuracy: 0.9563\n",
      "Epoch 193/200\n",
      "21984/21984 [==============================] - 7s 321us/sample - loss: 3.6877e-04 - accuracy: 0.9999 - val_loss: 0.4234 - val_accuracy: 0.9564\n",
      "Epoch 194/200\n",
      "21984/21984 [==============================] - 7s 314us/sample - loss: 3.2594e-04 - accuracy: 0.9999 - val_loss: 0.4337 - val_accuracy: 0.9561\n",
      "Epoch 195/200\n",
      "21984/21984 [==============================] - 7s 325us/sample - loss: 3.4118e-04 - accuracy: 0.9999 - val_loss: 0.4353 - val_accuracy: 0.9562\n",
      "Epoch 196/200\n",
      "21984/21984 [==============================] - 7s 336us/sample - loss: 3.5367e-04 - accuracy: 0.9999 - val_loss: 0.4326 - val_accuracy: 0.9563\n",
      "Epoch 197/200\n",
      "21984/21984 [==============================] - 7s 319us/sample - loss: 3.2412e-04 - accuracy: 0.9999 - val_loss: 0.4361 - val_accuracy: 0.9561\n",
      "Epoch 198/200\n",
      "21984/21984 [==============================] - 7s 320us/sample - loss: 3.1376e-04 - accuracy: 0.9999 - val_loss: 0.4329 - val_accuracy: 0.9563\n",
      "Epoch 199/200\n",
      "21984/21984 [==============================] - 7s 326us/sample - loss: 3.1938e-04 - accuracy: 0.9999 - val_loss: 0.4334 - val_accuracy: 0.9562\n",
      "Epoch 200/200\n",
      "21984/21984 [==============================] - 7s 322us/sample - loss: 3.2163e-04 - accuracy: 0.9999 - val_loss: 0.4333 - val_accuracy: 0.9562\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[X_sentiments_train, X_train],\n",
    "                    y=Y2_train,\n",
    "                    shuffle=True,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    validation_data=([X_sentiments_val, X_val], Y2_val),\n",
    "                    verbose=1,\n",
    "                    callbacks=[clr, mcp]) #es, rlrop, tb, mcp, \n",
    "\n",
    "#history = model.fit(x=[X_sentiments_train, X_train],\n",
    "#                    y=Y_train,\n",
    "#                    shuffle=True,\n",
    "#                    batch_size=BATCH_SIZE,\n",
    "#                    epochs=NUM_EPOCHS,\n",
    "#                    validation_data=([X_sentiments_val, X_val], Y_val),\n",
    "#                    verbose=1,\n",
    "#                    callbacks=[clr, mcp]) #es, rlrop, tb, mcp, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric_names = ['loss' ,'accuracy']\n",
    "\n",
    "for i, j in zip(metric_names, ['val_'+i for i in metric_names]):\n",
    "    plt.plot(history.history[i])\n",
    "    plt.plot(history.history[j])\n",
    "    plt.title('Model '+i)\n",
    "    plt.ylabel(i.upper())\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = tf.keras.models.load_model(\n",
    "    filepath=\"../results/\"+MODEL_PREFIX+\"Checkpoint.h5\",\n",
    "    compile=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(x = [X_sentiments_train, X_train], batch_size=PREDICT_BATCH_SIZE)\n",
    "pred_val = model.predict(x = [X_sentiments_val, X_val], batch_size=PREDICT_BATCH_SIZE)\n",
    "pred_test = model.predict(x = [X_sentiments_test, X_test], batch_size=PREDICT_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21984, 102), (21984, 102), (21984, 102))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, pred_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_words = [i[j>0.5].tolist() for i,j in zip(X_train, pred_train)]\n",
    "pred_val_words = [i[j>0.5].tolist() for i,j in zip(X_val, pred_val)]\n",
    "pred_test_words = [i[j>0.5].tolist() for i,j in zip(X_test, pred_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_words = Tkn.sequences_to_texts(pred_train_words)\n",
    "pred_val_words = Tkn.sequences_to_texts(pred_val_words)\n",
    "pred_test_words = Tkn.sequences_to_texts(pred_test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(str1, str2):\n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21985, (21985,), (21984, 102))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_idx), keep_x_train.shape, pred_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame({\n",
    "    \"pred_selected_text\" : pred_train_words + pred_val_words,\n",
    "    \"original_index\" : np.concatenate((np.array(train_idx, dtype=np.int64)[keep_x_train],\n",
    "                                       np.array(val_idx, dtype=np.int64)[keep_x_val])),\n",
    "    \"set\" : [\"train\" for i in range(sum(keep_x_train))] + [\"val\" for i in range(sum(keep_x_val))]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (predictions.original_index.min(), predictions.original_index.max()) == (df.original_index.min(), df.original_index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27481, 6) (27479, 3)\n",
      "(27481, 6) (27479, 3) (27479, 8)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape, predictions.shape)\n",
    "results = pd.merge(df, predictions, on = \"original_index\", how=\"inner\")\n",
    "print(df.shape, predictions.shape, results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>original_index</th>\n",
       "      <th>sentiment_code</th>\n",
       "      <th>pred_selected_text</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc2cbefa9d</td>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n",
       "      <td>Wow... u just became cooler.</td>\n",
       "      <td>positive</td>\n",
       "      <td>9</td>\n",
       "      <td>positive</td>\n",
       "      <td>wow</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>919fa93391</td>\n",
       "      <td>i`ve been sick for the past few days  and thus...</td>\n",
       "      <td>sick</td>\n",
       "      <td>negative</td>\n",
       "      <td>17</td>\n",
       "      <td>negative</td>\n",
       "      <td>i ve</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bdc32ea43c</td>\n",
       "      <td>On the way to Malaysia...no internet access to...</td>\n",
       "      <td>.no internet</td>\n",
       "      <td>negative</td>\n",
       "      <td>27</td>\n",
       "      <td>negative</td>\n",
       "      <td>the no access to</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6ce4a4954b</td>\n",
       "      <td>juss came backk from Berkeleyy ; omg its madd ...</td>\n",
       "      <td>fun</td>\n",
       "      <td>positive</td>\n",
       "      <td>28</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2863f435bd</td>\n",
       "      <td>A little happy for the wine jeje ok it`sm my f...</td>\n",
       "      <td>A little happy fo</td>\n",
       "      <td>positive</td>\n",
       "      <td>39</td>\n",
       "      <td>positive</td>\n",
       "      <td>i love this day</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>d93afa85cf</td>\n",
       "      <td>Car not happy, big big dent in boot! Hoping t...</td>\n",
       "      <td>Car not happy, big big dent in boot! Hoping th...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>40</td>\n",
       "      <td>neutral</td>\n",
       "      <td>car not happy big big dent in boot hoping they...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>c77717b103</td>\n",
       "      <td>I love to! But I`m only available from 5pm.  ...</td>\n",
       "      <td>I love to!</td>\n",
       "      <td>positive</td>\n",
       "      <td>44</td>\n",
       "      <td>positive</td>\n",
       "      <td>help her</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>a9d499e123</td>\n",
       "      <td>The girl in the hair salon asked me 'Shall I t...</td>\n",
       "      <td>The girl in the hair salon asked me 'Shall I t...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>45</td>\n",
       "      <td>neutral</td>\n",
       "      <td>the girl in the hair salon asked me 'shall i t...</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>52483f7da8</td>\n",
       "      <td>i lost all my friends, i`m alone and sleepy..i...</td>\n",
       "      <td>i lost all my friends, i`m alone and sleepy..</td>\n",
       "      <td>negative</td>\n",
       "      <td>60</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>90a2cdb657</td>\n",
       "      <td>What better way to spoil mum than to let her k...</td>\n",
       "      <td>favorite</td>\n",
       "      <td>positive</td>\n",
       "      <td>63</td>\n",
       "      <td>positive</td>\n",
       "      <td>than let her kick bottle of a</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        textID                                               text  \\\n",
       "9   fc2cbefa9d   Journey!? Wow... u just became cooler.  hehe....   \n",
       "17  919fa93391  i`ve been sick for the past few days  and thus...   \n",
       "27  bdc32ea43c  On the way to Malaysia...no internet access to...   \n",
       "28  6ce4a4954b  juss came backk from Berkeleyy ; omg its madd ...   \n",
       "39  2863f435bd  A little happy for the wine jeje ok it`sm my f...   \n",
       "40  d93afa85cf   Car not happy, big big dent in boot! Hoping t...   \n",
       "44  c77717b103   I love to! But I`m only available from 5pm.  ...   \n",
       "45  a9d499e123  The girl in the hair salon asked me 'Shall I t...   \n",
       "60  52483f7da8  i lost all my friends, i`m alone and sleepy..i...   \n",
       "63  90a2cdb657  What better way to spoil mum than to let her k...   \n",
       "\n",
       "                                        selected_text sentiment  \\\n",
       "9                        Wow... u just became cooler.  positive   \n",
       "17                                               sick  negative   \n",
       "27                                       .no internet  negative   \n",
       "28                                                fun  positive   \n",
       "39                                  A little happy fo  positive   \n",
       "40  Car not happy, big big dent in boot! Hoping th...   neutral   \n",
       "44                                         I love to!  positive   \n",
       "45  The girl in the hair salon asked me 'Shall I t...   neutral   \n",
       "60      i lost all my friends, i`m alone and sleepy..  negative   \n",
       "63                                           favorite  positive   \n",
       "\n",
       "    original_index sentiment_code  \\\n",
       "9                9       positive   \n",
       "17              17       negative   \n",
       "27              27       negative   \n",
       "28              28       positive   \n",
       "39              39       positive   \n",
       "40              40        neutral   \n",
       "44              44       positive   \n",
       "45              45        neutral   \n",
       "60              60       negative   \n",
       "63              63       positive   \n",
       "\n",
       "                                   pred_selected_text  set  \n",
       "9                                                 wow  val  \n",
       "17                                               i ve  val  \n",
       "27                                   the no access to  val  \n",
       "28                                                     val  \n",
       "39                                    i love this day  val  \n",
       "40  car not happy big big dent in boot hoping they...  val  \n",
       "44                                           help her  val  \n",
       "45  the girl in the hair salon asked me 'shall i t...  val  \n",
       "60                                                     val  \n",
       "63                      than let her kick bottle of a  val  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[results.set==\"val\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>original_index</th>\n",
       "      <th>sentiment_code</th>\n",
       "      <th>pred_selected_text</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>i d have responded if i were going</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>sad</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>is bullying</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>what interview leave me</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28b57f3990</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>5</td>\n",
       "      <td>neutral</td>\n",
       "      <td>http www dothebouncy com smf some shameless pl...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6e0c6d75b1</td>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>fun</td>\n",
       "      <td>positive</td>\n",
       "      <td>6</td>\n",
       "      <td>positive</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50e14c0bb8</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "      <td>7</td>\n",
       "      <td>neutral</td>\n",
       "      <td>soooo high</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e050245fbd</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "      <td>8</td>\n",
       "      <td>neutral</td>\n",
       "      <td>both of you</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2339a9b08b</td>\n",
       "      <td>as much as i love to be hopeful, i reckon the...</td>\n",
       "      <td>as much as i love to be hopeful, i reckon the ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>10</td>\n",
       "      <td>neutral</td>\n",
       "      <td>as much as i love to be hopeful i reckon the c...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        textID                                               text  \\\n",
       "0   cb774db0d1                I`d have responded, if I were going   \n",
       "1   549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2   088c60f138                          my boss is bullying me...   \n",
       "3   9642c003ef                     what interview! leave me alone   \n",
       "4   358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "5   28b57f3990  http://www.dothebouncy.com/smf - some shameles...   \n",
       "6   6e0c6d75b1  2am feedings for the baby are fun when he is a...   \n",
       "7   50e14c0bb8                                         Soooo high   \n",
       "8   e050245fbd                                        Both of you   \n",
       "10  2339a9b08b   as much as i love to be hopeful, i reckon the...   \n",
       "\n",
       "                                        selected_text sentiment  \\\n",
       "0                 I`d have responded, if I were going   neutral   \n",
       "1                                            Sooo SAD  negative   \n",
       "2                                         bullying me  negative   \n",
       "3                                      leave me alone  negative   \n",
       "4                                       Sons of ****,  negative   \n",
       "5   http://www.dothebouncy.com/smf - some shameles...   neutral   \n",
       "6                                                 fun  positive   \n",
       "7                                          Soooo high   neutral   \n",
       "8                                         Both of you   neutral   \n",
       "10  as much as i love to be hopeful, i reckon the ...   neutral   \n",
       "\n",
       "    original_index sentiment_code  \\\n",
       "0                0        neutral   \n",
       "1                1       negative   \n",
       "2                2       negative   \n",
       "3                3       negative   \n",
       "4                4       negative   \n",
       "5                5        neutral   \n",
       "6                6       positive   \n",
       "7                7        neutral   \n",
       "8                8        neutral   \n",
       "10              10        neutral   \n",
       "\n",
       "                                   pred_selected_text    set  \n",
       "0                  i d have responded if i were going  train  \n",
       "1                                                 sad  train  \n",
       "2                                         is bullying  train  \n",
       "3                             what interview leave me  train  \n",
       "4                                                      train  \n",
       "5   http www dothebouncy com smf some shameless pl...  train  \n",
       "6                                                      train  \n",
       "7                                          soooo high  train  \n",
       "8                                         both of you  train  \n",
       "10  as much as i love to be hopeful i reckon the c...  train  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.loc[results.set==\"train\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_train = confusion_matrix(Y_train.argmax(axis=1).reshape(-1), pred_train.reshape(-1))\n",
    "conf_mat_val = confusion_matrix(Y_val.argmax(axis=1).reshape(-1), pred_val.reshape(-1))\n",
    "print(\"The train accuracy is\\t\",np.round(100 * np.sum(np.diag(conf_mat_train)) / np.sum(conf_mat_train),2))\n",
    "print(\"The valid accuracy is\\t\",np.round(100 * np.sum(np.diag(conf_mat_val)) / np.sum(conf_mat_val),2))\n",
    "\n",
    "np.savetxt(X=conf_mat_train, fname=\"../results/ConfMatrix_train_\" + MODEL_PREFIX + \".txt\")\n",
    "np.savetxt(X=conf_mat_val, fname=\"../results/ConfMatrix_val_\" + MODEL_PREFIX + \".txt\")\n",
    "\n",
    "f1_train = f1_score(Y_train.argmax(axis=1).reshape(-1), pred_train.reshape(-1), average='macro')\n",
    "f1_val = f1_score(Y_val.argmax(axis=1).reshape(-1), pred_val.reshape(-1), average='macro')\n",
    "print(\"The train macro f1score is\\t\",np.round(f1_train,2))\n",
    "print(\"The valid macro f1score is\\t\",np.round(f1_val,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'time':test_df['time'],'open_channels':pred_test.reshape(-1)})\n",
    "submission.to_csv(\"../results/submission_20200412V\"+MODEL_NUMBER+\".csv\", index=False, float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "best_model = tf.keras.models.load_model(\n",
    "    filepath=\"../results/\"+MODEL_PREFIX+\"Checkpoint.h5\",\n",
    "    compile=True,\n",
    "    custom_objects = {'macro_soft_f1':macro_soft_f1, 'macro_f1':macro_f1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = best_model.predict(x = X_train, batch_size=PREDICT_BATCH_SIZE)\n",
    "pred_val = best_model.predict(x = X_val, batch_size=PREDICT_BATCH_SIZE)\n",
    "pred_test = best_model.predict(x = X_test, batch_size=PREDICT_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = pred_train.argmax(axis=1)\n",
    "pred_val = pred_val.argmax(axis=1)\n",
    "pred_test = pred_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_train = confusion_matrix(Y_train.argmax(axis=1).reshape(-1), pred_train.reshape(-1))\n",
    "conf_mat_val = confusion_matrix(Y_val.argmax(axis=1).reshape(-1), pred_val.reshape(-1))\n",
    "\n",
    "print(\"The train accuracy is\\t\",np.round(100 * np.sum(np.diag(conf_mat_train)) / np.sum(conf_mat_train),2))\n",
    "print(\"The valid accuracy is\\t\",np.round(100 * np.sum(np.diag(conf_mat_val)) / np.sum(conf_mat_val),2))\n",
    "\n",
    "np.savetxt(X=conf_mat_train, fname=\"../results/BestConfMatrix_train_\" + MODEL_PREFIX + \".txt\")\n",
    "np.savetxt(X=conf_mat_val, fname=\"../results/BestConfMatrix_val_\" + MODEL_PREFIX + \".txt\")\n",
    "\n",
    "f1_train = f1_score(Y_train.argmax(axis=1).reshape(-1), pred_train.reshape(-1), average='macro')\n",
    "f1_val = f1_score(Y_train.argmax(axis=1).reshape(-1), pred_train.reshape(-1), average='macro')\n",
    "print(\"The train macro f1score is\\t\",np.round(f1_train,2))\n",
    "print(\"The valid macro f1score is\\t\",np.round(f1_val,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'time':test_df['time'],'open_channels':pred_test.reshape(-1)})\n",
    "submission.to_csv(\"../results/best_submission_20200412V\"+MODEL_NUMBER+\".csv\", index=False, float_format='%.4f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
